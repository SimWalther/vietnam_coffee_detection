{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lonely-extreme",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/tb/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import Sequential, activations, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Activation, SpatialDropout2D, GlobalAveragePooling2D,\n",
    "    Dense, Dropout, Flatten,\n",
    "    Conv2D, MaxPooling2D, SeparableConv2D\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from albumentations import Compose\n",
    "\n",
    "# Import project utils scripts\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join('../src/')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from visualizationUtils import plot_confusion_matrix\n",
    "from statisticsUtils import recall_precision_fscore_from_confusion_matrix\n",
    "from lossesUtils import categorical_focal_loss\n",
    "from bandUtils import Band \n",
    "from labelsUtils import (\n",
    "    Label,\n",
    "    LabelCategory,\n",
    "    category_from_label,\n",
    "    categories_from_label_set\n",
    ")\n",
    "\n",
    "from rasterUtils import make_dataset_from_raster_files\n",
    "from regionUtils import (\n",
    "    vietnam_labels_coordinates,\n",
    ")\n",
    "from convNetUtils import (\n",
    "    images_from_dataset,\n",
    "    labels_from_dataset,\n",
    "    cross_validation,\n",
    "    AUGMENTATIONS,\n",
    "    ImageMultiOutputSequence,\n",
    "    train_model,\n",
    "    evaluate_multi_output_model,\n",
    ")\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "characteristic-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_PIXEL_AROUND = 4\n",
    "EPOCHS = 2000\n",
    "NB_TESTS = 4\n",
    "\n",
    "labels = [\n",
    "    Label.COFFEE,\n",
    "    Label.DENSE_FOREST,\n",
    "    Label.RUBBER,\n",
    "    Label.SEASONAL_AGRICULTURE,\n",
    "    Label.URBAN,\n",
    "    Label.WATER,\n",
    "    Label.OTHER_TREE,\n",
    "    Label.NATIVE_NO_TREE,\n",
    "    Label.PEPPER,\n",
    "    Label.TEA,\n",
    "    Label.RICE,     \n",
    "    Label.DECIDUOUS_FOREST,\n",
    "    Label.PINE_TREES,     \n",
    "    Label.SHRUBLAND_BUSHLAND,     \n",
    "    Label.SPARE_TREE,     \n",
    "    Label.GRASSLAND,     \n",
    "    Label.SECONDARY_DEGRADED_FOREST,     \n",
    "    Label.MINE_BARESOIL,\n",
    "]\n",
    "\n",
    "labels_names = [label.name for label in labels]\n",
    "categories = pd.unique([category_from_label(label) for label in labels])\n",
    "\n",
    "bands = [\n",
    "    Band.COASTAL_AEROSOL.value, \n",
    "    Band.BLUE.value, \n",
    "    Band.GREEN.value, \n",
    "    Band.RED.value, \n",
    "    Band.NIR.value, \n",
    "    Band.SWIR1.value, \n",
    "    Band.SWIR2.value, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reasonable-sight",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_coordinates = vietnam_labels_coordinates()\n",
    "\n",
    "dataset_args = dict(\n",
    "    labels = labels,\n",
    "    raster_paths = [os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_whole_year_collection2/merged.tif')],\n",
    "    labels_coordinates_list = [labels_coordinates],\n",
    "    nb_pixel_around = NB_PIXEL_AROUND\n",
    ")\n",
    "\n",
    "dataset = make_dataset_from_raster_files(**dataset_args)\n",
    "\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entertaining-evans",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 9, 9, 7)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_4 (Rescaling)         (None, 9, 9, 7)      0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 9, 9, 7)      28          rescaling_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 9, 9, 16)     464         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 9, 9, 16)     64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 9, 9, 16)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 9, 9, 16)     1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 16)     64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 9, 9, 16)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 9, 9, 16)     1040        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 16)     64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 9, 9, 16)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 9, 9, 16)     1040        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 9, 16)     64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 9, 9, 16)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "last_pretrained_layer (Flatten) (None, 1296)         0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          166016      last_pretrained_layer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "label (Dense)                   (None, 18)           2322        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "category (Dense)                (None, 6)            774         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 189,492\n",
      "Trainable params: 189,350\n",
      "Non-trainable params: 142\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"final_model\"\n",
    "\n",
    "model = load_model(\n",
    "    os.path.join(MODEL_ROOT_PATH, 'multi_output_pretrained_with_reptile_v4.hdf5'),\n",
    "    custom_objects={\n",
    "        'categorical_focal_loss_fixed': categorical_focal_loss\n",
    "    }\n",
    ")\n",
    "\n",
    "layers = model.layers\n",
    "\n",
    "# Add trainable layers before output layers\n",
    "layers = Dense(128, activation='relu')(model.get_layer('last_pretrained_layer').output)\n",
    "layers = Dense(128, activation='relu')(layers)\n",
    "layers = Dropout(0.25)(layers)\n",
    "\n",
    "# Define output layers\n",
    "label_output = Dense(len(labels), activation='softmax', name=\"label\")(layers)\n",
    "category_output = Dense(len(categories), activation='softmax', name=\"category\")(layers)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=model.input, outputs=[label_output, category_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss={\n",
    "    'label': categorical_focal_loss([[.25] * len(labels)]),\n",
    "    'category': categorical_focal_loss([[.25] * len(categories)])\n",
    "}, metrics={\n",
    "    'label': 'accuracy',\n",
    "    'category': 'accuracy'\n",
    "})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monetary-asthma",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 9, 9, 7)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_4 (Rescaling)         (None, 9, 9, 7)      0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 9, 9, 7)      28          rescaling_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 9, 9, 16)     464         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 9, 9, 16)     64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 9, 9, 16)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 9, 9, 16)     1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 16)     64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 9, 9, 16)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 9, 9, 16)     1040        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 16)     64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 9, 9, 16)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 9, 9, 16)     1040        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 9, 16)     64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 9, 9, 16)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "last_pretrained_layer (Flatten) (None, 1296)         0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          166016      last_pretrained_layer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "label (Dense)                   (None, 18)           2322        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "category (Dense)                (None, 6)            774         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 189,492\n",
      "Trainable params: 189,350\n",
      "Non-trainable params: 142\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Validation 1, fold 1 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "352/352 [==============================] - 2s 4ms/step - loss: 0.3959 - label_loss: 0.2977 - category_loss: 0.0982 - label_accuracy: 0.4753 - category_accuracy: 0.7648 - val_loss: 0.8147 - val_label_loss: 0.5990 - val_category_loss: 0.2157 - val_label_accuracy: 0.2558 - val_category_accuracy: 0.6758\n",
      "len(train_images): 11274, len(train_classes['label']): 11274, len(train_classes['category']): 11274\n",
      "len(target_train[0]):  11274\n",
      "len(predicted_train[0]):  11274\n",
      "len(target_train[0]):  11274\n",
      "len(predicted_train[0]):  11274\n",
      "Epoch 2/2000\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 0.2882 - label_loss: 0.2203 - category_loss: 0.0678 - label_accuracy: 0.5756 - category_accuracy: 0.8179 - val_loss: 0.2583 - val_label_loss: 0.1994 - val_category_loss: 0.0589 - val_label_accuracy: 0.6038 - val_category_accuracy: 0.8365\n",
      "len(train_images): 11274, len(train_classes['label']): 11274, len(train_classes['category']): 11274\n",
      "len(target_train[0]):  11274\n",
      "len(predicted_train[0]):  11274\n",
      "len(target_train[0]):  11274\n",
      "len(predicted_train[0]):  11274\n",
      "Epoch 3/2000\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 0.2569 - label_loss: 0.1976 - category_loss: 0.0593 - label_accuracy: 0.6059 - category_accuracy: 0.8323 - val_loss: 0.2213 - val_label_loss: 0.1717 - val_category_loss: 0.0495 - val_label_accuracy: 0.6321 - val_category_accuracy: 0.8404\n",
      "len(train_images): 11274, len(train_classes['label']): 11274, len(train_classes['category']): 11274\n",
      "len(target_train[0]):  11274\n",
      "len(predicted_train[0]):  11274\n",
      "len(target_train[0]):  11274\n",
      "len(predicted_train[0]):  11274\n",
      "Epoch 4/2000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2397 - label_loss: 0.1847 - category_loss: 0.0551 - label_accuracy: 0.6186 - category_accuracy: 0.8416"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-622f066a83e4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmean_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmean_accuracy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhistories\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconf_matrix\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcross_validation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbands\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNB_TESTS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mearly_stopping\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwith_model_checkpoint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcategories\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcategories\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/HEIG/TB/scripts/notebooks/../src/convNetUtils.py\u001B[0m in \u001B[0;36mcross_validation\u001B[0;34m(model, dataset, bands, labels, epochs, nb_cross_validations, k, early_stopping, with_model_checkpoint, model_name, categories)\u001B[0m\n\u001B[1;32m    414\u001B[0m                 \u001B[0mcurrent_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'categorical_crossentropy'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'adam'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'accuracy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    415\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 416\u001B[0;31m             history, trained_model = train_model(\n\u001B[0m\u001B[1;32m    417\u001B[0m                 \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcurrent_model\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    418\u001B[0m                 \u001B[0mtrain_datagen\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_datagen\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/HEIG/TB/scripts/notebooks/../src/convNetUtils.py\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(model, train_datagen, validation_datagen, class_weights, epochs, steps_per_epoch, early_stopping, model_checkpoint_cb, categories)\u001B[0m\n\u001B[1;32m    265\u001B[0m     )\n\u001B[1;32m    266\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 267\u001B[0;31m     \u001B[0mhistory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mfit_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    268\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mhistory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1212\u001B[0m                 \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1213\u001B[0m                 steps_per_execution=self._steps_per_execution)\n\u001B[0;32m-> 1214\u001B[0;31m           val_logs = self.evaluate(\n\u001B[0m\u001B[1;32m   1215\u001B[0m               \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mval_x\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1216\u001B[0m               \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mval_y\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   1487\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1488\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1489\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1490\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1491\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    922\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    923\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 924\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    925\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    926\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3021\u001B[0m       (graph_function,\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3023\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3024\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1958\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1960\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1961\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    590\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 591\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    592\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    593\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "mean_loss, mean_accuracy, histories, conf_matrix = cross_validation(model, dataset, bands, labels, EPOCHS, NB_TESTS, early_stopping=True, with_model_checkpoint=True, model_name=model_name, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-chrome",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf_matrices, accuracy, loss = evaluate_multi_output_model(trained_model, X_test, Y_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-ballot",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(12, 10), dpi=80)\n",
    "\n",
    "plot_confusion_matrix(conf_matrices[0], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-species",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recall, precision, fscore = recall_precision_fscore_from_confusion_matrix(conf_matrices[0])\n",
    "\n",
    "print(\"Precisions: \", precision)\n",
    "print(\"Mean precision: \", np.mean(precision))\n",
    "print(\"\\nRecalls: \", recall)\n",
    "print(\"Mean recall: \", np.mean(recall))\n",
    "print(\"\\nF-Score: \", fscore)\n",
    "print(\"Mean f-score: \", np.mean(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-worcester",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "plot_confusion_matrix(conf_matrices[1], [category.name for category in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-invite",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recall, precision, fscore = recall_precision_fscore_from_confusion_matrix(conf_matrices[1])\n",
    "\n",
    "print(\"Precisions: \", precision)\n",
    "print(\"Mean precision: \", np.mean(precision))\n",
    "print(\"\\nRecalls: \", recall)\n",
    "print(\"Mean recall: \", np.mean(recall))\n",
    "print(\"\\nF-Score: \", fscore)\n",
    "print(\"Mean f-score: \", np.mean(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-arkansas",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figure, axis = pl.subplots(1, 3, figsize=(12,4))\n",
    "axis[0].plot(history.history['loss'], label='Loss', color=\"blue\")\n",
    "axis[0].legend()\n",
    "axis[1].plot(history.history['label_accuracy'], label='Label accuracy', color=\"blue\")\n",
    "axis[1].set_ylim([0,1])\n",
    "axis[1].legend()\n",
    "axis[2].plot(history.history['category_accuracy'], label='Category accuracy', color=\"blue\")\n",
    "axis[2].set_ylim([0,1])\n",
    "axis[2].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "EPOCHS = 500\n",
     "\n",
     "labels = [\n",
     "    Label.COFFEE,\n",
     "    Label.DENSE_FOREST,\n",
     "    Label.RUBBER,\n",
     "    Label.SEASONAL_AGRICULTURE,\n",
     "    Label.URBAN,\n",
     "    Label.WATER,\n",
     "    Label.OTHER_TREE,\n",
     "    Label.NATIVE_NO_TREE,\n",
     "    Label.PEPPER,\n",
     "    Label.TEA,\n",
     "    Label.RICE,\n",
     "    Label.DECIDUOUS_FOREST,\n",
     "    Label.PINE_TREES,\n",
     "    Label.SHRUBLAND_BUSHLAND,\n",
     "    Label.SPARE_TREE,\n",
     "    Label.GRASSLAND,\n",
     "    Label.SECONDARY_DEGRADED_FOREST,\n",
     "    Label.MINE_BARESOIL,\n",
     "]\n",
     "\n",
     "labels_names = [label.name for label in labels]\n",
     "categories = pd.unique([category_from_label(label) for label in labels])\n",
     "\n",
     "bands = [\n",
     "    Band.COASTAL_AEROSOL.value,\n",
     "    Band.BLUE.value,\n",
     "    Band.GREEN.value,\n",
     "    Band.RED.value,\n",
     "    Band.NIR.value,\n",
     "    Band.SWIR1.value,\n",
     "    Band.SWIR2.value,\n",
     "]\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}