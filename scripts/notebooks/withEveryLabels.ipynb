{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "varied-facial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/tb/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, activations, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Activation, SpatialDropout2D, GlobalAveragePooling2D,\n",
    "    Dense, Dropout, Flatten,\n",
    "    Conv2D, MaxPooling2D, SeparableConv2D\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "# Import project utils scripts\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join('../src/')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from statisticsUtils import recall_precision_fscore_from_confusion_matrix\n",
    "from labelsUtils import Label\n",
    "from regionUtils import vietnam_labels_coordinates\n",
    "from rasterUtils import make_dataset_from_raster_files\n",
    "from convNetUtils import cross_validation, evaluate_model\n",
    "from visualizationUtils import label_first_detections, plot_confusion_matrix\n",
    "from bandUtils import Band\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_TESTS = 4\n",
    "NB_PIXEL_AROUND = 4\n",
    "EPOCHS = 2000\n",
    "LABELS_COORDINATES = vietnam_labels_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acquired-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without :\n",
    "# Label.INTERCROP,\n",
    "# Label.STICK_FOR_PEPPER,   \n",
    "# Label.PEPPER_AND_COFFEE,     \n",
    "# Label.PEPPER_AND_OTHER\n",
    "# Label.SPARE_TREE,     \n",
    "\n",
    "\n",
    "bands = [\n",
    "    Band.COASTAL_AEROSOL.value, \n",
    "    Band.BLUE.value, \n",
    "    Band.GREEN.value, \n",
    "    Band.RED.value, \n",
    "    Band.NIR.value, \n",
    "    Band.SWIR1.value, \n",
    "    Band.SWIR2.value, \n",
    "]\n",
    "\n",
    "labels = [\n",
    "    Label.COFFEE,\n",
    "    Label.DENSE_FOREST,\n",
    "    Label.RUBBER,\n",
    "    Label.SEASONAL_AGRICULTURE,\n",
    "    Label.URBAN,\n",
    "    Label.WATER,\n",
    "    Label.OTHER_TREE,\n",
    "    Label.NATIVE_NO_TREE,\n",
    "    Label.PEPPER,\n",
    "    Label.TEA,\n",
    "    Label.RICE,     \n",
    "    Label.DECIDUOUS_FOREST,\n",
    "    Label.PINE_TREES,     \n",
    "    Label.SHRUBLAND_BUSHLAND,     \n",
    "    Label.GRASSLAND,     \n",
    "    Label.SECONDARY_DEGRADED_FOREST,     \n",
    "    Label.MINE_BARESOIL,\n",
    "]\n",
    "\n",
    "dataset_args = dict(\n",
    "    labels = labels,\n",
    "    raster_paths = [os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_january_to_april_collection2/merged.tif')],\n",
    "    labels_coordinates_list = [LABELS_COORDINATES],\n",
    "    nb_pixel_around = NB_PIXEL_AROUND\n",
    ")\n",
    "\n",
    "dataset = make_dataset_from_raster_files(**dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "heavy-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 9, 9, 7)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 9, 9, 7)           28        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 9, 9, 32)          2048      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d (SpatialDr (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 77,261\n",
      "Trainable params: 77,247\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n",
      "\n",
      "Validation 1, fold 1 :\n",
      "---------------------------\n",
      "\n",
      "WARNING:tensorflow:From /home/simon/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.9004 - accuracy: 0.1020 - val_loss: 2.7922 - val_accuracy: 0.2522\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7192 - accuracy: 0.1700 - val_loss: 2.3769 - val_accuracy: 0.1780\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.5588 - accuracy: 0.1754 - val_loss: 2.3714 - val_accuracy: 0.1794\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3789 - accuracy: 0.2112 - val_loss: 2.2333 - val_accuracy: 0.2437\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2969 - accuracy: 0.2267 - val_loss: 2.1391 - val_accuracy: 0.2842\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1643 - accuracy: 0.2573 - val_loss: 2.1413 - val_accuracy: 0.2544\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1850 - accuracy: 0.2631 - val_loss: 2.0653 - val_accuracy: 0.2856\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0533 - accuracy: 0.2710 - val_loss: 1.9389 - val_accuracy: 0.3542\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8877 - accuracy: 0.3144 - val_loss: 1.9555 - val_accuracy: 0.3282\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8149 - accuracy: 0.3340 - val_loss: 1.8497 - val_accuracy: 0.4011\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7075 - accuracy: 0.3376 - val_loss: 1.9031 - val_accuracy: 0.3410\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7335 - accuracy: 0.3505 - val_loss: 1.7186 - val_accuracy: 0.4131\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7159 - accuracy: 0.3427 - val_loss: 1.8316 - val_accuracy: 0.3485\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5857 - accuracy: 0.3638 - val_loss: 1.6534 - val_accuracy: 0.4071\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5353 - accuracy: 0.3814 - val_loss: 1.7294 - val_accuracy: 0.4075\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4599 - accuracy: 0.4034 - val_loss: 1.5860 - val_accuracy: 0.4337\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5250 - accuracy: 0.3738 - val_loss: 1.6677 - val_accuracy: 0.4316\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4399 - accuracy: 0.4125 - val_loss: 1.8701 - val_accuracy: 0.3528\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4297 - accuracy: 0.4129 - val_loss: 1.7321 - val_accuracy: 0.4028\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3793 - accuracy: 0.4222 - val_loss: 1.5158 - val_accuracy: 0.4757\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4320 - accuracy: 0.4123 - val_loss: 1.6683 - val_accuracy: 0.4494\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3282 - accuracy: 0.4361 - val_loss: 1.5804 - val_accuracy: 0.4671\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4079 - accuracy: 0.4369 - val_loss: 1.6053 - val_accuracy: 0.4558\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3207 - accuracy: 0.4371 - val_loss: 1.5065 - val_accuracy: 0.4796\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3046 - accuracy: 0.4425 - val_loss: 1.4289 - val_accuracy: 0.5218\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4334 - accuracy: 0.4357 - val_loss: 1.6132 - val_accuracy: 0.4561\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3614 - accuracy: 0.4550 - val_loss: 1.4509 - val_accuracy: 0.5218\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3886 - accuracy: 0.4362 - val_loss: 1.4309 - val_accuracy: 0.4970\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2149 - accuracy: 0.4754 - val_loss: 1.5523 - val_accuracy: 0.4877\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2246 - accuracy: 0.4755 - val_loss: 1.3939 - val_accuracy: 0.5325\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2778 - accuracy: 0.4768 - val_loss: 1.3552 - val_accuracy: 0.5439\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2705 - accuracy: 0.4684 - val_loss: 1.4311 - val_accuracy: 0.5094\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1869 - accuracy: 0.4856 - val_loss: 1.4087 - val_accuracy: 0.5187\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1632 - accuracy: 0.4964 - val_loss: 1.3948 - val_accuracy: 0.5130\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1726 - accuracy: 0.4917 - val_loss: 1.4101 - val_accuracy: 0.5325\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2540 - accuracy: 0.4825 - val_loss: 1.7552 - val_accuracy: 0.4419\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2040 - accuracy: 0.4802 - val_loss: 1.4659 - val_accuracy: 0.5158\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1384 - accuracy: 0.4971 - val_loss: 1.3857 - val_accuracy: 0.5375\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1476 - accuracy: 0.5025 - val_loss: 1.3833 - val_accuracy: 0.5563\n",
      "Epoch 40/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1152 - accuracy: 0.5029 - val_loss: 1.4864 - val_accuracy: 0.4959\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2542 - accuracy: 0.4742 - val_loss: 1.3668 - val_accuracy: 0.5339\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2146 - accuracy: 0.4766 - val_loss: 1.5816 - val_accuracy: 0.4519\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1539 - accuracy: 0.4958 - val_loss: 1.3101 - val_accuracy: 0.5385\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0868 - accuracy: 0.5078 - val_loss: 1.3214 - val_accuracy: 0.5492\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3625 - accuracy: 0.4809 - val_loss: 1.4926 - val_accuracy: 0.4675\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1459 - accuracy: 0.4936 - val_loss: 1.4206 - val_accuracy: 0.5385\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1005 - accuracy: 0.5171 - val_loss: 1.4809 - val_accuracy: 0.5133\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0621 - accuracy: 0.5201 - val_loss: 1.2768 - val_accuracy: 0.5741\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0870 - accuracy: 0.5256 - val_loss: 1.4816 - val_accuracy: 0.5528\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0052 - accuracy: 0.5329 - val_loss: 1.2257 - val_accuracy: 0.5929\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9336 - accuracy: 0.5485 - val_loss: 1.1971 - val_accuracy: 0.5954\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0316 - accuracy: 0.5366 - val_loss: 1.3263 - val_accuracy: 0.5357\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1312 - accuracy: 0.5132 - val_loss: 1.3478 - val_accuracy: 0.5496\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0467 - accuracy: 0.5266 - val_loss: 1.3016 - val_accuracy: 0.5648\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1053 - accuracy: 0.5282 - val_loss: 1.2039 - val_accuracy: 0.5851\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2280 - accuracy: 0.5129 - val_loss: 1.4507 - val_accuracy: 0.5275\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5080 - accuracy: 0.5077 - val_loss: 1.3900 - val_accuracy: 0.5524\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1277 - accuracy: 0.5195 - val_loss: 1.3721 - val_accuracy: 0.5414\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.1256 - accuracy: 0.5350 - val_loss: 1.3231 - val_accuracy: 0.5520\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0078 - accuracy: 0.5391 - val_loss: 1.5221 - val_accuracy: 0.5030\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0355 - accuracy: 0.5414 - val_loss: 1.3784 - val_accuracy: 0.5542\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0713 - accuracy: 0.5255 - val_loss: 1.3047 - val_accuracy: 0.5687\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1105 - accuracy: 0.5303 - val_loss: 1.2116 - val_accuracy: 0.5940\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9841 - accuracy: 0.4816 - val_loss: 1.4459 - val_accuracy: 0.5243\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4637 - accuracy: 0.4708 - val_loss: 1.4637 - val_accuracy: 0.5176\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1825 - accuracy: 0.5098 - val_loss: 1.4613 - val_accuracy: 0.5147\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1433 - accuracy: 0.5115 - val_loss: 1.2827 - val_accuracy: 0.5620\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0184 - accuracy: 0.5491 - val_loss: 1.2127 - val_accuracy: 0.5901\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0095 - accuracy: 0.5401 - val_loss: 1.2908 - val_accuracy: 0.5595\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0281 - accuracy: 0.5420 - val_loss: 1.2090 - val_accuracy: 0.6057\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0266 - accuracy: 0.5453 - val_loss: 1.2436 - val_accuracy: 0.5737\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0165 - accuracy: 0.5270 - val_loss: 1.6413 - val_accuracy: 0.4686\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9434 - accuracy: 0.5502 - val_loss: 1.2362 - val_accuracy: 0.5822\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9461 - accuracy: 0.5609 - val_loss: 1.2126 - val_accuracy: 0.5972\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9526 - accuracy: 0.5575 - val_loss: 1.2414 - val_accuracy: 0.5805\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8996 - accuracy: 0.5742 - val_loss: 1.2629 - val_accuracy: 0.5780\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1253 - accuracy: 0.5306 - val_loss: 1.4891 - val_accuracy: 0.5052\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3845 - accuracy: 0.4960 - val_loss: 1.5938 - val_accuracy: 0.4522\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3970 - accuracy: 0.4961 - val_loss: 1.4625 - val_accuracy: 0.5133\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3102 - accuracy: 0.4674 - val_loss: 1.4401 - val_accuracy: 0.5062\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2458 - accuracy: 0.5021 - val_loss: 1.4264 - val_accuracy: 0.5176\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0625 - accuracy: 0.5432 - val_loss: 1.2315 - val_accuracy: 0.5908\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0034 - accuracy: 0.5509 - val_loss: 1.2854 - val_accuracy: 0.5581\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9008 - accuracy: 0.5701 - val_loss: 1.2228 - val_accuracy: 0.5947\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8984 - accuracy: 0.5700 - val_loss: 1.1028 - val_accuracy: 0.6231\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9496 - accuracy: 0.5614 - val_loss: 1.2380 - val_accuracy: 0.5787\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9190 - accuracy: 0.5606 - val_loss: 1.1405 - val_accuracy: 0.6039\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9422 - accuracy: 0.5734 - val_loss: 1.4129 - val_accuracy: 0.5403\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0277 - accuracy: 0.5536 - val_loss: 1.1543 - val_accuracy: 0.6011\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9587 - accuracy: 0.5677 - val_loss: 1.1149 - val_accuracy: 0.6284\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1883 - accuracy: 0.5330 - val_loss: 1.3169 - val_accuracy: 0.5528\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5061 - accuracy: 0.4710 - val_loss: 1.3216 - val_accuracy: 0.5464\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2520 - accuracy: 0.4852 - val_loss: 1.2988 - val_accuracy: 0.5591\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0426 - accuracy: 0.5258 - val_loss: 1.2425 - val_accuracy: 0.5801\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9141 - accuracy: 0.5647 - val_loss: 1.2713 - val_accuracy: 0.5712\n",
      "Epoch 96/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9575 - accuracy: 0.5552 - val_loss: 1.1508 - val_accuracy: 0.6146\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9232 - accuracy: 0.5623 - val_loss: 1.2222 - val_accuracy: 0.5922\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1993 - accuracy: 0.5353 - val_loss: 1.2361 - val_accuracy: 0.5861\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0263 - accuracy: 0.5407 - val_loss: 1.1945 - val_accuracy: 0.5872\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1593 - accuracy: 0.5272 - val_loss: 1.1491 - val_accuracy: 0.6014\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2430 - accuracy: 0.5449 - val_loss: 1.2996 - val_accuracy: 0.5641\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0707 - accuracy: 0.5685 - val_loss: 1.1206 - val_accuracy: 0.6167\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0529 - accuracy: 0.5487 - val_loss: 1.1257 - val_accuracy: 0.6149\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8560 - accuracy: 0.5750 - val_loss: 1.2748 - val_accuracy: 0.5805\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9147 - accuracy: 0.5693 - val_loss: 1.2124 - val_accuracy: 0.5812\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9440 - accuracy: 0.5618 - val_loss: 1.1147 - val_accuracy: 0.6291\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8837 - accuracy: 0.5802 - val_loss: 1.2061 - val_accuracy: 0.5886\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8968 - accuracy: 0.5788 - val_loss: 1.1455 - val_accuracy: 0.6174\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0616 - accuracy: 0.5552 - val_loss: 1.2207 - val_accuracy: 0.5918\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8610 - accuracy: 0.5880 - val_loss: 1.1811 - val_accuracy: 0.6036\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8412 - accuracy: 0.5889 - val_loss: 1.0965 - val_accuracy: 0.6274\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9839 - accuracy: 0.5503 - val_loss: 1.1027 - val_accuracy: 0.6323\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1209 - accuracy: 0.5269 - val_loss: 1.2955 - val_accuracy: 0.5705\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3485 - accuracy: 0.5168 - val_loss: 1.3355 - val_accuracy: 0.5432\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1640 - accuracy: 0.5234 - val_loss: 1.1712 - val_accuracy: 0.5972\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2554 - accuracy: 0.5432 - val_loss: 1.2387 - val_accuracy: 0.5925\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0648 - accuracy: 0.5282 - val_loss: 1.2020 - val_accuracy: 0.5893\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9389 - accuracy: 0.5591 - val_loss: 1.1680 - val_accuracy: 0.6043\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9137 - accuracy: 0.5778 - val_loss: 1.1556 - val_accuracy: 0.6117\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8368 - accuracy: 0.5893 - val_loss: 1.0859 - val_accuracy: 0.6341\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8426 - accuracy: 0.5806 - val_loss: 1.0672 - val_accuracy: 0.6416\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8408 - accuracy: 0.5959 - val_loss: 1.1268 - val_accuracy: 0.6163\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8579 - accuracy: 0.5813 - val_loss: 1.1612 - val_accuracy: 0.5982\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8115 - accuracy: 0.5893 - val_loss: 1.0775 - val_accuracy: 0.6288\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8881 - accuracy: 0.5807 - val_loss: 1.4245 - val_accuracy: 0.5293\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0925 - accuracy: 0.5283 - val_loss: 1.1080 - val_accuracy: 0.6355\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8878 - accuracy: 0.5808 - val_loss: 1.1144 - val_accuracy: 0.6306\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9359 - accuracy: 0.5603 - val_loss: 1.3040 - val_accuracy: 0.5670\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0083 - accuracy: 0.5801 - val_loss: 1.4097 - val_accuracy: 0.5506\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3047 - accuracy: 0.5158 - val_loss: 1.4118 - val_accuracy: 0.5279\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1775 - accuracy: 0.5075 - val_loss: 1.2976 - val_accuracy: 0.5524\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2683 - accuracy: 0.5047 - val_loss: 1.3084 - val_accuracy: 0.5545\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0243 - accuracy: 0.5230 - val_loss: 1.2518 - val_accuracy: 0.5567\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3614 - accuracy: 0.5325 - val_loss: 1.7589 - val_accuracy: 0.4409\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1766 - accuracy: 0.5043 - val_loss: 1.1866 - val_accuracy: 0.5993\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9842 - accuracy: 0.5642 - val_loss: 1.1747 - val_accuracy: 0.6036\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1882 - accuracy: 0.5718 - val_loss: 1.2098 - val_accuracy: 0.5929\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1629 - accuracy: 0.5475 - val_loss: 1.3046 - val_accuracy: 0.5478\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0087 - accuracy: 0.5116 - val_loss: 1.1677 - val_accuracy: 0.5908\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1836 - accuracy: 0.5425 - val_loss: 1.1206 - val_accuracy: 0.6131\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8928 - accuracy: 0.5737 - val_loss: 1.1615 - val_accuracy: 0.5986\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1751 - accuracy: 0.5614 - val_loss: 1.4311 - val_accuracy: 0.5204\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4632 - accuracy: 0.5138 - val_loss: 1.2684 - val_accuracy: 0.5815\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1117 - accuracy: 0.5110 - val_loss: 1.1389 - val_accuracy: 0.6146\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9765 - accuracy: 0.5438 - val_loss: 1.1826 - val_accuracy: 0.5872\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8848 - accuracy: 0.5754 - val_loss: 1.1517 - val_accuracy: 0.6053\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1080 - accuracy: 0.5523 - val_loss: 1.1782 - val_accuracy: 0.6060\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8924 - accuracy: 0.5819 - val_loss: 1.0889 - val_accuracy: 0.6224\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8327 - accuracy: 0.5922 - val_loss: 1.1292 - val_accuracy: 0.6153\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9036 - accuracy: 0.5738 - val_loss: 1.0762 - val_accuracy: 0.6362\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8015 - accuracy: 0.6034 - val_loss: 1.0578 - val_accuracy: 0.6465\n",
      "Epoch 152/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8627 - accuracy: 0.5837 - val_loss: 1.1336 - val_accuracy: 0.6238\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8175 - accuracy: 0.5919 - val_loss: 1.0394 - val_accuracy: 0.6565\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9247 - accuracy: 0.5812 - val_loss: 1.1982 - val_accuracy: 0.5964\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9731 - accuracy: 0.5696 - val_loss: 1.0596 - val_accuracy: 0.6515\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8617 - accuracy: 0.5881 - val_loss: 1.1042 - val_accuracy: 0.6306\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9768 - accuracy: 0.5773 - val_loss: 1.7400 - val_accuracy: 0.4810\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1684 - accuracy: 0.5266 - val_loss: 1.1209 - val_accuracy: 0.6327\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9946 - accuracy: 0.5866 - val_loss: 1.0592 - val_accuracy: 0.6369\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1765 - accuracy: 0.5282 - val_loss: 1.2258 - val_accuracy: 0.5794\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9951 - accuracy: 0.5615 - val_loss: 1.6032 - val_accuracy: 0.4845\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1568 - accuracy: 0.5255 - val_loss: 1.2230 - val_accuracy: 0.5773\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9485 - accuracy: 0.5579 - val_loss: 1.1427 - val_accuracy: 0.6110\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9496 - accuracy: 0.5431 - val_loss: 1.0762 - val_accuracy: 0.6444\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2318 - accuracy: 0.5611 - val_loss: 1.1593 - val_accuracy: 0.6053\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3825 - accuracy: 0.5133 - val_loss: 1.4429 - val_accuracy: 0.5172\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3184 - accuracy: 0.5284 - val_loss: 1.2435 - val_accuracy: 0.5677\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1282 - accuracy: 0.5574 - val_loss: 1.2241 - val_accuracy: 0.5872\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8433 - accuracy: 0.5840 - val_loss: 1.1436 - val_accuracy: 0.6121\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0337 - accuracy: 0.5854 - val_loss: 1.1516 - val_accuracy: 0.6231\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8965 - accuracy: 0.5893 - val_loss: 1.0836 - val_accuracy: 0.6625\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8938 - accuracy: 0.5851 - val_loss: 1.2488 - val_accuracy: 0.5851\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0343 - accuracy: 0.5609 - val_loss: 1.2421 - val_accuracy: 0.5776\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0562 - accuracy: 0.5560 - val_loss: 1.3220 - val_accuracy: 0.5453\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8526 - accuracy: 0.5743 - val_loss: 1.1402 - val_accuracy: 0.6256\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3554 - accuracy: 0.5706 - val_loss: 1.1943 - val_accuracy: 0.5854\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.2256 - accuracy: 0.5527 - val_loss: 1.2966 - val_accuracy: 0.5524\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4258 - accuracy: 0.4987 - val_loss: 1.3918 - val_accuracy: 0.5226\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3337 - accuracy: 0.5202 - val_loss: 1.2995 - val_accuracy: 0.5702\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1228 - accuracy: 0.5450 - val_loss: 1.2396 - val_accuracy: 0.5982\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9319 - accuracy: 0.5671 - val_loss: 1.1929 - val_accuracy: 0.6018\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9793 - accuracy: 0.5766 - val_loss: 1.2062 - val_accuracy: 0.6160\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1281 - accuracy: 0.5643 - val_loss: 1.1153 - val_accuracy: 0.6217\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8590 - accuracy: 0.5910 - val_loss: 1.1198 - val_accuracy: 0.6380\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8582 - accuracy: 0.5814 - val_loss: 1.1533 - val_accuracy: 0.6139\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3104 - accuracy: 0.5654 - val_loss: 1.1331 - val_accuracy: 0.6387\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9890 - accuracy: 0.5955 - val_loss: 1.2796 - val_accuracy: 0.5805\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9151 - accuracy: 0.5894 - val_loss: 1.3874 - val_accuracy: 0.5226\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0029 - accuracy: 0.5713 - val_loss: 1.2027 - val_accuracy: 0.6099\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8264 - accuracy: 0.5980 - val_loss: 1.0642 - val_accuracy: 0.6433\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8218 - accuracy: 0.6040 - val_loss: 1.0353 - val_accuracy: 0.6561\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8811 - accuracy: 0.6038 - val_loss: 1.1986 - val_accuracy: 0.5968\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0817 - accuracy: 0.5554 - val_loss: 1.1637 - val_accuracy: 0.6050\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9115 - accuracy: 0.5819 - val_loss: 1.1573 - val_accuracy: 0.6217\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9169 - accuracy: 0.5888 - val_loss: 1.1585 - val_accuracy: 0.6139\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9638 - accuracy: 0.5703 - val_loss: 1.2057 - val_accuracy: 0.5996\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0696 - accuracy: 0.5934 - val_loss: 1.2730 - val_accuracy: 0.5520\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3670 - accuracy: 0.5388 - val_loss: 1.2059 - val_accuracy: 0.6039\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8903 - accuracy: 0.5861 - val_loss: 1.1606 - val_accuracy: 0.6323\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9636 - accuracy: 0.5628 - val_loss: 1.1786 - val_accuracy: 0.6146\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1583 - accuracy: 0.5714 - val_loss: 1.3319 - val_accuracy: 0.5577\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9601 - accuracy: 0.5630 - val_loss: 1.2690 - val_accuracy: 0.5694\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8868 - accuracy: 0.5793 - val_loss: 1.1237 - val_accuracy: 0.6409\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8098 - accuracy: 0.6014 - val_loss: 1.1606 - val_accuracy: 0.6174\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9012 - accuracy: 0.6037 - val_loss: 1.7222 - val_accuracy: 0.4455\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0272 - accuracy: 0.5369 - val_loss: 1.1427 - val_accuracy: 0.6053\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9617 - accuracy: 0.5750 - val_loss: 1.1926 - val_accuracy: 0.5861\n",
      "Epoch 208/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0222 - accuracy: 0.5488 - val_loss: 1.2473 - val_accuracy: 0.5854\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8905 - accuracy: 0.5784 - val_loss: 1.0904 - val_accuracy: 0.6355\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7717 - accuracy: 0.6093 - val_loss: 1.1210 - val_accuracy: 0.6337\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9321 - accuracy: 0.5580 - val_loss: 1.3844 - val_accuracy: 0.5442\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9591 - accuracy: 0.5728 - val_loss: 1.1549 - val_accuracy: 0.6178\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7878 - accuracy: 0.6093 - val_loss: 1.0002 - val_accuracy: 0.6771\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8977 - accuracy: 0.5906 - val_loss: 1.1262 - val_accuracy: 0.6142\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8306 - accuracy: 0.5956 - val_loss: 1.0083 - val_accuracy: 0.6544\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8757 - accuracy: 0.5928 - val_loss: 1.1132 - val_accuracy: 0.6202\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9238 - accuracy: 0.5863 - val_loss: 1.1618 - val_accuracy: 0.6192\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9256 - accuracy: 0.5767 - val_loss: 1.0810 - val_accuracy: 0.6330\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8346 - accuracy: 0.6055 - val_loss: 1.0286 - val_accuracy: 0.6618\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8487 - accuracy: 0.6028 - val_loss: 1.0416 - val_accuracy: 0.6551\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9148 - accuracy: 0.5988 - val_loss: 1.0928 - val_accuracy: 0.6249\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8380 - accuracy: 0.6090 - val_loss: 1.0624 - val_accuracy: 0.6394\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8671 - accuracy: 0.6077 - val_loss: 1.0151 - val_accuracy: 0.6519\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0486 - accuracy: 0.5774 - val_loss: 1.1114 - val_accuracy: 0.6142\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9735 - accuracy: 0.5988 - val_loss: 1.0748 - val_accuracy: 0.6341\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8124 - accuracy: 0.6099 - val_loss: 1.1093 - val_accuracy: 0.6259\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9205 - accuracy: 0.5796 - val_loss: 1.3065 - val_accuracy: 0.5751\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1341 - accuracy: 0.5472 - val_loss: 1.3130 - val_accuracy: 0.5666\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1126 - accuracy: 0.5483 - val_loss: 1.0838 - val_accuracy: 0.6341\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0723 - accuracy: 0.5569 - val_loss: 1.3096 - val_accuracy: 0.5602\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1353 - accuracy: 0.5390 - val_loss: 1.1580 - val_accuracy: 0.6206\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9489 - accuracy: 0.5738 - val_loss: 1.1180 - val_accuracy: 0.6281\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8775 - accuracy: 0.5967 - val_loss: 1.0736 - val_accuracy: 0.6362\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7900 - accuracy: 0.6083 - val_loss: 1.0521 - val_accuracy: 0.6437\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9203 - accuracy: 0.5866 - val_loss: 1.1815 - val_accuracy: 0.5975\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9883 - accuracy: 0.5577 - val_loss: 1.1541 - val_accuracy: 0.6050\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9022 - accuracy: 0.5922 - val_loss: 1.0818 - val_accuracy: 0.6448\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0382 - accuracy: 0.5715 - val_loss: 1.4159 - val_accuracy: 0.5240\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3332 - accuracy: 0.5715 - val_loss: 1.1138 - val_accuracy: 0.6210\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7418 - accuracy: 0.5774 - val_loss: 1.2720 - val_accuracy: 0.5719\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4635 - accuracy: 0.5333 - val_loss: 1.1739 - val_accuracy: 0.6103\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0363 - accuracy: 0.5480 - val_loss: 1.1860 - val_accuracy: 0.5989\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9010 - accuracy: 0.5719 - val_loss: 1.1407 - val_accuracy: 0.6174\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9633 - accuracy: 0.5434 - val_loss: 1.1590 - val_accuracy: 0.6036\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7943 - accuracy: 0.6042 - val_loss: 1.0480 - val_accuracy: 0.6416\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1387 - accuracy: 0.5688 - val_loss: 1.1688 - val_accuracy: 0.6298\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9840 - accuracy: 0.5819 - val_loss: 1.0926 - val_accuracy: 0.6387\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8315 - accuracy: 0.6028 - val_loss: 1.0555 - val_accuracy: 0.6455\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0879 - accuracy: 0.5774 - val_loss: 1.6226 - val_accuracy: 0.4490\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5026 - accuracy: 0.4618 - val_loss: 1.4587 - val_accuracy: 0.4938\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1114 - accuracy: 0.5193 - val_loss: 1.1862 - val_accuracy: 0.5975\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0231 - accuracy: 0.5348 - val_loss: 1.1365 - val_accuracy: 0.6025\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9698 - accuracy: 0.5485 - val_loss: 1.2496 - val_accuracy: 0.5680\n",
      "\n",
      "Validation 1, fold 2 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8783 - accuracy: 0.0724 - val_loss: 2.8109 - val_accuracy: 0.0586\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.6671 - accuracy: 0.1128 - val_loss: 2.4438 - val_accuracy: 0.1815\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4311 - accuracy: 0.1821 - val_loss: 2.2292 - val_accuracy: 0.2437\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2900 - accuracy: 0.2023 - val_loss: 2.1408 - val_accuracy: 0.2536\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0559 - accuracy: 0.2261 - val_loss: 2.0036 - val_accuracy: 0.3187\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1944 - accuracy: 0.2306 - val_loss: 2.1797 - val_accuracy: 0.2263\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0460 - accuracy: 0.2532 - val_loss: 2.1766 - val_accuracy: 0.2881\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8920 - accuracy: 0.2930 - val_loss: 1.9702 - val_accuracy: 0.3076\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8563 - accuracy: 0.3132 - val_loss: 1.7816 - val_accuracy: 0.4238\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7658 - accuracy: 0.3362 - val_loss: 1.8577 - val_accuracy: 0.3652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6773 - accuracy: 0.3552 - val_loss: 1.7654 - val_accuracy: 0.4181\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6988 - accuracy: 0.3509 - val_loss: 1.8016 - val_accuracy: 0.3822\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5261 - accuracy: 0.3842 - val_loss: 1.6640 - val_accuracy: 0.4171\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4433 - accuracy: 0.3968 - val_loss: 1.5749 - val_accuracy: 0.4433\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4270 - accuracy: 0.3982 - val_loss: 1.9012 - val_accuracy: 0.3787\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4559 - accuracy: 0.4034 - val_loss: 1.7843 - val_accuracy: 0.3957\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5338 - accuracy: 0.4094 - val_loss: 1.7331 - val_accuracy: 0.4298\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5541 - accuracy: 0.3923 - val_loss: 1.6657 - val_accuracy: 0.4142\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6454 - accuracy: 0.3997 - val_loss: 1.6760 - val_accuracy: 0.4281\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4400 - accuracy: 0.4208 - val_loss: 1.6554 - val_accuracy: 0.4483\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3443 - accuracy: 0.4298 - val_loss: 1.5013 - val_accuracy: 0.5027\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4039 - accuracy: 0.4213 - val_loss: 1.6143 - val_accuracy: 0.4430\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3093 - accuracy: 0.4541 - val_loss: 1.8063 - val_accuracy: 0.4419\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3164 - accuracy: 0.4417 - val_loss: 1.5568 - val_accuracy: 0.4636\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2126 - accuracy: 0.4779 - val_loss: 1.4130 - val_accuracy: 0.5222\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2349 - accuracy: 0.4757 - val_loss: 1.5295 - val_accuracy: 0.4810\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2731 - accuracy: 0.4497 - val_loss: 1.5847 - val_accuracy: 0.4710\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2852 - accuracy: 0.4633 - val_loss: 1.5069 - val_accuracy: 0.4714\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2312 - accuracy: 0.4679 - val_loss: 1.4893 - val_accuracy: 0.4845\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1435 - accuracy: 0.4959 - val_loss: 1.3372 - val_accuracy: 0.5474\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1550 - accuracy: 0.5016 - val_loss: 1.6521 - val_accuracy: 0.4540\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1366 - accuracy: 0.4840 - val_loss: 1.5041 - val_accuracy: 0.4753\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1568 - accuracy: 0.4925 - val_loss: 1.9016 - val_accuracy: 0.3787\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2110 - accuracy: 0.4835 - val_loss: 1.6743 - val_accuracy: 0.4139\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1635 - accuracy: 0.4867 - val_loss: 1.3129 - val_accuracy: 0.5357\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1484 - accuracy: 0.5067 - val_loss: 1.4490 - val_accuracy: 0.5126\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0874 - accuracy: 0.5117 - val_loss: 1.3379 - val_accuracy: 0.5471\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1792 - accuracy: 0.4915 - val_loss: 1.4324 - val_accuracy: 0.5126\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0820 - accuracy: 0.5028 - val_loss: 1.4966 - val_accuracy: 0.4813\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0458 - accuracy: 0.5087 - val_loss: 1.4146 - val_accuracy: 0.5073\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1425 - accuracy: 0.5118 - val_loss: 1.3977 - val_accuracy: 0.5126\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1400 - accuracy: 0.5009 - val_loss: 1.5149 - val_accuracy: 0.4735\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3100 - accuracy: 0.4721 - val_loss: 1.4563 - val_accuracy: 0.4934\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2166 - accuracy: 0.4760 - val_loss: 1.3857 - val_accuracy: 0.5226\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4540 - accuracy: 0.4846 - val_loss: 1.3828 - val_accuracy: 0.5147\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3674 - accuracy: 0.4831 - val_loss: 1.6353 - val_accuracy: 0.4920\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1765 - accuracy: 0.4956 - val_loss: 1.3696 - val_accuracy: 0.5140\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0492 - accuracy: 0.5235 - val_loss: 1.3201 - val_accuracy: 0.5307\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0756 - accuracy: 0.5231 - val_loss: 1.2872 - val_accuracy: 0.5513\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0044 - accuracy: 0.5258 - val_loss: 1.3694 - val_accuracy: 0.5016\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0229 - accuracy: 0.5310 - val_loss: 1.3780 - val_accuracy: 0.5314\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0386 - accuracy: 0.5284 - val_loss: 1.2133 - val_accuracy: 0.5908\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0302 - accuracy: 0.5283 - val_loss: 1.3941 - val_accuracy: 0.5236\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0716 - accuracy: 0.5165 - val_loss: 1.3085 - val_accuracy: 0.5471\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9793 - accuracy: 0.5375 - val_loss: 1.2891 - val_accuracy: 0.5549\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2335 - accuracy: 0.5348 - val_loss: 1.4869 - val_accuracy: 0.4895\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5143 - accuracy: 0.4734 - val_loss: 1.4160 - val_accuracy: 0.5087\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5651 - accuracy: 0.4653 - val_loss: 1.5691 - val_accuracy: 0.4647\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2578 - accuracy: 0.4787 - val_loss: 1.3024 - val_accuracy: 0.5403\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3025 - accuracy: 0.5010 - val_loss: 1.3779 - val_accuracy: 0.5211\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3700 - accuracy: 0.4870 - val_loss: 1.3605 - val_accuracy: 0.5499\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1590 - accuracy: 0.4996 - val_loss: 1.3544 - val_accuracy: 0.5272\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0339 - accuracy: 0.5316 - val_loss: 1.2978 - val_accuracy: 0.5623\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9837 - accuracy: 0.5471 - val_loss: 1.3313 - val_accuracy: 0.5453\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0798 - accuracy: 0.5182 - val_loss: 1.3943 - val_accuracy: 0.5343\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2536 - accuracy: 0.5139 - val_loss: 1.4274 - val_accuracy: 0.5229\n",
      "Epoch 67/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0639 - accuracy: 0.5308 - val_loss: 1.2538 - val_accuracy: 0.5712\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1231 - accuracy: 0.5403 - val_loss: 1.2796 - val_accuracy: 0.5663\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9451 - accuracy: 0.5608 - val_loss: 1.2086 - val_accuracy: 0.5808\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9151 - accuracy: 0.5712 - val_loss: 1.1676 - val_accuracy: 0.6099\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9380 - accuracy: 0.5559 - val_loss: 1.2685 - val_accuracy: 0.5606\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9853 - accuracy: 0.5504 - val_loss: 1.2325 - val_accuracy: 0.5869\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0474 - accuracy: 0.5369 - val_loss: 1.3241 - val_accuracy: 0.5563\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9685 - accuracy: 0.5543 - val_loss: 1.2392 - val_accuracy: 0.5883\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9201 - accuracy: 0.5626 - val_loss: 1.2193 - val_accuracy: 0.5854\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9730 - accuracy: 0.5560 - val_loss: 1.4943 - val_accuracy: 0.4888\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0073 - accuracy: 0.5286 - val_loss: 1.2257 - val_accuracy: 0.5943\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4406 - accuracy: 0.4993 - val_loss: 1.2662 - val_accuracy: 0.5591\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9384 - accuracy: 0.5498 - val_loss: 1.2353 - val_accuracy: 0.5737\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1876 - accuracy: 0.5263 - val_loss: 1.2942 - val_accuracy: 0.5599\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0019 - accuracy: 0.5251 - val_loss: 1.2565 - val_accuracy: 0.5687\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0122 - accuracy: 0.5321 - val_loss: 1.2351 - val_accuracy: 0.5861\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9157 - accuracy: 0.5583 - val_loss: 1.2214 - val_accuracy: 0.5915\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0584 - accuracy: 0.5416 - val_loss: 1.2395 - val_accuracy: 0.5726\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9595 - accuracy: 0.5500 - val_loss: 1.2187 - val_accuracy: 0.5744\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9441 - accuracy: 0.5710 - val_loss: 1.1672 - val_accuracy: 0.6089\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9468 - accuracy: 0.5552 - val_loss: 1.1897 - val_accuracy: 0.6053\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9387 - accuracy: 0.5594 - val_loss: 1.2226 - val_accuracy: 0.5741\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8834 - accuracy: 0.5687 - val_loss: 1.1486 - val_accuracy: 0.6160\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1472 - accuracy: 0.5385 - val_loss: 1.4874 - val_accuracy: 0.4980\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1578 - accuracy: 0.5247 - val_loss: 1.2734 - val_accuracy: 0.5794\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9579 - accuracy: 0.5471 - val_loss: 1.2084 - val_accuracy: 0.6025\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9920 - accuracy: 0.5552 - val_loss: 1.1801 - val_accuracy: 0.5954\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9069 - accuracy: 0.5653 - val_loss: 1.1769 - val_accuracy: 0.5996\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8962 - accuracy: 0.5694 - val_loss: 1.1865 - val_accuracy: 0.6018\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1419 - accuracy: 0.5417 - val_loss: 1.2263 - val_accuracy: 0.5883\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0319 - accuracy: 0.5361 - val_loss: 1.3361 - val_accuracy: 0.5346\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9325 - accuracy: 0.5627 - val_loss: 1.1436 - val_accuracy: 0.6199\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9591 - accuracy: 0.5546 - val_loss: 1.1654 - val_accuracy: 0.6039\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0648 - accuracy: 0.5401 - val_loss: 1.2798 - val_accuracy: 0.5460\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0334 - accuracy: 0.5422 - val_loss: 1.2389 - val_accuracy: 0.5623\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9680 - accuracy: 0.5448 - val_loss: 1.2325 - val_accuracy: 0.5851\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1614 - accuracy: 0.5437 - val_loss: 1.3235 - val_accuracy: 0.5535\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6457 - accuracy: 0.5143 - val_loss: 1.6243 - val_accuracy: 0.4806\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5282 - accuracy: 0.4821 - val_loss: 1.3080 - val_accuracy: 0.5613\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2248 - accuracy: 0.5232 - val_loss: 1.3086 - val_accuracy: 0.5645\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0768 - accuracy: 0.5361 - val_loss: 1.1654 - val_accuracy: 0.6085\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9287 - accuracy: 0.5713 - val_loss: 1.1751 - val_accuracy: 0.6167\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9306 - accuracy: 0.5669 - val_loss: 1.2306 - val_accuracy: 0.5840\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9879 - accuracy: 0.5372 - val_loss: 1.3525 - val_accuracy: 0.5336\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9618 - accuracy: 0.5640 - val_loss: 1.1575 - val_accuracy: 0.6128\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9016 - accuracy: 0.5819 - val_loss: 1.1608 - val_accuracy: 0.6028\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8405 - accuracy: 0.5925 - val_loss: 1.1150 - val_accuracy: 0.6227\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9854 - accuracy: 0.5630 - val_loss: 1.2537 - val_accuracy: 0.5961\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0009 - accuracy: 0.5453 - val_loss: 1.2866 - val_accuracy: 0.5776\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9518 - accuracy: 0.5636 - val_loss: 1.4154 - val_accuracy: 0.5147\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3519 - accuracy: 0.4992 - val_loss: 1.4630 - val_accuracy: 0.5474\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0878 - accuracy: 0.5471 - val_loss: 1.2650 - val_accuracy: 0.5609\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0832 - accuracy: 0.5413 - val_loss: 1.1915 - val_accuracy: 0.5922\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8718 - accuracy: 0.5812 - val_loss: 1.1277 - val_accuracy: 0.6167\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8664 - accuracy: 0.5793 - val_loss: 1.0997 - val_accuracy: 0.6242\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8635 - accuracy: 0.5864 - val_loss: 1.1905 - val_accuracy: 0.5989\n",
      "Epoch 123/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0113 - accuracy: 0.5535 - val_loss: 1.2384 - val_accuracy: 0.5773\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8461 - accuracy: 0.5782 - val_loss: 1.1001 - val_accuracy: 0.6266\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9657 - accuracy: 0.5560 - val_loss: 1.1458 - val_accuracy: 0.6121\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8635 - accuracy: 0.5835 - val_loss: 1.2059 - val_accuracy: 0.5918\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9141 - accuracy: 0.5793 - val_loss: 1.1879 - val_accuracy: 0.5904\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8418 - accuracy: 0.5836 - val_loss: 1.1901 - val_accuracy: 0.5975\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8317 - accuracy: 0.5846 - val_loss: 1.2038 - val_accuracy: 0.5911\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8793 - accuracy: 0.5836 - val_loss: 1.1556 - val_accuracy: 0.6238\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8207 - accuracy: 0.5936 - val_loss: 1.0982 - val_accuracy: 0.6295\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9213 - accuracy: 0.5860 - val_loss: 1.1198 - val_accuracy: 0.6149\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8231 - accuracy: 0.5966 - val_loss: 1.0685 - val_accuracy: 0.6391\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8247 - accuracy: 0.5939 - val_loss: 1.0956 - val_accuracy: 0.6355\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0784 - accuracy: 0.5579 - val_loss: 1.4761 - val_accuracy: 0.5108\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6802 - accuracy: 0.5051 - val_loss: 1.2924 - val_accuracy: 0.5652\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5537 - accuracy: 0.5173 - val_loss: 1.3229 - val_accuracy: 0.5382\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0413 - accuracy: 0.5520 - val_loss: 1.2300 - val_accuracy: 0.5886\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2906 - accuracy: 0.5205 - val_loss: 1.6065 - val_accuracy: 0.4707\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3061 - accuracy: 0.5264 - val_loss: 1.2532 - val_accuracy: 0.5840\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9809 - accuracy: 0.5621 - val_loss: 1.3364 - val_accuracy: 0.5361\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1268 - accuracy: 0.5353 - val_loss: 1.2689 - val_accuracy: 0.5666\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1352 - accuracy: 0.5145 - val_loss: 1.2247 - val_accuracy: 0.5531\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0276 - accuracy: 0.5289 - val_loss: 1.1803 - val_accuracy: 0.5883\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9248 - accuracy: 0.5662 - val_loss: 1.1073 - val_accuracy: 0.6195\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8703 - accuracy: 0.5798 - val_loss: 1.1355 - val_accuracy: 0.6092\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8360 - accuracy: 0.5887 - val_loss: 1.2557 - val_accuracy: 0.5879\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0274 - accuracy: 0.5456 - val_loss: 1.2209 - val_accuracy: 0.5829\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8430 - accuracy: 0.5874 - val_loss: 1.1294 - val_accuracy: 0.6259\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8261 - accuracy: 0.5893 - val_loss: 1.1314 - val_accuracy: 0.6199\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7818 - accuracy: 0.6040 - val_loss: 1.1790 - val_accuracy: 0.5982\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8697 - accuracy: 0.5758 - val_loss: 1.1240 - val_accuracy: 0.6210\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8420 - accuracy: 0.5929 - val_loss: 1.0785 - val_accuracy: 0.6433\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9056 - accuracy: 0.5746 - val_loss: 1.1597 - val_accuracy: 0.6075\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8211 - accuracy: 0.5941 - val_loss: 1.2105 - val_accuracy: 0.5734\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8524 - accuracy: 0.5966 - val_loss: 1.2642 - val_accuracy: 0.5687\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9458 - accuracy: 0.5638 - val_loss: 1.2388 - val_accuracy: 0.5691\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8579 - accuracy: 0.5866 - val_loss: 1.2070 - val_accuracy: 0.6096\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8682 - accuracy: 0.5824 - val_loss: 1.1018 - val_accuracy: 0.6437\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8035 - accuracy: 0.5960 - val_loss: 1.0757 - val_accuracy: 0.6281\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0188 - accuracy: 0.5696 - val_loss: 1.4253 - val_accuracy: 0.5176\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0561 - accuracy: 0.5327 - val_loss: 1.4259 - val_accuracy: 0.5037\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9365 - accuracy: 0.5664 - val_loss: 1.1908 - val_accuracy: 0.5908\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8221 - accuracy: 0.5869 - val_loss: 1.0936 - val_accuracy: 0.6369\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8169 - accuracy: 0.6036 - val_loss: 1.2162 - val_accuracy: 0.5975\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8340 - accuracy: 0.5886 - val_loss: 1.1282 - val_accuracy: 0.6099\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1537 - accuracy: 0.5631 - val_loss: 1.2540 - val_accuracy: 0.5840\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0474 - accuracy: 0.5691 - val_loss: 1.1705 - val_accuracy: 0.6160\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8385 - accuracy: 0.5983 - val_loss: 1.0851 - val_accuracy: 0.6416\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2704 - accuracy: 0.5796 - val_loss: 1.1838 - val_accuracy: 0.6107\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7053 - accuracy: 0.5464 - val_loss: 1.3128 - val_accuracy: 0.5321\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0413 - accuracy: 0.5473 - val_loss: 1.2538 - val_accuracy: 0.5691\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9863 - accuracy: 0.5663 - val_loss: 1.4210 - val_accuracy: 0.5183\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9393 - accuracy: 0.5710 - val_loss: 1.1900 - val_accuracy: 0.5996\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9505 - accuracy: 0.5726 - val_loss: 1.2892 - val_accuracy: 0.5602\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9522 - accuracy: 0.5763 - val_loss: 1.1110 - val_accuracy: 0.6298\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8197 - accuracy: 0.5933 - val_loss: 1.1267 - val_accuracy: 0.6249\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7950 - accuracy: 0.6116 - val_loss: 1.1702 - val_accuracy: 0.5954\n",
      "Epoch 179/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8410 - accuracy: 0.5900 - val_loss: 1.1477 - val_accuracy: 0.6060\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8791 - accuracy: 0.5785 - val_loss: 1.2206 - val_accuracy: 0.6071\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8698 - accuracy: 0.5790 - val_loss: 1.1308 - val_accuracy: 0.6185\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9161 - accuracy: 0.5925 - val_loss: 1.1489 - val_accuracy: 0.6181\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8254 - accuracy: 0.5910 - val_loss: 1.1386 - val_accuracy: 0.6046\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8183 - accuracy: 0.5858 - val_loss: 1.1738 - val_accuracy: 0.6039\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8769 - accuracy: 0.5942 - val_loss: 1.0881 - val_accuracy: 0.6384\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7856 - accuracy: 0.6103 - val_loss: 1.0164 - val_accuracy: 0.6586\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8065 - accuracy: 0.5991 - val_loss: 1.2169 - val_accuracy: 0.5879\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1616 - accuracy: 0.5132 - val_loss: 1.1344 - val_accuracy: 0.6067\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9875 - accuracy: 0.5767 - val_loss: 1.8048 - val_accuracy: 0.4089\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9750 - accuracy: 0.5607 - val_loss: 1.2051 - val_accuracy: 0.5865\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8897 - accuracy: 0.5865 - val_loss: 1.1140 - val_accuracy: 0.6231\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8174 - accuracy: 0.6111 - val_loss: 1.1883 - val_accuracy: 0.5972\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7590 - accuracy: 0.6156 - val_loss: 1.0762 - val_accuracy: 0.6348\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2452 - accuracy: 0.5777 - val_loss: 1.7228 - val_accuracy: 0.4078\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1456 - accuracy: 0.4552 - val_loss: 1.3393 - val_accuracy: 0.5393\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3325 - accuracy: 0.5221 - val_loss: 1.2947 - val_accuracy: 0.5542\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3754 - accuracy: 0.5251 - val_loss: 1.3226 - val_accuracy: 0.5613\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9376 - accuracy: 0.5778 - val_loss: 1.1277 - val_accuracy: 0.6266\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9459 - accuracy: 0.5859 - val_loss: 1.1892 - val_accuracy: 0.5954\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8791 - accuracy: 0.5945 - val_loss: 1.1463 - val_accuracy: 0.6092\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8945 - accuracy: 0.5915 - val_loss: 1.1527 - val_accuracy: 0.6213\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8399 - accuracy: 0.5927 - val_loss: 1.3509 - val_accuracy: 0.5829\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7989 - accuracy: 0.6165 - val_loss: 1.0951 - val_accuracy: 0.6277\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8708 - accuracy: 0.6058 - val_loss: 1.1368 - val_accuracy: 0.6167\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7532 - accuracy: 0.6224 - val_loss: 1.1173 - val_accuracy: 0.6433\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8578 - accuracy: 0.5903 - val_loss: 1.2579 - val_accuracy: 0.5787\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2334 - accuracy: 0.5173 - val_loss: 1.2702 - val_accuracy: 0.5872\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3518 - accuracy: 0.5074 - val_loss: 1.4134 - val_accuracy: 0.5158\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2495 - accuracy: 0.5282 - val_loss: 1.5338 - val_accuracy: 0.5147\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2405 - accuracy: 0.5414 - val_loss: 1.2325 - val_accuracy: 0.5819\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1349 - accuracy: 0.5649 - val_loss: 1.6063 - val_accuracy: 0.4917\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 3.5930 - accuracy: 0.5004 - val_loss: 1.5877 - val_accuracy: 0.4501\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5562 - accuracy: 0.5013 - val_loss: 1.2450 - val_accuracy: 0.5709\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9588 - accuracy: 0.5457 - val_loss: 1.2741 - val_accuracy: 0.5716\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8823 - accuracy: 0.5845 - val_loss: 1.0631 - val_accuracy: 0.6440\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8398 - accuracy: 0.6002 - val_loss: 1.1274 - val_accuracy: 0.6256\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9959 - accuracy: 0.5677 - val_loss: 1.1117 - val_accuracy: 0.6171\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8364 - accuracy: 0.5853 - val_loss: 1.2205 - val_accuracy: 0.5968\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8202 - accuracy: 0.5999 - val_loss: 1.1438 - val_accuracy: 0.6252\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8311 - accuracy: 0.6031 - val_loss: 1.0980 - val_accuracy: 0.6448\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8347 - accuracy: 0.6054 - val_loss: 1.1661 - val_accuracy: 0.5996\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7732 - accuracy: 0.6192 - val_loss: 1.1800 - val_accuracy: 0.6032\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7784 - accuracy: 0.6176 - val_loss: 1.0808 - val_accuracy: 0.6391\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8652 - accuracy: 0.5972 - val_loss: 1.7796 - val_accuracy: 0.4398\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9423 - accuracy: 0.5614 - val_loss: 1.1605 - val_accuracy: 0.6192\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0613 - accuracy: 0.5457 - val_loss: 1.1700 - val_accuracy: 0.6121\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1055 - accuracy: 0.5865 - val_loss: 1.1853 - val_accuracy: 0.6135\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8917 - accuracy: 0.5755 - val_loss: 1.1531 - val_accuracy: 0.6103\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9597 - accuracy: 0.5686 - val_loss: 1.2151 - val_accuracy: 0.5851\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0472 - accuracy: 0.5610 - val_loss: 1.1223 - val_accuracy: 0.6110\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8339 - accuracy: 0.5912 - val_loss: 1.0522 - val_accuracy: 0.6419\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8229 - accuracy: 0.5973 - val_loss: 1.1254 - val_accuracy: 0.6277\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8306 - accuracy: 0.5978 - val_loss: 1.0369 - val_accuracy: 0.6519\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7778 - accuracy: 0.6095 - val_loss: 1.0435 - val_accuracy: 0.6416\n",
      "Epoch 235/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8746 - accuracy: 0.5813 - val_loss: 1.0771 - val_accuracy: 0.6298\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5285 - accuracy: 0.4750 - val_loss: 1.3262 - val_accuracy: 0.5613\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2556 - accuracy: 0.5221 - val_loss: 1.4049 - val_accuracy: 0.5218\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0161 - accuracy: 0.5522 - val_loss: 1.1681 - val_accuracy: 0.6096\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2067 - accuracy: 0.5452 - val_loss: 1.1748 - val_accuracy: 0.6078\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8721 - accuracy: 0.5832 - val_loss: 1.1290 - val_accuracy: 0.6316\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8946 - accuracy: 0.6016 - val_loss: 1.1862 - val_accuracy: 0.5989\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0154 - accuracy: 0.5472 - val_loss: 1.1796 - val_accuracy: 0.6124\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8325 - accuracy: 0.5977 - val_loss: 1.1426 - val_accuracy: 0.6178\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8541 - accuracy: 0.5859 - val_loss: 1.1177 - val_accuracy: 0.6217\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8355 - accuracy: 0.5989 - val_loss: 1.2273 - val_accuracy: 0.5911\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8312 - accuracy: 0.5958 - val_loss: 1.1125 - val_accuracy: 0.6224\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8921 - accuracy: 0.6145 - val_loss: 1.4408 - val_accuracy: 0.5268\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.6763 - accuracy: 0.4758 - val_loss: 1.3389 - val_accuracy: 0.5602\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9905 - accuracy: 0.5629 - val_loss: 1.2369 - val_accuracy: 0.5869\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9951 - accuracy: 0.5657 - val_loss: 1.2188 - val_accuracy: 0.5993\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8332 - accuracy: 0.5964 - val_loss: 1.1020 - val_accuracy: 0.6348\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0879 - accuracy: 0.5545 - val_loss: 1.4552 - val_accuracy: 0.5361\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7872 - accuracy: 0.5256 - val_loss: 1.6096 - val_accuracy: 0.4540\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1238 - accuracy: 0.4935 - val_loss: 1.3198 - val_accuracy: 0.5545\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9724 - accuracy: 0.5587 - val_loss: 1.1816 - val_accuracy: 0.6018\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2436 - accuracy: 0.5530 - val_loss: 1.6605 - val_accuracy: 0.4654\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0118 - accuracy: 0.4668 - val_loss: 1.4306 - val_accuracy: 0.5250\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1091 - accuracy: 0.4916 - val_loss: 1.5326 - val_accuracy: 0.4970\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1021 - accuracy: 0.5268 - val_loss: 1.2920 - val_accuracy: 0.5751\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.5674 - val_loss: 1.3470 - val_accuracy: 0.5645\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0074 - accuracy: 0.5553 - val_loss: 1.2058 - val_accuracy: 0.5989\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0456 - accuracy: 0.5644 - val_loss: 1.2369 - val_accuracy: 0.5986\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8456 - accuracy: 0.5915 - val_loss: 1.1644 - val_accuracy: 0.6313\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9273 - accuracy: 0.5946 - val_loss: 1.3792 - val_accuracy: 0.5407\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9614 - accuracy: 0.5721 - val_loss: 1.1856 - val_accuracy: 0.6110\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9103 - accuracy: 0.5912 - val_loss: 1.2564 - val_accuracy: 0.5478\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4587 - accuracy: 0.5639 - val_loss: 1.1384 - val_accuracy: 0.6323\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0267 - accuracy: 0.4857 - val_loss: 1.3881 - val_accuracy: 0.5385\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 3.1871 - accuracy: 0.4377 - val_loss: 1.6621 - val_accuracy: 0.4121\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2996 - accuracy: 0.4824 - val_loss: 1.4417 - val_accuracy: 0.5151\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0523 - accuracy: 0.5521 - val_loss: 1.5355 - val_accuracy: 0.5421\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1363 - accuracy: 0.5078 - val_loss: 1.2968 - val_accuracy: 0.5780\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0103 - accuracy: 0.5556 - val_loss: 1.4355 - val_accuracy: 0.5183\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9239 - accuracy: 0.5741 - val_loss: 1.1983 - val_accuracy: 0.6181\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9782 - accuracy: 0.5671 - val_loss: 1.2709 - val_accuracy: 0.5851\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8935 - accuracy: 0.5742 - val_loss: 1.1304 - val_accuracy: 0.6398\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9587 - accuracy: 0.5941 - val_loss: 1.7487 - val_accuracy: 0.5179\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1959 - accuracy: 0.4561 - val_loss: 1.6020 - val_accuracy: 0.4600\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2027 - accuracy: 0.4940 - val_loss: 1.2669 - val_accuracy: 0.5766\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9450 - accuracy: 0.5621 - val_loss: 1.2023 - val_accuracy: 0.6075\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1529 - accuracy: 0.5555 - val_loss: 1.1796 - val_accuracy: 0.6046\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9482 - accuracy: 0.5708 - val_loss: 1.2025 - val_accuracy: 0.6028\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8414 - accuracy: 0.5965 - val_loss: 1.1355 - val_accuracy: 0.6288\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7971 - accuracy: 0.6084 - val_loss: 1.0968 - val_accuracy: 0.6448\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8701 - accuracy: 0.6014 - val_loss: 1.0878 - val_accuracy: 0.6540\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0532 - accuracy: 0.5702 - val_loss: 1.2173 - val_accuracy: 0.5915\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9852 - accuracy: 0.5803 - val_loss: 1.5239 - val_accuracy: 0.4913\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0580 - accuracy: 0.5383 - val_loss: 1.1250 - val_accuracy: 0.6199\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9546 - accuracy: 0.5646 - val_loss: 1.1364 - val_accuracy: 0.6259\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0675 - accuracy: 0.5711 - val_loss: 1.2289 - val_accuracy: 0.5865\n",
      "Epoch 291/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9907 - accuracy: 0.5813 - val_loss: 1.4469 - val_accuracy: 0.5456\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9936 - accuracy: 0.5583 - val_loss: 1.1758 - val_accuracy: 0.6192\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8987 - accuracy: 0.5758 - val_loss: 1.4071 - val_accuracy: 0.5233\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8013 - accuracy: 0.5991 - val_loss: 1.1248 - val_accuracy: 0.6281\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7820 - accuracy: 0.6058 - val_loss: 1.1486 - val_accuracy: 0.6281\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8391 - accuracy: 0.5972 - val_loss: 1.4214 - val_accuracy: 0.5144\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8927 - accuracy: 0.5770 - val_loss: 1.0494 - val_accuracy: 0.6586\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8743 - accuracy: 0.5870 - val_loss: 1.0925 - val_accuracy: 0.6437\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7469 - accuracy: 0.5552 - val_loss: 1.2431 - val_accuracy: 0.5758\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1902 - accuracy: 0.5410 - val_loss: 1.8071 - val_accuracy: 0.4199\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6935 - accuracy: 0.4750 - val_loss: 1.4585 - val_accuracy: 0.5126\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7004 - accuracy: 0.5352 - val_loss: 1.3173 - val_accuracy: 0.5648\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5710 - accuracy: 0.5258 - val_loss: 1.4463 - val_accuracy: 0.5197\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0308 - accuracy: 0.5324 - val_loss: 1.2551 - val_accuracy: 0.5876\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9038 - accuracy: 0.5743 - val_loss: 1.1246 - val_accuracy: 0.6302\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9096 - accuracy: 0.5853 - val_loss: 1.1116 - val_accuracy: 0.6401\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0563 - accuracy: 0.5329 - val_loss: 1.3950 - val_accuracy: 0.5428\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1131 - accuracy: 0.5059 - val_loss: 1.2451 - val_accuracy: 0.5908\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9790 - accuracy: 0.5449 - val_loss: 1.2290 - val_accuracy: 0.5865\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8526 - accuracy: 0.5901 - val_loss: 1.1471 - val_accuracy: 0.6096\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8245 - accuracy: 0.5978 - val_loss: 1.2604 - val_accuracy: 0.5847\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8114 - accuracy: 0.6019 - val_loss: 1.1547 - val_accuracy: 0.6117\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8197 - accuracy: 0.6004 - val_loss: 1.1258 - val_accuracy: 0.6345\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8801 - accuracy: 0.5955 - val_loss: 1.2657 - val_accuracy: 0.5762\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8590 - accuracy: 0.5896 - val_loss: 1.1452 - val_accuracy: 0.6384\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8816 - accuracy: 0.5982 - val_loss: 1.1453 - val_accuracy: 0.6295\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8057 - accuracy: 0.6128 - val_loss: 1.0995 - val_accuracy: 0.6295\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8090 - accuracy: 0.6063 - val_loss: 1.1058 - val_accuracy: 0.6348\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3136 - accuracy: 0.4961 - val_loss: 1.6486 - val_accuracy: 0.4455\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1038 - accuracy: 0.5076 - val_loss: 1.2293 - val_accuracy: 0.5975\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0125 - accuracy: 0.5482 - val_loss: 1.4002 - val_accuracy: 0.5574\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9286 - accuracy: 0.5697 - val_loss: 1.4864 - val_accuracy: 0.4675\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1633 - accuracy: 0.4738 - val_loss: 1.2232 - val_accuracy: 0.5851\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8823 - accuracy: 0.5663 - val_loss: 1.1203 - val_accuracy: 0.6245\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9984 - accuracy: 0.5758 - val_loss: 1.1792 - val_accuracy: 0.5989\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8467 - accuracy: 0.5975 - val_loss: 1.1243 - val_accuracy: 0.6277\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8405 - accuracy: 0.5028 - val_loss: 1.3777 - val_accuracy: 0.5357\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 3.1454 - accuracy: 0.4301 - val_loss: 1.5693 - val_accuracy: 0.4703\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7547 - accuracy: 0.3806 - val_loss: 1.6428 - val_accuracy: 0.4263\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9478 - accuracy: 0.4249 - val_loss: 1.6440 - val_accuracy: 0.4483\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6764 - accuracy: 0.4278 - val_loss: 1.6696 - val_accuracy: 0.4409\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3489 - accuracy: 0.4632 - val_loss: 1.5581 - val_accuracy: 0.4945\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3101 - accuracy: 0.5044 - val_loss: 1.7583 - val_accuracy: 0.5016\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4344 - accuracy: 0.5083 - val_loss: 1.3634 - val_accuracy: 0.5520\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1497 - accuracy: 0.5326 - val_loss: 1.3069 - val_accuracy: 0.5805\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7588 - accuracy: 0.4894 - val_loss: 1.6231 - val_accuracy: 0.4657\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4220 - accuracy: 0.4735 - val_loss: 1.5333 - val_accuracy: 0.5126\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3211 - accuracy: 0.4936 - val_loss: 1.5289 - val_accuracy: 0.5037\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2300 - accuracy: 0.4988 - val_loss: 1.3785 - val_accuracy: 0.5741\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1889 - accuracy: 0.5213 - val_loss: 1.3280 - val_accuracy: 0.5780\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3521 - accuracy: 0.4822 - val_loss: 1.3746 - val_accuracy: 0.5410\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5559 - accuracy: 0.4807 - val_loss: 2.0029 - val_accuracy: 0.3819\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3657 - accuracy: 0.4718 - val_loss: 1.5590 - val_accuracy: 0.4842\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1009 - accuracy: 0.5018 - val_loss: 1.3247 - val_accuracy: 0.5698\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3109 - accuracy: 0.5238 - val_loss: 1.3541 - val_accuracy: 0.5545\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3610 - accuracy: 0.5133 - val_loss: 1.6304 - val_accuracy: 0.4689\n",
      "Epoch 347/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1539 - accuracy: 0.5018 - val_loss: 1.3447 - val_accuracy: 0.5414\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4203 - accuracy: 0.5136 - val_loss: 1.5964 - val_accuracy: 0.4845\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4260 - accuracy: 0.5161 - val_loss: 1.5788 - val_accuracy: 0.4913\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0387 - accuracy: 0.5290 - val_loss: 1.3516 - val_accuracy: 0.5453\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4223 - accuracy: 0.5299 - val_loss: 1.3647 - val_accuracy: 0.5488\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0902 - accuracy: 0.5411 - val_loss: 1.3122 - val_accuracy: 0.5751\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2335 - accuracy: 0.5329 - val_loss: 1.4555 - val_accuracy: 0.5485\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4137 - accuracy: 0.5234 - val_loss: 1.3031 - val_accuracy: 0.5915\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0233 - accuracy: 0.5394 - val_loss: 1.2136 - val_accuracy: 0.6121\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0384 - accuracy: 0.5470 - val_loss: 1.2193 - val_accuracy: 0.5961\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1639 - accuracy: 0.5294 - val_loss: 1.3148 - val_accuracy: 0.5748\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0527 - accuracy: 0.5393 - val_loss: 1.3172 - val_accuracy: 0.5552\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0774 - accuracy: 0.5226 - val_loss: 1.2529 - val_accuracy: 0.5808\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2212 - accuracy: 0.5438 - val_loss: 1.7372 - val_accuracy: 0.4398\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0396 - accuracy: 0.5135 - val_loss: 1.3095 - val_accuracy: 0.5719\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0710 - accuracy: 0.5295 - val_loss: 1.2239 - val_accuracy: 0.6036\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1620 - accuracy: 0.5004 - val_loss: 1.3465 - val_accuracy: 0.5510\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9568 - accuracy: 0.5545 - val_loss: 1.2915 - val_accuracy: 0.5776\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8522 - accuracy: 0.5940 - val_loss: 1.2563 - val_accuracy: 0.5794\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4216 - accuracy: 0.5234 - val_loss: 1.2794 - val_accuracy: 0.5854\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0552 - accuracy: 0.5319 - val_loss: 1.2515 - val_accuracy: 0.5883\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9613 - accuracy: 0.5633 - val_loss: 1.2263 - val_accuracy: 0.6021\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1188 - accuracy: 0.5511 - val_loss: 1.3905 - val_accuracy: 0.5375\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2400 - accuracy: 0.5303 - val_loss: 1.3323 - val_accuracy: 0.5531\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4867 - accuracy: 0.5053 - val_loss: 1.4332 - val_accuracy: 0.5211\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3245 - accuracy: 0.4923 - val_loss: 1.4056 - val_accuracy: 0.5364\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8265 - accuracy: 0.4782 - val_loss: 1.3355 - val_accuracy: 0.5439\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1100 - accuracy: 0.5338 - val_loss: 1.3083 - val_accuracy: 0.5609\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2640 - accuracy: 0.4993 - val_loss: 1.4213 - val_accuracy: 0.5293\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1510 - accuracy: 0.5093 - val_loss: 1.5625 - val_accuracy: 0.4767\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0168 - accuracy: 0.5388 - val_loss: 1.3075 - val_accuracy: 0.5783\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9695 - accuracy: 0.5575 - val_loss: 1.4090 - val_accuracy: 0.5382\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9499 - accuracy: 0.5683 - val_loss: 1.1357 - val_accuracy: 0.6348\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9863 - accuracy: 0.5757 - val_loss: 1.2638 - val_accuracy: 0.6000\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0085 - accuracy: 0.5422 - val_loss: 1.1780 - val_accuracy: 0.6156\n",
      "Epoch 382/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9248 - accuracy: 0.5804 - val_loss: 1.4429 - val_accuracy: 0.5250\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8493 - accuracy: 0.5887 - val_loss: 1.2316 - val_accuracy: 0.5982\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0785 - accuracy: 0.5197 - val_loss: 1.4543 - val_accuracy: 0.5151\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9300 - accuracy: 0.5703 - val_loss: 1.1739 - val_accuracy: 0.6167\n",
      "\n",
      "Validation 1, fold 3 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8743 - accuracy: 0.0885 - val_loss: 2.8050 - val_accuracy: 0.1187\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7749 - accuracy: 0.1347 - val_loss: 2.3654 - val_accuracy: 0.2302\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.5307 - accuracy: 0.1908 - val_loss: 2.3587 - val_accuracy: 0.2494\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3634 - accuracy: 0.2189 - val_loss: 2.1423 - val_accuracy: 0.3002\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1972 - accuracy: 0.2316 - val_loss: 2.1427 - val_accuracy: 0.2480\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1965 - accuracy: 0.2401 - val_loss: 2.1880 - val_accuracy: 0.2458\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1898 - accuracy: 0.2550 - val_loss: 2.1435 - val_accuracy: 0.2458\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0637 - accuracy: 0.2688 - val_loss: 2.0862 - val_accuracy: 0.3222\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1486 - accuracy: 0.2864 - val_loss: 2.0271 - val_accuracy: 0.3073\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2391 - accuracy: 0.2682 - val_loss: 1.8962 - val_accuracy: 0.3545\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9403 - accuracy: 0.3259 - val_loss: 1.7365 - val_accuracy: 0.4110\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9740 - accuracy: 0.3396 - val_loss: 1.7915 - val_accuracy: 0.4117\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1236 - accuracy: 0.3058 - val_loss: 1.8410 - val_accuracy: 0.3574\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7566 - accuracy: 0.3554 - val_loss: 1.8496 - val_accuracy: 0.3815\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.6833 - accuracy: 0.3714 - val_loss: 1.8999 - val_accuracy: 0.3282\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6455 - accuracy: 0.3629 - val_loss: 1.7116 - val_accuracy: 0.3989\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5460 - accuracy: 0.3853 - val_loss: 1.5458 - val_accuracy: 0.4632\n",
      "Epoch 18/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6096 - accuracy: 0.3955 - val_loss: 1.7602 - val_accuracy: 0.3982\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6104 - accuracy: 0.3946 - val_loss: 1.4890 - val_accuracy: 0.5076\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5330 - accuracy: 0.4153 - val_loss: 1.7207 - val_accuracy: 0.4135\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5635 - accuracy: 0.3972 - val_loss: 1.5720 - val_accuracy: 0.4497\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4649 - accuracy: 0.4142 - val_loss: 1.5170 - val_accuracy: 0.4760\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4137 - accuracy: 0.4337 - val_loss: 1.5257 - val_accuracy: 0.4877\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4212 - accuracy: 0.4470 - val_loss: 1.9085 - val_accuracy: 0.4782\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4251 - accuracy: 0.4568 - val_loss: 1.6079 - val_accuracy: 0.4796\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3363 - accuracy: 0.4512 - val_loss: 1.7052 - val_accuracy: 0.4348\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3021 - accuracy: 0.4678 - val_loss: 1.4313 - val_accuracy: 0.5378\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3988 - accuracy: 0.4601 - val_loss: 1.4414 - val_accuracy: 0.5272\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2530 - accuracy: 0.4758 - val_loss: 1.5072 - val_accuracy: 0.5275\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5814 - accuracy: 0.4365 - val_loss: 1.4272 - val_accuracy: 0.5162\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4959 - accuracy: 0.4306 - val_loss: 1.4358 - val_accuracy: 0.5258\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3636 - accuracy: 0.4630 - val_loss: 1.4904 - val_accuracy: 0.5101\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3445 - accuracy: 0.4759 - val_loss: 1.3175 - val_accuracy: 0.5634\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2117 - accuracy: 0.4988 - val_loss: 1.6051 - val_accuracy: 0.4863\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3139 - accuracy: 0.4957 - val_loss: 1.4125 - val_accuracy: 0.5194\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4049 - accuracy: 0.4840 - val_loss: 1.3844 - val_accuracy: 0.5421\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4995 - accuracy: 0.4687 - val_loss: 1.4180 - val_accuracy: 0.5176\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2066 - accuracy: 0.4837 - val_loss: 1.4385 - val_accuracy: 0.5211\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1584 - accuracy: 0.5082 - val_loss: 1.5187 - val_accuracy: 0.5083\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1639 - accuracy: 0.4960 - val_loss: 1.2991 - val_accuracy: 0.5631\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2159 - accuracy: 0.5132 - val_loss: 1.2869 - val_accuracy: 0.5726\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1986 - accuracy: 0.5044 - val_loss: 1.2737 - val_accuracy: 0.5798\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1743 - accuracy: 0.5163 - val_loss: 1.2217 - val_accuracy: 0.5847\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1431 - accuracy: 0.5285 - val_loss: 1.3964 - val_accuracy: 0.5350\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1270 - accuracy: 0.5180 - val_loss: 1.2066 - val_accuracy: 0.6085\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0238 - accuracy: 0.5375 - val_loss: 1.2350 - val_accuracy: 0.5673\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1810 - accuracy: 0.5133 - val_loss: 1.4763 - val_accuracy: 0.5030\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0887 - accuracy: 0.5154 - val_loss: 1.2714 - val_accuracy: 0.5666\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1298 - accuracy: 0.5118 - val_loss: 1.2345 - val_accuracy: 0.5833\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0825 - accuracy: 0.5320 - val_loss: 1.2026 - val_accuracy: 0.6107\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1732 - accuracy: 0.5400 - val_loss: 1.3780 - val_accuracy: 0.5577\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1703 - accuracy: 0.5136 - val_loss: 1.3302 - val_accuracy: 0.5549\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2109 - accuracy: 0.5138 - val_loss: 1.2160 - val_accuracy: 0.5986\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2501 - accuracy: 0.4893 - val_loss: 1.4137 - val_accuracy: 0.5243\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1236 - accuracy: 0.5343 - val_loss: 1.2455 - val_accuracy: 0.5645\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1494 - accuracy: 0.5244 - val_loss: 1.2548 - val_accuracy: 0.5758\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0680 - accuracy: 0.5421 - val_loss: 1.2289 - val_accuracy: 0.5989\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0372 - accuracy: 0.5426 - val_loss: 1.3427 - val_accuracy: 0.5425\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0490 - accuracy: 0.5340 - val_loss: 1.1950 - val_accuracy: 0.6011\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0084 - accuracy: 0.5467 - val_loss: 1.2635 - val_accuracy: 0.5670\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0981 - accuracy: 0.5316 - val_loss: 1.1790 - val_accuracy: 0.6007\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4895 - accuracy: 0.5293 - val_loss: 1.7059 - val_accuracy: 0.4195\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5684 - accuracy: 0.4581 - val_loss: 1.2889 - val_accuracy: 0.5545\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1779 - accuracy: 0.4964 - val_loss: 1.2569 - val_accuracy: 0.5616\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1440 - accuracy: 0.5079 - val_loss: 1.3265 - val_accuracy: 0.5258\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0583 - accuracy: 0.5248 - val_loss: 1.2300 - val_accuracy: 0.5762\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2680 - accuracy: 0.5257 - val_loss: 1.4358 - val_accuracy: 0.5123\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0270 - accuracy: 0.5222 - val_loss: 1.2045 - val_accuracy: 0.5872\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0477 - accuracy: 0.5477 - val_loss: 1.2808 - val_accuracy: 0.5663\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3292 - accuracy: 0.5195 - val_loss: 1.1604 - val_accuracy: 0.6117\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1480 - accuracy: 0.5181 - val_loss: 1.3203 - val_accuracy: 0.5609\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0152 - accuracy: 0.5415 - val_loss: 1.2346 - val_accuracy: 0.5819\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9880 - accuracy: 0.5522 - val_loss: 1.1282 - val_accuracy: 0.6171\n",
      "Epoch 74/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9384 - accuracy: 0.5512 - val_loss: 1.1622 - val_accuracy: 0.6163\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9110 - accuracy: 0.5695 - val_loss: 1.1424 - val_accuracy: 0.6178\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0607 - accuracy: 0.5388 - val_loss: 1.2541 - val_accuracy: 0.5741\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2790 - accuracy: 0.5121 - val_loss: 1.2357 - val_accuracy: 0.5790\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1164 - accuracy: 0.5275 - val_loss: 1.2435 - val_accuracy: 0.5826\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0515 - accuracy: 0.5385 - val_loss: 1.2094 - val_accuracy: 0.5798\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9907 - accuracy: 0.5413 - val_loss: 1.3218 - val_accuracy: 0.5481\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1637 - accuracy: 0.5224 - val_loss: 1.1805 - val_accuracy: 0.5801\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9604 - accuracy: 0.5465 - val_loss: 1.0971 - val_accuracy: 0.6149\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1202 - accuracy: 0.5414 - val_loss: 1.1522 - val_accuracy: 0.5972\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0236 - accuracy: 0.5505 - val_loss: 1.2499 - val_accuracy: 0.5758\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9554 - accuracy: 0.5648 - val_loss: 1.0957 - val_accuracy: 0.6284\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0468 - accuracy: 0.5394 - val_loss: 1.1397 - val_accuracy: 0.6064\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9134 - accuracy: 0.5721 - val_loss: 1.0625 - val_accuracy: 0.6306\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8991 - accuracy: 0.5755 - val_loss: 1.0519 - val_accuracy: 0.6405\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8851 - accuracy: 0.5860 - val_loss: 1.1403 - val_accuracy: 0.6124\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9734 - accuracy: 0.5663 - val_loss: 1.0938 - val_accuracy: 0.6327\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9570 - accuracy: 0.5802 - val_loss: 1.0840 - val_accuracy: 0.6291\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9032 - accuracy: 0.5811 - val_loss: 1.6337 - val_accuracy: 0.5531\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0773 - accuracy: 0.5596 - val_loss: 1.0893 - val_accuracy: 0.6341\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3489 - accuracy: 0.5274 - val_loss: 1.2299 - val_accuracy: 0.5581\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1379 - accuracy: 0.5386 - val_loss: 1.1031 - val_accuracy: 0.6202\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9305 - accuracy: 0.5762 - val_loss: 1.3418 - val_accuracy: 0.5744\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9429 - accuracy: 0.5696 - val_loss: 1.0463 - val_accuracy: 0.6440\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9258 - accuracy: 0.5734 - val_loss: 1.1744 - val_accuracy: 0.6153\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3278 - accuracy: 0.5239 - val_loss: 1.2994 - val_accuracy: 0.5442\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1598 - accuracy: 0.5317 - val_loss: 1.2987 - val_accuracy: 0.5634\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9929 - accuracy: 0.5608 - val_loss: 1.1688 - val_accuracy: 0.6021\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9299 - accuracy: 0.5780 - val_loss: 1.1082 - val_accuracy: 0.6298\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9013 - accuracy: 0.5853 - val_loss: 1.2055 - val_accuracy: 0.5954\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1103 - accuracy: 0.5338 - val_loss: 1.3669 - val_accuracy: 0.5357\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3544 - accuracy: 0.5233 - val_loss: 1.1808 - val_accuracy: 0.5918\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3929 - accuracy: 0.5450 - val_loss: 1.3860 - val_accuracy: 0.5446\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4402 - accuracy: 0.5194 - val_loss: 1.3059 - val_accuracy: 0.5627\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1081 - accuracy: 0.5380 - val_loss: 1.1029 - val_accuracy: 0.6238\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1237 - accuracy: 0.5361 - val_loss: 1.1246 - val_accuracy: 0.6195\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0271 - accuracy: 0.5462 - val_loss: 1.2258 - val_accuracy: 0.5890\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9902 - accuracy: 0.5597 - val_loss: 1.1773 - val_accuracy: 0.6039\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1217 - accuracy: 0.5683 - val_loss: 1.2001 - val_accuracy: 0.6085\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9602 - accuracy: 0.5694 - val_loss: 1.1383 - val_accuracy: 0.6167\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8593 - accuracy: 0.5882 - val_loss: 1.1278 - val_accuracy: 0.6238\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9620 - accuracy: 0.5630 - val_loss: 1.2702 - val_accuracy: 0.5570\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9951 - accuracy: 0.5521 - val_loss: 1.1646 - val_accuracy: 0.5964\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1244 - accuracy: 0.5316 - val_loss: 1.2867 - val_accuracy: 0.5570\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0315 - accuracy: 0.5390 - val_loss: 1.0760 - val_accuracy: 0.6277\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 3.2160 - accuracy: 0.5341 - val_loss: 1.4329 - val_accuracy: 0.5233\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9432 - accuracy: 0.4693 - val_loss: 1.3666 - val_accuracy: 0.5506\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3203 - accuracy: 0.5037 - val_loss: 1.3678 - val_accuracy: 0.5560\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4667 - accuracy: 0.5144 - val_loss: 1.2525 - val_accuracy: 0.5812\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1835 - accuracy: 0.5298 - val_loss: 1.6595 - val_accuracy: 0.4892\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1669 - accuracy: 0.5126 - val_loss: 1.1566 - val_accuracy: 0.6096\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1966 - accuracy: 0.5340 - val_loss: 1.2929 - val_accuracy: 0.5524\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0906 - accuracy: 0.5341 - val_loss: 1.1101 - val_accuracy: 0.6270\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9834 - accuracy: 0.5529 - val_loss: 1.1055 - val_accuracy: 0.6224\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0256 - accuracy: 0.5549 - val_loss: 1.4387 - val_accuracy: 0.5052\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3336 - accuracy: 0.5130 - val_loss: 1.2572 - val_accuracy: 0.5815\n",
      "Epoch 130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0383 - accuracy: 0.5584 - val_loss: 1.1126 - val_accuracy: 0.6288\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9436 - accuracy: 0.5685 - val_loss: 1.1611 - val_accuracy: 0.6032\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9056 - accuracy: 0.5837 - val_loss: 1.0525 - val_accuracy: 0.6398\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9241 - accuracy: 0.5844 - val_loss: 1.1818 - val_accuracy: 0.6014\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9577 - accuracy: 0.5576 - val_loss: 1.2410 - val_accuracy: 0.5652\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1067 - accuracy: 0.5294 - val_loss: 1.2520 - val_accuracy: 0.5748\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9497 - accuracy: 0.5516 - val_loss: 1.0663 - val_accuracy: 0.6529\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9069 - accuracy: 0.5800 - val_loss: 1.1191 - val_accuracy: 0.6256\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2025 - accuracy: 0.5387 - val_loss: 1.3670 - val_accuracy: 0.5673\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0226 - accuracy: 0.5342 - val_loss: 1.1361 - val_accuracy: 0.6039\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5052 - accuracy: 0.5462 - val_loss: 1.7699 - val_accuracy: 0.4039\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4026 - accuracy: 0.4467 - val_loss: 1.2970 - val_accuracy: 0.5385\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3694 - accuracy: 0.4887 - val_loss: 1.3026 - val_accuracy: 0.5538\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3160 - accuracy: 0.5112 - val_loss: 1.2619 - val_accuracy: 0.5762\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9956 - accuracy: 0.5500 - val_loss: 1.1438 - val_accuracy: 0.6036\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9695 - accuracy: 0.5587 - val_loss: 1.1385 - val_accuracy: 0.6153\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0232 - accuracy: 0.5598 - val_loss: 1.1303 - val_accuracy: 0.6028\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9655 - accuracy: 0.5599 - val_loss: 1.1878 - val_accuracy: 0.5975\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9267 - accuracy: 0.5760 - val_loss: 1.1818 - val_accuracy: 0.6032\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9374 - accuracy: 0.5716 - val_loss: 1.0449 - val_accuracy: 0.6558\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8806 - accuracy: 0.5835 - val_loss: 1.1299 - val_accuracy: 0.6167\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9121 - accuracy: 0.5758 - val_loss: 1.0583 - val_accuracy: 0.6309\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8504 - accuracy: 0.5916 - val_loss: 1.1409 - val_accuracy: 0.6039\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8956 - accuracy: 0.5926 - val_loss: 1.1502 - val_accuracy: 0.6085\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0030 - accuracy: 0.5584 - val_loss: 1.0511 - val_accuracy: 0.6437\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3653 - accuracy: 0.5456 - val_loss: 1.1001 - val_accuracy: 0.6139\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0129 - accuracy: 0.5550 - val_loss: 1.1280 - val_accuracy: 0.6139\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0645 - accuracy: 0.5765 - val_loss: 2.4104 - val_accuracy: 0.4629\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8144 - accuracy: 0.5203 - val_loss: 1.1384 - val_accuracy: 0.6231\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9218 - accuracy: 0.5782 - val_loss: 1.1153 - val_accuracy: 0.6139\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8599 - accuracy: 0.5958 - val_loss: 1.4001 - val_accuracy: 0.5393\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1281 - accuracy: 0.5347 - val_loss: 1.2272 - val_accuracy: 0.5769\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9891 - accuracy: 0.5687 - val_loss: 1.0473 - val_accuracy: 0.6401\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8854 - accuracy: 0.5861 - val_loss: 1.0521 - val_accuracy: 0.6451\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8539 - accuracy: 0.5983 - val_loss: 1.1695 - val_accuracy: 0.5975\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0796 - accuracy: 0.5537 - val_loss: 1.1740 - val_accuracy: 0.6071\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0667 - accuracy: 0.5464 - val_loss: 1.0879 - val_accuracy: 0.6245\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8453 - accuracy: 0.5999 - val_loss: 1.0478 - val_accuracy: 0.6352\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9117 - accuracy: 0.5779 - val_loss: 1.0794 - val_accuracy: 0.6149\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8472 - accuracy: 0.6055 - val_loss: 1.1054 - val_accuracy: 0.6202\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9815 - accuracy: 0.5957 - val_loss: 1.1440 - val_accuracy: 0.6213\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0316 - accuracy: 0.5653 - val_loss: 1.3752 - val_accuracy: 0.5275\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1774 - accuracy: 0.5512 - val_loss: 1.7718 - val_accuracy: 0.4881\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2353 - accuracy: 0.5251 - val_loss: 1.1336 - val_accuracy: 0.6316\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9556 - accuracy: 0.5686 - val_loss: 1.0380 - val_accuracy: 0.6508\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1015 - accuracy: 0.5707 - val_loss: 1.3564 - val_accuracy: 0.5631\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9763 - accuracy: 0.5726 - val_loss: 1.0661 - val_accuracy: 0.6302\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9670 - accuracy: 0.5642 - val_loss: 1.1363 - val_accuracy: 0.6199\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1862 - accuracy: 0.5699 - val_loss: 1.1609 - val_accuracy: 0.5982\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4218 - accuracy: 0.5684 - val_loss: 1.1447 - val_accuracy: 0.6146\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9739 - accuracy: 0.5727 - val_loss: 1.0829 - val_accuracy: 0.6167\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9489 - accuracy: 0.5749 - val_loss: 1.2635 - val_accuracy: 0.5787\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8605 - accuracy: 0.5925 - val_loss: 1.1214 - val_accuracy: 0.6298\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9133 - accuracy: 0.5847 - val_loss: 1.0496 - val_accuracy: 0.6487\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8103 - accuracy: 0.6096 - val_loss: 1.1692 - val_accuracy: 0.6139\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8130 - accuracy: 0.5970 - val_loss: 0.9890 - val_accuracy: 0.6657\n",
      "Epoch 186/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0006 - accuracy: 0.5890 - val_loss: 1.1083 - val_accuracy: 0.6259\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9068 - accuracy: 0.5928 - val_loss: 1.0201 - val_accuracy: 0.6565\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9611 - accuracy: 0.5834 - val_loss: 1.1011 - val_accuracy: 0.6277\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8752 - accuracy: 0.5869 - val_loss: 1.1037 - val_accuracy: 0.6266\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8846 - accuracy: 0.5861 - val_loss: 1.1401 - val_accuracy: 0.6174\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9326 - accuracy: 0.5644 - val_loss: 1.0321 - val_accuracy: 0.6494\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8053 - accuracy: 0.6072 - val_loss: 1.0298 - val_accuracy: 0.6469\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8456 - accuracy: 0.6053 - val_loss: 1.0269 - val_accuracy: 0.6384\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8247 - accuracy: 0.6056 - val_loss: 1.1872 - val_accuracy: 0.5993\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4975 - accuracy: 0.5258 - val_loss: 1.2104 - val_accuracy: 0.5847\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9529 - accuracy: 0.5635 - val_loss: 1.0752 - val_accuracy: 0.6291\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8272 - accuracy: 0.6017 - val_loss: 0.9844 - val_accuracy: 0.6668\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8534 - accuracy: 0.6001 - val_loss: 0.9889 - val_accuracy: 0.6625\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8851 - accuracy: 0.5993 - val_loss: 1.0304 - val_accuracy: 0.6437\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8405 - accuracy: 0.6026 - val_loss: 1.3851 - val_accuracy: 0.5567\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8437 - accuracy: 0.5905 - val_loss: 0.9850 - val_accuracy: 0.6629\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7659 - accuracy: 0.6143 - val_loss: 1.0308 - val_accuracy: 0.6419\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9385 - accuracy: 0.5609 - val_loss: 1.0726 - val_accuracy: 0.6458\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8264 - accuracy: 0.5934 - val_loss: 1.0176 - val_accuracy: 0.6494\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9634 - accuracy: 0.5775 - val_loss: 1.1220 - val_accuracy: 0.6078\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8322 - accuracy: 0.5128 - val_loss: 1.5234 - val_accuracy: 0.5187\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1830 - accuracy: 0.5421 - val_loss: 1.1913 - val_accuracy: 0.6082\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2935 - accuracy: 0.5320 - val_loss: 1.3216 - val_accuracy: 0.5513\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9063 - accuracy: 0.5742 - val_loss: 1.0335 - val_accuracy: 0.6455\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1094 - accuracy: 0.5716 - val_loss: 1.1400 - val_accuracy: 0.6057\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8941 - accuracy: 0.5871 - val_loss: 1.1022 - val_accuracy: 0.6266\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8400 - accuracy: 0.6010 - val_loss: 1.0664 - val_accuracy: 0.6401\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0084 - accuracy: 0.5734 - val_loss: 1.0560 - val_accuracy: 0.6430\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8163 - accuracy: 0.6030 - val_loss: 1.0805 - val_accuracy: 0.6313\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9007 - accuracy: 0.5861 - val_loss: 1.0855 - val_accuracy: 0.6256\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8523 - accuracy: 0.6063 - val_loss: 1.0183 - val_accuracy: 0.6487\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8016 - accuracy: 0.6091 - val_loss: 0.9822 - val_accuracy: 0.6615\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8434 - accuracy: 0.5913 - val_loss: 1.0557 - val_accuracy: 0.6490\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9598 - accuracy: 0.5802 - val_loss: 1.0548 - val_accuracy: 0.6302\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8411 - accuracy: 0.5943 - val_loss: 1.0888 - val_accuracy: 0.6391\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8098 - accuracy: 0.6129 - val_loss: 0.9946 - val_accuracy: 0.6590\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7553 - accuracy: 0.6318 - val_loss: 1.0121 - val_accuracy: 0.6529\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9079 - accuracy: 0.5874 - val_loss: 1.0942 - val_accuracy: 0.6359\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1605 - accuracy: 0.5571 - val_loss: 1.0779 - val_accuracy: 0.6298\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6841 - accuracy: 0.5286 - val_loss: 1.3234 - val_accuracy: 0.5631\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5238 - accuracy: 0.5471 - val_loss: 1.1398 - val_accuracy: 0.6153\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1625 - accuracy: 0.5640 - val_loss: 1.0988 - val_accuracy: 0.6234\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8768 - accuracy: 0.5837 - val_loss: 1.0197 - val_accuracy: 0.6440\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8057 - accuracy: 0.6062 - val_loss: 1.0488 - val_accuracy: 0.6323\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8040 - accuracy: 0.6061 - val_loss: 1.0524 - val_accuracy: 0.6309\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8677 - accuracy: 0.5990 - val_loss: 1.0925 - val_accuracy: 0.6263\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8752 - accuracy: 0.5911 - val_loss: 1.0269 - val_accuracy: 0.6487\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7471 - accuracy: 0.6198 - val_loss: 1.0054 - val_accuracy: 0.6593\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8326 - accuracy: 0.6031 - val_loss: 1.0329 - val_accuracy: 0.6416\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8777 - accuracy: 0.5955 - val_loss: 1.1634 - val_accuracy: 0.6210\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8198 - accuracy: 0.6055 - val_loss: 1.0997 - val_accuracy: 0.6146\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9320 - accuracy: 0.5686 - val_loss: 1.0990 - val_accuracy: 0.6281\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7429 - accuracy: 0.6170 - val_loss: 0.9412 - val_accuracy: 0.6799\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8006 - accuracy: 0.6056 - val_loss: 0.9912 - val_accuracy: 0.6636\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9068 - accuracy: 0.5969 - val_loss: 1.2300 - val_accuracy: 0.6028\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8401 - accuracy: 0.6038 - val_loss: 0.9972 - val_accuracy: 0.6600\n",
      "Epoch 242/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8514 - accuracy: 0.6030 - val_loss: 1.0666 - val_accuracy: 0.6330\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9286 - accuracy: 0.5854 - val_loss: 1.3370 - val_accuracy: 0.5609\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8473 - accuracy: 0.5036 - val_loss: 1.1952 - val_accuracy: 0.6053\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9416 - accuracy: 0.5638 - val_loss: 1.0629 - val_accuracy: 0.6384\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9211 - accuracy: 0.5788 - val_loss: 1.1827 - val_accuracy: 0.6011\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9153 - accuracy: 0.5895 - val_loss: 1.6052 - val_accuracy: 0.5194\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8960 - accuracy: 0.5867 - val_loss: 1.0414 - val_accuracy: 0.6423\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7970 - accuracy: 0.6169 - val_loss: 0.9913 - val_accuracy: 0.6725\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7431 - accuracy: 0.6250 - val_loss: 1.0748 - val_accuracy: 0.6409\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7390 - accuracy: 0.6277 - val_loss: 0.9170 - val_accuracy: 0.6824\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0157 - accuracy: 0.5472 - val_loss: 1.1240 - val_accuracy: 0.6071\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9539 - accuracy: 0.5839 - val_loss: 1.0723 - val_accuracy: 0.6455\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7821 - accuracy: 0.6119 - val_loss: 0.9673 - val_accuracy: 0.6607\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8170 - accuracy: 0.6169 - val_loss: 0.9888 - val_accuracy: 0.6607\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0629 - accuracy: 0.5983 - val_loss: 1.2258 - val_accuracy: 0.5961\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3261 - accuracy: 0.4832 - val_loss: 1.4148 - val_accuracy: 0.5311\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1895 - accuracy: 0.5188 - val_loss: 1.2135 - val_accuracy: 0.5989\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9428 - accuracy: 0.5858 - val_loss: 1.0932 - val_accuracy: 0.6369\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8137 - accuracy: 0.5996 - val_loss: 1.0130 - val_accuracy: 0.6515\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8567 - accuracy: 0.5966 - val_loss: 1.0617 - val_accuracy: 0.6416\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8232 - accuracy: 0.5993 - val_loss: 0.9653 - val_accuracy: 0.6906\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1399 - accuracy: 0.5822 - val_loss: 1.0322 - val_accuracy: 0.6618\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8593 - accuracy: 0.6021 - val_loss: 1.0169 - val_accuracy: 0.6590\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8147 - accuracy: 0.6248 - val_loss: 1.0031 - val_accuracy: 0.6693\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8847 - accuracy: 0.6121 - val_loss: 1.0421 - val_accuracy: 0.6533\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2883 - accuracy: 0.5423 - val_loss: 1.5236 - val_accuracy: 0.4927\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2126 - accuracy: 0.5325 - val_loss: 1.1095 - val_accuracy: 0.6398\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9080 - accuracy: 0.6032 - val_loss: 1.0846 - val_accuracy: 0.6334\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7779 - accuracy: 0.6102 - val_loss: 1.0487 - val_accuracy: 0.6448\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3415 - accuracy: 0.5539 - val_loss: 1.2841 - val_accuracy: 0.5691\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8634 - accuracy: 0.5877 - val_loss: 1.0231 - val_accuracy: 0.6643\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9189 - accuracy: 0.6008 - val_loss: 1.1746 - val_accuracy: 0.6092\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8165 - accuracy: 0.6096 - val_loss: 1.0322 - val_accuracy: 0.6622\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9773 - accuracy: 0.5871 - val_loss: 1.0285 - val_accuracy: 0.6579\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5315 - accuracy: 0.5197 - val_loss: 1.2024 - val_accuracy: 0.6092\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2244 - accuracy: 0.5404 - val_loss: 1.1983 - val_accuracy: 0.6014\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9889 - accuracy: 0.5701 - val_loss: 1.1403 - val_accuracy: 0.6210\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8840 - accuracy: 0.5941 - val_loss: 1.3230 - val_accuracy: 0.5755\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8262 - accuracy: 0.6001 - val_loss: 1.0192 - val_accuracy: 0.6561\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4701 - accuracy: 0.5729 - val_loss: 1.2195 - val_accuracy: 0.5876\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2365 - accuracy: 0.5520 - val_loss: 1.0906 - val_accuracy: 0.6391\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0167 - accuracy: 0.5690 - val_loss: 1.1215 - val_accuracy: 0.6295\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0658 - accuracy: 0.5708 - val_loss: 1.1016 - val_accuracy: 0.6259\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8889 - accuracy: 0.5886 - val_loss: 1.0515 - val_accuracy: 0.6455\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8800 - accuracy: 0.5917 - val_loss: 1.0202 - val_accuracy: 0.6629\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8218 - accuracy: 0.6037 - val_loss: 1.0275 - val_accuracy: 0.6551\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7707 - accuracy: 0.6252 - val_loss: 1.1656 - val_accuracy: 0.6018\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8390 - accuracy: 0.6101 - val_loss: 1.4124 - val_accuracy: 0.5577\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5054 - accuracy: 0.5472 - val_loss: 1.1320 - val_accuracy: 0.6295\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9816 - accuracy: 0.5853 - val_loss: 1.2230 - val_accuracy: 0.5975\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8970 - accuracy: 0.5956 - val_loss: 1.2817 - val_accuracy: 0.5787\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8920 - accuracy: 0.5953 - val_loss: 1.1804 - val_accuracy: 0.5968\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8782 - accuracy: 0.5948 - val_loss: 1.1890 - val_accuracy: 0.5996\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9258 - accuracy: 0.5897 - val_loss: 1.0310 - val_accuracy: 0.6529\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7910 - accuracy: 0.6149 - val_loss: 1.0875 - val_accuracy: 0.6440\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8353 - accuracy: 0.6207 - val_loss: 1.1271 - val_accuracy: 0.6377\n",
      "Epoch 298/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8217 - accuracy: 0.6193 - val_loss: 0.9345 - val_accuracy: 0.6792\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0248 - accuracy: 0.5705 - val_loss: 1.0309 - val_accuracy: 0.6561\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9260 - accuracy: 0.5856 - val_loss: 1.1745 - val_accuracy: 0.5996\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8123 - accuracy: 0.5988 - val_loss: 1.0006 - val_accuracy: 0.6632\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1055 - accuracy: 0.5765 - val_loss: 1.0402 - val_accuracy: 0.6583\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9677 - accuracy: 0.5750 - val_loss: 1.0430 - val_accuracy: 0.6565\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9379 - accuracy: 0.5959 - val_loss: 1.1877 - val_accuracy: 0.6103\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7934 - accuracy: 0.6101 - val_loss: 1.0772 - val_accuracy: 0.6401\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8180 - accuracy: 0.6092 - val_loss: 1.0385 - val_accuracy: 0.6394\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8625 - accuracy: 0.6137 - val_loss: 0.9699 - val_accuracy: 0.6774\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7806 - accuracy: 0.6290 - val_loss: 0.9630 - val_accuracy: 0.6778\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2649 - accuracy: 0.5456 - val_loss: 1.0496 - val_accuracy: 0.6504\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3955 - accuracy: 0.5589 - val_loss: 1.3166 - val_accuracy: 0.5499\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0607 - accuracy: 0.5657 - val_loss: 1.0571 - val_accuracy: 0.6625\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8733 - accuracy: 0.5955 - val_loss: 1.1161 - val_accuracy: 0.6309\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0234 - accuracy: 0.5443 - val_loss: 1.2390 - val_accuracy: 0.5829\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8574 - accuracy: 0.5781 - val_loss: 1.1720 - val_accuracy: 0.6121\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9307 - accuracy: 0.5970 - val_loss: 1.0620 - val_accuracy: 0.6440\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8166 - accuracy: 0.6103 - val_loss: 0.9995 - val_accuracy: 0.6586\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9004 - accuracy: 0.5962 - val_loss: 1.1794 - val_accuracy: 0.6071\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7741 - accuracy: 0.6189 - val_loss: 0.9762 - val_accuracy: 0.6675\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9079 - accuracy: 0.6075 - val_loss: 1.0724 - val_accuracy: 0.6448\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8815 - accuracy: 0.5927 - val_loss: 1.0530 - val_accuracy: 0.6547\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8635 - accuracy: 0.6060 - val_loss: 1.1377 - val_accuracy: 0.6089\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8049 - accuracy: 0.6115 - val_loss: 1.1522 - val_accuracy: 0.6107\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8873 - accuracy: 0.6007 - val_loss: 1.0430 - val_accuracy: 0.6512\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9985 - accuracy: 0.5911 - val_loss: 1.2667 - val_accuracy: 0.5773\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0884 - accuracy: 0.5683 - val_loss: 1.1133 - val_accuracy: 0.6199\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8870 - accuracy: 0.5874 - val_loss: 1.0771 - val_accuracy: 0.6334\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9768 - accuracy: 0.5908 - val_loss: 1.1226 - val_accuracy: 0.6199\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8010 - accuracy: 0.6038 - val_loss: 1.1545 - val_accuracy: 0.6078\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7774 - accuracy: 0.6224 - val_loss: 1.1482 - val_accuracy: 0.6156\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7850 - accuracy: 0.6099 - val_loss: 1.1476 - val_accuracy: 0.6220\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7819 - accuracy: 0.6218 - val_loss: 0.9694 - val_accuracy: 0.6671\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9015 - accuracy: 0.5909 - val_loss: 1.1788 - val_accuracy: 0.5904\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9313 - accuracy: 0.5690 - val_loss: 1.1468 - val_accuracy: 0.6270\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7929 - accuracy: 0.6185 - val_loss: 0.9852 - val_accuracy: 0.6735\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7642 - accuracy: 0.6282 - val_loss: 0.9815 - val_accuracy: 0.6753\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7335 - accuracy: 0.6279 - val_loss: 0.9577 - val_accuracy: 0.6785\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8381 - accuracy: 0.6096 - val_loss: 1.1439 - val_accuracy: 0.6277\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7711 - accuracy: 0.6182 - val_loss: 0.9386 - val_accuracy: 0.6757\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7841 - accuracy: 0.6295 - val_loss: 1.2551 - val_accuracy: 0.5663\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8900 - accuracy: 0.5895 - val_loss: 1.5027 - val_accuracy: 0.5609\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5005 - accuracy: 0.5454 - val_loss: 1.1497 - val_accuracy: 0.5925\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0651 - accuracy: 0.5803 - val_loss: 1.2210 - val_accuracy: 0.5943\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8822 - accuracy: 0.5944 - val_loss: 1.0160 - val_accuracy: 0.6750\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0778 - accuracy: 0.5950 - val_loss: 1.1084 - val_accuracy: 0.6323\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8117 - accuracy: 0.5993 - val_loss: 0.9828 - val_accuracy: 0.6668\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7462 - accuracy: 0.6291 - val_loss: 0.9672 - val_accuracy: 0.6778\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9145 - accuracy: 0.5984 - val_loss: 0.9975 - val_accuracy: 0.6593\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7907 - accuracy: 0.6186 - val_loss: 0.9947 - val_accuracy: 0.6767\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7463 - accuracy: 0.6232 - val_loss: 0.9597 - val_accuracy: 0.6760\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7257 - accuracy: 0.6344 - val_loss: 0.9210 - val_accuracy: 0.6885\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7739 - accuracy: 0.6290 - val_loss: 0.9845 - val_accuracy: 0.6593\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8704 - accuracy: 0.5978 - val_loss: 1.0012 - val_accuracy: 0.6490\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1632 - accuracy: 0.5317 - val_loss: 1.2204 - val_accuracy: 0.5901\n",
      "Epoch 354/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9587 - accuracy: 0.5742 - val_loss: 1.1717 - val_accuracy: 0.6053\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9892 - accuracy: 0.5000 - val_loss: 1.6942 - val_accuracy: 0.4178\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6966 - accuracy: 0.3991 - val_loss: 1.4463 - val_accuracy: 0.4945\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1818 - accuracy: 0.5089 - val_loss: 1.1563 - val_accuracy: 0.6075\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9277 - accuracy: 0.5602 - val_loss: 1.1246 - val_accuracy: 0.6146\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9494 - accuracy: 0.5731 - val_loss: 1.0375 - val_accuracy: 0.6497\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8854 - accuracy: 0.6003 - val_loss: 0.9921 - val_accuracy: 0.6668\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1766 - accuracy: 0.5497 - val_loss: 1.3094 - val_accuracy: 0.5648\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8797 - accuracy: 0.5997 - val_loss: 1.0704 - val_accuracy: 0.6462\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8691 - accuracy: 0.5861 - val_loss: 1.1844 - val_accuracy: 0.6014\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8373 - accuracy: 0.6063 - val_loss: 1.0227 - val_accuracy: 0.6607\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1175 - accuracy: 0.5612 - val_loss: 1.4372 - val_accuracy: 0.5638\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8652 - accuracy: 0.5950 - val_loss: 1.0273 - val_accuracy: 0.6458\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9492 - accuracy: 0.5936 - val_loss: 1.0449 - val_accuracy: 0.6476\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8141 - accuracy: 0.6065 - val_loss: 0.9703 - val_accuracy: 0.6774\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7604 - accuracy: 0.6285 - val_loss: 1.0501 - val_accuracy: 0.6494\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9027 - accuracy: 0.6136 - val_loss: 1.0154 - val_accuracy: 0.6643\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7834 - accuracy: 0.6291 - val_loss: 0.9536 - val_accuracy: 0.6732\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.6403 - val_loss: 1.3640 - val_accuracy: 0.5560\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8010 - accuracy: 0.5983 - val_loss: 0.9935 - val_accuracy: 0.6583\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7527 - accuracy: 0.6236 - val_loss: 1.0584 - val_accuracy: 0.6465\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7519 - accuracy: 0.6261 - val_loss: 0.9626 - val_accuracy: 0.6650\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7706 - accuracy: 0.6289 - val_loss: 1.0160 - val_accuracy: 0.6615\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9957 - accuracy: 0.5870 - val_loss: 1.1815 - val_accuracy: 0.6135\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2103 - accuracy: 0.5685 - val_loss: 1.4498 - val_accuracy: 0.5208\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9677 - accuracy: 0.5873 - val_loss: 1.0561 - val_accuracy: 0.6394\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9818 - accuracy: 0.5917 - val_loss: 1.0464 - val_accuracy: 0.6544\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.8835 - accuracy: 0.6002 - val_loss: 0.9459 - val_accuracy: 0.6813\n",
      "Epoch 382/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7267 - accuracy: 0.6372 - val_loss: 0.9117 - val_accuracy: 0.6895\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7543 - accuracy: 0.6265 - val_loss: 0.9663 - val_accuracy: 0.6863\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7310 - accuracy: 0.6390 - val_loss: 0.9720 - val_accuracy: 0.6739\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7605 - accuracy: 0.6120 - val_loss: 1.0734 - val_accuracy: 0.6337\n",
      "Epoch 386/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8362 - accuracy: 0.6141 - val_loss: 1.6840 - val_accuracy: 0.4394\n",
      "Epoch 387/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0762 - accuracy: 0.5207 - val_loss: 1.2476 - val_accuracy: 0.5677\n",
      "Epoch 388/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8562 - accuracy: 0.5732 - val_loss: 1.0736 - val_accuracy: 0.6341\n",
      "Epoch 389/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7549 - accuracy: 0.6155 - val_loss: 0.9937 - val_accuracy: 0.6561\n",
      "Epoch 390/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8688 - accuracy: 0.6130 - val_loss: 1.0969 - val_accuracy: 0.6369\n",
      "Epoch 391/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0114 - accuracy: 0.5215 - val_loss: 1.4250 - val_accuracy: 0.5229\n",
      "Epoch 392/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6929 - accuracy: 0.5132 - val_loss: 1.2052 - val_accuracy: 0.6071\n",
      "Epoch 393/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7404 - accuracy: 0.4829 - val_loss: 1.2983 - val_accuracy: 0.5751\n",
      "Epoch 394/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1765 - accuracy: 0.5388 - val_loss: 1.2068 - val_accuracy: 0.5851\n",
      "Epoch 395/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2682 - accuracy: 0.5472 - val_loss: 1.5028 - val_accuracy: 0.5069\n",
      "Epoch 396/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0506 - accuracy: 0.5498 - val_loss: 1.1096 - val_accuracy: 0.6359\n",
      "Epoch 397/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0153 - accuracy: 0.5646 - val_loss: 1.0800 - val_accuracy: 0.6341\n",
      "Epoch 398/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0494 - accuracy: 0.5859 - val_loss: 1.1786 - val_accuracy: 0.6135\n",
      "Epoch 399/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0387 - accuracy: 0.5659 - val_loss: 1.0541 - val_accuracy: 0.6583\n",
      "Epoch 400/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8230 - accuracy: 0.6154 - val_loss: 0.9947 - val_accuracy: 0.6789\n",
      "Epoch 401/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7691 - accuracy: 0.6274 - val_loss: 0.9633 - val_accuracy: 0.6824\n",
      "Epoch 402/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7104 - accuracy: 0.6315 - val_loss: 0.9976 - val_accuracy: 0.6618\n",
      "Epoch 403/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7379 - accuracy: 0.6221 - val_loss: 0.8772 - val_accuracy: 0.7083\n",
      "Epoch 404/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7641 - accuracy: 0.6266 - val_loss: 1.0784 - val_accuracy: 0.6419\n",
      "Epoch 405/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8374 - accuracy: 0.6035 - val_loss: 1.0060 - val_accuracy: 0.6799\n",
      "Epoch 406/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8269 - accuracy: 0.6052 - val_loss: 1.0050 - val_accuracy: 0.6615\n",
      "Epoch 407/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9735 - accuracy: 0.5960 - val_loss: 1.0625 - val_accuracy: 0.6426\n",
      "Epoch 408/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8281 - accuracy: 0.6182 - val_loss: 0.9409 - val_accuracy: 0.6885\n",
      "Epoch 409/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1960 - accuracy: 0.5782 - val_loss: 1.4190 - val_accuracy: 0.5581\n",
      "Epoch 410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 3.1829 - accuracy: 0.4756 - val_loss: 1.2698 - val_accuracy: 0.6000\n",
      "Epoch 411/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1014 - accuracy: 0.5402 - val_loss: 1.4909 - val_accuracy: 0.5293\n",
      "Epoch 412/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5598 - accuracy: 0.5027 - val_loss: 1.2720 - val_accuracy: 0.5773\n",
      "Epoch 413/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4023 - accuracy: 0.5344 - val_loss: 1.1712 - val_accuracy: 0.6135\n",
      "Epoch 414/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0042 - accuracy: 0.5811 - val_loss: 1.0445 - val_accuracy: 0.6657\n",
      "Epoch 415/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2176 - accuracy: 0.5560 - val_loss: 1.1179 - val_accuracy: 0.6373\n",
      "Epoch 416/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9563 - accuracy: 0.5838 - val_loss: 1.0764 - val_accuracy: 0.6515\n",
      "Epoch 417/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9795 - accuracy: 0.5829 - val_loss: 1.0440 - val_accuracy: 0.6568\n",
      "Epoch 418/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0390 - accuracy: 0.5807 - val_loss: 1.4728 - val_accuracy: 0.5101\n",
      "Epoch 419/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1451 - accuracy: 0.5408 - val_loss: 1.0079 - val_accuracy: 0.6597\n",
      "Epoch 420/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1288 - accuracy: 0.5456 - val_loss: 1.2004 - val_accuracy: 0.6085\n",
      "Epoch 421/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9736 - accuracy: 0.5979 - val_loss: 1.0036 - val_accuracy: 0.6728\n",
      "Epoch 422/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3284 - accuracy: 0.5913 - val_loss: 1.0489 - val_accuracy: 0.6476\n",
      "Epoch 423/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8432 - accuracy: 0.6077 - val_loss: 1.0635 - val_accuracy: 0.6483\n",
      "Epoch 424/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7967 - accuracy: 0.6233 - val_loss: 0.9954 - val_accuracy: 0.6703\n",
      "Epoch 425/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1137 - accuracy: 0.6200 - val_loss: 1.2129 - val_accuracy: 0.5861\n",
      "Epoch 426/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6164 - accuracy: 0.4851 - val_loss: 1.2324 - val_accuracy: 0.5933\n",
      "Epoch 427/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1805 - accuracy: 0.5682 - val_loss: 1.2207 - val_accuracy: 0.6032\n",
      "Epoch 428/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0077 - accuracy: 0.5873 - val_loss: 1.0757 - val_accuracy: 0.6369\n",
      "Epoch 429/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8653 - accuracy: 0.6075 - val_loss: 1.0432 - val_accuracy: 0.6440\n",
      "Epoch 430/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9593 - accuracy: 0.5935 - val_loss: 1.2106 - val_accuracy: 0.6171\n",
      "Epoch 431/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8335 - accuracy: 0.6107 - val_loss: 1.1098 - val_accuracy: 0.6284\n",
      "Epoch 432/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0615 - accuracy: 0.5858 - val_loss: 1.1793 - val_accuracy: 0.6306\n",
      "Epoch 433/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8640 - accuracy: 0.6101 - val_loss: 1.0881 - val_accuracy: 0.6163\n",
      "Epoch 434/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0772 - accuracy: 0.5694 - val_loss: 1.4048 - val_accuracy: 0.5485\n",
      "Epoch 435/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0527 - accuracy: 0.5471 - val_loss: 1.1075 - val_accuracy: 0.6210\n",
      "Epoch 436/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9577 - accuracy: 0.5727 - val_loss: 1.7355 - val_accuracy: 0.4632\n",
      "Epoch 437/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4538 - accuracy: 0.5049 - val_loss: 1.2156 - val_accuracy: 0.5776\n",
      "Epoch 438/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9211 - accuracy: 0.5879 - val_loss: 1.2049 - val_accuracy: 0.5950\n",
      "Epoch 439/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9568 - accuracy: 0.5712 - val_loss: 1.2694 - val_accuracy: 0.5716\n",
      "Epoch 440/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8827 - accuracy: 0.5937 - val_loss: 1.0539 - val_accuracy: 0.6607\n",
      "Epoch 441/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7932 - accuracy: 0.6145 - val_loss: 0.9948 - val_accuracy: 0.6639\n",
      "Epoch 442/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2711 - accuracy: 0.5326 - val_loss: 1.5070 - val_accuracy: 0.4604\n",
      "Epoch 443/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2503 - accuracy: 0.4797 - val_loss: 1.2414 - val_accuracy: 0.5670\n",
      "Epoch 444/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0442 - accuracy: 0.5473 - val_loss: 1.2148 - val_accuracy: 0.5986\n",
      "Epoch 445/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9013 - accuracy: 0.5901 - val_loss: 1.0293 - val_accuracy: 0.6522\n",
      "Epoch 446/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9062 - accuracy: 0.5991 - val_loss: 1.1633 - val_accuracy: 0.6274\n",
      "Epoch 447/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8238 - accuracy: 0.6194 - val_loss: 1.0085 - val_accuracy: 0.6604\n",
      "Epoch 448/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0821 - accuracy: 0.5591 - val_loss: 1.1917 - val_accuracy: 0.5726\n",
      "Epoch 449/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1802 - accuracy: 0.5542 - val_loss: 1.0938 - val_accuracy: 0.6242\n",
      "Epoch 450/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8823 - accuracy: 0.5923 - val_loss: 1.0446 - val_accuracy: 0.6465\n",
      "Epoch 451/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8795 - accuracy: 0.5981 - val_loss: 0.9896 - val_accuracy: 0.6600\n",
      "Epoch 452/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8086 - accuracy: 0.6106 - val_loss: 1.0118 - val_accuracy: 0.6469\n",
      "Epoch 453/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8869 - accuracy: 0.6017 - val_loss: 1.2590 - val_accuracy: 0.5798\n",
      "Epoch 454/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8038 - accuracy: 0.6069 - val_loss: 0.9462 - val_accuracy: 0.6906\n",
      "Epoch 455/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7822 - accuracy: 0.6151 - val_loss: 0.9326 - val_accuracy: 0.6828\n",
      "Epoch 456/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0019 - accuracy: 0.5844 - val_loss: 1.1798 - val_accuracy: 0.6291\n",
      "Epoch 457/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2039 - accuracy: 0.4765 - val_loss: 1.3010 - val_accuracy: 0.5773\n",
      "Epoch 458/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0466 - accuracy: 0.5554 - val_loss: 1.0454 - val_accuracy: 0.6536\n",
      "Epoch 459/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1902 - accuracy: 0.5658 - val_loss: 1.0862 - val_accuracy: 0.6455\n",
      "Epoch 460/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8998 - accuracy: 0.5951 - val_loss: 1.1279 - val_accuracy: 0.6224\n",
      "Epoch 461/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9579 - accuracy: 0.5963 - val_loss: 0.9905 - val_accuracy: 0.6689\n",
      "Epoch 462/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8057 - accuracy: 0.6194 - val_loss: 0.9786 - val_accuracy: 0.6806\n",
      "Epoch 463/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7993 - accuracy: 0.6182 - val_loss: 0.9621 - val_accuracy: 0.6682\n",
      "Epoch 464/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7126 - accuracy: 0.6319 - val_loss: 0.9263 - val_accuracy: 0.6757\n",
      "Epoch 465/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9613 - accuracy: 0.5878 - val_loss: 0.9730 - val_accuracy: 0.6679\n",
      "Epoch 466/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8096 - accuracy: 0.6172 - val_loss: 0.9857 - val_accuracy: 0.6572\n",
      "Epoch 467/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8089 - accuracy: 0.6218 - val_loss: 1.0628 - val_accuracy: 0.6302\n",
      "Epoch 468/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9505 - accuracy: 0.5851 - val_loss: 1.3126 - val_accuracy: 0.5741\n",
      "Epoch 469/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9284 - accuracy: 0.5777 - val_loss: 1.0192 - val_accuracy: 0.6593\n",
      "Epoch 470/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1127 - accuracy: 0.5543 - val_loss: 1.2113 - val_accuracy: 0.5933\n",
      "Epoch 471/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9548 - accuracy: 0.6002 - val_loss: 0.9781 - val_accuracy: 0.6714\n",
      "Epoch 472/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8640 - accuracy: 0.6046 - val_loss: 1.2153 - val_accuracy: 0.5968\n",
      "Epoch 473/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8021 - accuracy: 0.6108 - val_loss: 0.9259 - val_accuracy: 0.6888\n",
      "Epoch 474/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7434 - accuracy: 0.6187 - val_loss: 0.9518 - val_accuracy: 0.6671\n",
      "Epoch 475/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7824 - accuracy: 0.6257 - val_loss: 1.0207 - val_accuracy: 0.6526\n",
      "Epoch 476/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7494 - accuracy: 0.6376 - val_loss: 0.9430 - val_accuracy: 0.6732\n",
      "Epoch 477/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9649 - accuracy: 0.5931 - val_loss: 0.9109 - val_accuracy: 0.6860\n",
      "Epoch 478/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9394 - accuracy: 0.6012 - val_loss: 1.4622 - val_accuracy: 0.5101\n",
      "Epoch 479/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4424 - accuracy: 0.4910 - val_loss: 1.1405 - val_accuracy: 0.6128\n",
      "Epoch 480/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6448 - accuracy: 0.5306 - val_loss: 1.2224 - val_accuracy: 0.5858\n",
      "Epoch 481/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1296 - accuracy: 0.5782 - val_loss: 1.3111 - val_accuracy: 0.5748\n",
      "Epoch 482/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9190 - accuracy: 0.5815 - val_loss: 0.9909 - val_accuracy: 0.6739\n",
      "Epoch 483/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7881 - accuracy: 0.6144 - val_loss: 1.3123 - val_accuracy: 0.5645\n",
      "Epoch 484/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8751 - accuracy: 0.5891 - val_loss: 1.1854 - val_accuracy: 0.6110\n",
      "Epoch 485/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1803 - accuracy: 0.5412 - val_loss: 1.0894 - val_accuracy: 0.6330\n",
      "Epoch 486/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8811 - accuracy: 0.5996 - val_loss: 1.0632 - val_accuracy: 0.6437\n",
      "Epoch 487/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9898 - accuracy: 0.5899 - val_loss: 1.2083 - val_accuracy: 0.6000\n",
      "Epoch 488/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9322 - accuracy: 0.5885 - val_loss: 1.0607 - val_accuracy: 0.6526\n",
      "Epoch 489/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9794 - accuracy: 0.5735 - val_loss: 1.2193 - val_accuracy: 0.5872\n",
      "Epoch 490/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9086 - accuracy: 0.5945 - val_loss: 1.0092 - val_accuracy: 0.6508\n",
      "Epoch 491/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8278 - accuracy: 0.6137 - val_loss: 1.0581 - val_accuracy: 0.6451\n",
      "Epoch 492/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8315 - accuracy: 0.6139 - val_loss: 1.0895 - val_accuracy: 0.6202\n",
      "Epoch 493/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2339 - accuracy: 0.4948 - val_loss: 1.8241 - val_accuracy: 0.3858\n",
      "Epoch 494/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8201 - accuracy: 0.4282 - val_loss: 1.5513 - val_accuracy: 0.4909\n",
      "Epoch 495/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0906 - accuracy: 0.5373 - val_loss: 1.2327 - val_accuracy: 0.5922\n",
      "Epoch 496/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1759 - accuracy: 0.5362 - val_loss: 1.2835 - val_accuracy: 0.5844\n",
      "Epoch 497/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0767 - accuracy: 0.5621 - val_loss: 1.1943 - val_accuracy: 0.6156\n",
      "Epoch 498/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8705 - accuracy: 0.5925 - val_loss: 1.0122 - val_accuracy: 0.6625\n",
      "Epoch 499/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8806 - accuracy: 0.5936 - val_loss: 1.1454 - val_accuracy: 0.6210\n",
      "Epoch 500/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8147 - accuracy: 0.6125 - val_loss: 0.9673 - val_accuracy: 0.6643\n",
      "Epoch 501/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7842 - accuracy: 0.6254 - val_loss: 1.0120 - val_accuracy: 0.6515\n",
      "Epoch 502/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9624 - accuracy: 0.5951 - val_loss: 1.2017 - val_accuracy: 0.6014\n",
      "Epoch 503/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1918 - accuracy: 0.5726 - val_loss: 1.0943 - val_accuracy: 0.6487\n",
      "\n",
      "Validation 1, fold 4 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8725 - accuracy: 0.0258 - val_loss: 2.8144 - val_accuracy: 0.0522\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.6867 - accuracy: 0.1258 - val_loss: 2.2968 - val_accuracy: 0.2007\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.4418 - accuracy: 0.1884 - val_loss: 2.1905 - val_accuracy: 0.2583\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3191 - accuracy: 0.2119 - val_loss: 2.3490 - val_accuracy: 0.2043\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2531 - accuracy: 0.2173 - val_loss: 2.3093 - val_accuracy: 0.2202\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1364 - accuracy: 0.2483 - val_loss: 2.0712 - val_accuracy: 0.2835\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1555 - accuracy: 0.2368 - val_loss: 1.9327 - val_accuracy: 0.3545\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1611 - accuracy: 0.2718 - val_loss: 2.0107 - val_accuracy: 0.2917\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2174 - accuracy: 0.2748 - val_loss: 1.9963 - val_accuracy: 0.3190\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8972 - accuracy: 0.3051 - val_loss: 1.8281 - val_accuracy: 0.4036\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8226 - accuracy: 0.3452 - val_loss: 2.0087 - val_accuracy: 0.2973\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9701 - accuracy: 0.3291 - val_loss: 1.8779 - val_accuracy: 0.3723\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8287 - accuracy: 0.3424 - val_loss: 1.8500 - val_accuracy: 0.3986\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7739 - accuracy: 0.3583 - val_loss: 1.7799 - val_accuracy: 0.4220\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6984 - accuracy: 0.3707 - val_loss: 1.6625 - val_accuracy: 0.4721\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7522 - accuracy: 0.3560 - val_loss: 1.7164 - val_accuracy: 0.4330\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5906 - accuracy: 0.3903 - val_loss: 1.5648 - val_accuracy: 0.4682\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4661 - accuracy: 0.4234 - val_loss: 1.6566 - val_accuracy: 0.4458\n",
      "Epoch 19/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4779 - accuracy: 0.4220 - val_loss: 1.9716 - val_accuracy: 0.3165\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5346 - accuracy: 0.4100 - val_loss: 1.4882 - val_accuracy: 0.5254\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4167 - accuracy: 0.4258 - val_loss: 1.7285 - val_accuracy: 0.4185\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5173 - accuracy: 0.4337 - val_loss: 1.5567 - val_accuracy: 0.5044\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7392 - accuracy: 0.4143 - val_loss: 1.4935 - val_accuracy: 0.5030\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5184 - accuracy: 0.4264 - val_loss: 1.5514 - val_accuracy: 0.4899\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5815 - accuracy: 0.4234 - val_loss: 1.9148 - val_accuracy: 0.3758\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5024 - accuracy: 0.4271 - val_loss: 1.5242 - val_accuracy: 0.4899\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3801 - accuracy: 0.4691 - val_loss: 1.7145 - val_accuracy: 0.4536\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4511 - accuracy: 0.4530 - val_loss: 1.5460 - val_accuracy: 0.4966\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3103 - accuracy: 0.4726 - val_loss: 1.7341 - val_accuracy: 0.4547\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3111 - accuracy: 0.4686 - val_loss: 1.4574 - val_accuracy: 0.5265\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2344 - accuracy: 0.4898 - val_loss: 1.4218 - val_accuracy: 0.5307\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2013 - accuracy: 0.4938 - val_loss: 1.3794 - val_accuracy: 0.5499\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2479 - accuracy: 0.4854 - val_loss: 1.3536 - val_accuracy: 0.5556\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3181 - accuracy: 0.4909 - val_loss: 1.5790 - val_accuracy: 0.4856\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1704 - accuracy: 0.5050 - val_loss: 1.4624 - val_accuracy: 0.5318\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2040 - accuracy: 0.4950 - val_loss: 1.3282 - val_accuracy: 0.5762\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1602 - accuracy: 0.5037 - val_loss: 1.4004 - val_accuracy: 0.5403\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4651 - accuracy: 0.4889 - val_loss: 1.8312 - val_accuracy: 0.3933\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7601 - accuracy: 0.4327 - val_loss: 1.4344 - val_accuracy: 0.5247\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2669 - accuracy: 0.4862 - val_loss: 1.4259 - val_accuracy: 0.5282\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1694 - accuracy: 0.5032 - val_loss: 1.7368 - val_accuracy: 0.4664\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1412 - accuracy: 0.5062 - val_loss: 1.3859 - val_accuracy: 0.5567\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3368 - accuracy: 0.4745 - val_loss: 1.6644 - val_accuracy: 0.4618\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7699 - accuracy: 0.4557 - val_loss: 1.5217 - val_accuracy: 0.4874\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4210 - accuracy: 0.4547 - val_loss: 1.5546 - val_accuracy: 0.4977\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1957 - accuracy: 0.5053 - val_loss: 1.4785 - val_accuracy: 0.5108\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1733 - accuracy: 0.4964 - val_loss: 1.3746 - val_accuracy: 0.5417\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1191 - accuracy: 0.5168 - val_loss: 1.4425 - val_accuracy: 0.5254\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4671 - accuracy: 0.4527 - val_loss: 1.4701 - val_accuracy: 0.4977\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3414 - accuracy: 0.4787 - val_loss: 1.3893 - val_accuracy: 0.5318\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0935 - accuracy: 0.5202 - val_loss: 1.3269 - val_accuracy: 0.5606\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1599 - accuracy: 0.5229 - val_loss: 1.3769 - val_accuracy: 0.5357\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2148 - accuracy: 0.5083 - val_loss: 1.7132 - val_accuracy: 0.4142\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1008 - accuracy: 0.4989 - val_loss: 1.3392 - val_accuracy: 0.5560\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0935 - accuracy: 0.5152 - val_loss: 1.3228 - val_accuracy: 0.5638\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0495 - accuracy: 0.5384 - val_loss: 1.4476 - val_accuracy: 0.5137\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2067 - accuracy: 0.5009 - val_loss: 1.4830 - val_accuracy: 0.5233\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1061 - accuracy: 0.5218 - val_loss: 1.2417 - val_accuracy: 0.5876\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5503 - accuracy: 0.4956 - val_loss: 2.1525 - val_accuracy: 0.3950\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5394 - accuracy: 0.4370 - val_loss: 1.4105 - val_accuracy: 0.5382\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1489 - accuracy: 0.5148 - val_loss: 1.3174 - val_accuracy: 0.5758\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0785 - accuracy: 0.5286 - val_loss: 1.5852 - val_accuracy: 0.4863\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1152 - accuracy: 0.5150 - val_loss: 1.3780 - val_accuracy: 0.5492\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0539 - accuracy: 0.5268 - val_loss: 1.3340 - val_accuracy: 0.5407\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1379 - accuracy: 0.5212 - val_loss: 1.3132 - val_accuracy: 0.5833\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1574 - accuracy: 0.5270 - val_loss: 1.2438 - val_accuracy: 0.5936\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0846 - accuracy: 0.5239 - val_loss: 1.3935 - val_accuracy: 0.5563\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0889 - accuracy: 0.5327 - val_loss: 1.4737 - val_accuracy: 0.4888\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1806 - accuracy: 0.5189 - val_loss: 1.5237 - val_accuracy: 0.4906\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5153 - accuracy: 0.4987 - val_loss: 1.4441 - val_accuracy: 0.5371\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6002 - accuracy: 0.4756 - val_loss: 1.5856 - val_accuracy: 0.4746\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2698 - accuracy: 0.4801 - val_loss: 1.3348 - val_accuracy: 0.5616\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2809 - accuracy: 0.5272 - val_loss: 1.4510 - val_accuracy: 0.5307\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2888 - accuracy: 0.5036 - val_loss: 1.5136 - val_accuracy: 0.4767\n",
      "Epoch 75/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2386 - accuracy: 0.4961 - val_loss: 1.4679 - val_accuracy: 0.5286\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1014 - accuracy: 0.5274 - val_loss: 1.2630 - val_accuracy: 0.5890\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1786 - accuracy: 0.5120 - val_loss: 1.3173 - val_accuracy: 0.5734\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1252 - accuracy: 0.5210 - val_loss: 1.3664 - val_accuracy: 0.5474\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0304 - accuracy: 0.5297 - val_loss: 1.2081 - val_accuracy: 0.6011\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1184 - accuracy: 0.5302 - val_loss: 1.3382 - val_accuracy: 0.5570\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0171 - accuracy: 0.5465 - val_loss: 1.2262 - val_accuracy: 0.5929\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0449 - accuracy: 0.5438 - val_loss: 1.1805 - val_accuracy: 0.6124\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0195 - accuracy: 0.5344 - val_loss: 1.3250 - val_accuracy: 0.5648\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9283 - accuracy: 0.5597 - val_loss: 1.2422 - val_accuracy: 0.5933\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9743 - accuracy: 0.5625 - val_loss: 1.4807 - val_accuracy: 0.5368\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9827 - accuracy: 0.5539 - val_loss: 1.3044 - val_accuracy: 0.5616\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1376 - accuracy: 0.5167 - val_loss: 1.4625 - val_accuracy: 0.5069\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3257 - accuracy: 0.4804 - val_loss: 1.7165 - val_accuracy: 0.5115\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2219 - accuracy: 0.4745 - val_loss: 1.3351 - val_accuracy: 0.5567\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9838 - accuracy: 0.5383 - val_loss: 1.3054 - val_accuracy: 0.5751\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0236 - accuracy: 0.5568 - val_loss: 1.2365 - val_accuracy: 0.5890\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9797 - accuracy: 0.5457 - val_loss: 1.3468 - val_accuracy: 0.5513\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0335 - accuracy: 0.5358 - val_loss: 1.2020 - val_accuracy: 0.6053\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5088 - accuracy: 0.5216 - val_loss: 1.3299 - val_accuracy: 0.5723\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2833 - accuracy: 0.5067 - val_loss: 1.4646 - val_accuracy: 0.5027\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0527 - accuracy: 0.5297 - val_loss: 1.3300 - val_accuracy: 0.5577\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9903 - accuracy: 0.5482 - val_loss: 1.2163 - val_accuracy: 0.6004\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0553 - accuracy: 0.5492 - val_loss: 1.1841 - val_accuracy: 0.6057\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9091 - accuracy: 0.5648 - val_loss: 1.1949 - val_accuracy: 0.6043\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9940 - accuracy: 0.5676 - val_loss: 1.2425 - val_accuracy: 0.5893\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0407 - accuracy: 0.5380 - val_loss: 1.4671 - val_accuracy: 0.5332\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9493 - accuracy: 0.5505 - val_loss: 1.1708 - val_accuracy: 0.6103\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1253 - accuracy: 0.5327 - val_loss: 1.2295 - val_accuracy: 0.5982\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5393 - accuracy: 0.5057 - val_loss: 1.3916 - val_accuracy: 0.5513\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3371 - accuracy: 0.5091 - val_loss: 1.3921 - val_accuracy: 0.5449\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1993 - accuracy: 0.5190 - val_loss: 1.2403 - val_accuracy: 0.5996\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0642 - accuracy: 0.5574 - val_loss: 1.3549 - val_accuracy: 0.5574\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0702 - accuracy: 0.5375 - val_loss: 1.4962 - val_accuracy: 0.5016\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9503 - accuracy: 0.5493 - val_loss: 1.1877 - val_accuracy: 0.6135\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8989 - accuracy: 0.5641 - val_loss: 1.1752 - val_accuracy: 0.6053\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9149 - accuracy: 0.5710 - val_loss: 1.1985 - val_accuracy: 0.6082\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8697 - accuracy: 0.5823 - val_loss: 1.1316 - val_accuracy: 0.6345\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0314 - accuracy: 0.5477 - val_loss: 1.3822 - val_accuracy: 0.5350\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0267 - accuracy: 0.5294 - val_loss: 1.2018 - val_accuracy: 0.6089\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9052 - accuracy: 0.5800 - val_loss: 1.3088 - val_accuracy: 0.5609\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1467 - accuracy: 0.5436 - val_loss: 1.2404 - val_accuracy: 0.5940\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8803 - accuracy: 0.5839 - val_loss: 1.1409 - val_accuracy: 0.6330\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1207 - accuracy: 0.5363 - val_loss: 1.4456 - val_accuracy: 0.5183\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1631 - accuracy: 0.5241 - val_loss: 1.2846 - val_accuracy: 0.5833\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1709 - accuracy: 0.5384 - val_loss: 1.2331 - val_accuracy: 0.5996\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0604 - accuracy: 0.5439 - val_loss: 1.1551 - val_accuracy: 0.6259\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1491 - accuracy: 0.5575 - val_loss: 1.3667 - val_accuracy: 0.5570\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2663 - accuracy: 0.5272 - val_loss: 1.2197 - val_accuracy: 0.5872\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1859 - accuracy: 0.5162 - val_loss: 1.4319 - val_accuracy: 0.5137\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2703 - accuracy: 0.5139 - val_loss: 1.2145 - val_accuracy: 0.6032\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2903 - accuracy: 0.5369 - val_loss: 1.2875 - val_accuracy: 0.5663\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1511 - accuracy: 0.5423 - val_loss: 1.1919 - val_accuracy: 0.6121\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9208 - accuracy: 0.5679 - val_loss: 1.1714 - val_accuracy: 0.6142\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9173 - accuracy: 0.5769 - val_loss: 1.2321 - val_accuracy: 0.5901\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9791 - accuracy: 0.5548 - val_loss: 1.3125 - val_accuracy: 0.5655\n",
      "Epoch 131/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9234 - accuracy: 0.5736 - val_loss: 1.2385 - val_accuracy: 0.6188\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0472 - accuracy: 0.5548 - val_loss: 1.2002 - val_accuracy: 0.6067\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8689 - accuracy: 0.5818 - val_loss: 1.1788 - val_accuracy: 0.6092\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8658 - accuracy: 0.5880 - val_loss: 1.1021 - val_accuracy: 0.6455\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2280 - accuracy: 0.5020 - val_loss: 1.2941 - val_accuracy: 0.5794\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1632 - accuracy: 0.5244 - val_loss: 1.2551 - val_accuracy: 0.5780\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5661 - accuracy: 0.5188 - val_loss: 1.3354 - val_accuracy: 0.5602\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0978 - accuracy: 0.5207 - val_loss: 1.2676 - val_accuracy: 0.5798\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0877 - accuracy: 0.5572 - val_loss: 1.2104 - val_accuracy: 0.5989\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9656 - accuracy: 0.5695 - val_loss: 1.4725 - val_accuracy: 0.5389\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9518 - accuracy: 0.5589 - val_loss: 1.2043 - val_accuracy: 0.6256\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1873 - accuracy: 0.5107 - val_loss: 1.3406 - val_accuracy: 0.5492\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0145 - accuracy: 0.5315 - val_loss: 1.3083 - val_accuracy: 0.5702\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0424 - accuracy: 0.5426 - val_loss: 1.2570 - val_accuracy: 0.5876\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9527 - accuracy: 0.5637 - val_loss: 1.2130 - val_accuracy: 0.6057\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9347 - accuracy: 0.5832 - val_loss: 1.1619 - val_accuracy: 0.6274\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9498 - accuracy: 0.5686 - val_loss: 1.2752 - val_accuracy: 0.5829\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1828 - accuracy: 0.5406 - val_loss: 1.2655 - val_accuracy: 0.5766\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0687 - accuracy: 0.5370 - val_loss: 1.3828 - val_accuracy: 0.5638\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1220 - accuracy: 0.5226 - val_loss: 1.2651 - val_accuracy: 0.5833\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4376 - accuracy: 0.5260 - val_loss: 1.3770 - val_accuracy: 0.5471\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1242 - accuracy: 0.5402 - val_loss: 1.2683 - val_accuracy: 0.5893\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9298 - accuracy: 0.5647 - val_loss: 1.1757 - val_accuracy: 0.6178\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1780 - accuracy: 0.5258 - val_loss: 1.2812 - val_accuracy: 0.5826\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9739 - accuracy: 0.5474 - val_loss: 1.2459 - val_accuracy: 0.5883\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0020 - accuracy: 0.5452 - val_loss: 1.4141 - val_accuracy: 0.5435\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9506 - accuracy: 0.5577 - val_loss: 1.1740 - val_accuracy: 0.6181\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8718 - accuracy: 0.5845 - val_loss: 1.1962 - val_accuracy: 0.6128\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9563 - accuracy: 0.5440 - val_loss: 1.2081 - val_accuracy: 0.5922\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8724 - accuracy: 0.5790 - val_loss: 1.2348 - val_accuracy: 0.6011\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3799 - accuracy: 0.5458 - val_loss: 1.6533 - val_accuracy: 0.5268\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5876 - accuracy: 0.4750 - val_loss: 1.6306 - val_accuracy: 0.4671\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0921 - accuracy: 0.5103 - val_loss: 1.3917 - val_accuracy: 0.5428\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3169 - accuracy: 0.5253 - val_loss: 1.2110 - val_accuracy: 0.6096\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3576 - accuracy: 0.5232 - val_loss: 1.2887 - val_accuracy: 0.5936\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9993 - accuracy: 0.5552 - val_loss: 1.1748 - val_accuracy: 0.6117\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8860 - accuracy: 0.5809 - val_loss: 1.2648 - val_accuracy: 0.5890\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1735 - accuracy: 0.5451 - val_loss: 1.3082 - val_accuracy: 0.5705\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9373 - accuracy: 0.5690 - val_loss: 1.1436 - val_accuracy: 0.6302\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8801 - accuracy: 0.5878 - val_loss: 1.3781 - val_accuracy: 0.5709\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8395 - accuracy: 0.5931 - val_loss: 1.0808 - val_accuracy: 0.6515\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9284 - accuracy: 0.5734 - val_loss: 1.1342 - val_accuracy: 0.6234\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9763 - accuracy: 0.5718 - val_loss: 1.1604 - val_accuracy: 0.6202\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2129 - accuracy: 0.5386 - val_loss: 1.4448 - val_accuracy: 0.5247\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3250 - accuracy: 0.4838 - val_loss: 1.3433 - val_accuracy: 0.5535\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1814 - accuracy: 0.5617 - val_loss: 1.1700 - val_accuracy: 0.6142\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9257 - accuracy: 0.5774 - val_loss: 1.2246 - val_accuracy: 0.6156\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9854 - accuracy: 0.5814 - val_loss: 1.2577 - val_accuracy: 0.5876\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8543 - accuracy: 0.5877 - val_loss: 1.1715 - val_accuracy: 0.6213\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9900 - accuracy: 0.5626 - val_loss: 1.1708 - val_accuracy: 0.6114\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1914 - accuracy: 0.5442 - val_loss: 1.3014 - val_accuracy: 0.5904\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1398 - accuracy: 0.5463 - val_loss: 1.1730 - val_accuracy: 0.6284\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9250 - accuracy: 0.5615 - val_loss: 1.1807 - val_accuracy: 0.6128\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8484 - accuracy: 0.5868 - val_loss: 1.1279 - val_accuracy: 0.6295\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9092 - accuracy: 0.5776 - val_loss: 1.1566 - val_accuracy: 0.6178\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9293 - accuracy: 0.5744 - val_loss: 1.1608 - val_accuracy: 0.6227\n",
      "Epoch 187/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8289 - accuracy: 0.5896 - val_loss: 1.1534 - val_accuracy: 0.6302\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9253 - accuracy: 0.5860 - val_loss: 1.1942 - val_accuracy: 0.6128\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9608 - accuracy: 0.5626 - val_loss: 1.1134 - val_accuracy: 0.6277\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9619 - accuracy: 0.5924 - val_loss: 1.1968 - val_accuracy: 0.6096\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1310 - accuracy: 0.5541 - val_loss: 1.2152 - val_accuracy: 0.6028\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9956 - accuracy: 0.5564 - val_loss: 1.3057 - val_accuracy: 0.5343\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1891 - accuracy: 0.5384 - val_loss: 1.3047 - val_accuracy: 0.5687\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4983 - accuracy: 0.5109 - val_loss: 1.2351 - val_accuracy: 0.6096\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3081 - accuracy: 0.5345 - val_loss: 1.3162 - val_accuracy: 0.5751\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0050 - accuracy: 0.5603 - val_loss: 1.1540 - val_accuracy: 0.6199\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.1321 - accuracy: 0.5623 - val_loss: 1.1746 - val_accuracy: 0.6188\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1422 - accuracy: 0.5483 - val_loss: 1.3591 - val_accuracy: 0.5510\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.3924 - accuracy: 0.4982 - val_loss: 1.4291 - val_accuracy: 0.5339\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2532 - accuracy: 0.5289 - val_loss: 1.2514 - val_accuracy: 0.5957\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1849 - accuracy: 0.5509 - val_loss: 1.2486 - val_accuracy: 0.6011\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2813 - accuracy: 0.5479 - val_loss: 1.4184 - val_accuracy: 0.5290\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1444 - accuracy: 0.5321 - val_loss: 1.2870 - val_accuracy: 0.5911\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9935 - accuracy: 0.5733 - val_loss: 1.1889 - val_accuracy: 0.6217\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0105 - accuracy: 0.5733 - val_loss: 1.6290 - val_accuracy: 0.4899\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0314 - accuracy: 0.5506 - val_loss: 1.1598 - val_accuracy: 0.6217\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0393 - accuracy: 0.5547 - val_loss: 1.2119 - val_accuracy: 0.6099\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9068 - accuracy: 0.5870 - val_loss: 1.1307 - val_accuracy: 0.6391\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8147 - accuracy: 0.6122 - val_loss: 1.1129 - val_accuracy: 0.6362\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1610 - accuracy: 0.5266 - val_loss: 1.3039 - val_accuracy: 0.5673\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9508 - accuracy: 0.5645 - val_loss: 1.2554 - val_accuracy: 0.5961\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9616 - accuracy: 0.5614 - val_loss: 1.2773 - val_accuracy: 0.5822\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9884 - accuracy: 0.5747 - val_loss: 1.2814 - val_accuracy: 0.5766\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4005 - accuracy: 0.5224 - val_loss: 1.3384 - val_accuracy: 0.5357\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0137 - accuracy: 0.5498 - val_loss: 1.3595 - val_accuracy: 0.5517\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0009 - accuracy: 0.5545 - val_loss: 1.1720 - val_accuracy: 0.6067\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0697 - accuracy: 0.5649 - val_loss: 1.2599 - val_accuracy: 0.5901\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9545 - accuracy: 0.5864 - val_loss: 1.2050 - val_accuracy: 0.5950\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9407 - accuracy: 0.5720 - val_loss: 1.1907 - val_accuracy: 0.6092\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9742 - accuracy: 0.5719 - val_loss: 1.1906 - val_accuracy: 0.6149\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9004 - accuracy: 0.5828 - val_loss: 1.2028 - val_accuracy: 0.6238\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8073 - accuracy: 0.6004 - val_loss: 1.0980 - val_accuracy: 0.6448\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8184 - accuracy: 0.6022 - val_loss: 1.2372 - val_accuracy: 0.5872\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.7960 - accuracy: 0.6114 - val_loss: 1.1329 - val_accuracy: 0.6320\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9810 - accuracy: 0.5782 - val_loss: 1.3294 - val_accuracy: 0.5748\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1913 - accuracy: 0.5416 - val_loss: 1.2409 - val_accuracy: 0.6036\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0558 - accuracy: 0.5715 - val_loss: 1.2294 - val_accuracy: 0.6089\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9454 - accuracy: 0.5649 - val_loss: 1.1903 - val_accuracy: 0.6149\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9907 - accuracy: 0.5712 - val_loss: 1.1543 - val_accuracy: 0.6263\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9508 - accuracy: 0.5890 - val_loss: 1.3007 - val_accuracy: 0.5794\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8668 - accuracy: 0.5779 - val_loss: 1.1329 - val_accuracy: 0.6330\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5327 - accuracy: 0.5388 - val_loss: 1.3021 - val_accuracy: 0.5670\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1454 - accuracy: 0.5314 - val_loss: 1.2448 - val_accuracy: 0.5844\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9849 - accuracy: 0.5702 - val_loss: 1.6742 - val_accuracy: 0.4519\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1664 - accuracy: 0.5290 - val_loss: 1.2302 - val_accuracy: 0.5833\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0195 - accuracy: 0.5599 - val_loss: 1.1976 - val_accuracy: 0.5961\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9752 - accuracy: 0.5758 - val_loss: 1.4704 - val_accuracy: 0.5570\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1593 - accuracy: 0.5639 - val_loss: 1.2183 - val_accuracy: 0.6011\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9109 - accuracy: 0.5926 - val_loss: 1.1495 - val_accuracy: 0.6341\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8339 - accuracy: 0.6102 - val_loss: 1.2804 - val_accuracy: 0.5808\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1985 - accuracy: 0.5494 - val_loss: 1.2057 - val_accuracy: 0.6160\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1229 - accuracy: 0.5517 - val_loss: 1.2700 - val_accuracy: 0.5901\n",
      "Epoch 243/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4196 - accuracy: 0.5537 - val_loss: 1.3441 - val_accuracy: 0.5709\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8789 - accuracy: 0.5850 - val_loss: 1.1331 - val_accuracy: 0.6238\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0052 - accuracy: 0.5750 - val_loss: 1.1589 - val_accuracy: 0.6217\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9262 - accuracy: 0.5877 - val_loss: 1.1126 - val_accuracy: 0.6472\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1986 - accuracy: 0.5530 - val_loss: 1.2039 - val_accuracy: 0.6139\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9520 - accuracy: 0.5874 - val_loss: 1.1493 - val_accuracy: 0.6369\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8420 - accuracy: 0.6040 - val_loss: 1.1198 - val_accuracy: 0.6316\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8423 - accuracy: 0.5809 - val_loss: 1.1436 - val_accuracy: 0.6277\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8419 - accuracy: 0.5964 - val_loss: 1.1225 - val_accuracy: 0.6433\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9435 - accuracy: 0.5829 - val_loss: 1.1498 - val_accuracy: 0.6341\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8186 - accuracy: 0.5999 - val_loss: 1.1063 - val_accuracy: 0.6345\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9962 - accuracy: 0.5655 - val_loss: 1.3392 - val_accuracy: 0.5872\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9406 - accuracy: 0.5803 - val_loss: 1.2158 - val_accuracy: 0.6043\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9610 - accuracy: 0.5841 - val_loss: 1.2122 - val_accuracy: 0.6117\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.7816 - accuracy: 0.6091 - val_loss: 1.1929 - val_accuracy: 0.6306\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8058 - accuracy: 0.6139 - val_loss: 1.1260 - val_accuracy: 0.6323\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8658 - accuracy: 0.6052 - val_loss: 1.0878 - val_accuracy: 0.6433\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8549 - accuracy: 0.5865 - val_loss: 1.4518 - val_accuracy: 0.5286\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9671 - accuracy: 0.5823 - val_loss: 1.1413 - val_accuracy: 0.6284\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0685 - accuracy: 0.5587 - val_loss: 1.2755 - val_accuracy: 0.5950\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9265 - accuracy: 0.5899 - val_loss: 1.5692 - val_accuracy: 0.4881\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2329 - accuracy: 0.5302 - val_loss: 1.1693 - val_accuracy: 0.6053\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9394 - accuracy: 0.5774 - val_loss: 1.4818 - val_accuracy: 0.5623\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8407 - accuracy: 0.5986 - val_loss: 1.1082 - val_accuracy: 0.6419\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9797 - accuracy: 0.5908 - val_loss: 1.2338 - val_accuracy: 0.6131\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2420 - accuracy: 0.5445 - val_loss: 1.1786 - val_accuracy: 0.6206\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2648 - accuracy: 0.5684 - val_loss: 1.1956 - val_accuracy: 0.6107\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8437 - accuracy: 0.5960 - val_loss: 1.1255 - val_accuracy: 0.6334\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8538 - accuracy: 0.5940 - val_loss: 1.1786 - val_accuracy: 0.6202\n",
      "\n",
      "Validation 1, fold 5 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.9461 - accuracy: 0.0605 - val_loss: 2.8126 - val_accuracy: 0.0526\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7518 - accuracy: 0.1020 - val_loss: 2.5164 - val_accuracy: 0.2309\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7465 - accuracy: 0.1891 - val_loss: 2.4143 - val_accuracy: 0.1517\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5815 - accuracy: 0.1774 - val_loss: 2.3120 - val_accuracy: 0.2419\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3219 - accuracy: 0.1955 - val_loss: 2.3662 - val_accuracy: 0.2092\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.3720 - accuracy: 0.2122 - val_loss: 2.1309 - val_accuracy: 0.2728\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.3996 - accuracy: 0.2213 - val_loss: 2.2008 - val_accuracy: 0.2629\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.2392 - accuracy: 0.2267 - val_loss: 2.0907 - val_accuracy: 0.2782\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.1933 - accuracy: 0.2500 - val_loss: 2.2361 - val_accuracy: 0.2536\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.2552 - accuracy: 0.2505 - val_loss: 2.0355 - val_accuracy: 0.3492\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.1009 - accuracy: 0.2886 - val_loss: 2.0690 - val_accuracy: 0.2956\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.1423 - accuracy: 0.2854 - val_loss: 1.9241 - val_accuracy: 0.3623\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.9435 - accuracy: 0.3034 - val_loss: 1.9144 - val_accuracy: 0.3748\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.0049 - accuracy: 0.3151 - val_loss: 2.0334 - val_accuracy: 0.2899\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.8248 - accuracy: 0.3220 - val_loss: 2.0420 - val_accuracy: 0.2966\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.9792 - accuracy: 0.3051 - val_loss: 1.9153 - val_accuracy: 0.3421\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.8009 - accuracy: 0.3327 - val_loss: 1.8178 - val_accuracy: 0.3702\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.7089 - accuracy: 0.3365 - val_loss: 1.7113 - val_accuracy: 0.4313\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.6616 - accuracy: 0.3620 - val_loss: 1.9245 - val_accuracy: 0.3439\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.6348 - accuracy: 0.3528 - val_loss: 1.8406 - val_accuracy: 0.3670\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.6607 - accuracy: 0.3455 - val_loss: 1.6664 - val_accuracy: 0.4096\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.9023 - accuracy: 0.3426 - val_loss: 1.8287 - val_accuracy: 0.3929\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.7788 - accuracy: 0.3670 - val_loss: 1.8523 - val_accuracy: 0.3876\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.5746 - accuracy: 0.3779 - val_loss: 1.6235 - val_accuracy: 0.4476\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.5552 - accuracy: 0.3871 - val_loss: 1.6556 - val_accuracy: 0.4242\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4457 - accuracy: 0.4070 - val_loss: 1.6433 - val_accuracy: 0.4487\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4238 - accuracy: 0.4131 - val_loss: 1.5317 - val_accuracy: 0.4686\n",
      "Epoch 28/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 2s 5ms/step - loss: 1.3874 - accuracy: 0.4187 - val_loss: 1.6002 - val_accuracy: 0.4249\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4010 - accuracy: 0.4253 - val_loss: 1.5114 - val_accuracy: 0.4817\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4100 - accuracy: 0.4324 - val_loss: 1.9507 - val_accuracy: 0.3343\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4515 - accuracy: 0.4300 - val_loss: 1.6206 - val_accuracy: 0.4263\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.3879 - accuracy: 0.4386 - val_loss: 1.6681 - val_accuracy: 0.4568\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.3979 - accuracy: 0.4385 - val_loss: 1.5902 - val_accuracy: 0.4746\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2415 - accuracy: 0.4689 - val_loss: 1.4369 - val_accuracy: 0.5087\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4500 - accuracy: 0.4480 - val_loss: 1.5682 - val_accuracy: 0.4849\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4393 - accuracy: 0.4417 - val_loss: 1.4283 - val_accuracy: 0.5332\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2414 - accuracy: 0.4855 - val_loss: 1.4983 - val_accuracy: 0.4917\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2825 - accuracy: 0.4713 - val_loss: 1.4345 - val_accuracy: 0.5446\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2384 - accuracy: 0.4839 - val_loss: 1.5250 - val_accuracy: 0.5044\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.4542 - accuracy: 0.4571 - val_loss: 1.4965 - val_accuracy: 0.5172\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2399 - accuracy: 0.4854 - val_loss: 1.3793 - val_accuracy: 0.5325\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1919 - accuracy: 0.5069 - val_loss: 1.9498 - val_accuracy: 0.4025\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1870 - accuracy: 0.4946 - val_loss: 1.4760 - val_accuracy: 0.5165\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1636 - accuracy: 0.5065 - val_loss: 1.3803 - val_accuracy: 0.5417\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2468 - accuracy: 0.4927 - val_loss: 1.4497 - val_accuracy: 0.5353\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.5374 - accuracy: 0.4723 - val_loss: 1.6371 - val_accuracy: 0.4682\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.7632 - accuracy: 0.4443 - val_loss: 1.4393 - val_accuracy: 0.5115\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.3390 - accuracy: 0.4631 - val_loss: 1.5237 - val_accuracy: 0.4952\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.6119 - accuracy: 0.4639 - val_loss: 1.5898 - val_accuracy: 0.4725\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2072 - accuracy: 0.4824 - val_loss: 1.5643 - val_accuracy: 0.4885\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1559 - accuracy: 0.5113 - val_loss: 1.5254 - val_accuracy: 0.4998\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2748 - accuracy: 0.4777 - val_loss: 1.3964 - val_accuracy: 0.5464\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2368 - accuracy: 0.4897 - val_loss: 1.4307 - val_accuracy: 0.5318\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.3130 - accuracy: 0.4828 - val_loss: 1.3602 - val_accuracy: 0.5467\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2082 - accuracy: 0.4881 - val_loss: 1.5758 - val_accuracy: 0.5204\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.1880 - accuracy: 0.5108 - val_loss: 1.3488 - val_accuracy: 0.5542\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.3826 - accuracy: 0.4746 - val_loss: 1.4206 - val_accuracy: 0.5488\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1621 - accuracy: 0.4946 - val_loss: 1.2818 - val_accuracy: 0.5616\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0498 - accuracy: 0.5164 - val_loss: 1.2603 - val_accuracy: 0.5869\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.0581 - accuracy: 0.5366 - val_loss: 1.3799 - val_accuracy: 0.5339\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0511 - accuracy: 0.5292 - val_loss: 1.2147 - val_accuracy: 0.6117\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2329 - accuracy: 0.5262 - val_loss: 1.3612 - val_accuracy: 0.5435\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0416 - accuracy: 0.5321 - val_loss: 1.2798 - val_accuracy: 0.5861\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2360 - accuracy: 0.5196 - val_loss: 1.3597 - val_accuracy: 0.5432\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0499 - accuracy: 0.5308 - val_loss: 1.2928 - val_accuracy: 0.5510\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.1994 - accuracy: 0.4299 - val_loss: 1.4842 - val_accuracy: 0.5098\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.3273 - accuracy: 0.4810 - val_loss: 1.8616 - val_accuracy: 0.4199\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2307 - accuracy: 0.4877 - val_loss: 1.3007 - val_accuracy: 0.5776\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1006 - accuracy: 0.5179 - val_loss: 1.2338 - val_accuracy: 0.5929\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.0556 - accuracy: 0.5414 - val_loss: 1.3642 - val_accuracy: 0.5389\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0886 - accuracy: 0.5218 - val_loss: 1.3701 - val_accuracy: 0.5510\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0325 - accuracy: 0.5318 - val_loss: 1.2474 - val_accuracy: 0.5652\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0737 - accuracy: 0.5352 - val_loss: 1.3129 - val_accuracy: 0.5567\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1973 - accuracy: 0.5245 - val_loss: 1.3594 - val_accuracy: 0.5385\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0062 - accuracy: 0.5404 - val_loss: 1.1555 - val_accuracy: 0.6039\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.1176 - accuracy: 0.5393 - val_loss: 1.4606 - val_accuracy: 0.5300\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.1772 - accuracy: 0.5303 - val_loss: 1.4779 - val_accuracy: 0.5112\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2220 - accuracy: 0.4981 - val_loss: 1.6071 - val_accuracy: 0.5133\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2341 - accuracy: 0.5063 - val_loss: 1.3849 - val_accuracy: 0.5414\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1229 - accuracy: 0.5137 - val_loss: 1.3632 - val_accuracy: 0.5385\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2471 - accuracy: 0.4984 - val_loss: 1.3599 - val_accuracy: 0.5595\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0477 - accuracy: 0.5243 - val_loss: 1.2802 - val_accuracy: 0.5677\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1495 - accuracy: 0.5206 - val_loss: 1.3358 - val_accuracy: 0.5588\n",
      "Epoch 84/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1476 - accuracy: 0.5321 - val_loss: 1.3118 - val_accuracy: 0.5663\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2934 - accuracy: 0.5160 - val_loss: 1.2687 - val_accuracy: 0.5805\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9553 - accuracy: 0.5520 - val_loss: 1.2567 - val_accuracy: 0.5883\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0306 - accuracy: 0.5526 - val_loss: 1.2436 - val_accuracy: 0.5940\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9895 - accuracy: 0.5560 - val_loss: 1.2490 - val_accuracy: 0.5993\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9613 - accuracy: 0.5586 - val_loss: 1.4306 - val_accuracy: 0.5286\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0940 - accuracy: 0.5348 - val_loss: 1.1927 - val_accuracy: 0.6082\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4751 - accuracy: 0.5208 - val_loss: 1.4531 - val_accuracy: 0.5346\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1978 - accuracy: 0.5202 - val_loss: 1.2832 - val_accuracy: 0.5844\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0518 - accuracy: 0.5465 - val_loss: 1.3017 - val_accuracy: 0.5719\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1200 - accuracy: 0.5212 - val_loss: 1.3394 - val_accuracy: 0.5631\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9790 - accuracy: 0.5544 - val_loss: 1.4099 - val_accuracy: 0.5520\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9738 - accuracy: 0.5581 - val_loss: 1.2575 - val_accuracy: 0.5954\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9805 - accuracy: 0.5657 - val_loss: 1.2517 - val_accuracy: 0.5876\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6052 - accuracy: 0.5541 - val_loss: 1.3839 - val_accuracy: 0.5428\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4376 - accuracy: 0.5048 - val_loss: 1.3398 - val_accuracy: 0.5663\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3082 - accuracy: 0.5111 - val_loss: 1.5755 - val_accuracy: 0.4917\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5093 - accuracy: 0.4633 - val_loss: 1.4333 - val_accuracy: 0.5226\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3295 - accuracy: 0.4837 - val_loss: 1.4137 - val_accuracy: 0.5410\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2503 - accuracy: 0.5099 - val_loss: 1.3763 - val_accuracy: 0.5538\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0734 - accuracy: 0.5245 - val_loss: 1.2527 - val_accuracy: 0.5840\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1793 - accuracy: 0.5323 - val_loss: 1.1890 - val_accuracy: 0.6110\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0803 - accuracy: 0.5432 - val_loss: 1.2852 - val_accuracy: 0.5968\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1357 - accuracy: 0.5287 - val_loss: 1.3604 - val_accuracy: 0.5599\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1583 - accuracy: 0.5237 - val_loss: 1.3379 - val_accuracy: 0.5471\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1694 - accuracy: 0.5267 - val_loss: 1.2446 - val_accuracy: 0.5833\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0852 - accuracy: 0.5450 - val_loss: 1.2354 - val_accuracy: 0.6036\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9932 - accuracy: 0.5526 - val_loss: 1.1586 - val_accuracy: 0.6202\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8933 - accuracy: 0.5842 - val_loss: 1.1431 - val_accuracy: 0.6167\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0328 - accuracy: 0.5459 - val_loss: 1.1952 - val_accuracy: 0.5904\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0094 - accuracy: 0.5376 - val_loss: 1.3137 - val_accuracy: 0.5609\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9996 - accuracy: 0.5448 - val_loss: 1.4113 - val_accuracy: 0.5222\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1004 - accuracy: 0.5209 - val_loss: 1.3132 - val_accuracy: 0.5613\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5507 - accuracy: 0.5028 - val_loss: 1.5292 - val_accuracy: 0.4870\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2618 - accuracy: 0.5172 - val_loss: 1.2884 - val_accuracy: 0.5918\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1742 - accuracy: 0.5230 - val_loss: 1.2447 - val_accuracy: 0.6032\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1885 - accuracy: 0.5304 - val_loss: 1.2763 - val_accuracy: 0.5890\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0315 - accuracy: 0.5397 - val_loss: 1.3428 - val_accuracy: 0.5542\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9741 - accuracy: 0.5583 - val_loss: 1.2233 - val_accuracy: 0.5901\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2185 - accuracy: 0.5025 - val_loss: 1.2939 - val_accuracy: 0.5666\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0111 - accuracy: 0.5523 - val_loss: 1.3444 - val_accuracy: 0.5588\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2886 - accuracy: 0.5028 - val_loss: 1.4917 - val_accuracy: 0.4813\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2955 - accuracy: 0.5234 - val_loss: 1.2814 - val_accuracy: 0.5780\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1636 - accuracy: 0.5105 - val_loss: 1.3251 - val_accuracy: 0.5609\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1537 - accuracy: 0.5344 - val_loss: 1.2531 - val_accuracy: 0.5911\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9710 - accuracy: 0.5603 - val_loss: 1.2565 - val_accuracy: 0.5790\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0329 - accuracy: 0.5401 - val_loss: 1.2461 - val_accuracy: 0.5908\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1531 - accuracy: 0.5362 - val_loss: 1.2207 - val_accuracy: 0.5872\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1189 - accuracy: 0.5329 - val_loss: 1.1624 - val_accuracy: 0.6124\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2078 - accuracy: 0.5169 - val_loss: 1.2510 - val_accuracy: 0.5925\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1199 - accuracy: 0.5337 - val_loss: 1.4360 - val_accuracy: 0.5201\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1141 - accuracy: 0.5268 - val_loss: 1.3699 - val_accuracy: 0.5456\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2588 - accuracy: 0.5022 - val_loss: 1.3170 - val_accuracy: 0.5627\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0064 - accuracy: 0.5496 - val_loss: 1.3787 - val_accuracy: 0.5385\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9939 - accuracy: 0.5639 - val_loss: 1.1733 - val_accuracy: 0.6117\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0379 - accuracy: 0.5497 - val_loss: 1.1720 - val_accuracy: 0.6007\n",
      "Epoch 140/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9826 - accuracy: 0.5657 - val_loss: 1.3071 - val_accuracy: 0.5591\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0016 - accuracy: 0.5547 - val_loss: 1.1867 - val_accuracy: 0.6075\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9565 - accuracy: 0.5649 - val_loss: 1.3286 - val_accuracy: 0.5425\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9428 - accuracy: 0.5576 - val_loss: 1.5814 - val_accuracy: 0.4632\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0542 - accuracy: 0.5239 - val_loss: 1.1513 - val_accuracy: 0.6124\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9772 - accuracy: 0.5641 - val_loss: 1.3432 - val_accuracy: 0.5488\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9761 - accuracy: 0.5581 - val_loss: 1.2500 - val_accuracy: 0.5691\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0523 - accuracy: 0.5586 - val_loss: 1.1769 - val_accuracy: 0.6089\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8705 - accuracy: 0.5757 - val_loss: 1.1775 - val_accuracy: 0.5833\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0140 - accuracy: 0.5743 - val_loss: 1.1145 - val_accuracy: 0.6202\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9541 - accuracy: 0.5715 - val_loss: 1.4278 - val_accuracy: 0.4966\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0487 - accuracy: 0.5417 - val_loss: 1.6332 - val_accuracy: 0.4583\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4656 - accuracy: 0.4978 - val_loss: 1.3277 - val_accuracy: 0.5680\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0422 - accuracy: 0.5398 - val_loss: 1.3339 - val_accuracy: 0.5524\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2113 - accuracy: 0.5280 - val_loss: 1.2343 - val_accuracy: 0.5829\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1048 - accuracy: 0.5393 - val_loss: 1.2649 - val_accuracy: 0.5705\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0358 - accuracy: 0.5576 - val_loss: 1.1927 - val_accuracy: 0.6014\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0091 - accuracy: 0.5683 - val_loss: 1.1956 - val_accuracy: 0.5943\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9300 - accuracy: 0.5694 - val_loss: 1.2015 - val_accuracy: 0.5762\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0601 - accuracy: 0.5410 - val_loss: 1.2221 - val_accuracy: 0.5712\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9691 - accuracy: 0.5480 - val_loss: 1.1915 - val_accuracy: 0.6039\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8544 - accuracy: 0.5783 - val_loss: 1.1102 - val_accuracy: 0.6302\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9717 - accuracy: 0.5564 - val_loss: 1.1464 - val_accuracy: 0.6153\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1163 - accuracy: 0.5448 - val_loss: 1.3331 - val_accuracy: 0.5588\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9421 - accuracy: 0.5649 - val_loss: 1.1358 - val_accuracy: 0.6178\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1015 - accuracy: 0.5427 - val_loss: 1.1787 - val_accuracy: 0.6018\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0502 - accuracy: 0.5369 - val_loss: 1.3054 - val_accuracy: 0.5719\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9709 - accuracy: 0.5625 - val_loss: 1.1396 - val_accuracy: 0.6199\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2467 - accuracy: 0.5102 - val_loss: 1.3521 - val_accuracy: 0.5591\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0971 - accuracy: 0.5507 - val_loss: 1.1156 - val_accuracy: 0.6252\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8931 - accuracy: 0.5706 - val_loss: 1.2271 - val_accuracy: 0.5858\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8235 - accuracy: 0.5903 - val_loss: 1.1981 - val_accuracy: 0.5940\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0174 - accuracy: 0.5637 - val_loss: 1.2386 - val_accuracy: 0.5876\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9020 - accuracy: 0.5618 - val_loss: 1.1490 - val_accuracy: 0.6178\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9519 - accuracy: 0.5614 - val_loss: 1.1306 - val_accuracy: 0.6188\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9055 - accuracy: 0.5695 - val_loss: 1.2892 - val_accuracy: 0.5634\n",
      "\n",
      "Validation 2, fold 1 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.9388 - accuracy: 0.0614 - val_loss: 2.7745 - val_accuracy: 0.1094\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.8266 - accuracy: 0.1046 - val_loss: 2.4040 - val_accuracy: 0.1893\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5265 - accuracy: 0.1824 - val_loss: 2.6081 - val_accuracy: 0.1080\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5082 - accuracy: 0.1600 - val_loss: 2.4295 - val_accuracy: 0.1734\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2692 - accuracy: 0.2133 - val_loss: 2.2207 - val_accuracy: 0.2490\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2297 - accuracy: 0.2426 - val_loss: 2.1631 - val_accuracy: 0.2782\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1310 - accuracy: 0.2708 - val_loss: 2.0590 - val_accuracy: 0.3485\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1117 - accuracy: 0.2861 - val_loss: 2.0270 - val_accuracy: 0.3126\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9137 - accuracy: 0.3079 - val_loss: 1.7937 - val_accuracy: 0.4082\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8551 - accuracy: 0.3330 - val_loss: 2.0031 - val_accuracy: 0.3229\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7708 - accuracy: 0.3296 - val_loss: 1.7761 - val_accuracy: 0.3829\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8194 - accuracy: 0.3353 - val_loss: 1.8301 - val_accuracy: 0.3691\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6904 - accuracy: 0.3666 - val_loss: 1.6917 - val_accuracy: 0.4082\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7052 - accuracy: 0.3616 - val_loss: 1.7907 - val_accuracy: 0.3762\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6614 - accuracy: 0.3766 - val_loss: 1.8513 - val_accuracy: 0.3570\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5934 - accuracy: 0.3916 - val_loss: 1.7335 - val_accuracy: 0.4043\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5184 - accuracy: 0.3995 - val_loss: 1.6579 - val_accuracy: 0.4192\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4807 - accuracy: 0.4098 - val_loss: 1.6342 - val_accuracy: 0.4153\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5002 - accuracy: 0.4234 - val_loss: 1.6903 - val_accuracy: 0.4220\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4404 - accuracy: 0.4210 - val_loss: 1.5452 - val_accuracy: 0.4476\n",
      "Epoch 21/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3601 - accuracy: 0.4406 - val_loss: 1.5746 - val_accuracy: 0.4625\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4473 - accuracy: 0.4383 - val_loss: 1.6968 - val_accuracy: 0.4057\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3522 - accuracy: 0.4439 - val_loss: 1.5649 - val_accuracy: 0.4572\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3437 - accuracy: 0.4443 - val_loss: 1.5381 - val_accuracy: 0.4650\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3018 - accuracy: 0.4522 - val_loss: 1.4992 - val_accuracy: 0.4767\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3486 - accuracy: 0.4649 - val_loss: 1.5117 - val_accuracy: 0.4860\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2550 - accuracy: 0.4577 - val_loss: 1.4356 - val_accuracy: 0.4885\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2386 - accuracy: 0.4752 - val_loss: 1.5787 - val_accuracy: 0.4728\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2435 - accuracy: 0.4749 - val_loss: 1.4852 - val_accuracy: 0.4941\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1921 - accuracy: 0.4872 - val_loss: 1.4341 - val_accuracy: 0.5069\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3052 - accuracy: 0.4639 - val_loss: 1.7827 - val_accuracy: 0.3769\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2150 - accuracy: 0.4652 - val_loss: 1.3525 - val_accuracy: 0.5304\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2905 - accuracy: 0.4944 - val_loss: 1.5875 - val_accuracy: 0.4636\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1370 - accuracy: 0.4041 - val_loss: 1.6451 - val_accuracy: 0.4295\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4826 - accuracy: 0.4384 - val_loss: 1.5289 - val_accuracy: 0.4750\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3222 - accuracy: 0.4561 - val_loss: 1.4669 - val_accuracy: 0.4767\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4213 - accuracy: 0.4656 - val_loss: 1.4721 - val_accuracy: 0.5187\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2715 - accuracy: 0.4697 - val_loss: 1.5620 - val_accuracy: 0.4732\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2218 - accuracy: 0.4901 - val_loss: 1.6622 - val_accuracy: 0.4625\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2266 - accuracy: 0.4808 - val_loss: 1.3368 - val_accuracy: 0.5279\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1620 - accuracy: 0.4928 - val_loss: 1.6853 - val_accuracy: 0.4046\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1916 - accuracy: 0.4720 - val_loss: 1.3326 - val_accuracy: 0.5403\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1505 - accuracy: 0.5048 - val_loss: 1.4593 - val_accuracy: 0.4927\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1371 - accuracy: 0.5022 - val_loss: 1.4318 - val_accuracy: 0.4948\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0762 - accuracy: 0.5172 - val_loss: 1.2625 - val_accuracy: 0.5634\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0432 - accuracy: 0.5263 - val_loss: 1.2650 - val_accuracy: 0.5702\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1240 - accuracy: 0.5149 - val_loss: 1.2948 - val_accuracy: 0.5528\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0937 - accuracy: 0.5166 - val_loss: 1.4276 - val_accuracy: 0.5197\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3765 - accuracy: 0.4719 - val_loss: 1.4478 - val_accuracy: 0.4920\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3063 - accuracy: 0.4631 - val_loss: 1.4951 - val_accuracy: 0.4877\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1908 - accuracy: 0.4812 - val_loss: 1.3205 - val_accuracy: 0.5449\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1374 - accuracy: 0.5038 - val_loss: 1.3155 - val_accuracy: 0.5414\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2017 - accuracy: 0.5119 - val_loss: 1.3228 - val_accuracy: 0.5421\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2364 - accuracy: 0.4845 - val_loss: 1.2945 - val_accuracy: 0.5663\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0630 - accuracy: 0.5133 - val_loss: 1.3522 - val_accuracy: 0.5339\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0946 - accuracy: 0.5048 - val_loss: 1.2619 - val_accuracy: 0.5556\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0830 - accuracy: 0.5161 - val_loss: 1.2305 - val_accuracy: 0.5645\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1222 - accuracy: 0.5258 - val_loss: 1.2813 - val_accuracy: 0.5520\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0692 - accuracy: 0.5250 - val_loss: 1.3037 - val_accuracy: 0.5503\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0361 - accuracy: 0.5357 - val_loss: 1.5016 - val_accuracy: 0.5076\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3213 - accuracy: 0.5099 - val_loss: 1.2206 - val_accuracy: 0.5716\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0522 - accuracy: 0.5372 - val_loss: 1.3002 - val_accuracy: 0.5488\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0752 - accuracy: 0.5369 - val_loss: 1.2798 - val_accuracy: 0.5510\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1576 - accuracy: 0.5060 - val_loss: 1.3901 - val_accuracy: 0.5048\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9783 - accuracy: 0.5329 - val_loss: 1.1597 - val_accuracy: 0.5964\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9993 - accuracy: 0.5404 - val_loss: 1.2219 - val_accuracy: 0.5652\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1217 - accuracy: 0.5075 - val_loss: 1.5077 - val_accuracy: 0.4778\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1230 - accuracy: 0.5198 - val_loss: 1.3218 - val_accuracy: 0.5684\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1425 - accuracy: 0.5353 - val_loss: 1.2487 - val_accuracy: 0.5790\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0118 - accuracy: 0.5448 - val_loss: 1.2384 - val_accuracy: 0.5798\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0210 - accuracy: 0.5289 - val_loss: 1.2316 - val_accuracy: 0.5886\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9316 - accuracy: 0.5590 - val_loss: 1.0875 - val_accuracy: 0.6362\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1726 - accuracy: 0.5306 - val_loss: 1.2820 - val_accuracy: 0.5769\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8406 - accuracy: 0.4439 - val_loss: 1.7110 - val_accuracy: 0.4053\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7073 - accuracy: 0.4129 - val_loss: 1.4439 - val_accuracy: 0.4885\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6270 - accuracy: 0.4695 - val_loss: 1.5479 - val_accuracy: 0.4604\n",
      "Epoch 77/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2970 - accuracy: 0.4821 - val_loss: 1.3306 - val_accuracy: 0.5318\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1348 - accuracy: 0.5122 - val_loss: 1.3937 - val_accuracy: 0.5279\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0841 - accuracy: 0.5282 - val_loss: 1.2744 - val_accuracy: 0.5520\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0195 - accuracy: 0.5318 - val_loss: 1.2385 - val_accuracy: 0.5631\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0066 - accuracy: 0.5513 - val_loss: 1.3439 - val_accuracy: 0.5556\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2047 - accuracy: 0.5056 - val_loss: 1.2714 - val_accuracy: 0.5478\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9568 - accuracy: 0.5603 - val_loss: 1.3891 - val_accuracy: 0.5364\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0793 - accuracy: 0.5024 - val_loss: 1.2759 - val_accuracy: 0.5442\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9689 - accuracy: 0.5382 - val_loss: 1.4186 - val_accuracy: 0.5194\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0112 - accuracy: 0.5461 - val_loss: 1.3018 - val_accuracy: 0.5560\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0446 - accuracy: 0.5409 - val_loss: 1.3825 - val_accuracy: 0.5396\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2805 - accuracy: 0.5062 - val_loss: 1.4486 - val_accuracy: 0.5052\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1108 - accuracy: 0.5377 - val_loss: 1.3644 - val_accuracy: 0.5012\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0817 - accuracy: 0.5180 - val_loss: 1.3728 - val_accuracy: 0.5357\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1329 - accuracy: 0.5279 - val_loss: 1.1739 - val_accuracy: 0.5972\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9775 - accuracy: 0.5528 - val_loss: 1.2921 - val_accuracy: 0.5620\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9843 - accuracy: 0.5481 - val_loss: 1.1641 - val_accuracy: 0.5950\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1002 - accuracy: 0.5441 - val_loss: 1.4686 - val_accuracy: 0.4895\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1934 - accuracy: 0.5075 - val_loss: 1.3849 - val_accuracy: 0.5265\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1630 - accuracy: 0.5161 - val_loss: 1.5639 - val_accuracy: 0.4877\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4468 - accuracy: 0.4734 - val_loss: 1.3466 - val_accuracy: 0.5481\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0637 - accuracy: 0.5182 - val_loss: 1.2338 - val_accuracy: 0.5783\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0455 - accuracy: 0.5344 - val_loss: 1.2532 - val_accuracy: 0.5702\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1841 - accuracy: 0.5185 - val_loss: 1.2937 - val_accuracy: 0.5563\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9505 - accuracy: 0.5470 - val_loss: 1.1430 - val_accuracy: 0.6227\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0066 - accuracy: 0.5526 - val_loss: 1.4838 - val_accuracy: 0.5176\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5669 - accuracy: 0.5107 - val_loss: 1.5786 - val_accuracy: 0.4877\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3184 - accuracy: 0.4813 - val_loss: 1.4174 - val_accuracy: 0.5108\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1519 - accuracy: 0.5107 - val_loss: 1.6518 - val_accuracy: 0.4575\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0929 - accuracy: 0.5205 - val_loss: 1.4315 - val_accuracy: 0.5155\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1474 - accuracy: 0.5269 - val_loss: 1.2146 - val_accuracy: 0.5815\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0396 - accuracy: 0.5491 - val_loss: 1.2290 - val_accuracy: 0.5790\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9616 - accuracy: 0.5501 - val_loss: 1.2020 - val_accuracy: 0.5840\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8649 - accuracy: 0.5725 - val_loss: 1.1146 - val_accuracy: 0.6327\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8262 - accuracy: 0.5880 - val_loss: 1.1792 - val_accuracy: 0.5947\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0180 - accuracy: 0.5390 - val_loss: 1.1919 - val_accuracy: 0.6039\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9872 - accuracy: 0.5655 - val_loss: 1.2716 - val_accuracy: 0.5666\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1912 - accuracy: 0.5125 - val_loss: 1.2567 - val_accuracy: 0.5794\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9133 - accuracy: 0.5619 - val_loss: 1.1374 - val_accuracy: 0.6192\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9571 - accuracy: 0.5783 - val_loss: 1.1399 - val_accuracy: 0.6131\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0261 - accuracy: 0.5592 - val_loss: 1.1608 - val_accuracy: 0.5986\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1355 - accuracy: 0.5236 - val_loss: 1.2701 - val_accuracy: 0.5574\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9329 - accuracy: 0.5580 - val_loss: 1.1785 - val_accuracy: 0.6075\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9947 - accuracy: 0.5414 - val_loss: 1.2736 - val_accuracy: 0.5620\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9184 - accuracy: 0.5623 - val_loss: 1.2129 - val_accuracy: 0.6004\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9246 - accuracy: 0.5687 - val_loss: 1.2170 - val_accuracy: 0.5748\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8547 - accuracy: 0.5846 - val_loss: 1.0560 - val_accuracy: 0.6423\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8526 - accuracy: 0.5939 - val_loss: 1.1152 - val_accuracy: 0.6192\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0225 - accuracy: 0.5635 - val_loss: 1.4025 - val_accuracy: 0.5361\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2614 - accuracy: 0.5160 - val_loss: 1.4119 - val_accuracy: 0.5350\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9957 - accuracy: 0.5525 - val_loss: 1.1877 - val_accuracy: 0.6089\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0977 - accuracy: 0.5573 - val_loss: 1.1752 - val_accuracy: 0.5989\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3577 - accuracy: 0.5081 - val_loss: 1.3274 - val_accuracy: 0.5467\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9198 - accuracy: 0.5691 - val_loss: 1.1554 - val_accuracy: 0.6050\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3373 - accuracy: 0.5234 - val_loss: 1.5693 - val_accuracy: 0.4821\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4612 - accuracy: 0.5146 - val_loss: 1.2572 - val_accuracy: 0.5631\n",
      "Epoch 133/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0863 - accuracy: 0.5497 - val_loss: 1.2352 - val_accuracy: 0.5744\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9242 - accuracy: 0.5603 - val_loss: 1.1175 - val_accuracy: 0.6256\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8800 - accuracy: 0.5762 - val_loss: 1.0764 - val_accuracy: 0.6426\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9837 - accuracy: 0.5803 - val_loss: 1.3438 - val_accuracy: 0.5492\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0602 - accuracy: 0.5602 - val_loss: 1.2397 - val_accuracy: 0.5726\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8396 - accuracy: 0.5826 - val_loss: 1.0665 - val_accuracy: 0.6423\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8409 - accuracy: 0.6021 - val_loss: 1.0521 - val_accuracy: 0.6412\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9700 - accuracy: 0.5596 - val_loss: 1.2946 - val_accuracy: 0.5517\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0509 - accuracy: 0.5450 - val_loss: 1.1956 - val_accuracy: 0.5954\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8981 - accuracy: 0.5834 - val_loss: 1.1696 - val_accuracy: 0.6039\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9649 - accuracy: 0.5697 - val_loss: 1.0945 - val_accuracy: 0.6330\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9538 - accuracy: 0.5750 - val_loss: 1.1780 - val_accuracy: 0.5933\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8548 - accuracy: 0.5808 - val_loss: 1.0626 - val_accuracy: 0.6394\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2982 - accuracy: 0.5303 - val_loss: 1.9358 - val_accuracy: 0.3496\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7708 - accuracy: 0.4752 - val_loss: 1.8069 - val_accuracy: 0.4092\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7038 - accuracy: 0.4329 - val_loss: 1.3509 - val_accuracy: 0.5371\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4872 - accuracy: 0.5155 - val_loss: 1.2717 - val_accuracy: 0.5730\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3437 - accuracy: 0.5026 - val_loss: 1.3324 - val_accuracy: 0.5439\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3996 - accuracy: 0.5187 - val_loss: 1.2139 - val_accuracy: 0.5705\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1959 - accuracy: 0.5258 - val_loss: 1.3531 - val_accuracy: 0.5410\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1329 - accuracy: 0.5337 - val_loss: 1.2017 - val_accuracy: 0.5893\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2948 - accuracy: 0.5456 - val_loss: 1.7200 - val_accuracy: 0.4252\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0826 - accuracy: 0.5258 - val_loss: 1.2657 - val_accuracy: 0.5631\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1035 - accuracy: 0.5572 - val_loss: 1.3593 - val_accuracy: 0.5417\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1666 - accuracy: 0.5174 - val_loss: 1.2773 - val_accuracy: 0.5538\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1365 - accuracy: 0.5384 - val_loss: 1.2765 - val_accuracy: 0.5648\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9652 - accuracy: 0.5720 - val_loss: 1.1377 - val_accuracy: 0.6210\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1038 - accuracy: 0.5557 - val_loss: 1.4125 - val_accuracy: 0.5297\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0842 - accuracy: 0.5496 - val_loss: 1.2203 - val_accuracy: 0.5936\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3503 - accuracy: 0.4734 - val_loss: 1.6972 - val_accuracy: 0.3968\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1768 - accuracy: 0.4880 - val_loss: 1.2409 - val_accuracy: 0.5762\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2248 - accuracy: 0.5201 - val_loss: 1.2626 - val_accuracy: 0.5655\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0956 - accuracy: 0.5377 - val_loss: 1.1709 - val_accuracy: 0.5972\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9036 - accuracy: 0.5814 - val_loss: 1.1070 - val_accuracy: 0.6181\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9815 - accuracy: 0.5570 - val_loss: 1.1810 - val_accuracy: 0.5940\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0806 - accuracy: 0.5523 - val_loss: 1.4428 - val_accuracy: 0.5297\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0133 - accuracy: 0.5621 - val_loss: 1.1469 - val_accuracy: 0.6220\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8843 - accuracy: 0.5802 - val_loss: 1.4890 - val_accuracy: 0.4877\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8662 - accuracy: 0.5834 - val_loss: 1.1168 - val_accuracy: 0.6327\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9104 - accuracy: 0.5886 - val_loss: 1.1382 - val_accuracy: 0.6163\n",
      "\n",
      "Validation 2, fold 2 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8750 - accuracy: 0.0572 - val_loss: 2.8150 - val_accuracy: 0.0838\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7952 - accuracy: 0.0981 - val_loss: 2.6832 - val_accuracy: 0.1488\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.6552 - accuracy: 0.1512 - val_loss: 2.3303 - val_accuracy: 0.2380\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3907 - accuracy: 0.1961 - val_loss: 2.3505 - val_accuracy: 0.2103\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3433 - accuracy: 0.2044 - val_loss: 2.2724 - val_accuracy: 0.2238\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2225 - accuracy: 0.2112 - val_loss: 2.1280 - val_accuracy: 0.2377\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0798 - accuracy: 0.2799 - val_loss: 1.9396 - val_accuracy: 0.3467\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0000 - accuracy: 0.2945 - val_loss: 1.8745 - val_accuracy: 0.3737\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9640 - accuracy: 0.3069 - val_loss: 1.8950 - val_accuracy: 0.3801\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9507 - accuracy: 0.3226 - val_loss: 1.9273 - val_accuracy: 0.3190\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9205 - accuracy: 0.3322 - val_loss: 1.9452 - val_accuracy: 0.2917\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8557 - accuracy: 0.3279 - val_loss: 1.9759 - val_accuracy: 0.2948\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8777 - accuracy: 0.3429 - val_loss: 1.8238 - val_accuracy: 0.3528\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7852 - accuracy: 0.3670 - val_loss: 1.9658 - val_accuracy: 0.3410\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6443 - accuracy: 0.3876 - val_loss: 1.6221 - val_accuracy: 0.4448\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6347 - accuracy: 0.3855 - val_loss: 1.9998 - val_accuracy: 0.3382\n",
      "Epoch 17/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5855 - accuracy: 0.3960 - val_loss: 1.5987 - val_accuracy: 0.4341\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4893 - accuracy: 0.4038 - val_loss: 1.5136 - val_accuracy: 0.4693\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3625 - accuracy: 0.4387 - val_loss: 1.5085 - val_accuracy: 0.4728\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4052 - accuracy: 0.4388 - val_loss: 1.8645 - val_accuracy: 0.3421\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7210 - accuracy: 0.4242 - val_loss: 1.6281 - val_accuracy: 0.4433\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5149 - accuracy: 0.4016 - val_loss: 1.6749 - val_accuracy: 0.4110\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4076 - accuracy: 0.4267 - val_loss: 1.4360 - val_accuracy: 0.5190\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3688 - accuracy: 0.4259 - val_loss: 1.5772 - val_accuracy: 0.4671\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4476 - accuracy: 0.4516 - val_loss: 1.5819 - val_accuracy: 0.4437\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3127 - accuracy: 0.4498 - val_loss: 1.7308 - val_accuracy: 0.4192\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3732 - accuracy: 0.4382 - val_loss: 1.4833 - val_accuracy: 0.4796\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2392 - accuracy: 0.4762 - val_loss: 1.4068 - val_accuracy: 0.5176\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1973 - accuracy: 0.4751 - val_loss: 1.4429 - val_accuracy: 0.5112\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2225 - accuracy: 0.4734 - val_loss: 1.4886 - val_accuracy: 0.4796\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1651 - accuracy: 0.4848 - val_loss: 1.4822 - val_accuracy: 0.4909\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1184 - accuracy: 0.4927 - val_loss: 1.3385 - val_accuracy: 0.5343\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1938 - accuracy: 0.4751 - val_loss: 1.2975 - val_accuracy: 0.5549\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1911 - accuracy: 0.4930 - val_loss: 1.2910 - val_accuracy: 0.5520\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1092 - accuracy: 0.4997 - val_loss: 1.3160 - val_accuracy: 0.5492\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3849 - accuracy: 0.4808 - val_loss: 1.3639 - val_accuracy: 0.5375\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2022 - accuracy: 0.4937 - val_loss: 1.2535 - val_accuracy: 0.5687\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1934 - accuracy: 0.4969 - val_loss: 1.4229 - val_accuracy: 0.5130\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2653 - accuracy: 0.4720 - val_loss: 2.3077 - val_accuracy: 0.3265\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3409 - accuracy: 0.4560 - val_loss: 1.4201 - val_accuracy: 0.5080\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5478 - accuracy: 0.4647 - val_loss: 1.3356 - val_accuracy: 0.5449\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0774 - accuracy: 0.5079 - val_loss: 1.3688 - val_accuracy: 0.5268\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1673 - accuracy: 0.4965 - val_loss: 1.3314 - val_accuracy: 0.5346\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1128 - accuracy: 0.5107 - val_loss: 1.3020 - val_accuracy: 0.5570\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0885 - accuracy: 0.5336 - val_loss: 1.2938 - val_accuracy: 0.5517\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1443 - accuracy: 0.5092 - val_loss: 1.5426 - val_accuracy: 0.4821\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2035 - accuracy: 0.5094 - val_loss: 1.2963 - val_accuracy: 0.5520\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2019 - accuracy: 0.5068 - val_loss: 1.3919 - val_accuracy: 0.4977\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1579 - accuracy: 0.5106 - val_loss: 1.3455 - val_accuracy: 0.5464\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0983 - accuracy: 0.5234 - val_loss: 1.2893 - val_accuracy: 0.5456\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1497 - accuracy: 0.5031 - val_loss: 1.4669 - val_accuracy: 0.5194\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0221 - accuracy: 0.5338 - val_loss: 1.7750 - val_accuracy: 0.4654\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1036 - accuracy: 0.5041 - val_loss: 1.2705 - val_accuracy: 0.5623\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0891 - accuracy: 0.5341 - val_loss: 1.2895 - val_accuracy: 0.5663\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0147 - accuracy: 0.5371 - val_loss: 1.2589 - val_accuracy: 0.5670\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3466 - accuracy: 0.4686 - val_loss: 1.3179 - val_accuracy: 0.5535\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8418 - accuracy: 0.5025 - val_loss: 1.5438 - val_accuracy: 0.4554\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7549 - accuracy: 0.4329 - val_loss: 1.3947 - val_accuracy: 0.5126\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4619 - accuracy: 0.4643 - val_loss: 1.7201 - val_accuracy: 0.4426\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2492 - accuracy: 0.4751 - val_loss: 1.3456 - val_accuracy: 0.5353\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1427 - accuracy: 0.5046 - val_loss: 1.5520 - val_accuracy: 0.4675\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0650 - accuracy: 0.5193 - val_loss: 1.1624 - val_accuracy: 0.6018\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0615 - accuracy: 0.5370 - val_loss: 1.2219 - val_accuracy: 0.5712\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0257 - accuracy: 0.5352 - val_loss: 1.4439 - val_accuracy: 0.5194\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0464 - accuracy: 0.5252 - val_loss: 2.0403 - val_accuracy: 0.3901\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2458 - accuracy: 0.4941 - val_loss: 1.4268 - val_accuracy: 0.5052\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2100 - accuracy: 0.4988 - val_loss: 1.4424 - val_accuracy: 0.5261\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1733 - accuracy: 0.5013 - val_loss: 1.1408 - val_accuracy: 0.6121\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9954 - accuracy: 0.5417 - val_loss: 1.3141 - val_accuracy: 0.5499\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0537 - accuracy: 0.5481 - val_loss: 1.1671 - val_accuracy: 0.6071\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0303 - accuracy: 0.5354 - val_loss: 1.2163 - val_accuracy: 0.5737\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2134 - accuracy: 0.4710 - val_loss: 1.2243 - val_accuracy: 0.5552\n",
      "Epoch 73/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1156 - accuracy: 0.5323 - val_loss: 1.7591 - val_accuracy: 0.3865\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1016 - accuracy: 0.5086 - val_loss: 1.1293 - val_accuracy: 0.6178\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0959 - accuracy: 0.5342 - val_loss: 1.3540 - val_accuracy: 0.5446\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1143 - accuracy: 0.5139 - val_loss: 1.1635 - val_accuracy: 0.5996\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0153 - accuracy: 0.5513 - val_loss: 1.1850 - val_accuracy: 0.5989\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9928 - accuracy: 0.5401 - val_loss: 1.2475 - val_accuracy: 0.5719\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9759 - accuracy: 0.5476 - val_loss: 1.1369 - val_accuracy: 0.5975\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9492 - accuracy: 0.5575 - val_loss: 1.1773 - val_accuracy: 0.5812\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2843 - accuracy: 0.5183 - val_loss: 1.2317 - val_accuracy: 0.5876\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0808 - accuracy: 0.5439 - val_loss: 1.1871 - val_accuracy: 0.6039\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9426 - accuracy: 0.5741 - val_loss: 1.3429 - val_accuracy: 0.5471\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9675 - accuracy: 0.5570 - val_loss: 1.0881 - val_accuracy: 0.6277\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9756 - accuracy: 0.5646 - val_loss: 1.1064 - val_accuracy: 0.6227\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8657 - accuracy: 0.5917 - val_loss: 1.1736 - val_accuracy: 0.6014\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9079 - accuracy: 0.5776 - val_loss: 1.1354 - val_accuracy: 0.6082\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8967 - accuracy: 0.5755 - val_loss: 1.1796 - val_accuracy: 0.5908\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4551 - accuracy: 0.4934 - val_loss: 1.5788 - val_accuracy: 0.4700\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4868 - accuracy: 0.4957 - val_loss: 1.8657 - val_accuracy: 0.3844\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5516 - accuracy: 0.4441 - val_loss: 1.5508 - val_accuracy: 0.4728\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0431 - accuracy: 0.5218 - val_loss: 1.1927 - val_accuracy: 0.5865\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2859 - accuracy: 0.5337 - val_loss: 1.2040 - val_accuracy: 0.5737\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9810 - accuracy: 0.5427 - val_loss: 1.1945 - val_accuracy: 0.5847\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9701 - accuracy: 0.5532 - val_loss: 1.1286 - val_accuracy: 0.6057\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9439 - accuracy: 0.5650 - val_loss: 1.3372 - val_accuracy: 0.5393\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9201 - accuracy: 0.5599 - val_loss: 1.1323 - val_accuracy: 0.6071\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8622 - accuracy: 0.5833 - val_loss: 1.1647 - val_accuracy: 0.6078\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9686 - accuracy: 0.5464 - val_loss: 1.2700 - val_accuracy: 0.5456\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9815 - accuracy: 0.5477 - val_loss: 1.1085 - val_accuracy: 0.6224\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8673 - accuracy: 0.5812 - val_loss: 1.0565 - val_accuracy: 0.6323\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0903 - accuracy: 0.5348 - val_loss: 1.3616 - val_accuracy: 0.5314\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0782 - accuracy: 0.5300 - val_loss: 1.3105 - val_accuracy: 0.5634\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0693 - accuracy: 0.5642 - val_loss: 1.2529 - val_accuracy: 0.5652\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2210 - accuracy: 0.5353 - val_loss: 1.2088 - val_accuracy: 0.5762\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9411 - accuracy: 0.5815 - val_loss: 1.0631 - val_accuracy: 0.6366\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9003 - accuracy: 0.5815 - val_loss: 1.0484 - val_accuracy: 0.6355\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1300 - accuracy: 0.5659 - val_loss: 1.0966 - val_accuracy: 0.6348\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0468 - accuracy: 0.5639 - val_loss: 1.1469 - val_accuracy: 0.6110\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9888 - accuracy: 0.5671 - val_loss: 1.0640 - val_accuracy: 0.6373\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8687 - accuracy: 0.5822 - val_loss: 1.1143 - val_accuracy: 0.6121\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8587 - accuracy: 0.5861 - val_loss: 1.0890 - val_accuracy: 0.6277\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1837 - accuracy: 0.5369 - val_loss: 1.2143 - val_accuracy: 0.5897\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8668 - accuracy: 0.5906 - val_loss: 1.1193 - val_accuracy: 0.6153\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8623 - accuracy: 0.5921 - val_loss: 1.1247 - val_accuracy: 0.6149\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8703 - accuracy: 0.5882 - val_loss: 1.1095 - val_accuracy: 0.6174\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8397 - accuracy: 0.5968 - val_loss: 1.0539 - val_accuracy: 0.6298\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8209 - accuracy: 0.5960 - val_loss: 1.0524 - val_accuracy: 0.6316\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8124 - accuracy: 0.6048 - val_loss: 1.0836 - val_accuracy: 0.6409\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8070 - accuracy: 0.5989 - val_loss: 1.0150 - val_accuracy: 0.6607\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9309 - accuracy: 0.5717 - val_loss: 1.3248 - val_accuracy: 0.5425\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8759 - accuracy: 0.5722 - val_loss: 1.0931 - val_accuracy: 0.6249\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9694 - accuracy: 0.5579 - val_loss: 1.3222 - val_accuracy: 0.5265\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4747 - accuracy: 0.5170 - val_loss: 1.2400 - val_accuracy: 0.5734\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1469 - accuracy: 0.5466 - val_loss: 1.2163 - val_accuracy: 0.5879\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9635 - accuracy: 0.5503 - val_loss: 1.7993 - val_accuracy: 0.3837\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1978 - accuracy: 0.5078 - val_loss: 1.2357 - val_accuracy: 0.5641\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9769 - accuracy: 0.5675 - val_loss: 1.2696 - val_accuracy: 0.5638\n",
      "Epoch 129/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9623 - accuracy: 0.5601 - val_loss: 1.1701 - val_accuracy: 0.5808\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8712 - accuracy: 0.5694 - val_loss: 1.0525 - val_accuracy: 0.6348\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1758 - accuracy: 0.5433 - val_loss: 1.1953 - val_accuracy: 0.5964\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3423 - accuracy: 0.5387 - val_loss: 1.1961 - val_accuracy: 0.5805\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9900 - accuracy: 0.5458 - val_loss: 1.2788 - val_accuracy: 0.5488\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8987 - accuracy: 0.5509 - val_loss: 1.1100 - val_accuracy: 0.6078\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9036 - accuracy: 0.5631 - val_loss: 1.0538 - val_accuracy: 0.6323\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8562 - accuracy: 0.5821 - val_loss: 1.1072 - val_accuracy: 0.6249\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1112 - accuracy: 0.5602 - val_loss: 1.3258 - val_accuracy: 0.5595\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8559 - accuracy: 0.5809 - val_loss: 1.0551 - val_accuracy: 0.6544\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8544 - accuracy: 0.5928 - val_loss: 1.1598 - val_accuracy: 0.6146\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8514 - accuracy: 0.5912 - val_loss: 1.0579 - val_accuracy: 0.6245\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8262 - accuracy: 0.5904 - val_loss: 1.0497 - val_accuracy: 0.6416\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8109 - accuracy: 0.6054 - val_loss: 1.0345 - val_accuracy: 0.6291\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9245 - accuracy: 0.5864 - val_loss: 1.0222 - val_accuracy: 0.6593\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0305 - accuracy: 0.5655 - val_loss: 1.4236 - val_accuracy: 0.5236\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2524 - accuracy: 0.4909 - val_loss: 1.4264 - val_accuracy: 0.4977\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1738 - accuracy: 0.5163 - val_loss: 1.2153 - val_accuracy: 0.5737\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2551 - accuracy: 0.5091 - val_loss: 1.2501 - val_accuracy: 0.5620\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0413 - accuracy: 0.5316 - val_loss: 1.1404 - val_accuracy: 0.6174\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3134 - accuracy: 0.5127 - val_loss: 1.2370 - val_accuracy: 0.5986\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1109 - accuracy: 0.5393 - val_loss: 1.2154 - val_accuracy: 0.5837\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9261 - accuracy: 0.5671 - val_loss: 1.0974 - val_accuracy: 0.6174\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4691 - accuracy: 0.4607 - val_loss: 1.2271 - val_accuracy: 0.5922\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0444 - accuracy: 0.5285 - val_loss: 1.1466 - val_accuracy: 0.6036\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9698 - accuracy: 0.5690 - val_loss: 1.1107 - val_accuracy: 0.6245\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9192 - accuracy: 0.5574 - val_loss: 1.0821 - val_accuracy: 0.6032\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9045 - accuracy: 0.5676 - val_loss: 1.0740 - val_accuracy: 0.6234\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0079 - accuracy: 0.5567 - val_loss: 1.1542 - val_accuracy: 0.6078\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9553 - accuracy: 0.5704 - val_loss: 1.0616 - val_accuracy: 0.6369\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0704 - accuracy: 0.5520 - val_loss: 1.2302 - val_accuracy: 0.6089\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3497 - accuracy: 0.5758 - val_loss: 1.1514 - val_accuracy: 0.5876\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3227 - accuracy: 0.5487 - val_loss: 1.1297 - val_accuracy: 0.6114\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9437 - accuracy: 0.5652 - val_loss: 1.0901 - val_accuracy: 0.6391\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8948 - accuracy: 0.5805 - val_loss: 1.1484 - val_accuracy: 0.6092\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8260 - accuracy: 0.5969 - val_loss: 1.0034 - val_accuracy: 0.6583\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9443 - accuracy: 0.5725 - val_loss: 1.0296 - val_accuracy: 0.6544\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9866 - accuracy: 0.5799 - val_loss: 1.2649 - val_accuracy: 0.5634\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2058 - accuracy: 0.5518 - val_loss: 1.1974 - val_accuracy: 0.5844\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1735 - accuracy: 0.5414 - val_loss: 1.1938 - val_accuracy: 0.5904\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3131 - accuracy: 0.5256 - val_loss: 1.1486 - val_accuracy: 0.6135\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9560 - accuracy: 0.5679 - val_loss: 1.0723 - val_accuracy: 0.6345\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8429 - accuracy: 0.5904 - val_loss: 0.9698 - val_accuracy: 0.6686\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9961 - accuracy: 0.5866 - val_loss: 1.3545 - val_accuracy: 0.5332\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9258 - accuracy: 0.5801 - val_loss: 1.1039 - val_accuracy: 0.6085\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0511 - accuracy: 0.5312 - val_loss: 1.1372 - val_accuracy: 0.5897\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8185 - accuracy: 0.5902 - val_loss: 1.0576 - val_accuracy: 0.6302\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8037 - accuracy: 0.5953 - val_loss: 1.0128 - val_accuracy: 0.6483\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8412 - accuracy: 0.5868 - val_loss: 1.0237 - val_accuracy: 0.6270\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9046 - accuracy: 0.5677 - val_loss: 1.4103 - val_accuracy: 0.5218\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9811 - accuracy: 0.5540 - val_loss: 1.1366 - val_accuracy: 0.6092\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3664 - accuracy: 0.5267 - val_loss: 1.4966 - val_accuracy: 0.5137\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1450 - accuracy: 0.5169 - val_loss: 1.1171 - val_accuracy: 0.6199\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0832 - accuracy: 0.5353 - val_loss: 1.3915 - val_accuracy: 0.5634\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9699 - accuracy: 0.5457 - val_loss: 1.2109 - val_accuracy: 0.5890\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8376 - accuracy: 0.5992 - val_loss: 1.0846 - val_accuracy: 0.6362\n",
      "Epoch 185/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7919 - accuracy: 0.6024 - val_loss: 1.0556 - val_accuracy: 0.6433\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8009 - accuracy: 0.6073 - val_loss: 1.0813 - val_accuracy: 0.6227\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3120 - accuracy: 0.5611 - val_loss: 1.3947 - val_accuracy: 0.5208\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1377 - accuracy: 0.5240 - val_loss: 1.1988 - val_accuracy: 0.5794\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0083 - accuracy: 0.5615 - val_loss: 1.1928 - val_accuracy: 0.5769\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8529 - accuracy: 0.5853 - val_loss: 1.0335 - val_accuracy: 0.6401\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8911 - accuracy: 0.5954 - val_loss: 1.1018 - val_accuracy: 0.6288\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2294 - accuracy: 0.5762 - val_loss: 1.3125 - val_accuracy: 0.5517\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0014 - accuracy: 0.5656 - val_loss: 1.2767 - val_accuracy: 0.5467\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8708 - accuracy: 0.5929 - val_loss: 1.0031 - val_accuracy: 0.6472\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.5591 - val_loss: 1.0228 - val_accuracy: 0.6437\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8703 - accuracy: 0.5895 - val_loss: 1.0430 - val_accuracy: 0.6423\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8462 - accuracy: 0.6017 - val_loss: 1.0057 - val_accuracy: 0.6615\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8282 - accuracy: 0.6084 - val_loss: 1.0618 - val_accuracy: 0.6274\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9691 - accuracy: 0.5689 - val_loss: 1.1861 - val_accuracy: 0.5876\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9646 - accuracy: 0.5704 - val_loss: 1.0852 - val_accuracy: 0.6202\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8413 - accuracy: 0.5971 - val_loss: 1.0546 - val_accuracy: 0.6483\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9015 - accuracy: 0.5867 - val_loss: 1.1637 - val_accuracy: 0.5869\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1726 - accuracy: 0.5563 - val_loss: 1.4046 - val_accuracy: 0.5183\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7614 - accuracy: 0.4814 - val_loss: 1.2923 - val_accuracy: 0.5730\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1179 - accuracy: 0.5510 - val_loss: 1.5693 - val_accuracy: 0.5044\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0251 - accuracy: 0.5331 - val_loss: 1.1111 - val_accuracy: 0.6149\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9429 - accuracy: 0.5670 - val_loss: 1.5092 - val_accuracy: 0.4735\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9562 - accuracy: 0.5511 - val_loss: 1.1324 - val_accuracy: 0.6089\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9611 - accuracy: 0.5725 - val_loss: 1.6321 - val_accuracy: 0.4856\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8809 - accuracy: 0.5715 - val_loss: 1.2413 - val_accuracy: 0.5659\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8786 - accuracy: 0.5792 - val_loss: 1.0301 - val_accuracy: 0.6508\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0223 - accuracy: 0.5733 - val_loss: 1.0199 - val_accuracy: 0.6536\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9240 - accuracy: 0.5937 - val_loss: 1.0382 - val_accuracy: 0.6412\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7874 - accuracy: 0.5956 - val_loss: 0.9739 - val_accuracy: 0.6753\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0220 - accuracy: 0.5538 - val_loss: 1.2561 - val_accuracy: 0.5758\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9350 - accuracy: 0.5616 - val_loss: 1.1725 - val_accuracy: 0.5861\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0518 - accuracy: 0.5337 - val_loss: 1.1632 - val_accuracy: 0.5922\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1132 - accuracy: 0.5430 - val_loss: 1.1071 - val_accuracy: 0.6345\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9874 - accuracy: 0.5754 - val_loss: 1.0660 - val_accuracy: 0.6330\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8231 - accuracy: 0.5981 - val_loss: 1.0780 - val_accuracy: 0.6263\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8208 - accuracy: 0.5987 - val_loss: 1.3442 - val_accuracy: 0.5520\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8690 - accuracy: 0.5912 - val_loss: 1.0445 - val_accuracy: 0.6380\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9298 - accuracy: 0.5883 - val_loss: 1.2251 - val_accuracy: 0.5503\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2807 - accuracy: 0.4911 - val_loss: 1.2087 - val_accuracy: 0.5847\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9600 - accuracy: 0.5659 - val_loss: 1.3671 - val_accuracy: 0.5741\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9936 - accuracy: 0.5611 - val_loss: 1.0553 - val_accuracy: 0.6313\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8749 - accuracy: 0.5946 - val_loss: 0.9645 - val_accuracy: 0.6718\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0017 - accuracy: 0.5707 - val_loss: 1.0430 - val_accuracy: 0.6444\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9430 - accuracy: 0.5789 - val_loss: 1.0601 - val_accuracy: 0.6384\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8280 - accuracy: 0.5979 - val_loss: 0.9888 - val_accuracy: 0.6512\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7658 - accuracy: 0.6145 - val_loss: 0.9784 - val_accuracy: 0.6650\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7694 - accuracy: 0.6151 - val_loss: 1.0063 - val_accuracy: 0.6604\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9909 - accuracy: 0.5739 - val_loss: 1.4046 - val_accuracy: 0.5403\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5873 - accuracy: 0.4939 - val_loss: 1.1804 - val_accuracy: 0.6146\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8799 - accuracy: 0.5703 - val_loss: 1.1263 - val_accuracy: 0.6039\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8542 - accuracy: 0.5817 - val_loss: 1.1900 - val_accuracy: 0.5861\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0834 - accuracy: 0.5721 - val_loss: 1.1158 - val_accuracy: 0.6256\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9950 - accuracy: 0.5653 - val_loss: 1.2131 - val_accuracy: 0.5741\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9911 - accuracy: 0.5831 - val_loss: 1.1257 - val_accuracy: 0.6274\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0608 - accuracy: 0.5631 - val_loss: 1.0656 - val_accuracy: 0.6288\n",
      "Epoch 241/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8027 - accuracy: 0.6036 - val_loss: 1.0695 - val_accuracy: 0.6245\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8330 - accuracy: 0.6071 - val_loss: 1.0648 - val_accuracy: 0.6263\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9199 - accuracy: 0.5759 - val_loss: 1.2694 - val_accuracy: 0.5666\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0796 - accuracy: 0.5512 - val_loss: 1.0901 - val_accuracy: 0.6249\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9850 - accuracy: 0.5861 - val_loss: 1.0795 - val_accuracy: 0.6472\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9068 - accuracy: 0.5762 - val_loss: 1.1714 - val_accuracy: 0.6128\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3565 - accuracy: 0.5226 - val_loss: 1.2214 - val_accuracy: 0.5687\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1216 - accuracy: 0.5242 - val_loss: 1.2197 - val_accuracy: 0.5698\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2348 - accuracy: 0.5222 - val_loss: 1.2592 - val_accuracy: 0.5496\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0348 - accuracy: 0.5664 - val_loss: 1.0501 - val_accuracy: 0.6522\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0042 - accuracy: 0.5710 - val_loss: 1.0696 - val_accuracy: 0.6330\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9673 - accuracy: 0.5841 - val_loss: 1.3368 - val_accuracy: 0.5609\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0448 - accuracy: 0.5637 - val_loss: 1.1613 - val_accuracy: 0.6075\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8857 - accuracy: 0.5837 - val_loss: 0.9726 - val_accuracy: 0.6586\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8511 - accuracy: 0.5977 - val_loss: 1.1831 - val_accuracy: 0.5943\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7969 - accuracy: 0.6112 - val_loss: 0.9815 - val_accuracy: 0.6682\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8647 - accuracy: 0.5989 - val_loss: 1.1523 - val_accuracy: 0.6043\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9012 - accuracy: 0.5852 - val_loss: 1.0008 - val_accuracy: 0.6504\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7837 - accuracy: 0.6153 - val_loss: 1.0494 - val_accuracy: 0.6472\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8707 - accuracy: 0.5940 - val_loss: 1.0142 - val_accuracy: 0.6615\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7748 - accuracy: 0.6169 - val_loss: 1.0247 - val_accuracy: 0.6433\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1293 - accuracy: 0.5235 - val_loss: 1.2365 - val_accuracy: 0.5552\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2006 - accuracy: 0.4727 - val_loss: 1.4275 - val_accuracy: 0.5233\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6993 - accuracy: 0.5002 - val_loss: 1.2871 - val_accuracy: 0.5591\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2202 - accuracy: 0.5283 - val_loss: 1.3075 - val_accuracy: 0.5510\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1646 - accuracy: 0.5104 - val_loss: 1.2004 - val_accuracy: 0.5794\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6177 - accuracy: 0.5460 - val_loss: 1.1258 - val_accuracy: 0.6121\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0193 - accuracy: 0.5759 - val_loss: 1.0547 - val_accuracy: 0.6451\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9329 - accuracy: 0.5806 - val_loss: 1.1133 - val_accuracy: 0.6195\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5962 - accuracy: 0.5269 - val_loss: 1.1936 - val_accuracy: 0.5790\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8897 - accuracy: 0.5628 - val_loss: 1.1614 - val_accuracy: 0.6142\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9205 - accuracy: 0.5829 - val_loss: 1.1274 - val_accuracy: 0.6188\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8527 - accuracy: 0.5898 - val_loss: 1.0700 - val_accuracy: 0.6316\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8214 - accuracy: 0.5940 - val_loss: 1.0979 - val_accuracy: 0.6362\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8113 - accuracy: 0.5993 - val_loss: 0.9832 - val_accuracy: 0.6803\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7751 - accuracy: 0.6143 - val_loss: 0.9994 - val_accuracy: 0.6622\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8005 - accuracy: 0.6092 - val_loss: 1.1146 - val_accuracy: 0.6167\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8406 - accuracy: 0.6003 - val_loss: 1.0514 - val_accuracy: 0.6529\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7922 - accuracy: 0.6130 - val_loss: 0.9766 - val_accuracy: 0.6718\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1367 - accuracy: 0.5219 - val_loss: 1.1239 - val_accuracy: 0.6121\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8772 - accuracy: 0.5099 - val_loss: 1.2524 - val_accuracy: 0.5485\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0406 - accuracy: 0.5348 - val_loss: 1.3198 - val_accuracy: 0.5524\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0271 - accuracy: 0.5701 - val_loss: 1.2413 - val_accuracy: 0.5908\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8978 - accuracy: 0.6005 - val_loss: 1.0566 - val_accuracy: 0.6440\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9740 - accuracy: 0.6061 - val_loss: 1.0538 - val_accuracy: 0.6352\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3783 - accuracy: 0.4975 - val_loss: 1.5176 - val_accuracy: 0.5030\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8307 - accuracy: 0.4709 - val_loss: 1.2315 - val_accuracy: 0.5915\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2346 - accuracy: 0.5355 - val_loss: 1.1336 - val_accuracy: 0.6163\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3467 - accuracy: 0.5207 - val_loss: 1.1885 - val_accuracy: 0.5865\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0703 - accuracy: 0.5569 - val_loss: 1.5477 - val_accuracy: 0.4959\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0287 - accuracy: 0.5478 - val_loss: 1.1241 - val_accuracy: 0.6288\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9853 - accuracy: 0.5674 - val_loss: 1.0786 - val_accuracy: 0.6494\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9097 - accuracy: 0.5817 - val_loss: 1.0251 - val_accuracy: 0.6622\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9530 - accuracy: 0.5807 - val_loss: 1.0181 - val_accuracy: 0.6551\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1151 - accuracy: 0.5312 - val_loss: 1.1213 - val_accuracy: 0.6018\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3360 - accuracy: 0.5428 - val_loss: 1.6417 - val_accuracy: 0.4401\n",
      "Epoch 297/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 2.8541 - accuracy: 0.4052 - val_loss: 1.5986 - val_accuracy: 0.4632\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4287 - accuracy: 0.4923 - val_loss: 1.4257 - val_accuracy: 0.5726\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1889 - accuracy: 0.5008 - val_loss: 1.3330 - val_accuracy: 0.5353\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0703 - accuracy: 0.5322 - val_loss: 1.2055 - val_accuracy: 0.5854\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9603 - accuracy: 0.5593 - val_loss: 1.0684 - val_accuracy: 0.6306\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2660 - accuracy: 0.5566 - val_loss: 1.1335 - val_accuracy: 0.6231\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9356 - accuracy: 0.5732 - val_loss: 1.1289 - val_accuracy: 0.6295\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9006 - accuracy: 0.5758 - val_loss: 1.0213 - val_accuracy: 0.6583\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9726 - accuracy: 0.5926 - val_loss: 1.0317 - val_accuracy: 0.6504\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8987 - accuracy: 0.5801 - val_loss: 1.1188 - val_accuracy: 0.6064\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0799 - accuracy: 0.5663 - val_loss: 1.1410 - val_accuracy: 0.6124\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9866 - accuracy: 0.5715 - val_loss: 1.2920 - val_accuracy: 0.5570\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1757 - accuracy: 0.5067 - val_loss: 1.2287 - val_accuracy: 0.5901\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9169 - accuracy: 0.5801 - val_loss: 1.0500 - val_accuracy: 0.6540\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1538 - accuracy: 0.5687 - val_loss: 1.5417 - val_accuracy: 0.5190\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2870 - accuracy: 0.4806 - val_loss: 1.6578 - val_accuracy: 0.4405\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0108 - accuracy: 0.5416 - val_loss: 1.1914 - val_accuracy: 0.5766\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0186 - accuracy: 0.5590 - val_loss: 1.1068 - val_accuracy: 0.6146\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9483 - accuracy: 0.5679 - val_loss: 1.2687 - val_accuracy: 0.5751\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8911 - accuracy: 0.5841 - val_loss: 1.0088 - val_accuracy: 0.6558\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8323 - accuracy: 0.6070 - val_loss: 1.0106 - val_accuracy: 0.6501\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9159 - accuracy: 0.5932 - val_loss: 1.0179 - val_accuracy: 0.6536\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8301 - accuracy: 0.5966 - val_loss: 1.1198 - val_accuracy: 0.6167\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8146 - accuracy: 0.6044 - val_loss: 0.9425 - val_accuracy: 0.6828\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4104 - accuracy: 0.5447 - val_loss: 1.6651 - val_accuracy: 0.4757\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1566 - accuracy: 0.5464 - val_loss: 1.1585 - val_accuracy: 0.6007\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9596 - accuracy: 0.5744 - val_loss: 1.0874 - val_accuracy: 0.6217\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8798 - accuracy: 0.5883 - val_loss: 1.0019 - val_accuracy: 0.6572\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1007 - accuracy: 0.5589 - val_loss: 1.3280 - val_accuracy: 0.5599\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0842 - accuracy: 0.5095 - val_loss: 1.0998 - val_accuracy: 0.6195\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0318 - accuracy: 0.5569 - val_loss: 1.1496 - val_accuracy: 0.6149\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8873 - accuracy: 0.5799 - val_loss: 1.0627 - val_accuracy: 0.6458\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7961 - accuracy: 0.6040 - val_loss: 1.0317 - val_accuracy: 0.6366\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7788 - accuracy: 0.6036 - val_loss: 1.0055 - val_accuracy: 0.6636\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8770 - accuracy: 0.5944 - val_loss: 1.0269 - val_accuracy: 0.6430\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9584 - accuracy: 0.6043 - val_loss: 1.0815 - val_accuracy: 0.6355\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9970 - accuracy: 0.5612 - val_loss: 1.4372 - val_accuracy: 0.5151\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2010 - accuracy: 0.5299 - val_loss: 1.1645 - val_accuracy: 0.6124\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2005 - accuracy: 0.4742 - val_loss: 2.1688 - val_accuracy: 0.3147\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4041 - accuracy: 0.4426 - val_loss: 1.4105 - val_accuracy: 0.5268\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0581 - accuracy: 0.5379 - val_loss: 1.1644 - val_accuracy: 0.5989\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0212 - accuracy: 0.5544 - val_loss: 1.2727 - val_accuracy: 0.5641\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8955 - accuracy: 0.5797 - val_loss: 1.0481 - val_accuracy: 0.6320\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9804 - accuracy: 0.5959 - val_loss: 1.1045 - val_accuracy: 0.6210\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9477 - accuracy: 0.5028 - val_loss: 1.2422 - val_accuracy: 0.5808\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9274 - accuracy: 0.5615 - val_loss: 1.0511 - val_accuracy: 0.6430\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4910 - accuracy: 0.5278 - val_loss: 1.2335 - val_accuracy: 0.5776\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0052 - accuracy: 0.5558 - val_loss: 1.1043 - val_accuracy: 0.6238\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9422 - accuracy: 0.5686 - val_loss: 1.0643 - val_accuracy: 0.6600\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.8176 - accuracy: 0.6004 - val_loss: 0.9891 - val_accuracy: 0.6824\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8142 - accuracy: 0.5121 - val_loss: 1.2696 - val_accuracy: 0.5762\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2628 - accuracy: 0.5163 - val_loss: 1.3155 - val_accuracy: 0.5595\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2224 - accuracy: 0.5123 - val_loss: 1.3061 - val_accuracy: 0.5645\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0572 - accuracy: 0.5603 - val_loss: 1.2189 - val_accuracy: 0.5940\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9541 - accuracy: 0.5760 - val_loss: 1.4020 - val_accuracy: 0.5528\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0421 - accuracy: 0.5619 - val_loss: 1.3906 - val_accuracy: 0.5258\n",
      "Epoch 353/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0445 - accuracy: 0.5847 - val_loss: 1.2102 - val_accuracy: 0.5979\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2007 - accuracy: 0.5154 - val_loss: 1.2481 - val_accuracy: 0.6018\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1671 - accuracy: 0.5727 - val_loss: 1.2263 - val_accuracy: 0.5755\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1680 - accuracy: 0.5612 - val_loss: 1.0491 - val_accuracy: 0.6423\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9116 - accuracy: 0.5949 - val_loss: 1.0823 - val_accuracy: 0.6270\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8242 - accuracy: 0.5975 - val_loss: 1.1058 - val_accuracy: 0.6252\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7780 - accuracy: 0.6111 - val_loss: 1.0878 - val_accuracy: 0.6174\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8241 - accuracy: 0.6129 - val_loss: 1.0277 - val_accuracy: 0.6437\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7515 - accuracy: 0.6159 - val_loss: 1.0534 - val_accuracy: 0.6355\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9182 - accuracy: 0.5886 - val_loss: 1.1282 - val_accuracy: 0.6099\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7994 - accuracy: 0.6014 - val_loss: 0.9692 - val_accuracy: 0.6636\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7657 - accuracy: 0.6192 - val_loss: 1.0909 - val_accuracy: 0.6128\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8868 - accuracy: 0.5921 - val_loss: 0.9789 - val_accuracy: 0.6785\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9549 - accuracy: 0.5983 - val_loss: 1.5860 - val_accuracy: 0.4693\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2200 - accuracy: 0.4988 - val_loss: 1.2205 - val_accuracy: 0.5655\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.2613 - accuracy: 0.5416 - val_loss: 1.4530 - val_accuracy: 0.5094\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5795 - accuracy: 0.4535 - val_loss: 1.2375 - val_accuracy: 0.5833\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0000 - accuracy: 0.5489 - val_loss: 1.1123 - val_accuracy: 0.6199\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9344 - accuracy: 0.5867 - val_loss: 1.1248 - val_accuracy: 0.6078\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8625 - accuracy: 0.5966 - val_loss: 1.1998 - val_accuracy: 0.5933\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0925 - accuracy: 0.5346 - val_loss: 1.2707 - val_accuracy: 0.5517\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4170 - accuracy: 0.5582 - val_loss: 1.4281 - val_accuracy: 0.5179\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9407 - accuracy: 0.5693 - val_loss: 1.1301 - val_accuracy: 0.6075\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0675 - accuracy: 0.5624 - val_loss: 1.1481 - val_accuracy: 0.6227\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2074 - accuracy: 0.5647 - val_loss: 1.1481 - val_accuracy: 0.6146\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2893 - accuracy: 0.5687 - val_loss: 1.2384 - val_accuracy: 0.5808\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0433 - accuracy: 0.5547 - val_loss: 1.1119 - val_accuracy: 0.6231\n",
      "\n",
      "Validation 2, fold 3 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8983 - accuracy: 0.0914 - val_loss: 2.8011 - val_accuracy: 0.0529\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7496 - accuracy: 0.1127 - val_loss: 2.4279 - val_accuracy: 0.1481\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4967 - accuracy: 0.1803 - val_loss: 2.3107 - val_accuracy: 0.1961\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2709 - accuracy: 0.1878 - val_loss: 2.1639 - val_accuracy: 0.2682\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2660 - accuracy: 0.2067 - val_loss: 2.1667 - val_accuracy: 0.2153\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0923 - accuracy: 0.2298 - val_loss: 2.1427 - val_accuracy: 0.2622\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9280 - accuracy: 0.2766 - val_loss: 2.0636 - val_accuracy: 0.2558\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8316 - accuracy: 0.2854 - val_loss: 1.9831 - val_accuracy: 0.3265\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9272 - accuracy: 0.2987 - val_loss: 2.2347 - val_accuracy: 0.2401\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7355 - accuracy: 0.3117 - val_loss: 1.9121 - val_accuracy: 0.3325\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7163 - accuracy: 0.3411 - val_loss: 1.7436 - val_accuracy: 0.4107\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.7294 - accuracy: 0.3429 - val_loss: 1.8126 - val_accuracy: 0.3641\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5883 - accuracy: 0.3706 - val_loss: 1.8455 - val_accuracy: 0.3563\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6391 - accuracy: 0.3666 - val_loss: 1.7188 - val_accuracy: 0.4206\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4980 - accuracy: 0.3956 - val_loss: 1.7223 - val_accuracy: 0.4181\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4589 - accuracy: 0.4085 - val_loss: 1.6823 - val_accuracy: 0.4284\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4274 - accuracy: 0.4176 - val_loss: 1.6866 - val_accuracy: 0.4256\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4017 - accuracy: 0.4377 - val_loss: 1.6375 - val_accuracy: 0.4419\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3792 - accuracy: 0.4293 - val_loss: 1.5326 - val_accuracy: 0.4796\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.3332 - accuracy: 0.4328 - val_loss: 1.5797 - val_accuracy: 0.4462\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2998 - accuracy: 0.4500 - val_loss: 1.5003 - val_accuracy: 0.4742\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3273 - accuracy: 0.4460 - val_loss: 1.6715 - val_accuracy: 0.4586\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3484 - accuracy: 0.4607 - val_loss: 1.7644 - val_accuracy: 0.3901\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1136 - accuracy: 0.3869 - val_loss: 1.6535 - val_accuracy: 0.4547\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5194 - accuracy: 0.4193 - val_loss: 2.0698 - val_accuracy: 0.3300\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3704 - accuracy: 0.4422 - val_loss: 1.6382 - val_accuracy: 0.4440\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2114 - accuracy: 0.4710 - val_loss: 1.4925 - val_accuracy: 0.4856\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4669 - accuracy: 0.4415 - val_loss: 1.5744 - val_accuracy: 0.4693\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2187 - accuracy: 0.4772 - val_loss: 1.4434 - val_accuracy: 0.5332\n",
      "Epoch 30/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1477 - accuracy: 0.4890 - val_loss: 1.4169 - val_accuracy: 0.5226\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2666 - accuracy: 0.4752 - val_loss: 1.5045 - val_accuracy: 0.5062\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1563 - accuracy: 0.4944 - val_loss: 1.3741 - val_accuracy: 0.5432\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2414 - accuracy: 0.4847 - val_loss: 1.4998 - val_accuracy: 0.4970\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2745 - accuracy: 0.4737 - val_loss: 1.3892 - val_accuracy: 0.5538\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2217 - accuracy: 0.5000 - val_loss: 1.5575 - val_accuracy: 0.5016\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2884 - accuracy: 0.4905 - val_loss: 1.9082 - val_accuracy: 0.4348\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2370 - accuracy: 0.4757 - val_loss: 1.3628 - val_accuracy: 0.5478\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1596 - accuracy: 0.5070 - val_loss: 1.6308 - val_accuracy: 0.5044\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3500 - accuracy: 0.4718 - val_loss: 1.4722 - val_accuracy: 0.5044\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1828 - accuracy: 0.5027 - val_loss: 1.3346 - val_accuracy: 0.5570\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2588 - accuracy: 0.4829 - val_loss: 1.5115 - val_accuracy: 0.4902\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1145 - accuracy: 0.5000 - val_loss: 1.3822 - val_accuracy: 0.5300\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1212 - accuracy: 0.5035 - val_loss: 1.3855 - val_accuracy: 0.5321\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0582 - accuracy: 0.5070 - val_loss: 1.3051 - val_accuracy: 0.5510\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0737 - accuracy: 0.5254 - val_loss: 1.4256 - val_accuracy: 0.5318\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1340 - accuracy: 0.5038 - val_loss: 1.6233 - val_accuracy: 0.4686\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1405 - accuracy: 0.5004 - val_loss: 1.5232 - val_accuracy: 0.5076\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5916 - accuracy: 0.4631 - val_loss: 1.4243 - val_accuracy: 0.5240\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2344 - accuracy: 0.5008 - val_loss: 1.4759 - val_accuracy: 0.5155\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6215 - accuracy: 0.4514 - val_loss: 1.5021 - val_accuracy: 0.4828\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2708 - accuracy: 0.4516 - val_loss: 1.4222 - val_accuracy: 0.5115\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1444 - accuracy: 0.5036 - val_loss: 1.3307 - val_accuracy: 0.5666\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0827 - accuracy: 0.5172 - val_loss: 1.3812 - val_accuracy: 0.5563\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0768 - accuracy: 0.5186 - val_loss: 1.3350 - val_accuracy: 0.5623\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0322 - accuracy: 0.5212 - val_loss: 1.3276 - val_accuracy: 0.5485\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1319 - accuracy: 0.5172 - val_loss: 1.2717 - val_accuracy: 0.5741\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8223 - accuracy: 0.5090 - val_loss: 1.5715 - val_accuracy: 0.4899\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0432 - accuracy: 0.5242 - val_loss: 1.3919 - val_accuracy: 0.5279\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3425 - accuracy: 0.5041 - val_loss: 1.4457 - val_accuracy: 0.5368\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0744 - accuracy: 0.5264 - val_loss: 1.3698 - val_accuracy: 0.5645\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9830 - accuracy: 0.5431 - val_loss: 1.2620 - val_accuracy: 0.5861\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0398 - accuracy: 0.5369 - val_loss: 1.6561 - val_accuracy: 0.4398\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1373 - accuracy: 0.4898 - val_loss: 1.5728 - val_accuracy: 0.4710\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0548 - accuracy: 0.5153 - val_loss: 1.3738 - val_accuracy: 0.5616\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1351 - accuracy: 0.5116 - val_loss: 1.3875 - val_accuracy: 0.5169\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0349 - accuracy: 0.5339 - val_loss: 1.2827 - val_accuracy: 0.5734\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9682 - accuracy: 0.5489 - val_loss: 1.2750 - val_accuracy: 0.5691\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1571 - accuracy: 0.5226 - val_loss: 1.6338 - val_accuracy: 0.4742\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9758 - accuracy: 0.5406 - val_loss: 1.2148 - val_accuracy: 0.5925\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9998 - accuracy: 0.5348 - val_loss: 1.2343 - val_accuracy: 0.5893\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9489 - accuracy: 0.5526 - val_loss: 1.2139 - val_accuracy: 0.5957\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0111 - accuracy: 0.5397 - val_loss: 1.2302 - val_accuracy: 0.5819\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6506 - accuracy: 0.4944 - val_loss: 1.6310 - val_accuracy: 0.4384\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5982 - accuracy: 0.4453 - val_loss: 1.4209 - val_accuracy: 0.5400\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0558 - accuracy: 0.5235 - val_loss: 1.3768 - val_accuracy: 0.5432\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9599 - accuracy: 0.5395 - val_loss: 1.2328 - val_accuracy: 0.5819\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0215 - accuracy: 0.5179 - val_loss: 1.3350 - val_accuracy: 0.5581\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9376 - accuracy: 0.5499 - val_loss: 1.3051 - val_accuracy: 0.5591\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9025 - accuracy: 0.5617 - val_loss: 1.1920 - val_accuracy: 0.5975\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8695 - accuracy: 0.5745 - val_loss: 1.2141 - val_accuracy: 0.6000\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1234 - accuracy: 0.5214 - val_loss: 1.3021 - val_accuracy: 0.5663\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9251 - accuracy: 0.5593 - val_loss: 1.3516 - val_accuracy: 0.5520\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9270 - accuracy: 0.5612 - val_loss: 1.2774 - val_accuracy: 0.5829\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1298 - accuracy: 0.5140 - val_loss: 1.3430 - val_accuracy: 0.5449\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3155 - accuracy: 0.4852 - val_loss: 1.4005 - val_accuracy: 0.5467\n",
      "Epoch 86/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0732 - accuracy: 0.5277 - val_loss: 1.4310 - val_accuracy: 0.5293\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2144 - accuracy: 0.5203 - val_loss: 1.4522 - val_accuracy: 0.5126\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0014 - accuracy: 0.5410 - val_loss: 1.3251 - val_accuracy: 0.5591\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0035 - accuracy: 0.5442 - val_loss: 1.2247 - val_accuracy: 0.6089\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2449 - accuracy: 0.5459 - val_loss: 1.5172 - val_accuracy: 0.5062\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5134 - accuracy: 0.4529 - val_loss: 1.6375 - val_accuracy: 0.4675\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8125 - accuracy: 0.4243 - val_loss: 1.6477 - val_accuracy: 0.4472\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6590 - accuracy: 0.4439 - val_loss: 1.4905 - val_accuracy: 0.4941\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1869 - accuracy: 0.4947 - val_loss: 1.3701 - val_accuracy: 0.5538\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1839 - accuracy: 0.5048 - val_loss: 1.2938 - val_accuracy: 0.5631\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2070 - accuracy: 0.5171 - val_loss: 1.7604 - val_accuracy: 0.4487\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5654 - accuracy: 0.4928 - val_loss: 1.4314 - val_accuracy: 0.5147\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1742 - accuracy: 0.5004 - val_loss: 1.3371 - val_accuracy: 0.5528\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0793 - accuracy: 0.5191 - val_loss: 1.2795 - val_accuracy: 0.5787\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0340 - accuracy: 0.5284 - val_loss: 1.3386 - val_accuracy: 0.5648\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9778 - accuracy: 0.5457 - val_loss: 1.2440 - val_accuracy: 0.5986\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2445 - accuracy: 0.5217 - val_loss: 1.2879 - val_accuracy: 0.5677\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0577 - accuracy: 0.5419 - val_loss: 1.2128 - val_accuracy: 0.6057\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9913 - accuracy: 0.5441 - val_loss: 1.3801 - val_accuracy: 0.5226\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1078 - accuracy: 0.5193 - val_loss: 1.3606 - val_accuracy: 0.5560\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9871 - accuracy: 0.5461 - val_loss: 1.2536 - val_accuracy: 0.5829\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0162 - accuracy: 0.5315 - val_loss: 1.2850 - val_accuracy: 0.5719\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0720 - accuracy: 0.5430 - val_loss: 1.2882 - val_accuracy: 0.5751\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0858 - accuracy: 0.4443 - val_loss: 1.4976 - val_accuracy: 0.4828\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2232 - accuracy: 0.4854 - val_loss: 1.3588 - val_accuracy: 0.5403\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0968 - accuracy: 0.5176 - val_loss: 1.2646 - val_accuracy: 0.5758\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9955 - accuracy: 0.5453 - val_loss: 1.3599 - val_accuracy: 0.5588\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2552 - accuracy: 0.4867 - val_loss: 2.0665 - val_accuracy: 0.3762\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1485 - accuracy: 0.5035 - val_loss: 1.2277 - val_accuracy: 0.6004\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0621 - accuracy: 0.5280 - val_loss: 1.3000 - val_accuracy: 0.5645\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5195 - accuracy: 0.5226 - val_loss: 1.3119 - val_accuracy: 0.5531\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9878 - accuracy: 0.5521 - val_loss: 1.2697 - val_accuracy: 0.5858\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0322 - accuracy: 0.5513 - val_loss: 1.2705 - val_accuracy: 0.5940\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4399 - accuracy: 0.5009 - val_loss: 1.5135 - val_accuracy: 0.4824\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4441 - accuracy: 0.4832 - val_loss: 1.4651 - val_accuracy: 0.5073\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1721 - accuracy: 0.5002 - val_loss: 1.3338 - val_accuracy: 0.5520\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0649 - accuracy: 0.5278 - val_loss: 1.4235 - val_accuracy: 0.5165\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0368 - accuracy: 0.5242 - val_loss: 1.3000 - val_accuracy: 0.5691\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9736 - accuracy: 0.5514 - val_loss: 1.2163 - val_accuracy: 0.5968\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0457 - accuracy: 0.5429 - val_loss: 1.4729 - val_accuracy: 0.5105\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0660 - accuracy: 0.5312 - val_loss: 1.2540 - val_accuracy: 0.5638\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9761 - accuracy: 0.5448 - val_loss: 1.3221 - val_accuracy: 0.5595\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9697 - accuracy: 0.5542 - val_loss: 1.1984 - val_accuracy: 0.5861\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1023 - accuracy: 0.5321 - val_loss: 1.4323 - val_accuracy: 0.5410\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9708 - accuracy: 0.5463 - val_loss: 1.2844 - val_accuracy: 0.5599\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9748 - accuracy: 0.5365 - val_loss: 1.3167 - val_accuracy: 0.5620\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8684 - accuracy: 0.5752 - val_loss: 1.1808 - val_accuracy: 0.6071\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9497 - accuracy: 0.5672 - val_loss: 1.7928 - val_accuracy: 0.4078\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0634 - accuracy: 0.5362 - val_loss: 1.3112 - val_accuracy: 0.5687\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5459 - accuracy: 0.4837 - val_loss: 1.4828 - val_accuracy: 0.5108\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1856 - accuracy: 0.5186 - val_loss: 1.4101 - val_accuracy: 0.5364\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4592 - accuracy: 0.4950 - val_loss: 1.4277 - val_accuracy: 0.5250\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0118 - accuracy: 0.5417 - val_loss: 1.2136 - val_accuracy: 0.6028\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3352 - accuracy: 0.5313 - val_loss: 1.3085 - val_accuracy: 0.5684\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1054 - accuracy: 0.5353 - val_loss: 1.2106 - val_accuracy: 0.6021\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1673 - accuracy: 0.5362 - val_loss: 1.2746 - val_accuracy: 0.5886\n",
      "Epoch 142/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0166 - accuracy: 0.5547 - val_loss: 1.2573 - val_accuracy: 0.5815\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0010 - accuracy: 0.5518 - val_loss: 1.1979 - val_accuracy: 0.6032\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9700 - accuracy: 0.5594 - val_loss: 1.7535 - val_accuracy: 0.5890\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3898 - accuracy: 0.4872 - val_loss: 1.3857 - val_accuracy: 0.5229\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3319 - accuracy: 0.5115 - val_loss: 1.4597 - val_accuracy: 0.5137\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9833 - accuracy: 0.5302 - val_loss: 1.2920 - val_accuracy: 0.5812\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9644 - accuracy: 0.5389 - val_loss: 1.5938 - val_accuracy: 0.4558\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0311 - accuracy: 0.5271 - val_loss: 1.3737 - val_accuracy: 0.5353\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9893 - accuracy: 0.5462 - val_loss: 1.3288 - val_accuracy: 0.5584\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9830 - accuracy: 0.5566 - val_loss: 1.3103 - val_accuracy: 0.5851\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0394 - accuracy: 0.5392 - val_loss: 1.2441 - val_accuracy: 0.5947\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0565 - accuracy: 0.5586 - val_loss: 1.2685 - val_accuracy: 0.5925\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8739 - accuracy: 0.5697 - val_loss: 1.2325 - val_accuracy: 0.5986\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6800 - accuracy: 0.5535 - val_loss: 1.3211 - val_accuracy: 0.5481\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3817 - accuracy: 0.5097 - val_loss: 1.4482 - val_accuracy: 0.5396\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5181 - accuracy: 0.5146 - val_loss: 1.3173 - val_accuracy: 0.5670\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2233 - accuracy: 0.5338 - val_loss: 1.4382 - val_accuracy: 0.5279\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3671 - accuracy: 0.5131 - val_loss: 1.4792 - val_accuracy: 0.5233\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2374 - accuracy: 0.5073 - val_loss: 1.2920 - val_accuracy: 0.5808\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3807 - accuracy: 0.5341 - val_loss: 1.4513 - val_accuracy: 0.5361\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0303 - accuracy: 0.5537 - val_loss: 1.2206 - val_accuracy: 0.6028\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0222 - accuracy: 0.5471 - val_loss: 1.3521 - val_accuracy: 0.5595\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3149 - accuracy: 0.5348 - val_loss: 1.5308 - val_accuracy: 0.4970\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2191 - accuracy: 0.4938 - val_loss: 1.4057 - val_accuracy: 0.5293\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3714 - accuracy: 0.4994 - val_loss: 1.4511 - val_accuracy: 0.5240\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2006 - accuracy: 0.4945 - val_loss: 1.3093 - val_accuracy: 0.5620\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0863 - accuracy: 0.5403 - val_loss: 1.5186 - val_accuracy: 0.5076\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0450 - accuracy: 0.5311 - val_loss: 1.3345 - val_accuracy: 0.5616\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9732 - accuracy: 0.5431 - val_loss: 1.2433 - val_accuracy: 0.5901\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6728 - accuracy: 0.5089 - val_loss: 1.5719 - val_accuracy: 0.5105\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4905 - accuracy: 0.4881 - val_loss: 1.3374 - val_accuracy: 0.5623\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0237 - accuracy: 0.5511 - val_loss: 1.3657 - val_accuracy: 0.5499\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0023 - accuracy: 0.5549 - val_loss: 1.3410 - val_accuracy: 0.5826\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1222 - accuracy: 0.5319 - val_loss: 1.5053 - val_accuracy: 0.4998\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1787 - accuracy: 0.5132 - val_loss: 1.3059 - val_accuracy: 0.5805\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0681 - accuracy: 0.5433 - val_loss: 1.5754 - val_accuracy: 0.4853\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9505 - accuracy: 0.5464 - val_loss: 1.2135 - val_accuracy: 0.6075\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0608 - accuracy: 0.5342 - val_loss: 1.2633 - val_accuracy: 0.5790\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9036 - accuracy: 0.5744 - val_loss: 1.1994 - val_accuracy: 0.6064\n",
      "\n",
      "Validation 2, fold 4 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8884 - accuracy: 0.1068 - val_loss: 2.8052 - val_accuracy: 0.0423\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.8488 - accuracy: 0.1004 - val_loss: 2.5415 - val_accuracy: 0.1744\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.4776 - accuracy: 0.1816 - val_loss: 2.2893 - val_accuracy: 0.2391\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2698 - accuracy: 0.2363 - val_loss: 2.1439 - val_accuracy: 0.2799\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1771 - accuracy: 0.2519 - val_loss: 2.1122 - val_accuracy: 0.2831\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1069 - accuracy: 0.2435 - val_loss: 2.0329 - val_accuracy: 0.3098\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8896 - accuracy: 0.2945 - val_loss: 1.9728 - val_accuracy: 0.3204\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8464 - accuracy: 0.3131 - val_loss: 1.9399 - val_accuracy: 0.3417\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8082 - accuracy: 0.3444 - val_loss: 1.8168 - val_accuracy: 0.3872\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6956 - accuracy: 0.3670 - val_loss: 1.8205 - val_accuracy: 0.4036\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6408 - accuracy: 0.3861 - val_loss: 1.7563 - val_accuracy: 0.4060\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5595 - accuracy: 0.3833 - val_loss: 1.5911 - val_accuracy: 0.4600\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6641 - accuracy: 0.3941 - val_loss: 1.6584 - val_accuracy: 0.4433\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6679 - accuracy: 0.4095 - val_loss: 1.8129 - val_accuracy: 0.3858\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6240 - accuracy: 0.4123 - val_loss: 1.5845 - val_accuracy: 0.4838\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5809 - accuracy: 0.3996 - val_loss: 1.5217 - val_accuracy: 0.4835\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4845 - accuracy: 0.4488 - val_loss: 1.8495 - val_accuracy: 0.4206\n",
      "Epoch 18/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4300 - accuracy: 0.4369 - val_loss: 1.5259 - val_accuracy: 0.4956\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4758 - accuracy: 0.4257 - val_loss: 1.6486 - val_accuracy: 0.4615\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6723 - accuracy: 0.4149 - val_loss: 1.5319 - val_accuracy: 0.4849\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3451 - accuracy: 0.4475 - val_loss: 1.6001 - val_accuracy: 0.4753\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5014 - accuracy: 0.4527 - val_loss: 1.5257 - val_accuracy: 0.4931\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3304 - accuracy: 0.4638 - val_loss: 1.6071 - val_accuracy: 0.4693\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3193 - accuracy: 0.4602 - val_loss: 1.4861 - val_accuracy: 0.4938\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3212 - accuracy: 0.4607 - val_loss: 1.4511 - val_accuracy: 0.5190\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3128 - accuracy: 0.4599 - val_loss: 1.5440 - val_accuracy: 0.5009\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4391 - accuracy: 0.4491 - val_loss: 1.6019 - val_accuracy: 0.4810\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3483 - accuracy: 0.4600 - val_loss: 1.5563 - val_accuracy: 0.4913\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2396 - accuracy: 0.4905 - val_loss: 1.5770 - val_accuracy: 0.5048\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2041 - accuracy: 0.4917 - val_loss: 1.3744 - val_accuracy: 0.5510\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2070 - accuracy: 0.4990 - val_loss: 1.3532 - val_accuracy: 0.5851\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2361 - accuracy: 0.5077 - val_loss: 1.6383 - val_accuracy: 0.4654\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1913 - accuracy: 0.4876 - val_loss: 1.6266 - val_accuracy: 0.4757\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2176 - accuracy: 0.4862 - val_loss: 1.5170 - val_accuracy: 0.5034\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1369 - accuracy: 0.5100 - val_loss: 1.3938 - val_accuracy: 0.5492\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1612 - accuracy: 0.5012 - val_loss: 1.3333 - val_accuracy: 0.5542\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1034 - accuracy: 0.5125 - val_loss: 1.3191 - val_accuracy: 0.5680\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2837 - accuracy: 0.4852 - val_loss: 1.6866 - val_accuracy: 0.4295\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2158 - accuracy: 0.4847 - val_loss: 1.4105 - val_accuracy: 0.5428\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1128 - accuracy: 0.5306 - val_loss: 1.3807 - val_accuracy: 0.5613\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5720 - accuracy: 0.4995 - val_loss: 1.5090 - val_accuracy: 0.5268\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4665 - accuracy: 0.4666 - val_loss: 1.3210 - val_accuracy: 0.5634\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4063 - accuracy: 0.4936 - val_loss: 1.8821 - val_accuracy: 0.3837\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3595 - accuracy: 0.4860 - val_loss: 1.3531 - val_accuracy: 0.5677\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2083 - accuracy: 0.5142 - val_loss: 1.4197 - val_accuracy: 0.5513\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0217 - accuracy: 0.5348 - val_loss: 1.2463 - val_accuracy: 0.5961\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1633 - accuracy: 0.5192 - val_loss: 1.3370 - val_accuracy: 0.5698\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0876 - accuracy: 0.5226 - val_loss: 1.4307 - val_accuracy: 0.5400\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1204 - accuracy: 0.5213 - val_loss: 1.2407 - val_accuracy: 0.5790\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0498 - accuracy: 0.5215 - val_loss: 1.2460 - val_accuracy: 0.5812\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0332 - accuracy: 0.5323 - val_loss: 1.2385 - val_accuracy: 0.5798\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0234 - accuracy: 0.5159 - val_loss: 1.2643 - val_accuracy: 0.5719\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0778 - accuracy: 0.5193 - val_loss: 1.3416 - val_accuracy: 0.5375\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9932 - accuracy: 0.5501 - val_loss: 1.2681 - val_accuracy: 0.5808\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9498 - accuracy: 0.5522 - val_loss: 1.2842 - val_accuracy: 0.5702\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9979 - accuracy: 0.5405 - val_loss: 1.2573 - val_accuracy: 0.5712\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3369 - accuracy: 0.4936 - val_loss: 1.3773 - val_accuracy: 0.5393\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4266 - accuracy: 0.4869 - val_loss: 1.3066 - val_accuracy: 0.5655\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1164 - accuracy: 0.5121 - val_loss: 1.2631 - val_accuracy: 0.5833\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9931 - accuracy: 0.5489 - val_loss: 1.1889 - val_accuracy: 0.6092\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9891 - accuracy: 0.5440 - val_loss: 1.1980 - val_accuracy: 0.6021\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9477 - accuracy: 0.5563 - val_loss: 1.2121 - val_accuracy: 0.5964\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0472 - accuracy: 0.5302 - val_loss: 1.2990 - val_accuracy: 0.5471\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0446 - accuracy: 0.5248 - val_loss: 1.2482 - val_accuracy: 0.5663\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9603 - accuracy: 0.5623 - val_loss: 1.3174 - val_accuracy: 0.5837\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0131 - accuracy: 0.5477 - val_loss: 1.2387 - val_accuracy: 0.5872\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2346 - accuracy: 0.5397 - val_loss: 1.5271 - val_accuracy: 0.5048\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2220 - accuracy: 0.5083 - val_loss: 1.3356 - val_accuracy: 0.5545\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0703 - accuracy: 0.5327 - val_loss: 1.1680 - val_accuracy: 0.5961\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0844 - accuracy: 0.5441 - val_loss: 1.2389 - val_accuracy: 0.6078\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9594 - accuracy: 0.5544 - val_loss: 1.2825 - val_accuracy: 0.5858\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0062 - accuracy: 0.5439 - val_loss: 1.1570 - val_accuracy: 0.6131\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9240 - accuracy: 0.5596 - val_loss: 1.2115 - val_accuracy: 0.5847\n",
      "Epoch 74/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8776 - accuracy: 0.5680 - val_loss: 1.1901 - val_accuracy: 0.6000\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1162 - accuracy: 0.5452 - val_loss: 1.5276 - val_accuracy: 0.5048\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5151 - accuracy: 0.4854 - val_loss: 1.3104 - val_accuracy: 0.5602\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9762 - accuracy: 0.5457 - val_loss: 1.2154 - val_accuracy: 0.5872\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9565 - accuracy: 0.5539 - val_loss: 1.2623 - val_accuracy: 0.5762\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1464 - accuracy: 0.5295 - val_loss: 1.1695 - val_accuracy: 0.6043\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9519 - accuracy: 0.5583 - val_loss: 1.1362 - val_accuracy: 0.6092\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8752 - accuracy: 0.5826 - val_loss: 1.2110 - val_accuracy: 0.6124\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0607 - accuracy: 0.5460 - val_loss: 1.1305 - val_accuracy: 0.6110\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0549 - accuracy: 0.5555 - val_loss: 1.1476 - val_accuracy: 0.6071\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7471 - accuracy: 0.4888 - val_loss: 1.3580 - val_accuracy: 0.5403\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2548 - accuracy: 0.5219 - val_loss: 1.2563 - val_accuracy: 0.5879\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6734 - accuracy: 0.5450 - val_loss: 1.2539 - val_accuracy: 0.5925\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0415 - accuracy: 0.5455 - val_loss: 1.3230 - val_accuracy: 0.5829\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0114 - accuracy: 0.5427 - val_loss: 1.1592 - val_accuracy: 0.6220\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9900 - accuracy: 0.5447 - val_loss: 1.3003 - val_accuracy: 0.5449\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9415 - accuracy: 0.5456 - val_loss: 1.2011 - val_accuracy: 0.5883\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9098 - accuracy: 0.5675 - val_loss: 1.0984 - val_accuracy: 0.6323\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0118 - accuracy: 0.5410 - val_loss: 1.2203 - val_accuracy: 0.5911\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9883 - accuracy: 0.5599 - val_loss: 1.1838 - val_accuracy: 0.6099\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9016 - accuracy: 0.5773 - val_loss: 1.1060 - val_accuracy: 0.6188\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8544 - accuracy: 0.5863 - val_loss: 1.0734 - val_accuracy: 0.6416\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8411 - accuracy: 0.5856 - val_loss: 1.0947 - val_accuracy: 0.6149\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8064 - accuracy: 0.5974 - val_loss: 0.9841 - val_accuracy: 0.6622\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9376 - accuracy: 0.5717 - val_loss: 1.1048 - val_accuracy: 0.6512\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8815 - accuracy: 0.5751 - val_loss: 1.0443 - val_accuracy: 0.6561\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9192 - accuracy: 0.5861 - val_loss: 1.1373 - val_accuracy: 0.6202\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0008 - accuracy: 0.5455 - val_loss: 1.2193 - val_accuracy: 0.5904\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1025 - accuracy: 0.5329 - val_loss: 1.2702 - val_accuracy: 0.5655\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1099 - accuracy: 0.5331 - val_loss: 1.2271 - val_accuracy: 0.5812\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0671 - accuracy: 0.5393 - val_loss: 1.2101 - val_accuracy: 0.5993\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2006 - accuracy: 0.5514 - val_loss: 1.2173 - val_accuracy: 0.5890\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0032 - accuracy: 0.5520 - val_loss: 1.1927 - val_accuracy: 0.5993\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8598 - accuracy: 0.5882 - val_loss: 1.1414 - val_accuracy: 0.6245\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8846 - accuracy: 0.5871 - val_loss: 1.1179 - val_accuracy: 0.6284\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9063 - accuracy: 0.5666 - val_loss: 1.1752 - val_accuracy: 0.6043\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9155 - accuracy: 0.5766 - val_loss: 1.1863 - val_accuracy: 0.5858\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1840 - accuracy: 0.5647 - val_loss: 1.3687 - val_accuracy: 0.5329\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9627 - accuracy: 0.5693 - val_loss: 1.0976 - val_accuracy: 0.6355\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9488 - accuracy: 0.5684 - val_loss: 1.2729 - val_accuracy: 0.5513\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1888 - accuracy: 0.5300 - val_loss: 1.2345 - val_accuracy: 0.5712\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7835 - accuracy: 0.4956 - val_loss: 1.4614 - val_accuracy: 0.5290\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1012 - accuracy: 0.5293 - val_loss: 1.1148 - val_accuracy: 0.6099\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0682 - accuracy: 0.5439 - val_loss: 1.1857 - val_accuracy: 0.5851\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0553 - accuracy: 0.5554 - val_loss: 1.3048 - val_accuracy: 0.5648\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8919 - accuracy: 0.5754 - val_loss: 1.1385 - val_accuracy: 0.6153\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8876 - accuracy: 0.5769 - val_loss: 1.1390 - val_accuracy: 0.6067\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8537 - accuracy: 0.5829 - val_loss: 1.1525 - val_accuracy: 0.5929\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9018 - accuracy: 0.5785 - val_loss: 1.3390 - val_accuracy: 0.5503\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8846 - accuracy: 0.5738 - val_loss: 1.1077 - val_accuracy: 0.6224\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1855 - accuracy: 0.5451 - val_loss: 1.4565 - val_accuracy: 0.5265\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2912 - accuracy: 0.5115 - val_loss: 1.1516 - val_accuracy: 0.6131\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8930 - accuracy: 0.5661 - val_loss: 1.0862 - val_accuracy: 0.6419\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8518 - accuracy: 0.5915 - val_loss: 1.1032 - val_accuracy: 0.6266\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0032 - accuracy: 0.5654 - val_loss: 1.0706 - val_accuracy: 0.6359\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9995 - accuracy: 0.5746 - val_loss: 1.1559 - val_accuracy: 0.6071\n",
      "Epoch 130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8973 - accuracy: 0.5742 - val_loss: 1.0964 - val_accuracy: 0.6426\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8942 - accuracy: 0.5919 - val_loss: 1.1151 - val_accuracy: 0.6234\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8713 - accuracy: 0.5872 - val_loss: 1.1394 - val_accuracy: 0.6227\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8149 - accuracy: 0.5965 - val_loss: 1.4423 - val_accuracy: 0.5325\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8212 - accuracy: 0.5870 - val_loss: 1.1047 - val_accuracy: 0.6291\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8206 - accuracy: 0.6024 - val_loss: 1.0940 - val_accuracy: 0.6316\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8307 - accuracy: 0.6042 - val_loss: 1.1789 - val_accuracy: 0.6128\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8672 - accuracy: 0.5895 - val_loss: 1.0172 - val_accuracy: 0.6476\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1874 - accuracy: 0.5178 - val_loss: 1.1538 - val_accuracy: 0.6053\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9155 - accuracy: 0.5777 - val_loss: 1.1191 - val_accuracy: 0.6259\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7938 - accuracy: 0.6052 - val_loss: 1.0647 - val_accuracy: 0.6508\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7884 - accuracy: 0.6054 - val_loss: 1.1285 - val_accuracy: 0.6171\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8433 - accuracy: 0.5999 - val_loss: 1.1539 - val_accuracy: 0.6238\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2800 - accuracy: 0.5448 - val_loss: 1.1424 - val_accuracy: 0.6291\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0361 - accuracy: 0.5668 - val_loss: 1.5997 - val_accuracy: 0.4753\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1749 - accuracy: 0.5337 - val_loss: 1.1346 - val_accuracy: 0.6156\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8627 - accuracy: 0.5824 - val_loss: 1.0823 - val_accuracy: 0.6345\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7960 - accuracy: 0.6012 - val_loss: 1.1168 - val_accuracy: 0.6266\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9388 - accuracy: 0.5845 - val_loss: 1.1774 - val_accuracy: 0.6025\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1956 - accuracy: 0.5362 - val_loss: 1.2226 - val_accuracy: 0.5865\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3008 - accuracy: 0.5379 - val_loss: 1.1624 - val_accuracy: 0.6046\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0697 - accuracy: 0.5498 - val_loss: 1.1087 - val_accuracy: 0.6220\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8214 - accuracy: 0.5994 - val_loss: 1.1085 - val_accuracy: 0.6281\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8981 - accuracy: 0.5925 - val_loss: 1.2588 - val_accuracy: 0.5719\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8929 - accuracy: 0.5849 - val_loss: 1.1025 - val_accuracy: 0.6295\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8134 - accuracy: 0.6052 - val_loss: 1.2017 - val_accuracy: 0.5822\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9377 - accuracy: 0.5771 - val_loss: 1.1341 - val_accuracy: 0.6252\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8656 - accuracy: 0.5827 - val_loss: 1.0822 - val_accuracy: 0.6380\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9175 - accuracy: 0.5748 - val_loss: 1.1654 - val_accuracy: 0.5979\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8026 - accuracy: 0.6028 - val_loss: 1.0526 - val_accuracy: 0.6419\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8207 - accuracy: 0.6043 - val_loss: 1.0261 - val_accuracy: 0.6437\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9889 - accuracy: 0.5775 - val_loss: 1.2954 - val_accuracy: 0.5673\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9839 - accuracy: 0.5759 - val_loss: 1.1438 - val_accuracy: 0.6298\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8197 - accuracy: 0.6037 - val_loss: 1.0442 - val_accuracy: 0.6409\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9573 - accuracy: 0.5947 - val_loss: 1.0779 - val_accuracy: 0.6369\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9219 - accuracy: 0.5806 - val_loss: 1.1458 - val_accuracy: 0.6117\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9709 - accuracy: 0.5765 - val_loss: 1.2682 - val_accuracy: 0.5531\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9374 - accuracy: 0.5710 - val_loss: 1.0543 - val_accuracy: 0.6345\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8218 - accuracy: 0.6024 - val_loss: 1.0602 - val_accuracy: 0.6433\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8257 - accuracy: 0.6005 - val_loss: 1.1958 - val_accuracy: 0.6039\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8517 - accuracy: 0.6024 - val_loss: 1.1151 - val_accuracy: 0.6131\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7603 - accuracy: 0.6130 - val_loss: 1.0050 - val_accuracy: 0.6540\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8368 - accuracy: 0.6019 - val_loss: 1.0907 - val_accuracy: 0.6288\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9509 - accuracy: 0.5699 - val_loss: 1.1399 - val_accuracy: 0.6103\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8260 - accuracy: 0.5970 - val_loss: 0.9964 - val_accuracy: 0.6643\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7819 - accuracy: 0.6239 - val_loss: 1.1057 - val_accuracy: 0.6227\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7578 - accuracy: 0.6201 - val_loss: 1.0103 - val_accuracy: 0.6654\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8907 - accuracy: 0.5910 - val_loss: 1.2308 - val_accuracy: 0.5812\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9587 - accuracy: 0.5727 - val_loss: 1.0321 - val_accuracy: 0.6465\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1812 - accuracy: 0.5570 - val_loss: 1.0711 - val_accuracy: 0.6238\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0248 - accuracy: 0.5767 - val_loss: 1.0728 - val_accuracy: 0.6224\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8083 - accuracy: 0.6091 - val_loss: 1.0533 - val_accuracy: 0.6483\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7079 - accuracy: 0.6295 - val_loss: 1.0482 - val_accuracy: 0.6306\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1140 - accuracy: 0.5315 - val_loss: 1.1673 - val_accuracy: 0.6036\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8509 - accuracy: 0.5963 - val_loss: 1.0822 - val_accuracy: 0.6401\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8530 - accuracy: 0.6049 - val_loss: 0.9935 - val_accuracy: 0.6575\n",
      "Epoch 186/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7689 - accuracy: 0.6298 - val_loss: 0.9974 - val_accuracy: 0.6636\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7653 - accuracy: 0.6189 - val_loss: 1.0465 - val_accuracy: 0.6465\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7793 - accuracy: 0.6180 - val_loss: 1.1122 - val_accuracy: 0.6263\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8184 - accuracy: 0.6088 - val_loss: 1.1046 - val_accuracy: 0.6348\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9141 - accuracy: 0.5909 - val_loss: 1.1606 - val_accuracy: 0.6078\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0958 - accuracy: 0.5496 - val_loss: 1.3429 - val_accuracy: 0.5481\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8779 - accuracy: 0.5840 - val_loss: 1.2479 - val_accuracy: 0.5925\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8536 - accuracy: 0.5948 - val_loss: 1.0963 - val_accuracy: 0.6270\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7910 - accuracy: 0.6234 - val_loss: 1.0536 - val_accuracy: 0.6526\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7490 - accuracy: 0.6212 - val_loss: 1.0345 - val_accuracy: 0.6423\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8415 - accuracy: 0.6034 - val_loss: 1.0591 - val_accuracy: 0.6348\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8573 - accuracy: 0.6026 - val_loss: 1.1025 - val_accuracy: 0.6341\n",
      "\n",
      "Validation 2, fold 5 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8874 - accuracy: 0.1299 - val_loss: 2.8125 - val_accuracy: 0.0867\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7019 - accuracy: 0.1409 - val_loss: 2.4800 - val_accuracy: 0.1805\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5186 - accuracy: 0.1876 - val_loss: 2.3376 - val_accuracy: 0.2234\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3890 - accuracy: 0.1760 - val_loss: 2.1909 - val_accuracy: 0.2266\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3048 - accuracy: 0.2102 - val_loss: 2.1405 - val_accuracy: 0.2501\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1834 - accuracy: 0.2353 - val_loss: 2.0747 - val_accuracy: 0.3091\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0620 - accuracy: 0.2468 - val_loss: 2.0478 - val_accuracy: 0.2757\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2534 - accuracy: 0.2282 - val_loss: 2.0702 - val_accuracy: 0.2920\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2437 - accuracy: 0.2340 - val_loss: 2.1193 - val_accuracy: 0.2710\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2125 - accuracy: 0.2423 - val_loss: 1.9511 - val_accuracy: 0.3641\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0754 - accuracy: 0.2904 - val_loss: 1.8651 - val_accuracy: 0.3911\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0313 - accuracy: 0.3119 - val_loss: 1.9606 - val_accuracy: 0.3279\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8901 - accuracy: 0.3356 - val_loss: 1.8028 - val_accuracy: 0.3968\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7455 - accuracy: 0.3663 - val_loss: 1.8781 - val_accuracy: 0.3577\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6861 - accuracy: 0.3510 - val_loss: 1.7095 - val_accuracy: 0.4160\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7752 - accuracy: 0.3503 - val_loss: 1.7250 - val_accuracy: 0.3840\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.7351 - accuracy: 0.3506 - val_loss: 1.7148 - val_accuracy: 0.4014\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8056 - accuracy: 0.3370 - val_loss: 1.6328 - val_accuracy: 0.4377\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6735 - accuracy: 0.3662 - val_loss: 1.7303 - val_accuracy: 0.3922\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5818 - accuracy: 0.3881 - val_loss: 1.6495 - val_accuracy: 0.4018\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4289 - accuracy: 0.4146 - val_loss: 1.5531 - val_accuracy: 0.4494\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4015 - accuracy: 0.4138 - val_loss: 1.5258 - val_accuracy: 0.4774\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7329 - accuracy: 0.3766 - val_loss: 1.7758 - val_accuracy: 0.3787\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5605 - accuracy: 0.3776 - val_loss: 1.7469 - val_accuracy: 0.3840\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6090 - accuracy: 0.3977 - val_loss: 1.7085 - val_accuracy: 0.3993\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4037 - accuracy: 0.4220 - val_loss: 1.4215 - val_accuracy: 0.5183\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3661 - accuracy: 0.4388 - val_loss: 1.4348 - val_accuracy: 0.4988\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3788 - accuracy: 0.4353 - val_loss: 1.5482 - val_accuracy: 0.4750\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3351 - accuracy: 0.4504 - val_loss: 1.4239 - val_accuracy: 0.5222\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3480 - accuracy: 0.4483 - val_loss: 1.4485 - val_accuracy: 0.4899\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2718 - accuracy: 0.4551 - val_loss: 1.4022 - val_accuracy: 0.5151\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2259 - accuracy: 0.4689 - val_loss: 1.8928 - val_accuracy: 0.3265\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3747 - accuracy: 0.4417 - val_loss: 1.5599 - val_accuracy: 0.4622\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2806 - accuracy: 0.4668 - val_loss: 1.4156 - val_accuracy: 0.5226\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7135 - accuracy: 0.4304 - val_loss: 1.5709 - val_accuracy: 0.4714\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4136 - accuracy: 0.4422 - val_loss: 1.5634 - val_accuracy: 0.4647\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2421 - accuracy: 0.4763 - val_loss: 1.4470 - val_accuracy: 0.4945\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4282 - accuracy: 0.4531 - val_loss: 1.3564 - val_accuracy: 0.5258\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5234 - accuracy: 0.4564 - val_loss: 1.6657 - val_accuracy: 0.4504\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3267 - accuracy: 0.4653 - val_loss: 1.4812 - val_accuracy: 0.4963\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2746 - accuracy: 0.4725 - val_loss: 1.4626 - val_accuracy: 0.5002\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2287 - accuracy: 0.4803 - val_loss: 1.4941 - val_accuracy: 0.4760\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2888 - accuracy: 0.4828 - val_loss: 1.3757 - val_accuracy: 0.5503\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.2332 - accuracy: 0.4803 - val_loss: 1.3451 - val_accuracy: 0.5481\n",
      "Epoch 45/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2099 - accuracy: 0.4979 - val_loss: 1.3956 - val_accuracy: 0.5375\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1700 - accuracy: 0.4954 - val_loss: 1.3285 - val_accuracy: 0.5623\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2358 - accuracy: 0.4949 - val_loss: 1.5393 - val_accuracy: 0.5009\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2534 - accuracy: 0.4936 - val_loss: 1.4536 - val_accuracy: 0.4995\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1648 - accuracy: 0.4871 - val_loss: 1.3482 - val_accuracy: 0.5393\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2447 - accuracy: 0.4734 - val_loss: 1.3940 - val_accuracy: 0.5201\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5122 - accuracy: 0.4731 - val_loss: 1.3926 - val_accuracy: 0.5339\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0973 - accuracy: 0.5007 - val_loss: 1.3320 - val_accuracy: 0.5439\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2439 - accuracy: 0.4771 - val_loss: 1.6206 - val_accuracy: 0.4721\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1686 - accuracy: 0.4869 - val_loss: 1.4052 - val_accuracy: 0.5329\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2222 - accuracy: 0.4901 - val_loss: 1.4063 - val_accuracy: 0.5243\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0780 - accuracy: 0.5199 - val_loss: 1.2447 - val_accuracy: 0.5751\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2333 - accuracy: 0.5075 - val_loss: 1.4959 - val_accuracy: 0.5037\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2315 - accuracy: 0.5020 - val_loss: 1.2306 - val_accuracy: 0.5943\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9986 - accuracy: 0.5435 - val_loss: 1.2842 - val_accuracy: 0.5694\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0534 - accuracy: 0.5321 - val_loss: 1.4230 - val_accuracy: 0.5414\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2397 - accuracy: 0.4988 - val_loss: 1.3632 - val_accuracy: 0.5346\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1512 - accuracy: 0.5119 - val_loss: 1.3996 - val_accuracy: 0.5357\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1899 - accuracy: 0.4817 - val_loss: 1.3329 - val_accuracy: 0.5353\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0664 - accuracy: 0.5269 - val_loss: 1.2878 - val_accuracy: 0.5645\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1615 - accuracy: 0.5045 - val_loss: 1.3303 - val_accuracy: 0.5698\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1565 - accuracy: 0.5030 - val_loss: 1.3789 - val_accuracy: 0.5300\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1124 - accuracy: 0.5139 - val_loss: 1.3208 - val_accuracy: 0.5396\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1804 - accuracy: 0.4870 - val_loss: 1.3356 - val_accuracy: 0.5492\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0506 - accuracy: 0.5231 - val_loss: 1.2409 - val_accuracy: 0.5691\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0241 - accuracy: 0.5415 - val_loss: 1.2058 - val_accuracy: 0.5922\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1315 - accuracy: 0.5193 - val_loss: 1.2939 - val_accuracy: 0.5684\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0730 - accuracy: 0.5247 - val_loss: 1.2966 - val_accuracy: 0.5755\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2573 - accuracy: 0.4768 - val_loss: 1.3111 - val_accuracy: 0.5506\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2179 - accuracy: 0.5166 - val_loss: 1.3321 - val_accuracy: 0.5517\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0553 - accuracy: 0.5258 - val_loss: 1.2086 - val_accuracy: 0.5815\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1012 - accuracy: 0.5311 - val_loss: 1.2414 - val_accuracy: 0.5872\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0926 - accuracy: 0.5248 - val_loss: 1.2388 - val_accuracy: 0.5954\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0345 - accuracy: 0.5321 - val_loss: 1.4950 - val_accuracy: 0.5115\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1719 - accuracy: 0.5120 - val_loss: 1.3240 - val_accuracy: 0.5542\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1705 - accuracy: 0.5192 - val_loss: 1.3519 - val_accuracy: 0.5517\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0205 - accuracy: 0.5291 - val_loss: 1.2102 - val_accuracy: 0.5826\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9840 - accuracy: 0.5386 - val_loss: 1.3302 - val_accuracy: 0.5538\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9632 - accuracy: 0.5482 - val_loss: 1.2311 - val_accuracy: 0.5943\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0591 - accuracy: 0.5358 - val_loss: 1.2534 - val_accuracy: 0.5680\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2182 - accuracy: 0.5164 - val_loss: 1.3867 - val_accuracy: 0.5279\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4385 - accuracy: 0.4939 - val_loss: 1.2863 - val_accuracy: 0.5606\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4316 - accuracy: 0.5001 - val_loss: 1.4017 - val_accuracy: 0.5314\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0885 - accuracy: 0.5161 - val_loss: 1.1922 - val_accuracy: 0.5865\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0453 - accuracy: 0.5440 - val_loss: 1.2332 - val_accuracy: 0.5819\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0094 - accuracy: 0.5466 - val_loss: 1.2593 - val_accuracy: 0.5812\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3338 - accuracy: 0.5111 - val_loss: 1.3687 - val_accuracy: 0.5357\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2936 - accuracy: 0.4608 - val_loss: 1.6102 - val_accuracy: 0.5133\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4551 - accuracy: 0.4859 - val_loss: 1.3383 - val_accuracy: 0.5428\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3348 - accuracy: 0.5033 - val_loss: 1.3458 - val_accuracy: 0.5417\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1555 - accuracy: 0.5212 - val_loss: 1.4690 - val_accuracy: 0.5183\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0181 - accuracy: 0.5226 - val_loss: 1.1984 - val_accuracy: 0.5993\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9809 - accuracy: 0.5524 - val_loss: 1.2507 - val_accuracy: 0.5751\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9130 - accuracy: 0.5544 - val_loss: 1.1847 - val_accuracy: 0.5982\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0911 - accuracy: 0.5394 - val_loss: 1.2689 - val_accuracy: 0.5574\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0288 - accuracy: 0.5305 - val_loss: 1.2228 - val_accuracy: 0.5964\n",
      "Epoch 101/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9494 - accuracy: 0.5588 - val_loss: 1.1940 - val_accuracy: 0.5840\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9621 - accuracy: 0.5417 - val_loss: 1.2131 - val_accuracy: 0.5893\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9331 - accuracy: 0.5413 - val_loss: 1.1187 - val_accuracy: 0.6163\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1878 - accuracy: 0.5258 - val_loss: 1.2126 - val_accuracy: 0.5908\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0079 - accuracy: 0.5377 - val_loss: 1.3040 - val_accuracy: 0.5829\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9361 - accuracy: 0.4935 - val_loss: 1.5120 - val_accuracy: 0.4959\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1266 - accuracy: 0.4662 - val_loss: 1.5153 - val_accuracy: 0.4863\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5108 - accuracy: 0.4674 - val_loss: 1.5185 - val_accuracy: 0.4902\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2146 - accuracy: 0.4939 - val_loss: 1.3323 - val_accuracy: 0.5439\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2958 - accuracy: 0.5022 - val_loss: 1.2421 - val_accuracy: 0.5794\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4767 - accuracy: 0.5020 - val_loss: 1.2865 - val_accuracy: 0.5581\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0908 - accuracy: 0.5220 - val_loss: 1.2732 - val_accuracy: 0.5606\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9564 - accuracy: 0.5499 - val_loss: 1.1703 - val_accuracy: 0.5829\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0317 - accuracy: 0.5333 - val_loss: 1.4201 - val_accuracy: 0.5041\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1081 - accuracy: 0.5374 - val_loss: 1.1737 - val_accuracy: 0.6071\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0821 - accuracy: 0.5401 - val_loss: 1.2751 - val_accuracy: 0.5595\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0411 - accuracy: 0.5464 - val_loss: 1.1622 - val_accuracy: 0.5883\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2083 - accuracy: 0.5320 - val_loss: 1.2872 - val_accuracy: 0.5680\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1005 - accuracy: 0.5326 - val_loss: 1.1775 - val_accuracy: 0.6028\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1074 - accuracy: 0.5349 - val_loss: 1.2922 - val_accuracy: 0.5510\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0413 - accuracy: 0.5343 - val_loss: 1.2293 - val_accuracy: 0.5787\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9339 - accuracy: 0.5588 - val_loss: 1.2333 - val_accuracy: 0.5961\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7178 - accuracy: 0.4721 - val_loss: 1.3882 - val_accuracy: 0.5492\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6181 - accuracy: 0.4890 - val_loss: 1.3470 - val_accuracy: 0.5599\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1068 - accuracy: 0.5176 - val_loss: 1.4307 - val_accuracy: 0.5286\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1781 - accuracy: 0.5305 - val_loss: 1.2195 - val_accuracy: 0.5964\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9918 - accuracy: 0.5447 - val_loss: 1.1871 - val_accuracy: 0.6004\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0457 - accuracy: 0.5428 - val_loss: 1.1565 - val_accuracy: 0.6110\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0029 - accuracy: 0.5623 - val_loss: 1.1429 - val_accuracy: 0.6309\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0241 - accuracy: 0.5458 - val_loss: 1.1472 - val_accuracy: 0.6355\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9051 - accuracy: 0.5639 - val_loss: 1.1452 - val_accuracy: 0.6171\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0920 - accuracy: 0.5442 - val_loss: 1.1697 - val_accuracy: 0.6146\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9875 - accuracy: 0.5594 - val_loss: 1.2196 - val_accuracy: 0.6025\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0310 - accuracy: 0.5754 - val_loss: 1.5251 - val_accuracy: 0.4639\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0258 - accuracy: 0.5437 - val_loss: 1.0923 - val_accuracy: 0.6433\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0484 - accuracy: 0.5631 - val_loss: 1.3860 - val_accuracy: 0.5613\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9858 - accuracy: 0.5569 - val_loss: 1.2159 - val_accuracy: 0.5897\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3037 - accuracy: 0.5096 - val_loss: 1.4745 - val_accuracy: 0.5044\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1434 - accuracy: 0.5259 - val_loss: 1.2112 - val_accuracy: 0.5869\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9866 - accuracy: 0.5504 - val_loss: 1.1957 - val_accuracy: 0.6004\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9365 - accuracy: 0.5557 - val_loss: 1.1513 - val_accuracy: 0.5947\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8934 - accuracy: 0.5738 - val_loss: 1.1434 - val_accuracy: 0.6000\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7285 - accuracy: 0.4746 - val_loss: 1.5315 - val_accuracy: 0.4970\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4227 - accuracy: 0.5021 - val_loss: 1.2682 - val_accuracy: 0.5560\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0191 - accuracy: 0.5412 - val_loss: 1.1527 - val_accuracy: 0.6067\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2285 - accuracy: 0.5161 - val_loss: 1.3831 - val_accuracy: 0.5478\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9324 - accuracy: 0.5654 - val_loss: 1.0832 - val_accuracy: 0.6341\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9754 - accuracy: 0.5664 - val_loss: 1.1073 - val_accuracy: 0.6291\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0805 - accuracy: 0.5332 - val_loss: 1.3566 - val_accuracy: 0.5442\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9602 - accuracy: 0.5579 - val_loss: 1.1313 - val_accuracy: 0.6245\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9233 - accuracy: 0.5695 - val_loss: 1.2337 - val_accuracy: 0.5805\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9472 - accuracy: 0.5596 - val_loss: 1.1186 - val_accuracy: 0.6334\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2787 - accuracy: 0.5287 - val_loss: 1.6156 - val_accuracy: 0.4597\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2636 - accuracy: 0.5022 - val_loss: 1.4997 - val_accuracy: 0.5258\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4866 - accuracy: 0.5348 - val_loss: 1.1667 - val_accuracy: 0.6071\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0305 - accuracy: 0.5615 - val_loss: 1.2190 - val_accuracy: 0.6039\n",
      "Epoch 157/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1397 - accuracy: 0.5373 - val_loss: 1.4309 - val_accuracy: 0.5179\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0539 - accuracy: 0.5378 - val_loss: 1.1942 - val_accuracy: 0.6028\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9443 - accuracy: 0.5693 - val_loss: 1.1842 - val_accuracy: 0.5975\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9597 - accuracy: 0.5590 - val_loss: 1.1188 - val_accuracy: 0.6259\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4613 - accuracy: 0.5336 - val_loss: 1.4961 - val_accuracy: 0.4988\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0436 - accuracy: 0.5393 - val_loss: 1.2226 - val_accuracy: 0.5940\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9782 - accuracy: 0.5650 - val_loss: 1.1326 - val_accuracy: 0.6348\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9679 - accuracy: 0.5512 - val_loss: 1.2184 - val_accuracy: 0.5901\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8773 - accuracy: 0.5743 - val_loss: 1.1245 - val_accuracy: 0.6274\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8790 - accuracy: 0.5804 - val_loss: 1.1074 - val_accuracy: 0.6217\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8404 - accuracy: 0.5940 - val_loss: 1.0896 - val_accuracy: 0.6313\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8600 - accuracy: 0.5853 - val_loss: 1.1049 - val_accuracy: 0.6217\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9805 - accuracy: 0.5579 - val_loss: 1.0974 - val_accuracy: 0.6224\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5679 - accuracy: 0.5211 - val_loss: 1.5068 - val_accuracy: 0.4924\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2096 - accuracy: 0.5001 - val_loss: 1.2678 - val_accuracy: 0.5659\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1247 - accuracy: 0.5178 - val_loss: 1.2434 - val_accuracy: 0.5883\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9723 - accuracy: 0.5546 - val_loss: 1.1492 - val_accuracy: 0.6153\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9265 - accuracy: 0.5683 - val_loss: 1.1503 - val_accuracy: 0.6320\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9775 - accuracy: 0.5783 - val_loss: 1.1766 - val_accuracy: 0.6171\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9952 - accuracy: 0.5536 - val_loss: 1.1855 - val_accuracy: 0.5986\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0575 - accuracy: 0.5569 - val_loss: 1.3760 - val_accuracy: 0.5293\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0432 - accuracy: 0.5486 - val_loss: 1.2483 - val_accuracy: 0.5904\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8632 - accuracy: 0.5742 - val_loss: 1.1165 - val_accuracy: 0.6277\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8484 - accuracy: 0.5828 - val_loss: 1.1802 - val_accuracy: 0.6067\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8463 - accuracy: 0.5888 - val_loss: 1.1872 - val_accuracy: 0.6039\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9086 - accuracy: 0.5905 - val_loss: 1.6225 - val_accuracy: 0.5233\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9473 - accuracy: 0.5254 - val_loss: 1.1545 - val_accuracy: 0.6231\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1366 - accuracy: 0.5527 - val_loss: 1.5125 - val_accuracy: 0.5055\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0709 - accuracy: 0.5127 - val_loss: 1.1670 - val_accuracy: 0.6053\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0479 - accuracy: 0.5320 - val_loss: 1.2043 - val_accuracy: 0.5961\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1062 - accuracy: 0.5431 - val_loss: 1.7584 - val_accuracy: 0.4675\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2071 - accuracy: 0.5234 - val_loss: 1.1456 - val_accuracy: 0.6242\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2241 - accuracy: 0.5386 - val_loss: 1.2427 - val_accuracy: 0.5918\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9705 - accuracy: 0.5620 - val_loss: 1.1830 - val_accuracy: 0.6071\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1179 - accuracy: 0.5562 - val_loss: 1.3892 - val_accuracy: 0.5346\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9189 - accuracy: 0.5733 - val_loss: 1.1564 - val_accuracy: 0.6142\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9539 - accuracy: 0.5801 - val_loss: 1.1090 - val_accuracy: 0.6309\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8805 - accuracy: 0.5802 - val_loss: 1.0621 - val_accuracy: 0.6409\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8615 - accuracy: 0.5763 - val_loss: 1.0837 - val_accuracy: 0.6298\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8672 - accuracy: 0.5867 - val_loss: 1.1092 - val_accuracy: 0.6359\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9268 - accuracy: 0.5837 - val_loss: 1.6091 - val_accuracy: 0.4941\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9692 - accuracy: 0.5735 - val_loss: 1.1529 - val_accuracy: 0.6213\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0070 - accuracy: 0.5607 - val_loss: 1.1074 - val_accuracy: 0.6451\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0247 - accuracy: 0.5680 - val_loss: 1.3376 - val_accuracy: 0.5556\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4032 - accuracy: 0.5361 - val_loss: 1.1552 - val_accuracy: 0.6284\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2094 - accuracy: 0.5302 - val_loss: 1.2007 - val_accuracy: 0.5879\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9511 - accuracy: 0.5609 - val_loss: 1.1098 - val_accuracy: 0.6277\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3090 - accuracy: 0.5187 - val_loss: 1.2536 - val_accuracy: 0.5837\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0236 - accuracy: 0.5642 - val_loss: 1.1741 - val_accuracy: 0.6018\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0646 - accuracy: 0.5623 - val_loss: 1.5266 - val_accuracy: 0.4980\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9889 - accuracy: 0.5408 - val_loss: 1.0976 - val_accuracy: 0.6352\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1449 - accuracy: 0.5490 - val_loss: 1.6225 - val_accuracy: 0.4647\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9707 - accuracy: 0.5646 - val_loss: 1.5219 - val_accuracy: 0.5009\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1440 - accuracy: 0.5471 - val_loss: 1.2111 - val_accuracy: 0.6036\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9896 - accuracy: 0.5560 - val_loss: 1.1868 - val_accuracy: 0.6096\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0221 - accuracy: 0.5556 - val_loss: 1.1879 - val_accuracy: 0.6135\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9311 - accuracy: 0.5670 - val_loss: 1.1173 - val_accuracy: 0.6359\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8986 - accuracy: 0.5806 - val_loss: 1.1134 - val_accuracy: 0.6334\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0876 - accuracy: 0.5492 - val_loss: 1.3225 - val_accuracy: 0.5595\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9350 - accuracy: 0.5691 - val_loss: 1.1714 - val_accuracy: 0.6224\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0405 - accuracy: 0.5543 - val_loss: 1.5284 - val_accuracy: 0.4984\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0738 - accuracy: 0.5494 - val_loss: 1.1101 - val_accuracy: 0.6394\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9584 - accuracy: 0.5761 - val_loss: 1.0969 - val_accuracy: 0.6224\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0165 - accuracy: 0.5634 - val_loss: 1.1899 - val_accuracy: 0.5961\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8843 - accuracy: 0.5779 - val_loss: 1.1364 - val_accuracy: 0.6252\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8996 - accuracy: 0.5797 - val_loss: 1.0715 - val_accuracy: 0.6341\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9399 - accuracy: 0.5708 - val_loss: 1.1731 - val_accuracy: 0.5897\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8498 - accuracy: 0.5917 - val_loss: 1.0630 - val_accuracy: 0.6334\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7889 - accuracy: 0.6059 - val_loss: 0.9950 - val_accuracy: 0.6682\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9845 - accuracy: 0.5666 - val_loss: 1.1460 - val_accuracy: 0.6075\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9765 - accuracy: 0.5685 - val_loss: 1.0469 - val_accuracy: 0.6544\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1142 - accuracy: 0.5558 - val_loss: 1.6833 - val_accuracy: 0.4412\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0132 - accuracy: 0.5493 - val_loss: 1.3578 - val_accuracy: 0.5634\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2778 - accuracy: 0.5155 - val_loss: 1.2427 - val_accuracy: 0.5844\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2824 - accuracy: 0.5008 - val_loss: 1.2346 - val_accuracy: 0.5826\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3989 - accuracy: 0.4540 - val_loss: 1.4261 - val_accuracy: 0.5069\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1451 - accuracy: 0.5118 - val_loss: 1.1986 - val_accuracy: 0.5915\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9932 - accuracy: 0.5456 - val_loss: 1.1522 - val_accuracy: 0.6217\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8864 - accuracy: 0.5749 - val_loss: 1.0600 - val_accuracy: 0.6384\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8633 - accuracy: 0.5862 - val_loss: 1.0578 - val_accuracy: 0.6483\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9425 - accuracy: 0.5824 - val_loss: 1.3766 - val_accuracy: 0.5336\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9476 - accuracy: 0.5742 - val_loss: 1.0484 - val_accuracy: 0.6515\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8094 - accuracy: 0.5985 - val_loss: 1.1490 - val_accuracy: 0.6096\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9701 - accuracy: 0.5827 - val_loss: 1.1121 - val_accuracy: 0.6284\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2933 - accuracy: 0.5218 - val_loss: 1.1767 - val_accuracy: 0.6210\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2100 - accuracy: 0.5300 - val_loss: 1.2139 - val_accuracy: 0.5933\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9376 - accuracy: 0.5681 - val_loss: 1.3239 - val_accuracy: 0.5794\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9040 - accuracy: 0.5720 - val_loss: 1.1964 - val_accuracy: 0.6146\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9968 - accuracy: 0.5593 - val_loss: 1.3412 - val_accuracy: 0.5460\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8976 - accuracy: 0.5720 - val_loss: 1.1092 - val_accuracy: 0.6348\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9120 - accuracy: 0.5839 - val_loss: 1.0760 - val_accuracy: 0.6487\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9181 - accuracy: 0.6050 - val_loss: 1.1096 - val_accuracy: 0.6302\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8974 - accuracy: 0.5876 - val_loss: 1.2479 - val_accuracy: 0.6014\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8768 - accuracy: 0.5858 - val_loss: 1.1158 - val_accuracy: 0.6231\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8914 - accuracy: 0.5848 - val_loss: 1.3001 - val_accuracy: 0.5663\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8568 - accuracy: 0.5920 - val_loss: 0.9989 - val_accuracy: 0.6664\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8443 - accuracy: 0.5872 - val_loss: 1.4348 - val_accuracy: 0.5179\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8938 - accuracy: 0.5747 - val_loss: 1.1146 - val_accuracy: 0.6249\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7891 - accuracy: 0.6051 - val_loss: 0.9943 - val_accuracy: 0.6629\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5022 - accuracy: 0.5169 - val_loss: 1.3341 - val_accuracy: 0.5677\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0228 - accuracy: 0.5554 - val_loss: 1.1132 - val_accuracy: 0.6320\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2137 - accuracy: 0.5546 - val_loss: 1.2396 - val_accuracy: 0.5901\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9233 - accuracy: 0.5750 - val_loss: 1.0998 - val_accuracy: 0.6341\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1378 - accuracy: 0.5686 - val_loss: 1.2451 - val_accuracy: 0.5588\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3254 - accuracy: 0.4966 - val_loss: 1.2229 - val_accuracy: 0.6018\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0029 - accuracy: 0.5501 - val_loss: 1.2101 - val_accuracy: 0.6121\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1075 - accuracy: 0.5705 - val_loss: 1.1467 - val_accuracy: 0.6334\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0455 - accuracy: 0.5596 - val_loss: 1.2006 - val_accuracy: 0.5915\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0739 - accuracy: 0.5393 - val_loss: 1.1148 - val_accuracy: 0.6306\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8929 - accuracy: 0.5888 - val_loss: 1.2013 - val_accuracy: 0.6011\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8516 - accuracy: 0.5917 - val_loss: 1.1980 - val_accuracy: 0.5876\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8864 - accuracy: 0.5824 - val_loss: 1.1850 - val_accuracy: 0.6242\n",
      "Epoch 269/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0191 - accuracy: 0.5623 - val_loss: 1.2349 - val_accuracy: 0.5865\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8591 - accuracy: 0.5740 - val_loss: 1.0457 - val_accuracy: 0.6387\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8057 - accuracy: 0.6101 - val_loss: 1.0472 - val_accuracy: 0.6700\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8823 - accuracy: 0.5881 - val_loss: 1.1598 - val_accuracy: 0.5975\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7672 - accuracy: 0.6098 - val_loss: 1.0940 - val_accuracy: 0.6288\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7913 - accuracy: 0.6072 - val_loss: 0.9894 - val_accuracy: 0.6760\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8694 - accuracy: 0.5981 - val_loss: 1.1347 - val_accuracy: 0.6149\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0560 - accuracy: 0.5536 - val_loss: 1.4656 - val_accuracy: 0.5130\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1458 - accuracy: 0.5273 - val_loss: 1.1646 - val_accuracy: 0.6313\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8070 - accuracy: 0.5049 - val_loss: 1.2874 - val_accuracy: 0.5837\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3823 - accuracy: 0.5191 - val_loss: 1.1346 - val_accuracy: 0.6274\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8554 - accuracy: 0.5870 - val_loss: 1.0304 - val_accuracy: 0.6579\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9887 - accuracy: 0.5704 - val_loss: 1.0939 - val_accuracy: 0.6171\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9230 - accuracy: 0.6009 - val_loss: 1.2366 - val_accuracy: 0.5918\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9522 - accuracy: 0.5717 - val_loss: 1.1372 - val_accuracy: 0.6245\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8220 - accuracy: 0.5940 - val_loss: 1.0711 - val_accuracy: 0.6433\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0495 - accuracy: 0.5578 - val_loss: 1.1179 - val_accuracy: 0.6323\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4529 - accuracy: 0.5264 - val_loss: 1.3019 - val_accuracy: 0.5755\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9784 - accuracy: 0.5630 - val_loss: 1.0657 - val_accuracy: 0.6455\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9249 - accuracy: 0.5877 - val_loss: 1.3368 - val_accuracy: 0.5400\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8985 - accuracy: 0.5582 - val_loss: 1.1823 - val_accuracy: 0.6089\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9263 - accuracy: 0.5910 - val_loss: 1.0972 - val_accuracy: 0.6394\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8248 - accuracy: 0.6039 - val_loss: 1.0582 - val_accuracy: 0.6440\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7739 - accuracy: 0.6170 - val_loss: 1.1896 - val_accuracy: 0.6252\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8566 - accuracy: 0.5906 - val_loss: 1.1370 - val_accuracy: 0.6316\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9143 - accuracy: 0.5782 - val_loss: 1.0724 - val_accuracy: 0.6444\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5639 - accuracy: 0.5389 - val_loss: 1.2852 - val_accuracy: 0.5858\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6902 - accuracy: 0.5029 - val_loss: 1.4053 - val_accuracy: 0.5286\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.6226 - accuracy: 0.5101 - val_loss: 1.3672 - val_accuracy: 0.5421\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1136 - accuracy: 0.5393 - val_loss: 1.1511 - val_accuracy: 0.6060\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1195 - accuracy: 0.5461 - val_loss: 1.1833 - val_accuracy: 0.6067\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0071 - accuracy: 0.5587 - val_loss: 1.1606 - val_accuracy: 0.6110\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9233 - accuracy: 0.5715 - val_loss: 1.0798 - val_accuracy: 0.6451\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9361 - accuracy: 0.5829 - val_loss: 1.1475 - val_accuracy: 0.6263\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0908 - accuracy: 0.5337 - val_loss: 1.2160 - val_accuracy: 0.5982\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2134 - accuracy: 0.5195 - val_loss: 1.4458 - val_accuracy: 0.5350\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3456 - accuracy: 0.5290 - val_loss: 1.3752 - val_accuracy: 0.5655\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1703 - accuracy: 0.5290 - val_loss: 1.1924 - val_accuracy: 0.6139\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9108 - accuracy: 0.5730 - val_loss: 1.1649 - val_accuracy: 0.6291\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1051 - accuracy: 0.5748 - val_loss: 1.1300 - val_accuracy: 0.6359\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8919 - accuracy: 0.5957 - val_loss: 1.7019 - val_accuracy: 0.4735\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9736 - accuracy: 0.5671 - val_loss: 1.1629 - val_accuracy: 0.6249\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1763 - accuracy: 0.5578 - val_loss: 1.2992 - val_accuracy: 0.5563\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8577 - accuracy: 0.5976 - val_loss: 1.0398 - val_accuracy: 0.6590\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9097 - accuracy: 0.6005 - val_loss: 1.0611 - val_accuracy: 0.6490\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8119 - accuracy: 0.6131 - val_loss: 1.0648 - val_accuracy: 0.6320\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8873 - accuracy: 0.5821 - val_loss: 1.0918 - val_accuracy: 0.6320\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9569 - accuracy: 0.5926 - val_loss: 1.3743 - val_accuracy: 0.5425\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3466 - accuracy: 0.4785 - val_loss: 1.2937 - val_accuracy: 0.5574\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0848 - accuracy: 0.5329 - val_loss: 1.2290 - val_accuracy: 0.5915\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9036 - accuracy: 0.5917 - val_loss: 1.1230 - val_accuracy: 0.6167\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8761 - accuracy: 0.5888 - val_loss: 1.0594 - val_accuracy: 0.6355\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8864 - accuracy: 0.6038 - val_loss: 1.1284 - val_accuracy: 0.6213\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8756 - accuracy: 0.5917 - val_loss: 1.2337 - val_accuracy: 0.5780\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8069 - accuracy: 0.5989 - val_loss: 1.0406 - val_accuracy: 0.6572\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7603 - accuracy: 0.6083 - val_loss: 1.0220 - val_accuracy: 0.6504\n",
      "Epoch 325/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2919 - accuracy: 0.5224 - val_loss: 1.6062 - val_accuracy: 0.4838\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.5474 - val_loss: 1.0882 - val_accuracy: 0.6451\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8913 - accuracy: 0.5910 - val_loss: 1.1578 - val_accuracy: 0.6114\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9161 - accuracy: 0.5969 - val_loss: 1.1116 - val_accuracy: 0.6313\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8118 - accuracy: 0.6111 - val_loss: 1.1204 - val_accuracy: 0.6213\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1500 - accuracy: 0.5656 - val_loss: 1.3008 - val_accuracy: 0.5737\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9344 - accuracy: 0.5687 - val_loss: 1.2026 - val_accuracy: 0.6000\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9306 - accuracy: 0.5807 - val_loss: 1.1883 - val_accuracy: 0.6121\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9092 - accuracy: 0.6012 - val_loss: 1.1198 - val_accuracy: 0.6405\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8225 - accuracy: 0.6135 - val_loss: 1.0747 - val_accuracy: 0.6579\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6623 - accuracy: 0.5245 - val_loss: 1.7540 - val_accuracy: 0.4174\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3399 - accuracy: 0.4728 - val_loss: 1.3300 - val_accuracy: 0.5595\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1637 - accuracy: 0.5526 - val_loss: 1.2416 - val_accuracy: 0.6025\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9353 - accuracy: 0.5847 - val_loss: 1.1222 - val_accuracy: 0.6423\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8844 - accuracy: 0.5941 - val_loss: 1.1678 - val_accuracy: 0.6185\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.8660 - accuracy: 0.5988 - val_loss: 1.0395 - val_accuracy: 0.6568\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7747 - accuracy: 0.6159 - val_loss: 1.0823 - val_accuracy: 0.6529\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7979 - accuracy: 0.6071 - val_loss: 1.0918 - val_accuracy: 0.6309\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7682 - accuracy: 0.6139 - val_loss: 1.1012 - val_accuracy: 0.6409\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9308 - accuracy: 0.5708 - val_loss: 1.3000 - val_accuracy: 0.5705\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0411 - accuracy: 0.5785 - val_loss: 1.5885 - val_accuracy: 0.5151\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1294 - accuracy: 0.5342 - val_loss: 1.0701 - val_accuracy: 0.6568\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8157 - accuracy: 0.6170 - val_loss: 1.0628 - val_accuracy: 0.6512\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0550 - accuracy: 0.5958 - val_loss: 1.1545 - val_accuracy: 0.6302\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3401 - accuracy: 0.5129 - val_loss: 1.3447 - val_accuracy: 0.5680\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9511 - accuracy: 0.5829 - val_loss: 1.1163 - val_accuracy: 0.6249\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8418 - accuracy: 0.6077 - val_loss: 1.0658 - val_accuracy: 0.6554\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8954 - accuracy: 0.6034 - val_loss: 1.1042 - val_accuracy: 0.6306\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1223 - accuracy: 0.5612 - val_loss: 1.3181 - val_accuracy: 0.5808\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9103 - accuracy: 0.5888 - val_loss: 1.1251 - val_accuracy: 0.6231\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9494 - accuracy: 0.5829 - val_loss: 1.1632 - val_accuracy: 0.5936\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8341 - accuracy: 0.6045 - val_loss: 1.5451 - val_accuracy: 0.4966\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8262 - accuracy: 0.6014 - val_loss: 1.1067 - val_accuracy: 0.6298\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9441 - accuracy: 0.5771 - val_loss: 1.1473 - val_accuracy: 0.6188\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0106 - accuracy: 0.5835 - val_loss: 1.3197 - val_accuracy: 0.5712\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7376 - accuracy: 0.5307 - val_loss: 1.2992 - val_accuracy: 0.5712\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0423 - accuracy: 0.5618 - val_loss: 1.1689 - val_accuracy: 0.6171\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8497 - accuracy: 0.5992 - val_loss: 1.0867 - val_accuracy: 0.6409\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1494 - accuracy: 0.5729 - val_loss: 1.3427 - val_accuracy: 0.5549\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9375 - accuracy: 0.5824 - val_loss: 1.1437 - val_accuracy: 0.6323\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8297 - accuracy: 0.6012 - val_loss: 1.0265 - val_accuracy: 0.6650\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8828 - accuracy: 0.6041 - val_loss: 1.1814 - val_accuracy: 0.6075\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7830 - accuracy: 0.6143 - val_loss: 1.0330 - val_accuracy: 0.6636\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7951 - accuracy: 0.6262 - val_loss: 1.0070 - val_accuracy: 0.6767\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0027 - accuracy: 0.5711 - val_loss: 1.1955 - val_accuracy: 0.6021\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8530 - accuracy: 0.6030 - val_loss: 1.1644 - val_accuracy: 0.6231\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1967 - accuracy: 0.5591 - val_loss: 1.3232 - val_accuracy: 0.5673\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8459 - accuracy: 0.5966 - val_loss: 1.0451 - val_accuracy: 0.6373\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8339 - accuracy: 0.5985 - val_loss: 1.0415 - val_accuracy: 0.6465\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0971 - accuracy: 0.5523 - val_loss: 1.3986 - val_accuracy: 0.5158\n",
      "\n",
      "Validation 3, fold 1 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8941 - accuracy: 0.0712 - val_loss: 2.7944 - val_accuracy: 0.0639\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7715 - accuracy: 0.1265 - val_loss: 2.5608 - val_accuracy: 0.1861\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5424 - accuracy: 0.1699 - val_loss: 2.3404 - val_accuracy: 0.2696\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3230 - accuracy: 0.2175 - val_loss: 2.2522 - val_accuracy: 0.2082\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3054 - accuracy: 0.2116 - val_loss: 2.2375 - val_accuracy: 0.2252\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2246 - accuracy: 0.2249 - val_loss: 2.2479 - val_accuracy: 0.2519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0155 - accuracy: 0.2599 - val_loss: 1.9971 - val_accuracy: 0.3083\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.9705 - accuracy: 0.2882 - val_loss: 2.1647 - val_accuracy: 0.1936\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9509 - accuracy: 0.2836 - val_loss: 1.8191 - val_accuracy: 0.3648\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7306 - accuracy: 0.3509 - val_loss: 1.8651 - val_accuracy: 0.3599\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7677 - accuracy: 0.3401 - val_loss: 1.8168 - val_accuracy: 0.3187\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6397 - accuracy: 0.3610 - val_loss: 1.6839 - val_accuracy: 0.3982\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5570 - accuracy: 0.3781 - val_loss: 1.7980 - val_accuracy: 0.3780\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6477 - accuracy: 0.3877 - val_loss: 1.7280 - val_accuracy: 0.4128\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5761 - accuracy: 0.3965 - val_loss: 1.6642 - val_accuracy: 0.4284\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4917 - accuracy: 0.4024 - val_loss: 1.6332 - val_accuracy: 0.4291\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4375 - accuracy: 0.4138 - val_loss: 1.6389 - val_accuracy: 0.4309\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5040 - accuracy: 0.4044 - val_loss: 1.6015 - val_accuracy: 0.4373\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4360 - accuracy: 0.4201 - val_loss: 1.6306 - val_accuracy: 0.4263\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3311 - accuracy: 0.4424 - val_loss: 1.4801 - val_accuracy: 0.4782\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3319 - accuracy: 0.4446 - val_loss: 1.6352 - val_accuracy: 0.4337\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5796 - accuracy: 0.4047 - val_loss: 1.6782 - val_accuracy: 0.4231\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3846 - accuracy: 0.4471 - val_loss: 1.5284 - val_accuracy: 0.4909\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4030 - accuracy: 0.4389 - val_loss: 1.5549 - val_accuracy: 0.4679\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3152 - accuracy: 0.4514 - val_loss: 2.0617 - val_accuracy: 0.3371\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2976 - accuracy: 0.4500 - val_loss: 1.4536 - val_accuracy: 0.4899\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3657 - accuracy: 0.4451 - val_loss: 1.5482 - val_accuracy: 0.4782\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3074 - accuracy: 0.4725 - val_loss: 1.5414 - val_accuracy: 0.4735\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2599 - accuracy: 0.4593 - val_loss: 1.4740 - val_accuracy: 0.4948\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1985 - accuracy: 0.4853 - val_loss: 1.4213 - val_accuracy: 0.5155\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1578 - accuracy: 0.4835 - val_loss: 1.4002 - val_accuracy: 0.5229\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1332 - accuracy: 0.4933 - val_loss: 1.3683 - val_accuracy: 0.5250\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2608 - accuracy: 0.4676 - val_loss: 1.5052 - val_accuracy: 0.4764\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1532 - accuracy: 0.4905 - val_loss: 1.3704 - val_accuracy: 0.5393\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2273 - accuracy: 0.4656 - val_loss: 1.4042 - val_accuracy: 0.5052\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1854 - accuracy: 0.4734 - val_loss: 1.4308 - val_accuracy: 0.5218\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3613 - accuracy: 0.4820 - val_loss: 1.4196 - val_accuracy: 0.4984\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2994 - accuracy: 0.4808 - val_loss: 1.8583 - val_accuracy: 0.3925\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5949 - accuracy: 0.4504 - val_loss: 1.4946 - val_accuracy: 0.5197\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1253 - accuracy: 0.4959 - val_loss: 1.3197 - val_accuracy: 0.5655\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1603 - accuracy: 0.4868 - val_loss: 1.6647 - val_accuracy: 0.4515\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1264 - accuracy: 0.5073 - val_loss: 1.3165 - val_accuracy: 0.5535\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4799 - accuracy: 0.4728 - val_loss: 2.1032 - val_accuracy: 0.3563\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2776 - accuracy: 0.4810 - val_loss: 1.4047 - val_accuracy: 0.5204\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1051 - accuracy: 0.5120 - val_loss: 1.2464 - val_accuracy: 0.5798\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1228 - accuracy: 0.5166 - val_loss: 1.3257 - val_accuracy: 0.5339\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1102 - accuracy: 0.5050 - val_loss: 1.2895 - val_accuracy: 0.5378\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9929 - accuracy: 0.5332 - val_loss: 1.3033 - val_accuracy: 0.5439\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2515 - accuracy: 0.4940 - val_loss: 1.5252 - val_accuracy: 0.4796\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1361 - accuracy: 0.5020 - val_loss: 1.2718 - val_accuracy: 0.5517\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0664 - accuracy: 0.5273 - val_loss: 1.2861 - val_accuracy: 0.5567\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1095 - accuracy: 0.5183 - val_loss: 1.2927 - val_accuracy: 0.5634\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1043 - accuracy: 0.5217 - val_loss: 1.4210 - val_accuracy: 0.5236\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1895 - accuracy: 0.4967 - val_loss: 1.4620 - val_accuracy: 0.5020\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0404 - accuracy: 0.5222 - val_loss: 1.3782 - val_accuracy: 0.5350\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1804 - accuracy: 0.5211 - val_loss: 1.3468 - val_accuracy: 0.5538\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0555 - accuracy: 0.5189 - val_loss: 1.2514 - val_accuracy: 0.5783\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0948 - accuracy: 0.5226 - val_loss: 1.3984 - val_accuracy: 0.5236\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0586 - accuracy: 0.5295 - val_loss: 1.1709 - val_accuracy: 0.6018\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9996 - accuracy: 0.5442 - val_loss: 1.2839 - val_accuracy: 0.5680\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9766 - accuracy: 0.5393 - val_loss: 1.2663 - val_accuracy: 0.5691\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0027 - accuracy: 0.5320 - val_loss: 1.3195 - val_accuracy: 0.5393\n",
      "Epoch 63/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1666 - accuracy: 0.5274 - val_loss: 1.3077 - val_accuracy: 0.5581\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9798 - accuracy: 0.5465 - val_loss: 1.2363 - val_accuracy: 0.5936\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9364 - accuracy: 0.5599 - val_loss: 1.2434 - val_accuracy: 0.5901\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9711 - accuracy: 0.5529 - val_loss: 1.2540 - val_accuracy: 0.5876\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9691 - accuracy: 0.5549 - val_loss: 1.1464 - val_accuracy: 0.6227\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9883 - accuracy: 0.5478 - val_loss: 1.4499 - val_accuracy: 0.5442\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5618 - accuracy: 0.4727 - val_loss: 1.5556 - val_accuracy: 0.4725\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7849 - accuracy: 0.4705 - val_loss: 1.3961 - val_accuracy: 0.4995\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4660 - accuracy: 0.4733 - val_loss: 1.4578 - val_accuracy: 0.5105\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2229 - accuracy: 0.5049 - val_loss: 1.3550 - val_accuracy: 0.5453\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0719 - accuracy: 0.5354 - val_loss: 1.2453 - val_accuracy: 0.5883\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9835 - accuracy: 0.5429 - val_loss: 1.2734 - val_accuracy: 0.5684\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0367 - accuracy: 0.5363 - val_loss: 1.5026 - val_accuracy: 0.5066\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1524 - accuracy: 0.5073 - val_loss: 1.3868 - val_accuracy: 0.5325\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0345 - accuracy: 0.5232 - val_loss: 1.3437 - val_accuracy: 0.5435\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0806 - accuracy: 0.5274 - val_loss: 1.6547 - val_accuracy: 0.4778\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9810 - accuracy: 0.5287 - val_loss: 1.2284 - val_accuracy: 0.5758\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0415 - accuracy: 0.5330 - val_loss: 1.2075 - val_accuracy: 0.5982\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8867 - accuracy: 0.5637 - val_loss: 1.1881 - val_accuracy: 0.6046\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1028 - accuracy: 0.5459 - val_loss: 1.3702 - val_accuracy: 0.5439\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3390 - accuracy: 0.5029 - val_loss: 1.3395 - val_accuracy: 0.5545\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6697 - accuracy: 0.4861 - val_loss: 1.3950 - val_accuracy: 0.5275\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0169 - accuracy: 0.5430 - val_loss: 1.2069 - val_accuracy: 0.5869\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0432 - accuracy: 0.5360 - val_loss: 1.2764 - val_accuracy: 0.5609\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9872 - accuracy: 0.5419 - val_loss: 1.2462 - val_accuracy: 0.5826\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2267 - accuracy: 0.5328 - val_loss: 1.2166 - val_accuracy: 0.5837\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9642 - accuracy: 0.5524 - val_loss: 1.1763 - val_accuracy: 0.6117\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1624 - accuracy: 0.5217 - val_loss: 1.2477 - val_accuracy: 0.5744\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2071 - accuracy: 0.5358 - val_loss: 1.1952 - val_accuracy: 0.5925\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9864 - accuracy: 0.5494 - val_loss: 1.2325 - val_accuracy: 0.5808\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9395 - accuracy: 0.5392 - val_loss: 1.2269 - val_accuracy: 0.5762\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9104 - accuracy: 0.5643 - val_loss: 1.3006 - val_accuracy: 0.5748\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8925 - accuracy: 0.5599 - val_loss: 1.1801 - val_accuracy: 0.6103\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9877 - accuracy: 0.5448 - val_loss: 1.2272 - val_accuracy: 0.5918\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8763 - accuracy: 0.5715 - val_loss: 1.1797 - val_accuracy: 0.6099\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0310 - accuracy: 0.5285 - val_loss: 1.1737 - val_accuracy: 0.6036\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8667 - accuracy: 0.5774 - val_loss: 1.3800 - val_accuracy: 0.5442\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9116 - accuracy: 0.5779 - val_loss: 1.2651 - val_accuracy: 0.5677\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3510 - accuracy: 0.5355 - val_loss: 1.3789 - val_accuracy: 0.5336\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0082 - accuracy: 0.5385 - val_loss: 1.1896 - val_accuracy: 0.6050\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9925 - accuracy: 0.5507 - val_loss: 1.3093 - val_accuracy: 0.5716\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0060 - accuracy: 0.5466 - val_loss: 1.2342 - val_accuracy: 0.5986\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9154 - accuracy: 0.5674 - val_loss: 1.4277 - val_accuracy: 0.5368\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0064 - accuracy: 0.5468 - val_loss: 1.3848 - val_accuracy: 0.5588\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1390 - accuracy: 0.5335 - val_loss: 1.3032 - val_accuracy: 0.5726\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1295 - accuracy: 0.5528 - val_loss: 1.6429 - val_accuracy: 0.5140\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1498 - accuracy: 0.4902 - val_loss: 1.4376 - val_accuracy: 0.5311\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1858 - accuracy: 0.5069 - val_loss: 1.2870 - val_accuracy: 0.5783\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2336 - accuracy: 0.5131 - val_loss: 1.3382 - val_accuracy: 0.5563\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9600 - accuracy: 0.5459 - val_loss: 1.1442 - val_accuracy: 0.6060\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0246 - accuracy: 0.5321 - val_loss: 1.2538 - val_accuracy: 0.5723\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0658 - accuracy: 0.5393 - val_loss: 1.3504 - val_accuracy: 0.5297\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9736 - accuracy: 0.5526 - val_loss: 1.2169 - val_accuracy: 0.5904\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9973 - accuracy: 0.5581 - val_loss: 1.2076 - val_accuracy: 0.5950\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1194 - accuracy: 0.5326 - val_loss: 1.2353 - val_accuracy: 0.5794\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9826 - accuracy: 0.5463 - val_loss: 1.1661 - val_accuracy: 0.6167\n",
      "Epoch 119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9588 - accuracy: 0.5580 - val_loss: 1.1953 - val_accuracy: 0.6075\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0217 - accuracy: 0.5514 - val_loss: 1.9758 - val_accuracy: 0.3961\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2265 - accuracy: 0.4803 - val_loss: 1.3056 - val_accuracy: 0.5595\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4244 - accuracy: 0.4926 - val_loss: 1.2656 - val_accuracy: 0.5663\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0077 - accuracy: 0.5414 - val_loss: 1.1507 - val_accuracy: 0.6146\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0207 - accuracy: 0.5586 - val_loss: 1.2088 - val_accuracy: 0.5847\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8575 - accuracy: 0.5749 - val_loss: 1.1844 - val_accuracy: 0.5915\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8766 - accuracy: 0.5702 - val_loss: 1.2846 - val_accuracy: 0.5787\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0043 - accuracy: 0.5528 - val_loss: 1.1955 - val_accuracy: 0.6174\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8898 - accuracy: 0.5655 - val_loss: 1.2574 - val_accuracy: 0.5687\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8711 - accuracy: 0.5679 - val_loss: 1.1969 - val_accuracy: 0.6078\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8734 - accuracy: 0.5740 - val_loss: 1.1351 - val_accuracy: 0.6195\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9286 - accuracy: 0.5708 - val_loss: 1.1200 - val_accuracy: 0.6380\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0125 - accuracy: 0.5530 - val_loss: 1.1266 - val_accuracy: 0.6188\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8837 - accuracy: 0.5634 - val_loss: 1.2283 - val_accuracy: 0.5808\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0601 - accuracy: 0.5607 - val_loss: 1.5224 - val_accuracy: 0.5076\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0653 - accuracy: 0.5412 - val_loss: 1.4256 - val_accuracy: 0.5101\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9065 - accuracy: 0.5571 - val_loss: 1.1304 - val_accuracy: 0.6202\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8766 - accuracy: 0.5726 - val_loss: 1.1161 - val_accuracy: 0.6234\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9165 - accuracy: 0.5791 - val_loss: 1.2301 - val_accuracy: 0.5847\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9204 - accuracy: 0.5794 - val_loss: 1.1974 - val_accuracy: 0.5911\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6863 - accuracy: 0.5048 - val_loss: 1.4969 - val_accuracy: 0.5226\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9040 - accuracy: 0.5021 - val_loss: 1.4513 - val_accuracy: 0.5254\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2004 - accuracy: 0.5121 - val_loss: 1.2908 - val_accuracy: 0.5758\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1151 - accuracy: 0.5296 - val_loss: 1.3873 - val_accuracy: 0.5233\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9623 - accuracy: 0.5569 - val_loss: 1.2103 - val_accuracy: 0.5847\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8636 - accuracy: 0.5832 - val_loss: 1.2316 - val_accuracy: 0.5908\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9667 - accuracy: 0.5440 - val_loss: 1.2092 - val_accuracy: 0.5872\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8437 - accuracy: 0.5834 - val_loss: 1.1240 - val_accuracy: 0.6252\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8706 - accuracy: 0.5882 - val_loss: 1.1070 - val_accuracy: 0.6309\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8393 - accuracy: 0.5887 - val_loss: 1.0755 - val_accuracy: 0.6323\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8372 - accuracy: 0.5839 - val_loss: 1.0478 - val_accuracy: 0.6455\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9360 - accuracy: 0.5645 - val_loss: 1.3051 - val_accuracy: 0.5609\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9698 - accuracy: 0.5599 - val_loss: 1.1168 - val_accuracy: 0.6249\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8943 - accuracy: 0.5770 - val_loss: 1.1410 - val_accuracy: 0.6064\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9200 - accuracy: 0.5616 - val_loss: 1.0994 - val_accuracy: 0.6313\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0683 - accuracy: 0.5712 - val_loss: 1.2315 - val_accuracy: 0.5822\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8618 - accuracy: 0.5700 - val_loss: 1.1889 - val_accuracy: 0.6064\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1103 - accuracy: 0.5626 - val_loss: 1.1637 - val_accuracy: 0.6085\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7072 - accuracy: 0.5166 - val_loss: 1.2975 - val_accuracy: 0.5499\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5809 - accuracy: 0.5158 - val_loss: 1.5095 - val_accuracy: 0.5133\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3166 - accuracy: 0.5098 - val_loss: 1.6111 - val_accuracy: 0.4679\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9599 - accuracy: 0.5560 - val_loss: 1.1974 - val_accuracy: 0.5893\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9463 - accuracy: 0.5620 - val_loss: 1.4286 - val_accuracy: 0.5307\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8617 - accuracy: 0.5763 - val_loss: 1.2188 - val_accuracy: 0.5801\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9001 - accuracy: 0.5841 - val_loss: 1.1583 - val_accuracy: 0.5933\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8153 - accuracy: 0.5903 - val_loss: 1.1253 - val_accuracy: 0.6135\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8074 - accuracy: 0.5930 - val_loss: 1.0690 - val_accuracy: 0.6266\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9556 - accuracy: 0.5717 - val_loss: 1.3111 - val_accuracy: 0.5698\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8526 - accuracy: 0.5764 - val_loss: 1.1935 - val_accuracy: 0.6036\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9689 - accuracy: 0.5653 - val_loss: 1.2716 - val_accuracy: 0.5794\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8970 - accuracy: 0.5799 - val_loss: 1.1944 - val_accuracy: 0.6004\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8588 - accuracy: 0.5907 - val_loss: 1.1034 - val_accuracy: 0.6242\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8371 - accuracy: 0.5886 - val_loss: 1.0764 - val_accuracy: 0.6302\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9290 - accuracy: 0.5670 - val_loss: 1.1592 - val_accuracy: 0.6085\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8535 - accuracy: 0.5774 - val_loss: 1.1227 - val_accuracy: 0.6192\n",
      "Epoch 175/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8711 - accuracy: 0.5874 - val_loss: 1.1782 - val_accuracy: 0.6117\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9516 - accuracy: 0.5734 - val_loss: 1.1934 - val_accuracy: 0.6057\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0337 - accuracy: 0.5583 - val_loss: 1.2007 - val_accuracy: 0.5858\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8086 - accuracy: 0.5887 - val_loss: 1.0895 - val_accuracy: 0.6245\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8550 - accuracy: 0.5873 - val_loss: 1.2166 - val_accuracy: 0.5858\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8028 - accuracy: 0.6014 - val_loss: 1.1268 - val_accuracy: 0.6128\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8208 - accuracy: 0.5921 - val_loss: 1.1174 - val_accuracy: 0.6277\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7762 - accuracy: 0.6011 - val_loss: 1.0609 - val_accuracy: 0.6391\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9765 - accuracy: 0.5677 - val_loss: 1.2342 - val_accuracy: 0.5872\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8706 - accuracy: 0.5877 - val_loss: 1.1295 - val_accuracy: 0.6082\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8212 - accuracy: 0.5961 - val_loss: 1.1242 - val_accuracy: 0.6263\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8074 - accuracy: 0.6103 - val_loss: 1.0609 - val_accuracy: 0.6348\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2707 - accuracy: 0.5384 - val_loss: 1.4208 - val_accuracy: 0.5155\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0847 - accuracy: 0.5470 - val_loss: 1.3025 - val_accuracy: 0.5773\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9282 - accuracy: 0.5738 - val_loss: 1.2443 - val_accuracy: 0.5890\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8340 - accuracy: 0.5951 - val_loss: 1.1907 - val_accuracy: 0.5996\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8485 - accuracy: 0.5890 - val_loss: 1.4248 - val_accuracy: 0.5147\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7879 - accuracy: 0.5946 - val_loss: 1.2484 - val_accuracy: 0.5709\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8367 - accuracy: 0.5974 - val_loss: 1.5039 - val_accuracy: 0.5023\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2565 - accuracy: 0.5291 - val_loss: 1.5056 - val_accuracy: 0.5062\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1068 - accuracy: 0.5409 - val_loss: 1.1439 - val_accuracy: 0.6202\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4386 - accuracy: 0.5194 - val_loss: 1.3562 - val_accuracy: 0.5567\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9521 - accuracy: 0.5520 - val_loss: 1.1533 - val_accuracy: 0.6135\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9636 - accuracy: 0.5663 - val_loss: 1.1730 - val_accuracy: 0.5979\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8952 - accuracy: 0.5760 - val_loss: 1.0966 - val_accuracy: 0.6234\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6460 - accuracy: 0.5574 - val_loss: 1.2806 - val_accuracy: 0.5712\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9911 - accuracy: 0.5467 - val_loss: 1.1776 - val_accuracy: 0.5957\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8881 - accuracy: 0.5808 - val_loss: 1.1594 - val_accuracy: 0.6011\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3338 - accuracy: 0.5266 - val_loss: 1.2327 - val_accuracy: 0.6043\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1826 - accuracy: 0.5636 - val_loss: 1.1291 - val_accuracy: 0.6156\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8408 - accuracy: 0.5819 - val_loss: 1.1517 - val_accuracy: 0.6103\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8432 - accuracy: 0.5925 - val_loss: 1.0995 - val_accuracy: 0.6270\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7978 - accuracy: 0.6004 - val_loss: 1.0945 - val_accuracy: 0.6234\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7997 - accuracy: 0.6079 - val_loss: 1.2050 - val_accuracy: 0.6060\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9787 - accuracy: 0.5816 - val_loss: 1.1079 - val_accuracy: 0.6263\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9440 - accuracy: 0.5772 - val_loss: 1.2720 - val_accuracy: 0.5755\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8218 - accuracy: 0.5970 - val_loss: 1.1517 - val_accuracy: 0.6181\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8317 - accuracy: 0.5877 - val_loss: 1.1431 - val_accuracy: 0.6032\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7737 - accuracy: 0.6007 - val_loss: 1.0656 - val_accuracy: 0.6380\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8516 - accuracy: 0.5917 - val_loss: 1.0798 - val_accuracy: 0.6227\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8219 - accuracy: 0.6055 - val_loss: 1.2129 - val_accuracy: 0.5929\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9115 - accuracy: 0.5830 - val_loss: 1.2098 - val_accuracy: 0.6018\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7929 - accuracy: 0.5992 - val_loss: 1.0903 - val_accuracy: 0.6359\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8147 - accuracy: 0.6067 - val_loss: 1.2013 - val_accuracy: 0.6007\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.8154 - accuracy: 0.5952 - val_loss: 1.0591 - val_accuracy: 0.6490\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7163 - accuracy: 0.6267 - val_loss: 1.1550 - val_accuracy: 0.6110\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1500 - accuracy: 0.5608 - val_loss: 1.3761 - val_accuracy: 0.5623\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9744 - accuracy: 0.5704 - val_loss: 1.1045 - val_accuracy: 0.6096\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9245 - accuracy: 0.5811 - val_loss: 1.2066 - val_accuracy: 0.6089\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8455 - accuracy: 0.4879 - val_loss: 1.3458 - val_accuracy: 0.5577\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0899 - accuracy: 0.5362 - val_loss: 1.2097 - val_accuracy: 0.6121\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9152 - accuracy: 0.5792 - val_loss: 1.1976 - val_accuracy: 0.6117\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0421 - accuracy: 0.5769 - val_loss: 1.2146 - val_accuracy: 0.5915\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9151 - accuracy: 0.5875 - val_loss: 1.1325 - val_accuracy: 0.6224\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8123 - accuracy: 0.6004 - val_loss: 1.1025 - val_accuracy: 0.6210\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7730 - accuracy: 0.6082 - val_loss: 1.1312 - val_accuracy: 0.6298\n",
      "Epoch 231/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8578 - accuracy: 0.6038 - val_loss: 1.2370 - val_accuracy: 0.5744\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7539 - accuracy: 0.6042 - val_loss: 1.0662 - val_accuracy: 0.6334\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7819 - accuracy: 0.6084 - val_loss: 0.9942 - val_accuracy: 0.6639\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2494 - accuracy: 0.5466 - val_loss: 1.6040 - val_accuracy: 0.5208\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2326 - accuracy: 0.5413 - val_loss: 1.2241 - val_accuracy: 0.6117\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0722 - accuracy: 0.5807 - val_loss: 1.2254 - val_accuracy: 0.5911\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.5530 - val_loss: 1.2417 - val_accuracy: 0.5940\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5170 - accuracy: 0.5362 - val_loss: 1.3644 - val_accuracy: 0.5805\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2058 - accuracy: 0.5599 - val_loss: 1.2570 - val_accuracy: 0.5922\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9228 - accuracy: 0.5820 - val_loss: 1.0888 - val_accuracy: 0.6274\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1141 - accuracy: 0.5565 - val_loss: 1.2324 - val_accuracy: 0.5812\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1779 - accuracy: 0.5272 - val_loss: 1.4311 - val_accuracy: 0.5314\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9924 - accuracy: 0.5801 - val_loss: 1.1826 - val_accuracy: 0.6192\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8780 - accuracy: 0.5805 - val_loss: 1.1385 - val_accuracy: 0.6224\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9073 - accuracy: 0.5717 - val_loss: 1.1395 - val_accuracy: 0.6206\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9501 - accuracy: 0.5718 - val_loss: 1.1665 - val_accuracy: 0.6114\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9654 - accuracy: 0.5442 - val_loss: 1.1948 - val_accuracy: 0.5876\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9465 - accuracy: 0.5705 - val_loss: 1.1432 - val_accuracy: 0.6153\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9080 - accuracy: 0.5720 - val_loss: 1.3048 - val_accuracy: 0.5620\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0864 - accuracy: 0.5724 - val_loss: 1.2546 - val_accuracy: 0.5691\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0142 - accuracy: 0.5588 - val_loss: 1.1065 - val_accuracy: 0.6270\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4245 - accuracy: 0.5312 - val_loss: 1.4415 - val_accuracy: 0.5222\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9555 - accuracy: 0.5654 - val_loss: 1.1969 - val_accuracy: 0.6021\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8268 - accuracy: 0.5940 - val_loss: 1.0748 - val_accuracy: 0.6380\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0817 - accuracy: 0.5948 - val_loss: 1.2445 - val_accuracy: 0.5886\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9513 - accuracy: 0.5750 - val_loss: 1.2780 - val_accuracy: 0.5861\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7979 - accuracy: 0.6013 - val_loss: 1.0487 - val_accuracy: 0.6440\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8008 - accuracy: 0.6004 - val_loss: 1.1121 - val_accuracy: 0.6263\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7860 - accuracy: 0.5995 - val_loss: 1.0356 - val_accuracy: 0.6369\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7539 - accuracy: 0.6176 - val_loss: 1.0430 - val_accuracy: 0.6465\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8261 - accuracy: 0.5999 - val_loss: 1.0959 - val_accuracy: 0.6320\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7690 - accuracy: 0.6155 - val_loss: 1.0546 - val_accuracy: 0.6433\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8631 - accuracy: 0.5963 - val_loss: 1.1124 - val_accuracy: 0.6167\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7836 - accuracy: 0.6039 - val_loss: 1.1209 - val_accuracy: 0.6224\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8603 - accuracy: 0.5848 - val_loss: 1.2225 - val_accuracy: 0.5933\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8873 - accuracy: 0.5647 - val_loss: 1.5343 - val_accuracy: 0.4934\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0115 - accuracy: 0.5439 - val_loss: 1.1154 - val_accuracy: 0.6348\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9252 - accuracy: 0.5917 - val_loss: 1.1076 - val_accuracy: 0.6192\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1054 - accuracy: 0.5358 - val_loss: 1.3008 - val_accuracy: 0.5560\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9626 - accuracy: 0.5808 - val_loss: 1.1462 - val_accuracy: 0.6089\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9637 - accuracy: 0.5829 - val_loss: 1.1809 - val_accuracy: 0.5933\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9424 - accuracy: 0.5726 - val_loss: 1.1122 - val_accuracy: 0.6249\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8832 - accuracy: 0.5868 - val_loss: 1.1351 - val_accuracy: 0.6249\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7902 - accuracy: 0.6004 - val_loss: 1.0935 - val_accuracy: 0.6337\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7902 - accuracy: 0.6157 - val_loss: 1.1998 - val_accuracy: 0.5933\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8219 - accuracy: 0.5939 - val_loss: 1.0554 - val_accuracy: 0.6355\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9056 - accuracy: 0.5893 - val_loss: 1.0818 - val_accuracy: 0.6359\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8553 - accuracy: 0.5968 - val_loss: 1.0425 - val_accuracy: 0.6419\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7824 - accuracy: 0.6201 - val_loss: 1.1812 - val_accuracy: 0.5925\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8144 - accuracy: 0.5836 - val_loss: 1.1115 - val_accuracy: 0.6256\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8677 - accuracy: 0.5907 - val_loss: 1.3974 - val_accuracy: 0.5414\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8918 - accuracy: 0.5756 - val_loss: 1.0871 - val_accuracy: 0.6423\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7434 - accuracy: 0.6159 - val_loss: 1.0177 - val_accuracy: 0.6607\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7767 - accuracy: 0.6174 - val_loss: 1.1453 - val_accuracy: 0.6146\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7722 - accuracy: 0.6069 - val_loss: 1.0953 - val_accuracy: 0.6341\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8366 - accuracy: 0.6014 - val_loss: 1.2738 - val_accuracy: 0.5645\n",
      "Epoch 287/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1471 - accuracy: 0.5410 - val_loss: 1.2414 - val_accuracy: 0.5961\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8367 - accuracy: 0.5852 - val_loss: 1.1212 - val_accuracy: 0.6380\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5242 - accuracy: 0.5764 - val_loss: 1.3240 - val_accuracy: 0.5613\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3194 - accuracy: 0.5323 - val_loss: 1.1803 - val_accuracy: 0.6135\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9735 - accuracy: 0.5525 - val_loss: 1.2558 - val_accuracy: 0.5819\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0591 - accuracy: 0.5490 - val_loss: 1.2205 - val_accuracy: 0.5815\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4234 - accuracy: 0.5056 - val_loss: 1.3129 - val_accuracy: 0.5631\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5608 - accuracy: 0.5428 - val_loss: 1.2479 - val_accuracy: 0.5993\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9036 - accuracy: 0.5857 - val_loss: 1.1817 - val_accuracy: 0.6131\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8060 - accuracy: 0.6041 - val_loss: 1.0898 - val_accuracy: 0.6306\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7613 - accuracy: 0.6088 - val_loss: 1.0607 - val_accuracy: 0.6444\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8401 - accuracy: 0.6042 - val_loss: 1.0785 - val_accuracy: 0.6337\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0163 - accuracy: 0.5757 - val_loss: 1.1565 - val_accuracy: 0.6025\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0325 - accuracy: 0.5744 - val_loss: 1.2402 - val_accuracy: 0.5744\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0487 - accuracy: 0.5762 - val_loss: 1.1908 - val_accuracy: 0.6021\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8006 - accuracy: 0.6097 - val_loss: 1.0917 - val_accuracy: 0.6341\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9291 - accuracy: 0.5928 - val_loss: 1.1072 - val_accuracy: 0.6256\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7870 - accuracy: 0.5993 - val_loss: 1.0507 - val_accuracy: 0.6394\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7875 - accuracy: 0.6129 - val_loss: 1.1037 - val_accuracy: 0.6298\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7841 - accuracy: 0.6132 - val_loss: 1.0225 - val_accuracy: 0.6586\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9486 - accuracy: 0.6015 - val_loss: 1.2219 - val_accuracy: 0.6046\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9988 - accuracy: 0.5545 - val_loss: 1.2327 - val_accuracy: 0.5879\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8064 - accuracy: 0.6070 - val_loss: 1.0734 - val_accuracy: 0.6437\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7766 - accuracy: 0.6201 - val_loss: 1.0073 - val_accuracy: 0.6611\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7835 - accuracy: 0.6098 - val_loss: 1.2220 - val_accuracy: 0.6085\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8087 - accuracy: 0.6040 - val_loss: 1.2024 - val_accuracy: 0.6039\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8724 - accuracy: 0.6007 - val_loss: 1.1836 - val_accuracy: 0.5936\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9816 - accuracy: 0.5795 - val_loss: 1.3868 - val_accuracy: 0.5357\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0100 - accuracy: 0.5749 - val_loss: 1.4646 - val_accuracy: 0.5602\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0860 - accuracy: 0.5482 - val_loss: 1.1650 - val_accuracy: 0.6046\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1929 - accuracy: 0.5454 - val_loss: 1.1649 - val_accuracy: 0.6199\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8587 - accuracy: 0.5855 - val_loss: 1.1277 - val_accuracy: 0.6181\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7802 - accuracy: 0.6020 - val_loss: 1.0752 - val_accuracy: 0.6348\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8961 - accuracy: 0.5824 - val_loss: 1.0949 - val_accuracy: 0.6295\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8937 - accuracy: 0.5777 - val_loss: 1.2532 - val_accuracy: 0.5972\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8428 - accuracy: 0.5905 - val_loss: 1.1475 - val_accuracy: 0.6156\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5404 - accuracy: 0.5567 - val_loss: 1.3275 - val_accuracy: 0.5588\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1762 - accuracy: 0.5439 - val_loss: 1.2472 - val_accuracy: 0.5943\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9618 - accuracy: 0.5831 - val_loss: 1.0501 - val_accuracy: 0.6490\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7810 - accuracy: 0.6197 - val_loss: 1.0841 - val_accuracy: 0.6465\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8467 - accuracy: 0.6028 - val_loss: 1.0776 - val_accuracy: 0.6433\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7504 - accuracy: 0.6233 - val_loss: 1.0182 - val_accuracy: 0.6622\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7720 - accuracy: 0.6189 - val_loss: 1.0680 - val_accuracy: 0.6455\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0764 - accuracy: 0.5672 - val_loss: 1.1414 - val_accuracy: 0.6259\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1504 - accuracy: 0.6095 - val_loss: 1.3620 - val_accuracy: 0.5545\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8761 - accuracy: 0.5873 - val_loss: 1.0713 - val_accuracy: 0.6472\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7803 - accuracy: 0.6036 - val_loss: 1.2561 - val_accuracy: 0.5751\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7988 - accuracy: 0.6132 - val_loss: 1.0521 - val_accuracy: 0.6462\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7963 - accuracy: 0.6066 - val_loss: 1.0734 - val_accuracy: 0.6416\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9194 - accuracy: 0.5791 - val_loss: 1.3633 - val_accuracy: 0.5481\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8540 - accuracy: 0.5865 - val_loss: 1.0535 - val_accuracy: 0.6515\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9276 - accuracy: 0.5981 - val_loss: 1.1626 - val_accuracy: 0.6085\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8332 - accuracy: 0.5264 - val_loss: 1.5827 - val_accuracy: 0.4544\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7040 - accuracy: 0.5027 - val_loss: 1.2189 - val_accuracy: 0.5950\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7166 - accuracy: 0.5460 - val_loss: 1.1435 - val_accuracy: 0.6334\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9447 - accuracy: 0.5654 - val_loss: 1.1926 - val_accuracy: 0.6039\n",
      "Epoch 343/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2785 - accuracy: 0.5613 - val_loss: 1.2196 - val_accuracy: 0.6067\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8837 - accuracy: 0.5834 - val_loss: 1.2031 - val_accuracy: 0.5954\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8820 - accuracy: 0.5987 - val_loss: 1.1307 - val_accuracy: 0.6245\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7749 - accuracy: 0.6099 - val_loss: 1.0621 - val_accuracy: 0.6483\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9740 - accuracy: 0.5905 - val_loss: 1.1365 - val_accuracy: 0.6355\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7449 - accuracy: 0.6184 - val_loss: 1.0337 - val_accuracy: 0.6458\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7288 - accuracy: 0.6308 - val_loss: 1.0422 - val_accuracy: 0.6593\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.6353 - val_loss: 1.0758 - val_accuracy: 0.6512\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7693 - accuracy: 0.6158 - val_loss: 1.0068 - val_accuracy: 0.6632\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2601 - accuracy: 0.5251 - val_loss: 1.3649 - val_accuracy: 0.5346\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.5427 - val_loss: 1.2692 - val_accuracy: 0.5886\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8317 - accuracy: 0.5851 - val_loss: 1.1478 - val_accuracy: 0.6160\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9227 - accuracy: 0.5798 - val_loss: 1.1486 - val_accuracy: 0.6195\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9593 - accuracy: 0.5870 - val_loss: 1.2465 - val_accuracy: 0.5769\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8162 - accuracy: 0.5964 - val_loss: 1.0608 - val_accuracy: 0.6440\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7542 - accuracy: 0.6135 - val_loss: 1.0262 - val_accuracy: 0.6494\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8018 - accuracy: 0.6016 - val_loss: 1.0297 - val_accuracy: 0.6512\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1783 - accuracy: 0.5472 - val_loss: 1.7462 - val_accuracy: 0.4579\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2653 - accuracy: 0.5144 - val_loss: 1.1152 - val_accuracy: 0.6298\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8595 - accuracy: 0.5806 - val_loss: 1.1223 - val_accuracy: 0.6274\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7621 - accuracy: 0.5979 - val_loss: 1.1406 - val_accuracy: 0.6142\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8343 - accuracy: 0.6015 - val_loss: 1.0740 - val_accuracy: 0.6348\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8589 - accuracy: 0.5920 - val_loss: 1.2528 - val_accuracy: 0.5801\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8599 - accuracy: 0.5897 - val_loss: 1.0560 - val_accuracy: 0.6497\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9853 - accuracy: 0.5673 - val_loss: 1.1004 - val_accuracy: 0.6263\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7900 - accuracy: 0.6094 - val_loss: 1.0528 - val_accuracy: 0.6458\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1507 - accuracy: 0.5769 - val_loss: 2.1482 - val_accuracy: 0.4579\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0926 - accuracy: 0.5644 - val_loss: 1.5162 - val_accuracy: 0.5780\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0662 - accuracy: 0.5706 - val_loss: 1.3084 - val_accuracy: 0.5709\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9055 - accuracy: 0.5752 - val_loss: 1.1330 - val_accuracy: 0.6277\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7842 - accuracy: 0.6129 - val_loss: 1.0785 - val_accuracy: 0.6455\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8253 - accuracy: 0.6083 - val_loss: 1.1523 - val_accuracy: 0.6220\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7937 - accuracy: 0.6144 - val_loss: 1.3401 - val_accuracy: 0.5517\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0775 - accuracy: 0.5544 - val_loss: 1.6592 - val_accuracy: 0.4551\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0486 - accuracy: 0.5434 - val_loss: 1.2283 - val_accuracy: 0.5741\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8252 - accuracy: 0.5837 - val_loss: 1.0949 - val_accuracy: 0.6437\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3921 - accuracy: 0.5778 - val_loss: 1.6320 - val_accuracy: 0.4842\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3136 - accuracy: 0.5123 - val_loss: 1.8312 - val_accuracy: 0.5254\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9943 - accuracy: 0.5592 - val_loss: 1.3306 - val_accuracy: 0.5655\n",
      "Epoch 382/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8779 - accuracy: 0.5790 - val_loss: 1.1095 - val_accuracy: 0.6313\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7588 - accuracy: 0.6160 - val_loss: 1.0778 - val_accuracy: 0.6377\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9245 - accuracy: 0.5733 - val_loss: 1.1467 - val_accuracy: 0.6213\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9843 - accuracy: 0.5507 - val_loss: 1.3233 - val_accuracy: 0.5620\n",
      "Epoch 386/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1036 - accuracy: 0.5597 - val_loss: 1.0882 - val_accuracy: 0.6249\n",
      "Epoch 387/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1891 - accuracy: 0.5571 - val_loss: 1.3921 - val_accuracy: 0.5588\n",
      "Epoch 388/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2330 - accuracy: 0.5338 - val_loss: 1.4113 - val_accuracy: 0.5442\n",
      "Epoch 389/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9319 - accuracy: 0.5718 - val_loss: 1.1279 - val_accuracy: 0.6277\n",
      "Epoch 390/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9085 - accuracy: 0.5874 - val_loss: 1.0713 - val_accuracy: 0.6451\n",
      "Epoch 391/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8676 - accuracy: 0.5999 - val_loss: 1.0437 - val_accuracy: 0.6565\n",
      "Epoch 392/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7932 - accuracy: 0.6018 - val_loss: 1.0975 - val_accuracy: 0.6419\n",
      "Epoch 393/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7727 - accuracy: 0.6133 - val_loss: 1.1484 - val_accuracy: 0.6099\n",
      "Epoch 394/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9630 - accuracy: 0.5806 - val_loss: 1.2439 - val_accuracy: 0.5847\n",
      "Epoch 395/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9419 - accuracy: 0.5778 - val_loss: 1.0838 - val_accuracy: 0.6345\n",
      "Epoch 396/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9343 - accuracy: 0.5856 - val_loss: 1.1096 - val_accuracy: 0.6270\n",
      "Epoch 397/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7974 - accuracy: 0.6065 - val_loss: 1.0497 - val_accuracy: 0.6419\n",
      "Epoch 398/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8762 - accuracy: 0.6134 - val_loss: 1.2878 - val_accuracy: 0.5524\n",
      "Epoch 399/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9220 - accuracy: 0.5165 - val_loss: 1.3059 - val_accuracy: 0.5687\n",
      "Epoch 400/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0929 - accuracy: 0.4700 - val_loss: 1.5345 - val_accuracy: 0.4888\n",
      "Epoch 401/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0294 - accuracy: 0.4519 - val_loss: 1.4720 - val_accuracy: 0.5172\n",
      "Epoch 402/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3801 - accuracy: 0.4973 - val_loss: 1.4240 - val_accuracy: 0.5425\n",
      "Epoch 403/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4428 - accuracy: 0.4768 - val_loss: 1.4000 - val_accuracy: 0.5250\n",
      "Epoch 404/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2289 - accuracy: 0.4929 - val_loss: 1.3338 - val_accuracy: 0.5339\n",
      "Epoch 405/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1850 - accuracy: 0.5448 - val_loss: 1.2135 - val_accuracy: 0.5940\n",
      "Epoch 406/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2069 - accuracy: 0.5403 - val_loss: 1.3433 - val_accuracy: 0.5396\n",
      "Epoch 407/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0248 - accuracy: 0.5572 - val_loss: 1.2438 - val_accuracy: 0.5840\n",
      "Epoch 408/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1626 - accuracy: 0.5483 - val_loss: 1.1829 - val_accuracy: 0.5964\n",
      "Epoch 409/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9506 - accuracy: 0.5891 - val_loss: 1.1908 - val_accuracy: 0.6089\n",
      "Epoch 410/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9125 - accuracy: 0.5885 - val_loss: 1.0671 - val_accuracy: 0.6515\n",
      "\n",
      "Validation 3, fold 2 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8704 - accuracy: 0.0903 - val_loss: 2.8037 - val_accuracy: 0.2913\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7571 - accuracy: 0.1564 - val_loss: 2.6422 - val_accuracy: 0.2025\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.5736 - accuracy: 0.1837 - val_loss: 2.2868 - val_accuracy: 0.2131\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3450 - accuracy: 0.1909 - val_loss: 2.1819 - val_accuracy: 0.2583\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2722 - accuracy: 0.2167 - val_loss: 2.1370 - val_accuracy: 0.2725\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2915 - accuracy: 0.2454 - val_loss: 2.2636 - val_accuracy: 0.2515\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1275 - accuracy: 0.2507 - val_loss: 2.1324 - val_accuracy: 0.2611\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0156 - accuracy: 0.2722 - val_loss: 2.0305 - val_accuracy: 0.3222\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1568 - accuracy: 0.2627 - val_loss: 2.0277 - val_accuracy: 0.3162\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0378 - accuracy: 0.2631 - val_loss: 1.9535 - val_accuracy: 0.3467\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8918 - accuracy: 0.3085 - val_loss: 1.8760 - val_accuracy: 0.3687\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8753 - accuracy: 0.3227 - val_loss: 1.7920 - val_accuracy: 0.3620\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7515 - accuracy: 0.3508 - val_loss: 1.6822 - val_accuracy: 0.4355\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6405 - accuracy: 0.3750 - val_loss: 1.7811 - val_accuracy: 0.3805\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6973 - accuracy: 0.3603 - val_loss: 1.7063 - val_accuracy: 0.4160\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5079 - accuracy: 0.3974 - val_loss: 1.6083 - val_accuracy: 0.4366\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5522 - accuracy: 0.3793 - val_loss: 1.5583 - val_accuracy: 0.4362\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4954 - accuracy: 0.4128 - val_loss: 1.5166 - val_accuracy: 0.4629\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3881 - accuracy: 0.4214 - val_loss: 1.5570 - val_accuracy: 0.4579\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4288 - accuracy: 0.4340 - val_loss: 1.8305 - val_accuracy: 0.4018\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5753 - accuracy: 0.4049 - val_loss: 1.4938 - val_accuracy: 0.4810\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3938 - accuracy: 0.4368 - val_loss: 1.4163 - val_accuracy: 0.5016\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3327 - accuracy: 0.4436 - val_loss: 1.5099 - val_accuracy: 0.4693\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.3613 - accuracy: 0.4577 - val_loss: 1.4861 - val_accuracy: 0.4927\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4288 - accuracy: 0.4429 - val_loss: 1.5167 - val_accuracy: 0.4824\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3762 - accuracy: 0.4510 - val_loss: 1.4720 - val_accuracy: 0.5027\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2650 - accuracy: 0.4670 - val_loss: 1.5310 - val_accuracy: 0.4853\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2734 - accuracy: 0.4779 - val_loss: 1.3685 - val_accuracy: 0.5346\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2336 - accuracy: 0.4876 - val_loss: 1.5944 - val_accuracy: 0.4934\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2398 - accuracy: 0.4798 - val_loss: 1.3608 - val_accuracy: 0.5321\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4664 - accuracy: 0.4405 - val_loss: 1.4948 - val_accuracy: 0.4906\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3474 - accuracy: 0.4863 - val_loss: 1.4195 - val_accuracy: 0.5442\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2572 - accuracy: 0.4831 - val_loss: 1.4766 - val_accuracy: 0.5169\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1958 - accuracy: 0.5143 - val_loss: 1.3319 - val_accuracy: 0.5645\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2552 - accuracy: 0.4814 - val_loss: 1.3852 - val_accuracy: 0.5403\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1503 - accuracy: 0.5088 - val_loss: 1.4227 - val_accuracy: 0.5215\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1036 - accuracy: 0.5179 - val_loss: 1.3555 - val_accuracy: 0.5343\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3396 - accuracy: 0.4638 - val_loss: 1.5079 - val_accuracy: 0.4945\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2789 - accuracy: 0.4752 - val_loss: 1.4445 - val_accuracy: 0.5098\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1100 - accuracy: 0.5171 - val_loss: 1.3943 - val_accuracy: 0.5474\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0499 - accuracy: 0.5252 - val_loss: 1.2211 - val_accuracy: 0.5886\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1560 - accuracy: 0.5081 - val_loss: 1.3171 - val_accuracy: 0.5712\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1055 - accuracy: 0.5182 - val_loss: 1.4624 - val_accuracy: 0.5247\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2090 - accuracy: 0.5046 - val_loss: 1.3330 - val_accuracy: 0.5648\n",
      "Epoch 45/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0545 - accuracy: 0.5201 - val_loss: 1.2150 - val_accuracy: 0.5865\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1068 - accuracy: 0.5149 - val_loss: 1.1921 - val_accuracy: 0.6043\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0232 - accuracy: 0.5222 - val_loss: 1.2845 - val_accuracy: 0.5641\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0846 - accuracy: 0.5222 - val_loss: 1.3055 - val_accuracy: 0.5595\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0279 - accuracy: 0.5344 - val_loss: 1.2527 - val_accuracy: 0.5677\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0865 - accuracy: 0.5246 - val_loss: 1.3871 - val_accuracy: 0.5485\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1380 - accuracy: 0.5115 - val_loss: 1.2385 - val_accuracy: 0.5780\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1924 - accuracy: 0.5287 - val_loss: 1.6556 - val_accuracy: 0.4789\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5787 - accuracy: 0.4880 - val_loss: 1.5235 - val_accuracy: 0.5016\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3604 - accuracy: 0.4981 - val_loss: 1.3521 - val_accuracy: 0.5517\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0908 - accuracy: 0.5377 - val_loss: 1.3287 - val_accuracy: 0.5698\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0755 - accuracy: 0.5416 - val_loss: 1.2173 - val_accuracy: 0.5943\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.5344 - val_loss: 1.2155 - val_accuracy: 0.5869\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0149 - accuracy: 0.5528 - val_loss: 1.1990 - val_accuracy: 0.5950\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9670 - accuracy: 0.5531 - val_loss: 1.2271 - val_accuracy: 0.5837\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9723 - accuracy: 0.5464 - val_loss: 1.4440 - val_accuracy: 0.5233\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9972 - accuracy: 0.5551 - val_loss: 1.2745 - val_accuracy: 0.5794\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0441 - accuracy: 0.5393 - val_loss: 1.2563 - val_accuracy: 0.5481\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0202 - accuracy: 0.5329 - val_loss: 1.1340 - val_accuracy: 0.6220\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2273 - accuracy: 0.5640 - val_loss: 1.5240 - val_accuracy: 0.5052\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1646 - accuracy: 0.4937 - val_loss: 1.2121 - val_accuracy: 0.5837\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2428 - accuracy: 0.5054 - val_loss: 1.2766 - val_accuracy: 0.5815\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0237 - accuracy: 0.5345 - val_loss: 1.1964 - val_accuracy: 0.5872\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9623 - accuracy: 0.5595 - val_loss: 1.2824 - val_accuracy: 0.5641\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9813 - accuracy: 0.5569 - val_loss: 1.1993 - val_accuracy: 0.5918\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9028 - accuracy: 0.5666 - val_loss: 1.1656 - val_accuracy: 0.6121\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9538 - accuracy: 0.5750 - val_loss: 1.1210 - val_accuracy: 0.6252\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1119 - accuracy: 0.5488 - val_loss: 1.3095 - val_accuracy: 0.5755\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0499 - accuracy: 0.5497 - val_loss: 1.4740 - val_accuracy: 0.5080\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0097 - accuracy: 0.5549 - val_loss: 1.4670 - val_accuracy: 0.5243\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0348 - accuracy: 0.5371 - val_loss: 1.1462 - val_accuracy: 0.6217\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9098 - accuracy: 0.5705 - val_loss: 1.3979 - val_accuracy: 0.5353\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9076 - accuracy: 0.5703 - val_loss: 1.1408 - val_accuracy: 0.6213\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9246 - accuracy: 0.5745 - val_loss: 1.1983 - val_accuracy: 0.5989\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1066 - accuracy: 0.5306 - val_loss: 1.3324 - val_accuracy: 0.5687\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1113 - accuracy: 0.5375 - val_loss: 1.1429 - val_accuracy: 0.6142\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0343 - accuracy: 0.5575 - val_loss: 1.2667 - val_accuracy: 0.5893\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9652 - accuracy: 0.5666 - val_loss: 1.1282 - val_accuracy: 0.6320\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9602 - accuracy: 0.5598 - val_loss: 1.2908 - val_accuracy: 0.5659\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8992 - accuracy: 0.5764 - val_loss: 1.0709 - val_accuracy: 0.6451\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9507 - accuracy: 0.5835 - val_loss: 1.2210 - val_accuracy: 0.5904\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2139 - accuracy: 0.5365 - val_loss: 1.6192 - val_accuracy: 0.4430\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4415 - accuracy: 0.4809 - val_loss: 1.4826 - val_accuracy: 0.4980\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0417 - accuracy: 0.5305 - val_loss: 1.2255 - val_accuracy: 0.5964\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0788 - accuracy: 0.5646 - val_loss: 1.2600 - val_accuracy: 0.5769\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9339 - accuracy: 0.5733 - val_loss: 1.1744 - val_accuracy: 0.6075\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9273 - accuracy: 0.5734 - val_loss: 1.1912 - val_accuracy: 0.5961\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8769 - accuracy: 0.5789 - val_loss: 1.1645 - val_accuracy: 0.6110\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9143 - accuracy: 0.5709 - val_loss: 1.1663 - val_accuracy: 0.6011\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9448 - accuracy: 0.5639 - val_loss: 1.2387 - val_accuracy: 0.6064\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9813 - accuracy: 0.5448 - val_loss: 1.1586 - val_accuracy: 0.6036\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0785 - accuracy: 0.5378 - val_loss: 1.3393 - val_accuracy: 0.5567\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0542 - accuracy: 0.5612 - val_loss: 1.1596 - val_accuracy: 0.6156\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9438 - accuracy: 0.5643 - val_loss: 1.2350 - val_accuracy: 0.5954\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8234 - accuracy: 0.5881 - val_loss: 1.0736 - val_accuracy: 0.6274\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8573 - accuracy: 0.5854 - val_loss: 1.1953 - val_accuracy: 0.5933\n",
      "Epoch 101/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8882 - accuracy: 0.5889 - val_loss: 1.2018 - val_accuracy: 0.6000\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1538 - accuracy: 0.5531 - val_loss: 1.3822 - val_accuracy: 0.5435\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9709 - accuracy: 0.5611 - val_loss: 1.2254 - val_accuracy: 0.5947\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8706 - accuracy: 0.5856 - val_loss: 1.1224 - val_accuracy: 0.6252\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0069 - accuracy: 0.5542 - val_loss: 1.1268 - val_accuracy: 0.6295\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8864 - accuracy: 0.5872 - val_loss: 1.1072 - val_accuracy: 0.6345\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9179 - accuracy: 0.5786 - val_loss: 1.2220 - val_accuracy: 0.6153\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8995 - accuracy: 0.5837 - val_loss: 1.1132 - val_accuracy: 0.6284\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8601 - accuracy: 0.5944 - val_loss: 1.1596 - val_accuracy: 0.6160\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9856 - accuracy: 0.5760 - val_loss: 1.1940 - val_accuracy: 0.6046\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8605 - accuracy: 0.5868 - val_loss: 1.0837 - val_accuracy: 0.6387\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2505 - accuracy: 0.5246 - val_loss: 1.3601 - val_accuracy: 0.5350\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0626 - accuracy: 0.5362 - val_loss: 1.3079 - val_accuracy: 0.5545\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9677 - accuracy: 0.5602 - val_loss: 1.1892 - val_accuracy: 0.5975\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2472 - accuracy: 0.5479 - val_loss: 1.1826 - val_accuracy: 0.6060\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9053 - accuracy: 0.5726 - val_loss: 1.1201 - val_accuracy: 0.6323\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9590 - accuracy: 0.5764 - val_loss: 1.3242 - val_accuracy: 0.5599\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9629 - accuracy: 0.5554 - val_loss: 1.1029 - val_accuracy: 0.6263\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9016 - accuracy: 0.5830 - val_loss: 1.1356 - val_accuracy: 0.6060\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9276 - accuracy: 0.5920 - val_loss: 1.4274 - val_accuracy: 0.5439\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9038 - accuracy: 0.5861 - val_loss: 1.0870 - val_accuracy: 0.6430\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1252 - accuracy: 0.5331 - val_loss: 1.1813 - val_accuracy: 0.6156\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0473 - accuracy: 0.4831 - val_loss: 1.5358 - val_accuracy: 0.4934\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4846 - accuracy: 0.4859 - val_loss: 1.3734 - val_accuracy: 0.5613\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2477 - accuracy: 0.5206 - val_loss: 1.2346 - val_accuracy: 0.5812\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1073 - accuracy: 0.5498 - val_loss: 1.2170 - val_accuracy: 0.5822\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7698 - accuracy: 0.5169 - val_loss: 1.4181 - val_accuracy: 0.5183\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1347 - accuracy: 0.5200 - val_loss: 1.3413 - val_accuracy: 0.5460\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2696 - accuracy: 0.5349 - val_loss: 1.3520 - val_accuracy: 0.5673\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2011 - accuracy: 0.5321 - val_loss: 1.1971 - val_accuracy: 0.5982\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9123 - accuracy: 0.5695 - val_loss: 1.3388 - val_accuracy: 0.5801\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9529 - accuracy: 0.5692 - val_loss: 1.1300 - val_accuracy: 0.6078\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9383 - accuracy: 0.5785 - val_loss: 1.0884 - val_accuracy: 0.6298\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9278 - accuracy: 0.5761 - val_loss: 1.0764 - val_accuracy: 0.6391\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0284 - accuracy: 0.5702 - val_loss: 1.1602 - val_accuracy: 0.6014\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9712 - accuracy: 0.5683 - val_loss: 1.1668 - val_accuracy: 0.5957\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8615 - accuracy: 0.5902 - val_loss: 1.0653 - val_accuracy: 0.6320\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1095 - accuracy: 0.5378 - val_loss: 1.1387 - val_accuracy: 0.6306\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0566 - accuracy: 0.5516 - val_loss: 1.2624 - val_accuracy: 0.5769\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9399 - accuracy: 0.5846 - val_loss: 1.0828 - val_accuracy: 0.6398\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0048 - accuracy: 0.5733 - val_loss: 1.2909 - val_accuracy: 0.5925\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0094 - accuracy: 0.5428 - val_loss: 1.1644 - val_accuracy: 0.6067\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0126 - accuracy: 0.5464 - val_loss: 1.4173 - val_accuracy: 0.5321\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8729 - accuracy: 0.5813 - val_loss: 1.2134 - val_accuracy: 0.5854\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8206 - accuracy: 0.6045 - val_loss: 1.0350 - val_accuracy: 0.6590\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8638 - accuracy: 0.6030 - val_loss: 1.2866 - val_accuracy: 0.5783\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8132 - accuracy: 0.6040 - val_loss: 1.1655 - val_accuracy: 0.6234\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8753 - accuracy: 0.5862 - val_loss: 1.1564 - val_accuracy: 0.6060\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9707 - accuracy: 0.5710 - val_loss: 1.1472 - val_accuracy: 0.6234\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8951 - accuracy: 0.6027 - val_loss: 1.2828 - val_accuracy: 0.5471\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8782 - accuracy: 0.5858 - val_loss: 1.2272 - val_accuracy: 0.6039\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9956 - accuracy: 0.5822 - val_loss: 1.1312 - val_accuracy: 0.6426\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0179 - accuracy: 0.5846 - val_loss: 1.2065 - val_accuracy: 0.6103\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9933 - accuracy: 0.5846 - val_loss: 1.1600 - val_accuracy: 0.6249\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8240 - accuracy: 0.6048 - val_loss: 1.0268 - val_accuracy: 0.6600\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9059 - accuracy: 0.5909 - val_loss: 1.2929 - val_accuracy: 0.5876\n",
      "Epoch 157/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0326 - accuracy: 0.5661 - val_loss: 1.3045 - val_accuracy: 0.5773\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8979 - accuracy: 0.5879 - val_loss: 1.1631 - val_accuracy: 0.6210\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8165 - accuracy: 0.6000 - val_loss: 1.0747 - val_accuracy: 0.6472\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8469 - accuracy: 0.6015 - val_loss: 1.0802 - val_accuracy: 0.6426\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3285 - accuracy: 0.5734 - val_loss: 1.3690 - val_accuracy: 0.5485\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8549 - accuracy: 0.5165 - val_loss: 1.5178 - val_accuracy: 0.4895\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3150 - accuracy: 0.4920 - val_loss: 1.3705 - val_accuracy: 0.5577\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4611 - accuracy: 0.5115 - val_loss: 1.4383 - val_accuracy: 0.5361\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2295 - accuracy: 0.5335 - val_loss: 1.2286 - val_accuracy: 0.6053\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9653 - accuracy: 0.5671 - val_loss: 1.2173 - val_accuracy: 0.6124\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8855 - accuracy: 0.5928 - val_loss: 1.5005 - val_accuracy: 0.5375\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8936 - accuracy: 0.5843 - val_loss: 1.0400 - val_accuracy: 0.6501\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7975 - accuracy: 0.6136 - val_loss: 1.0654 - val_accuracy: 0.6440\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9471 - accuracy: 0.5826 - val_loss: 1.1627 - val_accuracy: 0.6313\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8744 - accuracy: 0.5979 - val_loss: 1.0611 - val_accuracy: 0.6664\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9855 - accuracy: 0.6005 - val_loss: 1.2628 - val_accuracy: 0.5716\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8700 - accuracy: 0.5999 - val_loss: 1.0646 - val_accuracy: 0.6544\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8637 - accuracy: 0.5995 - val_loss: 1.0243 - val_accuracy: 0.6565\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2401 - accuracy: 0.5520 - val_loss: 1.2436 - val_accuracy: 0.5776\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2840 - accuracy: 0.5192 - val_loss: 1.3965 - val_accuracy: 0.5439\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0753 - accuracy: 0.5535 - val_loss: 1.2308 - val_accuracy: 0.5918\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9135 - accuracy: 0.5734 - val_loss: 1.0914 - val_accuracy: 0.6263\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9413 - accuracy: 0.5785 - val_loss: 1.0929 - val_accuracy: 0.6430\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1543 - accuracy: 0.5556 - val_loss: 1.2903 - val_accuracy: 0.5805\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0573 - accuracy: 0.5444 - val_loss: 1.2073 - val_accuracy: 0.5883\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9640 - accuracy: 0.5721 - val_loss: 1.0907 - val_accuracy: 0.6330\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8564 - accuracy: 0.5907 - val_loss: 1.0245 - val_accuracy: 0.6501\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8486 - accuracy: 0.6100 - val_loss: 1.1613 - val_accuracy: 0.6156\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0160 - accuracy: 0.5930 - val_loss: 1.1723 - val_accuracy: 0.5982\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1993 - accuracy: 0.5438 - val_loss: 1.4866 - val_accuracy: 0.5147\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0971 - accuracy: 0.5603 - val_loss: 1.2264 - val_accuracy: 0.5996\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0873 - accuracy: 0.5640 - val_loss: 1.2126 - val_accuracy: 0.5947\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0754 - accuracy: 0.5288 - val_loss: 1.2512 - val_accuracy: 0.5751\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9197 - accuracy: 0.5827 - val_loss: 1.1271 - val_accuracy: 0.6359\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8633 - accuracy: 0.6108 - val_loss: 1.1699 - val_accuracy: 0.6245\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7992 - accuracy: 0.6099 - val_loss: 1.0639 - val_accuracy: 0.6458\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7574 - accuracy: 0.6130 - val_loss: 1.0013 - val_accuracy: 0.6650\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8183 - accuracy: 0.6080 - val_loss: 0.9991 - val_accuracy: 0.6654\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8028 - accuracy: 0.6134 - val_loss: 1.1600 - val_accuracy: 0.6067\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0669 - accuracy: 0.5449 - val_loss: 1.2504 - val_accuracy: 0.5826\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9404 - accuracy: 0.5590 - val_loss: 1.1665 - val_accuracy: 0.5982\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9227 - accuracy: 0.5762 - val_loss: 1.0569 - val_accuracy: 0.6476\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9744 - accuracy: 0.5575 - val_loss: 1.1144 - val_accuracy: 0.6476\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3267 - accuracy: 0.5643 - val_loss: 1.3447 - val_accuracy: 0.5616\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0664 - accuracy: 0.5678 - val_loss: 1.1222 - val_accuracy: 0.6270\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0067 - accuracy: 0.5594 - val_loss: 1.1529 - val_accuracy: 0.5925\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9329 - accuracy: 0.5829 - val_loss: 1.1349 - val_accuracy: 0.6302\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9931 - accuracy: 0.5851 - val_loss: 1.2833 - val_accuracy: 0.5655\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0165 - accuracy: 0.5803 - val_loss: 1.1584 - val_accuracy: 0.6210\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0408 - accuracy: 0.5751 - val_loss: 1.2780 - val_accuracy: 0.5826\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0205 - accuracy: 0.5837 - val_loss: 1.1467 - val_accuracy: 0.6220\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8131 - accuracy: 0.6117 - val_loss: 1.4526 - val_accuracy: 0.5442\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8822 - accuracy: 0.5858 - val_loss: 1.0952 - val_accuracy: 0.6483\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8186 - accuracy: 0.6137 - val_loss: 1.0800 - val_accuracy: 0.6416\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8424 - accuracy: 0.6154 - val_loss: 1.0131 - val_accuracy: 0.6664\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1967 - accuracy: 0.5796 - val_loss: 1.3983 - val_accuracy: 0.5261\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0282 - accuracy: 0.5770 - val_loss: 1.1603 - val_accuracy: 0.6195\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9130 - accuracy: 0.5922 - val_loss: 1.0548 - val_accuracy: 0.6668\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8738 - accuracy: 0.5953 - val_loss: 1.0550 - val_accuracy: 0.6572\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9340 - accuracy: 0.5918 - val_loss: 1.1328 - val_accuracy: 0.6227\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8494 - accuracy: 0.6067 - val_loss: 1.1125 - val_accuracy: 0.6423\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9849 - accuracy: 0.5984 - val_loss: 1.1634 - val_accuracy: 0.6227\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0021 - accuracy: 0.5568 - val_loss: 1.8023 - val_accuracy: 0.4750\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0282 - accuracy: 0.5140 - val_loss: 1.1686 - val_accuracy: 0.5986\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8883 - accuracy: 0.5799 - val_loss: 1.2398 - val_accuracy: 0.5648\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1660 - accuracy: 0.5465 - val_loss: 1.3026 - val_accuracy: 0.5751\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3782 - accuracy: 0.5191 - val_loss: 1.2088 - val_accuracy: 0.5961\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1478 - accuracy: 0.5258 - val_loss: 1.4006 - val_accuracy: 0.5389\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8202 - accuracy: 0.5845 - val_loss: 1.0549 - val_accuracy: 0.6533\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8042 - accuracy: 0.6000 - val_loss: 1.0578 - val_accuracy: 0.6412\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8011 - accuracy: 0.6128 - val_loss: 0.9742 - val_accuracy: 0.6725\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0435 - accuracy: 0.5772 - val_loss: 1.2303 - val_accuracy: 0.5915\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8859 - accuracy: 0.5837 - val_loss: 1.0453 - val_accuracy: 0.6501\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7551 - accuracy: 0.6230 - val_loss: 1.1633 - val_accuracy: 0.6135\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7897 - accuracy: 0.6302 - val_loss: 1.0355 - val_accuracy: 0.6607\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8250 - accuracy: 0.6016 - val_loss: 1.1148 - val_accuracy: 0.6231\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6395 - accuracy: 0.5719 - val_loss: 1.1879 - val_accuracy: 0.6178\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1728 - accuracy: 0.5523 - val_loss: 1.1471 - val_accuracy: 0.6128\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1273 - accuracy: 0.5346 - val_loss: 1.1755 - val_accuracy: 0.6000\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1383 - accuracy: 0.5645 - val_loss: 1.3062 - val_accuracy: 0.5716\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9599 - accuracy: 0.5617 - val_loss: 1.3492 - val_accuracy: 0.5549\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0706 - accuracy: 0.5560 - val_loss: 1.4097 - val_accuracy: 0.5531\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0241 - accuracy: 0.5234 - val_loss: 1.3294 - val_accuracy: 0.5826\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3894 - accuracy: 0.5169 - val_loss: 1.2121 - val_accuracy: 0.6004\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0764 - accuracy: 0.5745 - val_loss: 1.1660 - val_accuracy: 0.6242\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9841 - accuracy: 0.5705 - val_loss: 1.2102 - val_accuracy: 0.5904\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0160 - accuracy: 0.5680 - val_loss: 1.1265 - val_accuracy: 0.6256\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8839 - accuracy: 0.5880 - val_loss: 1.1354 - val_accuracy: 0.6114\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8326 - accuracy: 0.6033 - val_loss: 1.0624 - val_accuracy: 0.6409\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7982 - accuracy: 0.6063 - val_loss: 1.0541 - val_accuracy: 0.6490\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8952 - accuracy: 0.5961 - val_loss: 1.0706 - val_accuracy: 0.6458\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9376 - accuracy: 0.5859 - val_loss: 1.3746 - val_accuracy: 0.5488\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9354 - accuracy: 0.5512 - val_loss: 1.2243 - val_accuracy: 0.5933\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.8417 - accuracy: 0.5929 - val_loss: 1.2337 - val_accuracy: 0.5933\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8217 - accuracy: 0.6057 - val_loss: 1.0557 - val_accuracy: 0.6561\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0369 - accuracy: 0.6012 - val_loss: 1.1860 - val_accuracy: 0.5957\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9394 - accuracy: 0.5826 - val_loss: 1.1276 - val_accuracy: 0.6334\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9164 - accuracy: 0.5960 - val_loss: 1.0872 - val_accuracy: 0.6423\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1233 - accuracy: 0.5807 - val_loss: 1.2214 - val_accuracy: 0.5950\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.8696 - accuracy: 0.6067 - val_loss: 0.9828 - val_accuracy: 0.6750\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0452 - accuracy: 0.5759 - val_loss: 1.2344 - val_accuracy: 0.6028\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9002 - accuracy: 0.5970 - val_loss: 1.2824 - val_accuracy: 0.5893\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8714 - accuracy: 0.6055 - val_loss: 1.0703 - val_accuracy: 0.6629\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7648 - accuracy: 0.6274 - val_loss: 1.0176 - val_accuracy: 0.6682\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7918 - accuracy: 0.6188 - val_loss: 1.0815 - val_accuracy: 0.6398\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9165 - accuracy: 0.6292 - val_loss: 1.0962 - val_accuracy: 0.6362\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1639 - accuracy: 0.5450 - val_loss: 1.1834 - val_accuracy: 0.6121\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4248 - accuracy: 0.5163 - val_loss: 1.5134 - val_accuracy: 0.5044\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1428 - accuracy: 0.5094 - val_loss: 1.1845 - val_accuracy: 0.6060\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0877 - accuracy: 0.5560 - val_loss: 1.2275 - val_accuracy: 0.5901\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9625 - accuracy: 0.5626 - val_loss: 1.0564 - val_accuracy: 0.6469\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9499 - accuracy: 0.5786 - val_loss: 1.1295 - val_accuracy: 0.6210\n",
      "Epoch 269/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8603 - accuracy: 0.5916 - val_loss: 1.0448 - val_accuracy: 0.6423\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1027 - accuracy: 0.5758 - val_loss: 1.3571 - val_accuracy: 0.5602\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8820 - accuracy: 0.5189 - val_loss: 1.3248 - val_accuracy: 0.5655\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0318 - accuracy: 0.5539 - val_loss: 1.3785 - val_accuracy: 0.5485\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9139 - accuracy: 0.5825 - val_loss: 1.1557 - val_accuracy: 0.6178\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9084 - accuracy: 0.5977 - val_loss: 1.3538 - val_accuracy: 0.5709\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9711 - accuracy: 0.5575 - val_loss: 1.0745 - val_accuracy: 0.6533\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0485 - accuracy: 0.5914 - val_loss: 1.1800 - val_accuracy: 0.6089\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8718 - accuracy: 0.5852 - val_loss: 1.2757 - val_accuracy: 0.5805\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9099 - accuracy: 0.5845 - val_loss: 1.0782 - val_accuracy: 0.6224\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2696 - accuracy: 0.5515 - val_loss: 1.1480 - val_accuracy: 0.6355\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9059 - accuracy: 0.6036 - val_loss: 1.1282 - val_accuracy: 0.6295\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8143 - accuracy: 0.6083 - val_loss: 1.0574 - val_accuracy: 0.6536\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1719 - accuracy: 0.5768 - val_loss: 1.9044 - val_accuracy: 0.4163\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 3.5361 - accuracy: 0.4502 - val_loss: 1.5597 - val_accuracy: 0.5027\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.4541 - accuracy: 0.4901 - val_loss: 1.4235 - val_accuracy: 0.5389\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1583 - accuracy: 0.5398 - val_loss: 1.2656 - val_accuracy: 0.5876\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1403 - accuracy: 0.5522 - val_loss: 1.2828 - val_accuracy: 0.5726\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3201 - accuracy: 0.5444 - val_loss: 1.2208 - val_accuracy: 0.6021\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0639 - accuracy: 0.5358 - val_loss: 1.3060 - val_accuracy: 0.5599\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9974 - accuracy: 0.5629 - val_loss: 1.5168 - val_accuracy: 0.5009\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0243 - accuracy: 0.5664 - val_loss: 1.1403 - val_accuracy: 0.6139\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8684 - accuracy: 0.5952 - val_loss: 1.0960 - val_accuracy: 0.6270\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8696 - accuracy: 0.5941 - val_loss: 1.1093 - val_accuracy: 0.6238\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2235 - accuracy: 0.5613 - val_loss: 1.4711 - val_accuracy: 0.5528\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0843 - accuracy: 0.5257 - val_loss: 1.1919 - val_accuracy: 0.5989\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2115 - accuracy: 0.5372 - val_loss: 1.3265 - val_accuracy: 0.5794\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8826 - accuracy: 0.5868 - val_loss: 1.0795 - val_accuracy: 0.6451\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9588 - accuracy: 0.5996 - val_loss: 1.3758 - val_accuracy: 0.5293\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0506 - accuracy: 0.5685 - val_loss: 1.0447 - val_accuracy: 0.6497\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9161 - accuracy: 0.5691 - val_loss: 1.1573 - val_accuracy: 0.6117\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8540 - accuracy: 0.5925 - val_loss: 1.2831 - val_accuracy: 0.5780\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1167 - accuracy: 0.5635 - val_loss: 1.1661 - val_accuracy: 0.6096\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8498 - accuracy: 0.5981 - val_loss: 1.0614 - val_accuracy: 0.6536\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4514 - accuracy: 0.5538 - val_loss: 1.0971 - val_accuracy: 0.6334\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9325 - accuracy: 0.5972 - val_loss: 1.1249 - val_accuracy: 0.6419\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0173 - accuracy: 0.5855 - val_loss: 1.4947 - val_accuracy: 0.5208\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9511 - accuracy: 0.5629 - val_loss: 1.0995 - val_accuracy: 0.6444\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0167 - accuracy: 0.5821 - val_loss: 1.2738 - val_accuracy: 0.5794\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0711 - accuracy: 0.5842 - val_loss: 1.1994 - val_accuracy: 0.6064\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0682 - accuracy: 0.5581 - val_loss: 1.1279 - val_accuracy: 0.6437\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9731 - accuracy: 0.5871 - val_loss: 1.1020 - val_accuracy: 0.6359\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8483 - accuracy: 0.6118 - val_loss: 1.2006 - val_accuracy: 0.5886\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0386 - accuracy: 0.5894 - val_loss: 1.1604 - val_accuracy: 0.6202\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2770 - accuracy: 0.5425 - val_loss: 1.2560 - val_accuracy: 0.5922\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0328 - accuracy: 0.5645 - val_loss: 1.0973 - val_accuracy: 0.6369\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0780 - accuracy: 0.5869 - val_loss: 1.1323 - val_accuracy: 0.6124\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8788 - accuracy: 0.5904 - val_loss: 1.0895 - val_accuracy: 0.6384\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7969 - accuracy: 0.6158 - val_loss: 1.0732 - val_accuracy: 0.6465\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8458 - accuracy: 0.5916 - val_loss: 1.1484 - val_accuracy: 0.5961\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8821 - accuracy: 0.5906 - val_loss: 1.0680 - val_accuracy: 0.6377\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8437 - accuracy: 0.5953 - val_loss: 1.0341 - val_accuracy: 0.6547\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9823 - accuracy: 0.5906 - val_loss: 1.1615 - val_accuracy: 0.6192\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0544 - accuracy: 0.5724 - val_loss: 1.1416 - val_accuracy: 0.6249\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8831 - accuracy: 0.5729 - val_loss: 1.2799 - val_accuracy: 0.5382\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0063 - accuracy: 0.5561 - val_loss: 1.1110 - val_accuracy: 0.6437\n",
      "Epoch 325/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9576 - accuracy: 0.5765 - val_loss: 1.1579 - val_accuracy: 0.6174\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.8868 - accuracy: 0.5845 - val_loss: 1.0995 - val_accuracy: 0.6419\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7565 - accuracy: 0.6257 - val_loss: 1.0180 - val_accuracy: 0.6600\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2025 - accuracy: 0.5557 - val_loss: 1.5950 - val_accuracy: 0.5428\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1316 - accuracy: 0.5420 - val_loss: 1.3058 - val_accuracy: 0.5357\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0225 - accuracy: 0.5552 - val_loss: 1.0747 - val_accuracy: 0.6245\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8996 - accuracy: 0.5824 - val_loss: 1.0728 - val_accuracy: 0.6366\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7895 - accuracy: 0.6065 - val_loss: 1.0642 - val_accuracy: 0.6451\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0238 - accuracy: 0.5629 - val_loss: 1.2214 - val_accuracy: 0.6085\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2446 - accuracy: 0.5512 - val_loss: 1.3106 - val_accuracy: 0.5666\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0497 - accuracy: 0.5705 - val_loss: 1.1756 - val_accuracy: 0.6046\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8714 - accuracy: 0.6003 - val_loss: 1.1407 - val_accuracy: 0.6362\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8490 - accuracy: 0.6080 - val_loss: 1.0089 - val_accuracy: 0.6782\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8158 - accuracy: 0.6075 - val_loss: 1.0915 - val_accuracy: 0.6373\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0290 - accuracy: 0.5510 - val_loss: 1.1503 - val_accuracy: 0.6110\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9527 - accuracy: 0.5665 - val_loss: 1.3608 - val_accuracy: 0.5606\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0453 - accuracy: 0.5665 - val_loss: 1.3763 - val_accuracy: 0.5233\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1476 - accuracy: 0.5172 - val_loss: 1.1685 - val_accuracy: 0.6128\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1560 - accuracy: 0.5536 - val_loss: 1.2538 - val_accuracy: 0.5812\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6392 - accuracy: 0.5193 - val_loss: 1.3714 - val_accuracy: 0.5659\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2261 - accuracy: 0.5486 - val_loss: 1.4317 - val_accuracy: 0.5389\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5753 - accuracy: 0.4920 - val_loss: 1.2104 - val_accuracy: 0.6021\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0393 - accuracy: 0.5425 - val_loss: 1.1998 - val_accuracy: 0.6167\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9471 - accuracy: 0.5638 - val_loss: 1.1827 - val_accuracy: 0.6188\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0861 - accuracy: 0.5566 - val_loss: 1.3494 - val_accuracy: 0.5641\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0109 - accuracy: 0.5731 - val_loss: 1.1113 - val_accuracy: 0.6227\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2535 - accuracy: 0.5384 - val_loss: 1.4180 - val_accuracy: 0.5332\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1963 - accuracy: 0.5249 - val_loss: 1.2305 - val_accuracy: 0.5893\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1353 - accuracy: 0.5387 - val_loss: 1.1749 - val_accuracy: 0.6107\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9853 - accuracy: 0.5562 - val_loss: 1.4296 - val_accuracy: 0.5133\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3413 - accuracy: 0.5740 - val_loss: 1.2077 - val_accuracy: 0.6135\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8733 - accuracy: 0.5907 - val_loss: 1.0588 - val_accuracy: 0.6494\n",
      "\n",
      "Validation 3, fold 3 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 3.0933 - accuracy: 0.1135 - val_loss: 2.8020 - val_accuracy: 0.1655\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.6430 - accuracy: 0.1786 - val_loss: 2.4103 - val_accuracy: 0.1467\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5275 - accuracy: 0.1953 - val_loss: 2.2206 - val_accuracy: 0.2622\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3112 - accuracy: 0.2166 - val_loss: 2.1232 - val_accuracy: 0.2508\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1830 - accuracy: 0.2252 - val_loss: 2.0555 - val_accuracy: 0.2664\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1992 - accuracy: 0.2282 - val_loss: 2.1881 - val_accuracy: 0.1947\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0882 - accuracy: 0.2451 - val_loss: 1.9350 - val_accuracy: 0.3528\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9746 - accuracy: 0.3152 - val_loss: 1.9168 - val_accuracy: 0.3353\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9905 - accuracy: 0.3057 - val_loss: 1.8388 - val_accuracy: 0.3499\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8645 - accuracy: 0.3266 - val_loss: 1.8609 - val_accuracy: 0.3837\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6777 - accuracy: 0.3541 - val_loss: 1.6847 - val_accuracy: 0.4437\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7696 - accuracy: 0.3720 - val_loss: 1.9808 - val_accuracy: 0.3677\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5932 - accuracy: 0.3798 - val_loss: 1.8091 - val_accuracy: 0.4121\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6522 - accuracy: 0.3850 - val_loss: 2.2431 - val_accuracy: 0.3844\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6714 - accuracy: 0.3799 - val_loss: 2.1049 - val_accuracy: 0.3318\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4695 - accuracy: 0.4106 - val_loss: 1.5285 - val_accuracy: 0.4888\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3381 - accuracy: 0.4468 - val_loss: 1.4338 - val_accuracy: 0.5169\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3129 - accuracy: 0.4585 - val_loss: 1.4922 - val_accuracy: 0.4998\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3459 - accuracy: 0.4456 - val_loss: 1.4895 - val_accuracy: 0.5048\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2917 - accuracy: 0.4750 - val_loss: 1.4130 - val_accuracy: 0.5428\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2331 - accuracy: 0.4794 - val_loss: 1.6020 - val_accuracy: 0.4906\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7416 - accuracy: 0.3881 - val_loss: 1.5743 - val_accuracy: 0.4700\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5161 - accuracy: 0.4320 - val_loss: 1.5201 - val_accuracy: 0.4959\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4903 - accuracy: 0.4348 - val_loss: 1.4451 - val_accuracy: 0.5076\n",
      "Epoch 25/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4353 - accuracy: 0.4448 - val_loss: 1.5056 - val_accuracy: 0.5027\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2827 - accuracy: 0.4584 - val_loss: 1.6674 - val_accuracy: 0.4483\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1509 - accuracy: 0.4909 - val_loss: 1.3584 - val_accuracy: 0.5531\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3349 - accuracy: 0.4508 - val_loss: 1.5107 - val_accuracy: 0.4988\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2604 - accuracy: 0.4693 - val_loss: 1.3777 - val_accuracy: 0.5357\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1419 - accuracy: 0.4893 - val_loss: 1.4869 - val_accuracy: 0.4984\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0938 - accuracy: 0.5071 - val_loss: 1.3531 - val_accuracy: 0.5432\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4658 - accuracy: 0.4546 - val_loss: 1.5760 - val_accuracy: 0.4856\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9768 - accuracy: 0.4744 - val_loss: 1.5127 - val_accuracy: 0.4796\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3613 - accuracy: 0.4819 - val_loss: 1.4311 - val_accuracy: 0.5353\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1735 - accuracy: 0.4933 - val_loss: 1.3157 - val_accuracy: 0.5652\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1685 - accuracy: 0.5046 - val_loss: 1.8807 - val_accuracy: 0.4099\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3410 - accuracy: 0.4767 - val_loss: 1.3972 - val_accuracy: 0.5577\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3486 - accuracy: 0.4940 - val_loss: 1.3450 - val_accuracy: 0.5556\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1070 - accuracy: 0.5051 - val_loss: 1.3234 - val_accuracy: 0.5375\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0526 - accuracy: 0.5155 - val_loss: 1.4296 - val_accuracy: 0.5101\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6699 - accuracy: 0.4809 - val_loss: 1.4915 - val_accuracy: 0.4970\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4041 - accuracy: 0.4708 - val_loss: 1.4143 - val_accuracy: 0.5091\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2805 - accuracy: 0.4704 - val_loss: 1.2724 - val_accuracy: 0.5563\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1844 - accuracy: 0.5004 - val_loss: 1.6184 - val_accuracy: 0.4966\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1642 - accuracy: 0.4975 - val_loss: 1.2650 - val_accuracy: 0.5801\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1345 - accuracy: 0.5096 - val_loss: 1.3889 - val_accuracy: 0.5435\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1085 - accuracy: 0.5183 - val_loss: 1.2079 - val_accuracy: 0.5982\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1997 - accuracy: 0.5064 - val_loss: 1.4896 - val_accuracy: 0.5098\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1309 - accuracy: 0.5070 - val_loss: 1.3429 - val_accuracy: 0.5538\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1035 - accuracy: 0.5115 - val_loss: 1.2192 - val_accuracy: 0.5801\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0171 - accuracy: 0.5203 - val_loss: 1.2315 - val_accuracy: 0.5847\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1158 - accuracy: 0.5154 - val_loss: 1.2481 - val_accuracy: 0.5744\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9967 - accuracy: 0.5392 - val_loss: 1.1789 - val_accuracy: 0.5897\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9776 - accuracy: 0.5423 - val_loss: 1.2165 - val_accuracy: 0.5968\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0870 - accuracy: 0.5303 - val_loss: 1.3251 - val_accuracy: 0.5425\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1298 - accuracy: 0.5079 - val_loss: 1.3656 - val_accuracy: 0.5382\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1255 - accuracy: 0.5116 - val_loss: 1.3052 - val_accuracy: 0.5503\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9765 - accuracy: 0.5416 - val_loss: 1.3663 - val_accuracy: 0.5403\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8321 - accuracy: 0.4579 - val_loss: 1.4618 - val_accuracy: 0.5211\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3967 - accuracy: 0.4794 - val_loss: 1.4698 - val_accuracy: 0.5236\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2146 - accuracy: 0.5051 - val_loss: 1.2105 - val_accuracy: 0.5865\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2250 - accuracy: 0.4816 - val_loss: 1.4723 - val_accuracy: 0.4948\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1076 - accuracy: 0.5180 - val_loss: 1.3113 - val_accuracy: 0.5531\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1923 - accuracy: 0.5038 - val_loss: 1.3034 - val_accuracy: 0.5638\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1401 - accuracy: 0.5107 - val_loss: 1.4014 - val_accuracy: 0.5400\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9725 - accuracy: 0.5468 - val_loss: 1.2146 - val_accuracy: 0.5957\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0570 - accuracy: 0.5475 - val_loss: 1.3328 - val_accuracy: 0.5435\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1475 - accuracy: 0.5208 - val_loss: 1.3148 - val_accuracy: 0.5584\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1301 - accuracy: 0.5261 - val_loss: 1.6634 - val_accuracy: 0.4476\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2392 - accuracy: 0.4940 - val_loss: 1.2231 - val_accuracy: 0.5890\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1442 - accuracy: 0.5116 - val_loss: 1.2690 - val_accuracy: 0.5766\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1737 - accuracy: 0.5268 - val_loss: 1.2352 - val_accuracy: 0.5776\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9913 - accuracy: 0.5424 - val_loss: 1.2292 - val_accuracy: 0.5840\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.2817 - accuracy: 0.4785 - val_loss: 1.4207 - val_accuracy: 0.5396\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0932 - accuracy: 0.5157 - val_loss: 1.2896 - val_accuracy: 0.5542\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0341 - accuracy: 0.5216 - val_loss: 1.2500 - val_accuracy: 0.5854\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9689 - accuracy: 0.5467 - val_loss: 1.2930 - val_accuracy: 0.5776\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0397 - accuracy: 0.5266 - val_loss: 1.3065 - val_accuracy: 0.5321\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1088 - accuracy: 0.5171 - val_loss: 1.3013 - val_accuracy: 0.5609\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9332 - accuracy: 0.5600 - val_loss: 1.2362 - val_accuracy: 0.5861\n",
      "Epoch 81/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9262 - accuracy: 0.5644 - val_loss: 1.1800 - val_accuracy: 0.6050\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1635 - accuracy: 0.5353 - val_loss: 1.4077 - val_accuracy: 0.5083\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1116 - accuracy: 0.5188 - val_loss: 1.1741 - val_accuracy: 0.6014\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0255 - accuracy: 0.5315 - val_loss: 1.3133 - val_accuracy: 0.5410\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9743 - accuracy: 0.5434 - val_loss: 1.2736 - val_accuracy: 0.5762\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9616 - accuracy: 0.5488 - val_loss: 1.3477 - val_accuracy: 0.5574\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9779 - accuracy: 0.5532 - val_loss: 1.2184 - val_accuracy: 0.5901\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1815 - accuracy: 0.5296 - val_loss: 1.3235 - val_accuracy: 0.5631\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8684 - accuracy: 0.5206 - val_loss: 1.5700 - val_accuracy: 0.4735\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5198 - accuracy: 0.4655 - val_loss: 1.3493 - val_accuracy: 0.5314\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1309 - accuracy: 0.5145 - val_loss: 1.3052 - val_accuracy: 0.5481\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9993 - accuracy: 0.5426 - val_loss: 1.1812 - val_accuracy: 0.6131\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9870 - accuracy: 0.5464 - val_loss: 1.1905 - val_accuracy: 0.5911\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9713 - accuracy: 0.5591 - val_loss: 1.1669 - val_accuracy: 0.5961\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0782 - accuracy: 0.5240 - val_loss: 1.1950 - val_accuracy: 0.5865\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0012 - accuracy: 0.5357 - val_loss: 1.1962 - val_accuracy: 0.5957\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9129 - accuracy: 0.5617 - val_loss: 1.2160 - val_accuracy: 0.5986\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9153 - accuracy: 0.5666 - val_loss: 1.1891 - val_accuracy: 0.5979\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9264 - accuracy: 0.5608 - val_loss: 1.2527 - val_accuracy: 0.5801\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9491 - accuracy: 0.5572 - val_loss: 1.1397 - val_accuracy: 0.6050\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9060 - accuracy: 0.5696 - val_loss: 1.2194 - val_accuracy: 0.5744\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8588 - accuracy: 0.5780 - val_loss: 1.1713 - val_accuracy: 0.6007\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8622 - accuracy: 0.5791 - val_loss: 1.1185 - val_accuracy: 0.6146\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8770 - accuracy: 0.5742 - val_loss: 1.1506 - val_accuracy: 0.5954\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8880 - accuracy: 0.5716 - val_loss: 1.1578 - val_accuracy: 0.6007\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0866 - accuracy: 0.5715 - val_loss: 1.1996 - val_accuracy: 0.5837\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9270 - accuracy: 0.5603 - val_loss: 1.1326 - val_accuracy: 0.6174\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8642 - accuracy: 0.5750 - val_loss: 1.1050 - val_accuracy: 0.6313\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8742 - accuracy: 0.5923 - val_loss: 1.3024 - val_accuracy: 0.5748\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1440 - accuracy: 0.5601 - val_loss: 1.3150 - val_accuracy: 0.5403\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9979 - accuracy: 0.5316 - val_loss: 1.2986 - val_accuracy: 0.5609\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8777 - accuracy: 0.5689 - val_loss: 1.2072 - val_accuracy: 0.5886\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8263 - accuracy: 0.5914 - val_loss: 1.1349 - val_accuracy: 0.6174\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0956 - accuracy: 0.5503 - val_loss: 1.2675 - val_accuracy: 0.5666\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1306 - accuracy: 0.5483 - val_loss: 1.2563 - val_accuracy: 0.5790\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4969 - accuracy: 0.4954 - val_loss: 1.6511 - val_accuracy: 0.4867\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9188 - accuracy: 0.4971 - val_loss: 1.2469 - val_accuracy: 0.5911\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2705 - accuracy: 0.5496 - val_loss: 1.2570 - val_accuracy: 0.5780\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0963 - accuracy: 0.5436 - val_loss: 1.2802 - val_accuracy: 0.5694\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3144 - accuracy: 0.5520 - val_loss: 1.4205 - val_accuracy: 0.5272\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1265 - accuracy: 0.5403 - val_loss: 1.2835 - val_accuracy: 0.5790\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9798 - accuracy: 0.5598 - val_loss: 1.2004 - val_accuracy: 0.5972\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8850 - accuracy: 0.5753 - val_loss: 1.1253 - val_accuracy: 0.6309\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8454 - accuracy: 0.5874 - val_loss: 1.1467 - val_accuracy: 0.6252\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8749 - accuracy: 0.5837 - val_loss: 1.1335 - val_accuracy: 0.6195\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8468 - accuracy: 0.5929 - val_loss: 1.0924 - val_accuracy: 0.6373\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9665 - accuracy: 0.5725 - val_loss: 1.3216 - val_accuracy: 0.5829\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9593 - accuracy: 0.5631 - val_loss: 1.1667 - val_accuracy: 0.6071\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8275 - accuracy: 0.5877 - val_loss: 1.1049 - val_accuracy: 0.6220\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8993 - accuracy: 0.5649 - val_loss: 1.2104 - val_accuracy: 0.5787\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8875 - accuracy: 0.5819 - val_loss: 1.2682 - val_accuracy: 0.5805\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0359 - accuracy: 0.5633 - val_loss: 1.4013 - val_accuracy: 0.5528\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8870 - accuracy: 0.5886 - val_loss: 1.2184 - val_accuracy: 0.5897\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8266 - accuracy: 0.5842 - val_loss: 1.1901 - val_accuracy: 0.5769\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8752 - accuracy: 0.5755 - val_loss: 2.1504 - val_accuracy: 0.4046\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0603 - accuracy: 0.5267 - val_loss: 1.6226 - val_accuracy: 0.4476\n",
      "Epoch 137/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7587 - accuracy: 0.5055 - val_loss: 1.5969 - val_accuracy: 0.4522\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7464 - accuracy: 0.4412 - val_loss: 1.4344 - val_accuracy: 0.5140\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9511 - accuracy: 0.4556 - val_loss: 1.4172 - val_accuracy: 0.5403\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5477 - accuracy: 0.4839 - val_loss: 1.3228 - val_accuracy: 0.5584\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3040 - accuracy: 0.5194 - val_loss: 1.2689 - val_accuracy: 0.5677\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3925 - accuracy: 0.5144 - val_loss: 1.4308 - val_accuracy: 0.5432\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0272 - accuracy: 0.5457 - val_loss: 1.3143 - val_accuracy: 0.5663\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1308 - accuracy: 0.5472 - val_loss: 1.2913 - val_accuracy: 0.5886\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9078 - accuracy: 0.5687 - val_loss: 1.2539 - val_accuracy: 0.5883\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1492 - accuracy: 0.5101 - val_loss: 1.2309 - val_accuracy: 0.5982\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9765 - accuracy: 0.5529 - val_loss: 1.2534 - val_accuracy: 0.5801\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8955 - accuracy: 0.5760 - val_loss: 1.1362 - val_accuracy: 0.6124\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0552 - accuracy: 0.5635 - val_loss: 1.2409 - val_accuracy: 0.5929\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 1.1014 - accuracy: 0.5446 - val_loss: 1.2253 - val_accuracy: 0.5801\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1131 - accuracy: 0.5693 - val_loss: 1.2919 - val_accuracy: 0.5776\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1437 - accuracy: 0.5448 - val_loss: 1.2373 - val_accuracy: 0.5869\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9582 - accuracy: 0.5602 - val_loss: 1.2569 - val_accuracy: 0.5829\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8596 - accuracy: 0.5795 - val_loss: 1.0749 - val_accuracy: 0.6398\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0643 - accuracy: 0.5510 - val_loss: 1.3802 - val_accuracy: 0.5300\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9658 - accuracy: 0.5500 - val_loss: 1.2228 - val_accuracy: 0.5964\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9843 - accuracy: 0.5652 - val_loss: 1.4422 - val_accuracy: 0.5105\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5749 - accuracy: 0.5275 - val_loss: 1.8391 - val_accuracy: 0.3524\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1060 - accuracy: 0.4988 - val_loss: 1.2506 - val_accuracy: 0.5673\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9991 - accuracy: 0.5426 - val_loss: 1.2017 - val_accuracy: 0.5847\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9236 - accuracy: 0.5661 - val_loss: 1.2789 - val_accuracy: 0.5641\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9989 - accuracy: 0.5401 - val_loss: 1.2762 - val_accuracy: 0.5655\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8432 - accuracy: 0.5836 - val_loss: 1.1716 - val_accuracy: 0.5989\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8378 - accuracy: 0.5817 - val_loss: 1.1555 - val_accuracy: 0.6096\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8340 - accuracy: 0.5906 - val_loss: 1.1455 - val_accuracy: 0.6149\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8637 - accuracy: 0.5602 - val_loss: 1.2701 - val_accuracy: 0.5755\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9059 - accuracy: 0.5711 - val_loss: 1.1373 - val_accuracy: 0.6188\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1741 - accuracy: 0.5648 - val_loss: 1.3157 - val_accuracy: 0.5780\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5936 - accuracy: 0.5147 - val_loss: 1.3757 - val_accuracy: 0.5329\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5704 - accuracy: 0.4985 - val_loss: 1.2801 - val_accuracy: 0.5787\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3393 - accuracy: 0.5043 - val_loss: 1.4796 - val_accuracy: 0.4998\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1896 - accuracy: 0.5221 - val_loss: 1.7066 - val_accuracy: 0.4547\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2038 - accuracy: 0.5140 - val_loss: 1.3930 - val_accuracy: 0.5314\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0747 - accuracy: 0.5334 - val_loss: 1.2173 - val_accuracy: 0.6018\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0969 - accuracy: 0.5233 - val_loss: 1.5188 - val_accuracy: 0.4952\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1952 - accuracy: 0.5272 - val_loss: 1.2008 - val_accuracy: 0.5972\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9122 - accuracy: 0.5688 - val_loss: 1.1562 - val_accuracy: 0.6060\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0380 - accuracy: 0.5393 - val_loss: 1.1445 - val_accuracy: 0.6163\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9189 - accuracy: 0.5590 - val_loss: 1.2291 - val_accuracy: 0.5663\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9132 - accuracy: 0.5770 - val_loss: 1.2944 - val_accuracy: 0.5659\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1444 - accuracy: 0.5233 - val_loss: 1.2858 - val_accuracy: 0.5570\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4121 - accuracy: 0.5249 - val_loss: 1.8038 - val_accuracy: 0.4540\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9023 - accuracy: 0.4946 - val_loss: 1.5111 - val_accuracy: 0.5165\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0846 - accuracy: 0.5116 - val_loss: 1.2810 - val_accuracy: 0.5716\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7869 - accuracy: 0.4919 - val_loss: 1.5194 - val_accuracy: 0.4853\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5854 - accuracy: 0.4507 - val_loss: 1.4672 - val_accuracy: 0.4959\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2133 - accuracy: 0.4962 - val_loss: 1.4755 - val_accuracy: 0.4945\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2051 - accuracy: 0.5360 - val_loss: 1.3679 - val_accuracy: 0.5517\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0929 - accuracy: 0.5366 - val_loss: 1.2087 - val_accuracy: 0.5929\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9318 - accuracy: 0.5699 - val_loss: 1.1372 - val_accuracy: 0.6128\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9391 - accuracy: 0.5610 - val_loss: 1.1468 - val_accuracy: 0.6288\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9696 - accuracy: 0.5582 - val_loss: 1.2841 - val_accuracy: 0.5826\n",
      "Epoch 193/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0258 - accuracy: 0.5433 - val_loss: 1.2586 - val_accuracy: 0.5641\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0184 - accuracy: 0.5529 - val_loss: 1.2534 - val_accuracy: 0.5691\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9382 - accuracy: 0.5656 - val_loss: 1.2663 - val_accuracy: 0.5794\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8877 - accuracy: 0.5792 - val_loss: 1.1704 - val_accuracy: 0.6082\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8194 - accuracy: 0.5977 - val_loss: 1.0763 - val_accuracy: 0.6330\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8615 - accuracy: 0.5850 - val_loss: 1.2275 - val_accuracy: 0.5904\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3425 - accuracy: 0.5216 - val_loss: 1.2228 - val_accuracy: 0.5897\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9322 - accuracy: 0.5846 - val_loss: 1.2279 - val_accuracy: 0.5954\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8493 - accuracy: 0.5798 - val_loss: 1.1600 - val_accuracy: 0.6135\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9653 - accuracy: 0.5408 - val_loss: 1.2298 - val_accuracy: 0.5762\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9046 - accuracy: 0.5612 - val_loss: 1.2355 - val_accuracy: 0.5716\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7981 - accuracy: 0.5912 - val_loss: 1.1209 - val_accuracy: 0.6213\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8354 - accuracy: 0.5855 - val_loss: 1.1083 - val_accuracy: 0.6334\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8654 - accuracy: 0.5776 - val_loss: 1.1961 - val_accuracy: 0.5897\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8764 - accuracy: 0.5758 - val_loss: 1.1515 - val_accuracy: 0.6018\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8910 - accuracy: 0.5898 - val_loss: 1.2320 - val_accuracy: 0.5872\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8512 - accuracy: 0.5831 - val_loss: 1.4348 - val_accuracy: 0.5144\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9028 - accuracy: 0.5699 - val_loss: 1.1410 - val_accuracy: 0.5989\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8762 - accuracy: 0.5782 - val_loss: 1.1444 - val_accuracy: 0.6096\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7544 - accuracy: 0.6033 - val_loss: 1.1055 - val_accuracy: 0.6195\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5259 - accuracy: 0.5075 - val_loss: 1.2485 - val_accuracy: 0.5837\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2652 - accuracy: 0.5225 - val_loss: 1.2195 - val_accuracy: 0.5883\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9784 - accuracy: 0.5663 - val_loss: 1.2933 - val_accuracy: 0.5652\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8815 - accuracy: 0.5702 - val_loss: 1.3224 - val_accuracy: 0.5623\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8433 - accuracy: 0.5894 - val_loss: 1.1157 - val_accuracy: 0.6366\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1034 - accuracy: 0.5745 - val_loss: 1.5723 - val_accuracy: 0.5236\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9174 - accuracy: 0.5691 - val_loss: 1.0919 - val_accuracy: 0.6426\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0522 - accuracy: 0.5742 - val_loss: 1.1602 - val_accuracy: 0.6242\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9167 - accuracy: 0.5709 - val_loss: 1.1315 - val_accuracy: 0.6252\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0666 - accuracy: 0.5637 - val_loss: 1.1520 - val_accuracy: 0.6231\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3618 - accuracy: 0.5207 - val_loss: 1.5102 - val_accuracy: 0.4842\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0966 - accuracy: 0.4914 - val_loss: 1.4149 - val_accuracy: 0.5542\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9060 - accuracy: 0.5192 - val_loss: 1.4348 - val_accuracy: 0.5531\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9367 - accuracy: 0.5689 - val_loss: 1.2277 - val_accuracy: 0.5886\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9461 - accuracy: 0.5527 - val_loss: 1.1478 - val_accuracy: 0.6117\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0365 - accuracy: 0.5548 - val_loss: 1.1860 - val_accuracy: 0.6071\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8582 - accuracy: 0.5787 - val_loss: 1.1030 - val_accuracy: 0.6249\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8283 - accuracy: 0.5835 - val_loss: 1.1125 - val_accuracy: 0.6334\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8809 - accuracy: 0.5742 - val_loss: 1.1972 - val_accuracy: 0.5801\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8129 - accuracy: 0.5811 - val_loss: 1.1450 - val_accuracy: 0.6096\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7605 - accuracy: 0.6053 - val_loss: 1.0783 - val_accuracy: 0.6394\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8082 - accuracy: 0.5976 - val_loss: 1.0957 - val_accuracy: 0.6252\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1860 - accuracy: 0.5385 - val_loss: 1.5335 - val_accuracy: 0.4696\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0507 - accuracy: 0.5353 - val_loss: 1.2019 - val_accuracy: 0.5865\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8790 - accuracy: 0.5510 - val_loss: 1.1355 - val_accuracy: 0.6107\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8733 - accuracy: 0.5754 - val_loss: 1.1008 - val_accuracy: 0.6110\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2595 - accuracy: 0.5468 - val_loss: 1.2889 - val_accuracy: 0.5691\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0903 - accuracy: 0.5042 - val_loss: 1.2120 - val_accuracy: 0.5918\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3063 - accuracy: 0.5357 - val_loss: 1.3618 - val_accuracy: 0.5417\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9626 - accuracy: 0.5388 - val_loss: 1.2269 - val_accuracy: 0.6000\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8921 - accuracy: 0.5685 - val_loss: 1.1710 - val_accuracy: 0.5886\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0417 - accuracy: 0.5742 - val_loss: 1.1727 - val_accuracy: 0.6007\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6839 - accuracy: 0.5071 - val_loss: 1.4999 - val_accuracy: 0.4902\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1055 - accuracy: 0.5158 - val_loss: 1.2543 - val_accuracy: 0.5812\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9073 - accuracy: 0.5616 - val_loss: 1.2843 - val_accuracy: 0.5833\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8620 - accuracy: 0.5816 - val_loss: 1.0998 - val_accuracy: 0.6270\n",
      "Epoch 249/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5318 - accuracy: 0.5417 - val_loss: 1.2676 - val_accuracy: 0.5851\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8526 - accuracy: 0.5840 - val_loss: 1.1198 - val_accuracy: 0.6259\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8837 - accuracy: 0.5700 - val_loss: 1.1345 - val_accuracy: 0.6291\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.0987 - accuracy: 0.5258 - val_loss: 1.2694 - val_accuracy: 0.5641\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8321 - accuracy: 0.5174 - val_loss: 1.2632 - val_accuracy: 0.5822\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5231 - accuracy: 0.5513 - val_loss: 1.2381 - val_accuracy: 0.5805\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0778 - accuracy: 0.5301 - val_loss: 1.5337 - val_accuracy: 0.4998\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9428 - accuracy: 0.5612 - val_loss: 1.1934 - val_accuracy: 0.6043\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8383 - accuracy: 0.5885 - val_loss: 1.1391 - val_accuracy: 0.6121\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9929 - accuracy: 0.5598 - val_loss: 1.1595 - val_accuracy: 0.6096\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9106 - accuracy: 0.5698 - val_loss: 1.1759 - val_accuracy: 0.6046\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8684 - accuracy: 0.5692 - val_loss: 1.1135 - val_accuracy: 0.6238\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8872 - accuracy: 0.5788 - val_loss: 1.4199 - val_accuracy: 0.5179\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5051 - accuracy: 0.5226 - val_loss: 1.3229 - val_accuracy: 0.5520\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8667 - accuracy: 0.5754 - val_loss: 1.1740 - val_accuracy: 0.6067\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9443 - accuracy: 0.5560 - val_loss: 1.1208 - val_accuracy: 0.6160\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5793 - accuracy: 0.5036 - val_loss: 1.2832 - val_accuracy: 0.5716\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6794 - accuracy: 0.5091 - val_loss: 2.2343 - val_accuracy: 0.3471\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6268 - accuracy: 0.4929 - val_loss: 1.3265 - val_accuracy: 0.5396\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1013 - accuracy: 0.5233 - val_loss: 1.4732 - val_accuracy: 0.5059\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1239 - accuracy: 0.5136 - val_loss: 1.3063 - val_accuracy: 0.5538\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3488 - accuracy: 0.4902 - val_loss: 1.6910 - val_accuracy: 0.4671\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9681 - accuracy: 0.4855 - val_loss: 1.3786 - val_accuracy: 0.5428\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8856 - accuracy: 0.5035 - val_loss: 1.3770 - val_accuracy: 0.5353\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0277 - accuracy: 0.5390 - val_loss: 1.1530 - val_accuracy: 0.6067\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9333 - accuracy: 0.5616 - val_loss: 1.1391 - val_accuracy: 0.6149\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8328 - accuracy: 0.5844 - val_loss: 1.1421 - val_accuracy: 0.6185\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9769 - accuracy: 0.5626 - val_loss: 1.1765 - val_accuracy: 0.6050\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8445 - accuracy: 0.5895 - val_loss: 1.1264 - val_accuracy: 0.6284\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8268 - accuracy: 0.5944 - val_loss: 1.1636 - val_accuracy: 0.5922\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8317 - accuracy: 0.5929 - val_loss: 1.2633 - val_accuracy: 0.6039\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8156 - accuracy: 0.5968 - val_loss: 1.1522 - val_accuracy: 0.6238\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1878 - accuracy: 0.5209 - val_loss: 1.9875 - val_accuracy: 0.4067\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3009 - accuracy: 0.5109 - val_loss: 1.4316 - val_accuracy: 0.5325\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2452 - accuracy: 0.5083 - val_loss: 1.3955 - val_accuracy: 0.5353\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7345 - accuracy: 0.5419 - val_loss: 1.3983 - val_accuracy: 0.5204\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9575 - accuracy: 0.5552 - val_loss: 1.4264 - val_accuracy: 0.5190\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8954 - accuracy: 0.5705 - val_loss: 1.1294 - val_accuracy: 0.6114\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8602 - accuracy: 0.5802 - val_loss: 1.1907 - val_accuracy: 0.6000\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9699 - accuracy: 0.5637 - val_loss: 1.0373 - val_accuracy: 0.6647\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8387 - accuracy: 0.5843 - val_loss: 1.1527 - val_accuracy: 0.6071\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8703 - accuracy: 0.5829 - val_loss: 1.1328 - val_accuracy: 0.6188\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7449 - accuracy: 0.5166 - val_loss: 1.8929 - val_accuracy: 0.3716\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5333 - accuracy: 0.4173 - val_loss: 1.5122 - val_accuracy: 0.4728\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2887 - accuracy: 0.4581 - val_loss: 1.4445 - val_accuracy: 0.5037\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5778 - accuracy: 0.4584 - val_loss: 1.6384 - val_accuracy: 0.4451\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1251 - accuracy: 0.4858 - val_loss: 1.3388 - val_accuracy: 0.5311\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0217 - accuracy: 0.5179 - val_loss: 1.3955 - val_accuracy: 0.5368\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9318 - accuracy: 0.5518 - val_loss: 1.1942 - val_accuracy: 0.5933\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8881 - accuracy: 0.5700 - val_loss: 1.1753 - val_accuracy: 0.5918\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.8961 - accuracy: 0.5689 - val_loss: 1.3344 - val_accuracy: 0.5400\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8375 - accuracy: 0.5801 - val_loss: 1.1944 - val_accuracy: 0.5933\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9171 - accuracy: 0.5572 - val_loss: 1.1215 - val_accuracy: 0.6181\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8961 - accuracy: 0.5951 - val_loss: 1.2019 - val_accuracy: 0.5840\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9711 - accuracy: 0.5659 - val_loss: 1.4953 - val_accuracy: 0.5119\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8535 - accuracy: 0.5892 - val_loss: 1.1805 - val_accuracy: 0.5922\n",
      "Epoch 305/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8510 - accuracy: 0.5993 - val_loss: 1.7235 - val_accuracy: 0.4522\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1603 - accuracy: 0.5245 - val_loss: 1.2804 - val_accuracy: 0.5698\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9802 - accuracy: 0.5557 - val_loss: 1.4831 - val_accuracy: 0.4842\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.8488 - accuracy: 0.5026 - val_loss: 1.8779 - val_accuracy: 0.3570\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2790 - accuracy: 0.3631 - val_loss: 1.6423 - val_accuracy: 0.4494\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5377 - accuracy: 0.4328 - val_loss: 1.4121 - val_accuracy: 0.5215\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7658 - accuracy: 0.4465 - val_loss: 1.4786 - val_accuracy: 0.5052\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5759 - accuracy: 0.4812 - val_loss: 2.1897 - val_accuracy: 0.3474\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4290 - accuracy: 0.4766 - val_loss: 1.2334 - val_accuracy: 0.5780\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9942 - accuracy: 0.5445 - val_loss: 1.1852 - val_accuracy: 0.5925\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4418 - accuracy: 0.5149 - val_loss: 1.2553 - val_accuracy: 0.5783\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0627 - accuracy: 0.5389 - val_loss: 1.3508 - val_accuracy: 0.5353\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0780 - accuracy: 0.5266 - val_loss: 1.3608 - val_accuracy: 0.5535\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9307 - accuracy: 0.5514 - val_loss: 1.2431 - val_accuracy: 0.5815\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0987 - accuracy: 0.5231 - val_loss: 1.8840 - val_accuracy: 0.4089\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6236 - accuracy: 0.4713 - val_loss: 1.4627 - val_accuracy: 0.5187\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0611 - accuracy: 0.5191 - val_loss: 1.2997 - val_accuracy: 0.5655\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9847 - accuracy: 0.5511 - val_loss: 1.2546 - val_accuracy: 0.5922\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1028 - accuracy: 0.5252 - val_loss: 1.4222 - val_accuracy: 0.5449\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6314 - accuracy: 0.4510 - val_loss: 1.4892 - val_accuracy: 0.5101\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7148 - accuracy: 0.4515 - val_loss: 1.3923 - val_accuracy: 0.5282\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5797 - accuracy: 0.4989 - val_loss: 1.4856 - val_accuracy: 0.4842\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0769 - accuracy: 0.5246 - val_loss: 1.5529 - val_accuracy: 0.4881\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4384 - accuracy: 0.5043 - val_loss: 1.3268 - val_accuracy: 0.5524\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1256 - accuracy: 0.5091 - val_loss: 1.3984 - val_accuracy: 0.5368\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2313 - accuracy: 0.5232 - val_loss: 1.2880 - val_accuracy: 0.5670\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9560 - accuracy: 0.5469 - val_loss: 1.2541 - val_accuracy: 0.5933\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0716 - accuracy: 0.5562 - val_loss: 1.3204 - val_accuracy: 0.5687\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0026 - accuracy: 0.5520 - val_loss: 1.2257 - val_accuracy: 0.5844\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8692 - accuracy: 0.5772 - val_loss: 1.1578 - val_accuracy: 0.6064\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8332 - accuracy: 0.5944 - val_loss: 1.1573 - val_accuracy: 0.6188\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8703 - accuracy: 0.5860 - val_loss: 1.7080 - val_accuracy: 0.4693\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0465 - accuracy: 0.5246 - val_loss: 1.1922 - val_accuracy: 0.5936\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1157 - accuracy: 0.5477 - val_loss: 1.3071 - val_accuracy: 0.5734\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0184 - accuracy: 0.5369 - val_loss: 1.2123 - val_accuracy: 0.5961\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 3s 8ms/step - loss: 0.9526 - accuracy: 0.5590 - val_loss: 1.2954 - val_accuracy: 0.5574\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 3s 7ms/step - loss: 1.2710 - accuracy: 0.5208 - val_loss: 1.4537 - val_accuracy: 0.5108\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 4s 10ms/step - loss: 1.2526 - accuracy: 0.4811 - val_loss: 1.4725 - val_accuracy: 0.5208\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 2s 7ms/step - loss: 1.5749 - accuracy: 0.4904 - val_loss: 1.5073 - val_accuracy: 0.4693\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2353 - accuracy: 0.5053 - val_loss: 1.8111 - val_accuracy: 0.4032\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.1826 - accuracy: 0.5097 - val_loss: 1.3466 - val_accuracy: 0.5471\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.6504 - accuracy: 0.5054 - val_loss: 1.3924 - val_accuracy: 0.5332\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0921 - accuracy: 0.5369 - val_loss: 1.2502 - val_accuracy: 0.5911\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8942 - accuracy: 0.5699 - val_loss: 1.2055 - val_accuracy: 0.5893\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2332 - accuracy: 0.5280 - val_loss: 1.5902 - val_accuracy: 0.4693\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4642 - accuracy: 0.4720 - val_loss: 1.5616 - val_accuracy: 0.5055\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2654 - accuracy: 0.5193 - val_loss: 1.3371 - val_accuracy: 0.5591\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.1102 - accuracy: 0.5459 - val_loss: 1.2563 - val_accuracy: 0.5961\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7151 - accuracy: 0.5150 - val_loss: 1.3918 - val_accuracy: 0.5460\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0439 - accuracy: 0.5491 - val_loss: 1.3188 - val_accuracy: 0.5798\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0937 - accuracy: 0.5363 - val_loss: 1.7201 - val_accuracy: 0.4828\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9190 - accuracy: 0.5559 - val_loss: 1.1461 - val_accuracy: 0.6202\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8555 - accuracy: 0.5842 - val_loss: 1.1270 - val_accuracy: 0.6238\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8446 - accuracy: 0.5967 - val_loss: 1.1408 - val_accuracy: 0.6085\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1943 - accuracy: 0.5603 - val_loss: 1.2690 - val_accuracy: 0.5869\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9998 - accuracy: 0.5501 - val_loss: 1.2821 - val_accuracy: 0.5584\n",
      "Epoch 361/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0603 - accuracy: 0.5049 - val_loss: 1.5449 - val_accuracy: 0.4977\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1625 - accuracy: 0.5016 - val_loss: 1.1341 - val_accuracy: 0.6302\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3176 - accuracy: 0.5309 - val_loss: 1.4558 - val_accuracy: 0.5211\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1555 - accuracy: 0.5278 - val_loss: 1.2998 - val_accuracy: 0.5655\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1291 - accuracy: 0.5391 - val_loss: 1.2967 - val_accuracy: 0.5691\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9996 - accuracy: 0.5424 - val_loss: 1.2714 - val_accuracy: 0.5822\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3854 - accuracy: 0.5340 - val_loss: 1.4607 - val_accuracy: 0.5314\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3387 - accuracy: 0.5030 - val_loss: 1.5218 - val_accuracy: 0.4813\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2388 - accuracy: 0.4520 - val_loss: 1.3731 - val_accuracy: 0.5446\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9737 - accuracy: 0.5445 - val_loss: 1.2228 - val_accuracy: 0.5993\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9049 - accuracy: 0.5716 - val_loss: 1.1787 - val_accuracy: 0.6039\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.1797 - accuracy: 0.5098 - val_loss: 1.5255 - val_accuracy: 0.4888\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0440 - accuracy: 0.5167 - val_loss: 1.2406 - val_accuracy: 0.5961\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0259 - accuracy: 0.5457 - val_loss: 1.2758 - val_accuracy: 0.5698\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8619 - accuracy: 0.5815 - val_loss: 1.1696 - val_accuracy: 0.6092\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8988 - accuracy: 0.5778 - val_loss: 1.1648 - val_accuracy: 0.6131\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8886 - accuracy: 0.5782 - val_loss: 1.1212 - val_accuracy: 0.6163\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7833 - accuracy: 0.5985 - val_loss: 1.1193 - val_accuracy: 0.6291\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9156 - accuracy: 0.5671 - val_loss: 1.1204 - val_accuracy: 0.6224\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8923 - accuracy: 0.5724 - val_loss: 1.1562 - val_accuracy: 0.6131\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9105 - accuracy: 0.5678 - val_loss: 1.1825 - val_accuracy: 0.5993\n",
      "Epoch 382/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8020 - accuracy: 0.5898 - val_loss: 1.3285 - val_accuracy: 0.5734\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0645 - accuracy: 0.5369 - val_loss: 1.2900 - val_accuracy: 0.5815\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.9089 - accuracy: 0.4091 - val_loss: 1.3566 - val_accuracy: 0.5581\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3646 - accuracy: 0.5105 - val_loss: 1.3521 - val_accuracy: 0.5417\n",
      "Epoch 386/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1992 - accuracy: 0.5285 - val_loss: 1.2483 - val_accuracy: 0.5794\n",
      "Epoch 387/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1731 - accuracy: 0.5228 - val_loss: 1.4333 - val_accuracy: 0.5243\n",
      "Epoch 388/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9708 - accuracy: 0.5473 - val_loss: 1.2158 - val_accuracy: 0.5954\n",
      "\n",
      "Validation 3, fold 4 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8636 - accuracy: 0.1495 - val_loss: 2.8113 - val_accuracy: 0.1080\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7247 - accuracy: 0.1361 - val_loss: 2.4138 - val_accuracy: 0.1979\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.4874 - accuracy: 0.1607 - val_loss: 2.3046 - val_accuracy: 0.2693\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3621 - accuracy: 0.1793 - val_loss: 2.2190 - val_accuracy: 0.2163\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.3848 - accuracy: 0.1970 - val_loss: 2.4469 - val_accuracy: 0.1126\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1867 - accuracy: 0.2062 - val_loss: 2.3377 - val_accuracy: 0.1996\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2671 - accuracy: 0.2250 - val_loss: 2.1614 - val_accuracy: 0.2636\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.1555 - accuracy: 0.2813 - val_loss: 2.1038 - val_accuracy: 0.2721\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9998 - accuracy: 0.2836 - val_loss: 2.1130 - val_accuracy: 0.3211\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0487 - accuracy: 0.2886 - val_loss: 1.9546 - val_accuracy: 0.3641\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9334 - accuracy: 0.3066 - val_loss: 1.9898 - val_accuracy: 0.3233\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8864 - accuracy: 0.3155 - val_loss: 1.8547 - val_accuracy: 0.3783\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7688 - accuracy: 0.3488 - val_loss: 1.7141 - val_accuracy: 0.4220\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6355 - accuracy: 0.3720 - val_loss: 1.7923 - val_accuracy: 0.3780\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7721 - accuracy: 0.3671 - val_loss: 2.0521 - val_accuracy: 0.3407\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6632 - accuracy: 0.3768 - val_loss: 1.7986 - val_accuracy: 0.4210\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5874 - accuracy: 0.4083 - val_loss: 1.6706 - val_accuracy: 0.4416\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4499 - accuracy: 0.4307 - val_loss: 1.7297 - val_accuracy: 0.4114\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4570 - accuracy: 0.4213 - val_loss: 1.8513 - val_accuracy: 0.3783\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5883 - accuracy: 0.4203 - val_loss: 1.8271 - val_accuracy: 0.4213\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5759 - accuracy: 0.4314 - val_loss: 1.8671 - val_accuracy: 0.4330\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4480 - accuracy: 0.4359 - val_loss: 1.5648 - val_accuracy: 0.4760\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4541 - accuracy: 0.4379 - val_loss: 1.6142 - val_accuracy: 0.4639\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4316 - accuracy: 0.4433 - val_loss: 1.6147 - val_accuracy: 0.4547\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3962 - accuracy: 0.4575 - val_loss: 1.5362 - val_accuracy: 0.4917\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2586 - accuracy: 0.4693 - val_loss: 1.4580 - val_accuracy: 0.5012\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3987 - accuracy: 0.4643 - val_loss: 1.4252 - val_accuracy: 0.5268\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4984 - accuracy: 0.4315 - val_loss: 1.7131 - val_accuracy: 0.4316\n",
      "Epoch 29/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7021 - accuracy: 0.4195 - val_loss: 1.6070 - val_accuracy: 0.4664\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4645 - accuracy: 0.4396 - val_loss: 1.5567 - val_accuracy: 0.4909\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2824 - accuracy: 0.4623 - val_loss: 1.4689 - val_accuracy: 0.5073\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2973 - accuracy: 0.4670 - val_loss: 1.5099 - val_accuracy: 0.5023\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3455 - accuracy: 0.4708 - val_loss: 1.4411 - val_accuracy: 0.5020\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2950 - accuracy: 0.4768 - val_loss: 1.4636 - val_accuracy: 0.4870\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2083 - accuracy: 0.4846 - val_loss: 1.3864 - val_accuracy: 0.5403\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1866 - accuracy: 0.4948 - val_loss: 1.3589 - val_accuracy: 0.5510\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1907 - accuracy: 0.4829 - val_loss: 1.3854 - val_accuracy: 0.5321\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3023 - accuracy: 0.4696 - val_loss: 1.3890 - val_accuracy: 0.5162\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6801 - accuracy: 0.4628 - val_loss: 1.4257 - val_accuracy: 0.5208\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2989 - accuracy: 0.4789 - val_loss: 1.4323 - val_accuracy: 0.5197\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2352 - accuracy: 0.4956 - val_loss: 1.3390 - val_accuracy: 0.5609\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1676 - accuracy: 0.4848 - val_loss: 1.4830 - val_accuracy: 0.4995\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0728 - accuracy: 0.4457 - val_loss: 1.3438 - val_accuracy: 0.5535\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.2209 - accuracy: 0.4918 - val_loss: 1.3322 - val_accuracy: 0.5528\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1861 - accuracy: 0.4948 - val_loss: 1.3617 - val_accuracy: 0.5403\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2020 - accuracy: 0.4943 - val_loss: 1.3426 - val_accuracy: 0.5556\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1536 - accuracy: 0.5033 - val_loss: 1.2813 - val_accuracy: 0.5773\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1243 - accuracy: 0.5186 - val_loss: 1.3586 - val_accuracy: 0.5606\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1576 - accuracy: 0.5089 - val_loss: 1.3833 - val_accuracy: 0.5435\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1793 - accuracy: 0.5070 - val_loss: 1.3499 - val_accuracy: 0.5446\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1116 - accuracy: 0.5098 - val_loss: 1.2861 - val_accuracy: 0.5712\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1968 - accuracy: 0.5137 - val_loss: 1.3549 - val_accuracy: 0.5400\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1558 - accuracy: 0.5019 - val_loss: 1.3207 - val_accuracy: 0.5496\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1740 - accuracy: 0.5123 - val_loss: 1.3150 - val_accuracy: 0.5538\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1418 - accuracy: 0.5281 - val_loss: 1.3484 - val_accuracy: 0.5456\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1804 - accuracy: 0.5096 - val_loss: 1.4585 - val_accuracy: 0.5247\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3388 - accuracy: 0.4832 - val_loss: 1.2924 - val_accuracy: 0.5698\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1371 - accuracy: 0.5205 - val_loss: 1.4831 - val_accuracy: 0.4991\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1169 - accuracy: 0.5052 - val_loss: 1.2357 - val_accuracy: 0.5854\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0937 - accuracy: 0.5155 - val_loss: 1.2302 - val_accuracy: 0.5748\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0062 - accuracy: 0.5351 - val_loss: 1.2594 - val_accuracy: 0.5712\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0146 - accuracy: 0.5401 - val_loss: 1.3555 - val_accuracy: 0.5368\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1052 - accuracy: 0.5299 - val_loss: 1.2221 - val_accuracy: 0.5815\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1480 - accuracy: 0.5027 - val_loss: 1.5071 - val_accuracy: 0.4959\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2779 - accuracy: 0.4827 - val_loss: 1.3484 - val_accuracy: 0.5407\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5447 - accuracy: 0.4655 - val_loss: 1.4811 - val_accuracy: 0.5087\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 1.4608 - accuracy: 0.4718 - val_loss: 1.3493 - val_accuracy: 0.5314\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0813 - accuracy: 0.5100 - val_loss: 1.2558 - val_accuracy: 0.5776\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1755 - accuracy: 0.5120 - val_loss: 1.3803 - val_accuracy: 0.5286\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0731 - accuracy: 0.5268 - val_loss: 1.3616 - val_accuracy: 0.5432\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0875 - accuracy: 0.5272 - val_loss: 1.3518 - val_accuracy: 0.5492\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0077 - accuracy: 0.5377 - val_loss: 1.2546 - val_accuracy: 0.5787\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0470 - accuracy: 0.5436 - val_loss: 1.2600 - val_accuracy: 0.5705\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1247 - accuracy: 0.5273 - val_loss: 1.3093 - val_accuracy: 0.5599\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0478 - accuracy: 0.5453 - val_loss: 1.2115 - val_accuracy: 0.5901\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1046 - accuracy: 0.5255 - val_loss: 1.4655 - val_accuracy: 0.5020\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1412 - accuracy: 0.5209 - val_loss: 1.2209 - val_accuracy: 0.5957\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3761 - accuracy: 0.4989 - val_loss: 1.3324 - val_accuracy: 0.5620\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1045 - accuracy: 0.5302 - val_loss: 1.2346 - val_accuracy: 0.6007\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9901 - accuracy: 0.5442 - val_loss: 1.2016 - val_accuracy: 0.5972\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2609 - accuracy: 0.5166 - val_loss: 1.3061 - val_accuracy: 0.5535\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2509 - accuracy: 0.5058 - val_loss: 1.2801 - val_accuracy: 0.5723\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0867 - accuracy: 0.5227 - val_loss: 1.2176 - val_accuracy: 0.5911\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.4389 - accuracy: 0.4402 - val_loss: 1.8037 - val_accuracy: 0.3741\n",
      "Epoch 85/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9156 - accuracy: 0.4180 - val_loss: 1.3769 - val_accuracy: 0.5314\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2464 - accuracy: 0.4897 - val_loss: 1.4020 - val_accuracy: 0.5297\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2003 - accuracy: 0.5049 - val_loss: 1.4061 - val_accuracy: 0.5222\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1682 - accuracy: 0.4965 - val_loss: 1.4374 - val_accuracy: 0.5297\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7029 - accuracy: 0.4740 - val_loss: 1.5057 - val_accuracy: 0.5155\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1332 - accuracy: 0.5086 - val_loss: 1.2126 - val_accuracy: 0.5961\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0403 - accuracy: 0.5346 - val_loss: 1.2299 - val_accuracy: 0.5758\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9975 - accuracy: 0.5448 - val_loss: 1.2606 - val_accuracy: 0.5716\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0612 - accuracy: 0.5363 - val_loss: 1.1744 - val_accuracy: 0.6121\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9683 - accuracy: 0.5594 - val_loss: 1.2243 - val_accuracy: 0.6067\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1649 - accuracy: 0.5356 - val_loss: 1.7388 - val_accuracy: 0.5176\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5157 - accuracy: 0.4913 - val_loss: 1.3936 - val_accuracy: 0.5304\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0811 - accuracy: 0.5136 - val_loss: 1.2484 - val_accuracy: 0.5730\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0008 - accuracy: 0.5439 - val_loss: 1.1949 - val_accuracy: 0.5950\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1081 - accuracy: 0.5377 - val_loss: 1.5271 - val_accuracy: 0.4970\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1924 - accuracy: 0.4989 - val_loss: 1.3292 - val_accuracy: 0.5556\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0732 - accuracy: 0.5245 - val_loss: 1.8046 - val_accuracy: 0.4398\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0998 - accuracy: 0.5198 - val_loss: 1.2091 - val_accuracy: 0.5940\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1886 - accuracy: 0.5230 - val_loss: 1.3365 - val_accuracy: 0.5645\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1334 - accuracy: 0.5210 - val_loss: 1.3118 - val_accuracy: 0.5648\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9991 - accuracy: 0.5431 - val_loss: 1.2926 - val_accuracy: 0.5734\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9432 - accuracy: 0.5552 - val_loss: 1.1948 - val_accuracy: 0.6014\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9216 - accuracy: 0.5660 - val_loss: 1.1467 - val_accuracy: 0.6249\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9304 - accuracy: 0.5740 - val_loss: 1.1243 - val_accuracy: 0.6320\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9159 - accuracy: 0.5714 - val_loss: 1.1105 - val_accuracy: 0.6348\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9635 - accuracy: 0.5665 - val_loss: 1.2855 - val_accuracy: 0.5520\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9494 - accuracy: 0.5641 - val_loss: 1.2213 - val_accuracy: 0.5886\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9297 - accuracy: 0.5704 - val_loss: 1.2337 - val_accuracy: 0.6004\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4877 - accuracy: 0.5262 - val_loss: 1.4943 - val_accuracy: 0.5151\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0952 - accuracy: 0.5237 - val_loss: 1.3415 - val_accuracy: 0.5620\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9738 - accuracy: 0.5627 - val_loss: 1.2180 - val_accuracy: 0.5922\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9394 - accuracy: 0.5596 - val_loss: 1.2964 - val_accuracy: 0.5798\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0311 - accuracy: 0.5413 - val_loss: 1.2181 - val_accuracy: 0.5922\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1305 - accuracy: 0.5272 - val_loss: 1.3738 - val_accuracy: 0.5346\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0072 - accuracy: 0.5500 - val_loss: 1.1711 - val_accuracy: 0.6185\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9388 - accuracy: 0.5643 - val_loss: 1.1685 - val_accuracy: 0.6206\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0148 - accuracy: 0.5487 - val_loss: 1.2675 - val_accuracy: 0.5854\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9570 - accuracy: 0.5383 - val_loss: 1.6448 - val_accuracy: 0.4888\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3743 - accuracy: 0.5131 - val_loss: 1.2967 - val_accuracy: 0.5691\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0963 - accuracy: 0.5404 - val_loss: 1.2666 - val_accuracy: 0.5840\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4257 - accuracy: 0.5133 - val_loss: 1.2375 - val_accuracy: 0.6007\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9960 - accuracy: 0.5509 - val_loss: 1.4465 - val_accuracy: 0.5183\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3273 - accuracy: 0.5061 - val_loss: 1.3845 - val_accuracy: 0.5290\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0186 - accuracy: 0.5343 - val_loss: 1.2036 - val_accuracy: 0.5982\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0356 - accuracy: 0.5451 - val_loss: 1.5011 - val_accuracy: 0.5041\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0271 - accuracy: 0.5298 - val_loss: 1.1202 - val_accuracy: 0.6202\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9932 - accuracy: 0.5602 - val_loss: 1.2263 - val_accuracy: 0.5901\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9316 - accuracy: 0.5758 - val_loss: 1.2639 - val_accuracy: 0.5897\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9014 - accuracy: 0.5775 - val_loss: 1.3711 - val_accuracy: 0.5403\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1572 - accuracy: 0.5115 - val_loss: 1.2321 - val_accuracy: 0.5847\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9713 - accuracy: 0.5579 - val_loss: 1.1221 - val_accuracy: 0.6409\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8943 - accuracy: 0.5745 - val_loss: 1.1261 - val_accuracy: 0.6401\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9985 - accuracy: 0.5648 - val_loss: 1.1082 - val_accuracy: 0.6359\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8603 - accuracy: 0.5823 - val_loss: 1.1962 - val_accuracy: 0.6028\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9218 - accuracy: 0.5681 - val_loss: 1.2864 - val_accuracy: 0.5687\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9786 - accuracy: 0.5705 - val_loss: 1.4699 - val_accuracy: 0.5197\n",
      "Epoch 141/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0409 - accuracy: 0.5570 - val_loss: 1.1883 - val_accuracy: 0.6107\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9601 - accuracy: 0.5802 - val_loss: 1.1125 - val_accuracy: 0.6387\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3770 - accuracy: 0.5319 - val_loss: 1.4960 - val_accuracy: 0.4739\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4452 - accuracy: 0.4976 - val_loss: 1.2058 - val_accuracy: 0.5918\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1594 - accuracy: 0.5340 - val_loss: 1.2131 - val_accuracy: 0.5996\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1169 - accuracy: 0.5445 - val_loss: 1.1689 - val_accuracy: 0.6139\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9895 - accuracy: 0.5650 - val_loss: 1.1186 - val_accuracy: 0.6437\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9322 - accuracy: 0.5679 - val_loss: 1.0845 - val_accuracy: 0.6526\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0270 - accuracy: 0.5473 - val_loss: 1.2712 - val_accuracy: 0.5915\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9870 - accuracy: 0.5571 - val_loss: 1.2120 - val_accuracy: 0.6032\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1627 - accuracy: 0.5488 - val_loss: 1.1340 - val_accuracy: 0.6281\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0267 - accuracy: 0.5735 - val_loss: 1.1467 - val_accuracy: 0.6263\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9204 - accuracy: 0.5642 - val_loss: 1.0969 - val_accuracy: 0.6487\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9111 - accuracy: 0.5806 - val_loss: 1.1362 - val_accuracy: 0.6284\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8187 - accuracy: 0.6001 - val_loss: 1.0510 - val_accuracy: 0.6522\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5055 - accuracy: 0.5355 - val_loss: 1.2225 - val_accuracy: 0.5876\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2962 - accuracy: 0.5123 - val_loss: 1.1881 - val_accuracy: 0.5957\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3810 - accuracy: 0.4986 - val_loss: 1.2824 - val_accuracy: 0.5794\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3587 - accuracy: 0.4826 - val_loss: 1.3379 - val_accuracy: 0.5535\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0294 - accuracy: 0.5385 - val_loss: 1.2412 - val_accuracy: 0.5954\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1188 - accuracy: 0.5349 - val_loss: 1.1490 - val_accuracy: 0.6004\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0157 - accuracy: 0.5500 - val_loss: 1.1253 - val_accuracy: 0.6217\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8933 - accuracy: 0.5735 - val_loss: 1.1442 - val_accuracy: 0.6032\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9171 - accuracy: 0.5732 - val_loss: 1.1451 - val_accuracy: 0.6146\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9262 - accuracy: 0.5869 - val_loss: 1.3855 - val_accuracy: 0.5236\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1788 - accuracy: 0.5377 - val_loss: 1.1974 - val_accuracy: 0.6238\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0444 - accuracy: 0.5435 - val_loss: 1.1447 - val_accuracy: 0.6291\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5660 - accuracy: 0.5013 - val_loss: 1.3783 - val_accuracy: 0.5492\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7404 - accuracy: 0.5238 - val_loss: 1.2896 - val_accuracy: 0.5570\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2533 - accuracy: 0.5361 - val_loss: 1.4111 - val_accuracy: 0.5332\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3315 - accuracy: 0.5374 - val_loss: 1.5731 - val_accuracy: 0.4853\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1101 - accuracy: 0.5372 - val_loss: 1.2371 - val_accuracy: 0.5773\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0133 - accuracy: 0.5456 - val_loss: 1.3441 - val_accuracy: 0.5652\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 0.9042 - accuracy: 0.5569 - val_loss: 1.1323 - val_accuracy: 0.6291\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9370 - accuracy: 0.5765 - val_loss: 1.1181 - val_accuracy: 0.6281\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0755 - accuracy: 0.5409 - val_loss: 1.1424 - val_accuracy: 0.6259\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9986 - accuracy: 0.5743 - val_loss: 1.7775 - val_accuracy: 0.4085\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6597 - accuracy: 0.4400 - val_loss: 1.3058 - val_accuracy: 0.5517\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2903 - accuracy: 0.4930 - val_loss: 1.3074 - val_accuracy: 0.5726\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0783 - accuracy: 0.5238 - val_loss: 1.2030 - val_accuracy: 0.5876\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0174 - accuracy: 0.5445 - val_loss: 1.2163 - val_accuracy: 0.5808\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8797 - accuracy: 0.5703 - val_loss: 1.1235 - val_accuracy: 0.6256\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8538 - accuracy: 0.5921 - val_loss: 1.0857 - val_accuracy: 0.6316\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0418 - accuracy: 0.5412 - val_loss: 1.1743 - val_accuracy: 0.6142\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0514 - accuracy: 0.5570 - val_loss: 1.1318 - val_accuracy: 0.6227\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1141 - accuracy: 0.5483 - val_loss: 1.2046 - val_accuracy: 0.6039\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1846 - accuracy: 0.5319 - val_loss: 1.2405 - val_accuracy: 0.5982\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2288 - accuracy: 0.5300 - val_loss: 1.1840 - val_accuracy: 0.6018\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3688 - accuracy: 0.5280 - val_loss: 1.2910 - val_accuracy: 0.5812\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9762 - accuracy: 0.5707 - val_loss: 1.2217 - val_accuracy: 0.5940\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1148 - accuracy: 0.5469 - val_loss: 1.2179 - val_accuracy: 0.6050\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9055 - accuracy: 0.5724 - val_loss: 1.2273 - val_accuracy: 0.6007\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2209 - accuracy: 0.5128 - val_loss: 1.2904 - val_accuracy: 0.5705\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2699 - accuracy: 0.5315 - val_loss: 1.1650 - val_accuracy: 0.6153\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1168 - accuracy: 0.5578 - val_loss: 1.1688 - val_accuracy: 0.6110\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0475 - accuracy: 0.5523 - val_loss: 1.3400 - val_accuracy: 0.5556\n",
      "Epoch 197/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0550 - accuracy: 0.5475 - val_loss: 1.2543 - val_accuracy: 0.6067\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0366 - accuracy: 0.5290 - val_loss: 1.2565 - val_accuracy: 0.5826\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8932 - accuracy: 0.5653 - val_loss: 1.1221 - val_accuracy: 0.6274\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9092 - accuracy: 0.5714 - val_loss: 1.2362 - val_accuracy: 0.5829\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7993 - accuracy: 0.5998 - val_loss: 1.0248 - val_accuracy: 0.6561\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1066 - accuracy: 0.5339 - val_loss: 1.3424 - val_accuracy: 0.5428\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0469 - accuracy: 0.5357 - val_loss: 1.2101 - val_accuracy: 0.6071\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9594 - accuracy: 0.5602 - val_loss: 1.1415 - val_accuracy: 0.6234\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8416 - accuracy: 0.5830 - val_loss: 1.1083 - val_accuracy: 0.6224\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1530 - accuracy: 0.5464 - val_loss: 1.1774 - val_accuracy: 0.6078\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1701 - accuracy: 0.5554 - val_loss: 1.3042 - val_accuracy: 0.5737\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5662 - accuracy: 0.4763 - val_loss: 1.2459 - val_accuracy: 0.5819\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5468 - accuracy: 0.5166 - val_loss: 1.4098 - val_accuracy: 0.5222\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9994 - accuracy: 0.5486 - val_loss: 1.2123 - val_accuracy: 0.5933\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9173 - accuracy: 0.5698 - val_loss: 1.1736 - val_accuracy: 0.6142\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9427 - accuracy: 0.5821 - val_loss: 1.1224 - val_accuracy: 0.6210\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9834 - accuracy: 0.5687 - val_loss: 1.1579 - val_accuracy: 0.6192\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8918 - accuracy: 0.5854 - val_loss: 1.1546 - val_accuracy: 0.6217\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9920 - accuracy: 0.5797 - val_loss: 1.1569 - val_accuracy: 0.6053\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0499 - accuracy: 0.5653 - val_loss: 1.1919 - val_accuracy: 0.6007\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9716 - accuracy: 0.5884 - val_loss: 1.3016 - val_accuracy: 0.5641\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0822 - accuracy: 0.5395 - val_loss: 1.3421 - val_accuracy: 0.5620\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9327 - accuracy: 0.5542 - val_loss: 1.1195 - val_accuracy: 0.6174\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8596 - accuracy: 0.5890 - val_loss: 1.2033 - val_accuracy: 0.6064\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8395 - accuracy: 0.5822 - val_loss: 1.1777 - val_accuracy: 0.6046\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9339 - accuracy: 0.5829 - val_loss: 1.3221 - val_accuracy: 0.5709\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9997 - accuracy: 0.5610 - val_loss: 1.2210 - val_accuracy: 0.5893\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9099 - accuracy: 0.5758 - val_loss: 1.0919 - val_accuracy: 0.6306\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0326 - accuracy: 0.5363 - val_loss: 1.1632 - val_accuracy: 0.6124\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9252 - accuracy: 0.5593 - val_loss: 1.1299 - val_accuracy: 0.6131\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8948 - accuracy: 0.5880 - val_loss: 1.0318 - val_accuracy: 0.6554\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9438 - accuracy: 0.5919 - val_loss: 1.1576 - val_accuracy: 0.6057\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8121 - accuracy: 0.5948 - val_loss: 1.0342 - val_accuracy: 0.6480\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7903 - accuracy: 0.6091 - val_loss: 1.0599 - val_accuracy: 0.6458\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9627 - accuracy: 0.5583 - val_loss: 1.1947 - val_accuracy: 0.5936\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0045 - accuracy: 0.5691 - val_loss: 1.1031 - val_accuracy: 0.6366\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5172 - accuracy: 0.5156 - val_loss: 1.2710 - val_accuracy: 0.5709\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0359 - accuracy: 0.5465 - val_loss: 1.0949 - val_accuracy: 0.6252\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9674 - accuracy: 0.5708 - val_loss: 1.1699 - val_accuracy: 0.6139\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8813 - accuracy: 0.5933 - val_loss: 1.1028 - val_accuracy: 0.6302\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8501 - accuracy: 0.5980 - val_loss: 1.0882 - val_accuracy: 0.6327\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9260 - accuracy: 0.5780 - val_loss: 1.1853 - val_accuracy: 0.6156\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8900 - accuracy: 0.5889 - val_loss: 1.0767 - val_accuracy: 0.6327\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7821 - accuracy: 0.6027 - val_loss: 1.1861 - val_accuracy: 0.6139\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7959 - accuracy: 0.6077 - val_loss: 1.5890 - val_accuracy: 0.4838\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0350 - accuracy: 0.5423 - val_loss: 1.1896 - val_accuracy: 0.6014\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1009 - accuracy: 0.5457 - val_loss: 1.4076 - val_accuracy: 0.5044\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4024 - accuracy: 0.5295 - val_loss: 1.3258 - val_accuracy: 0.5705\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2585 - accuracy: 0.5352 - val_loss: 1.2327 - val_accuracy: 0.5872\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0220 - accuracy: 0.5448 - val_loss: 1.1830 - val_accuracy: 0.6103\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9710 - accuracy: 0.5615 - val_loss: 1.1081 - val_accuracy: 0.6224\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9942 - accuracy: 0.5518 - val_loss: 1.4432 - val_accuracy: 0.5119\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0476 - accuracy: 0.5615 - val_loss: 1.2117 - val_accuracy: 0.6071\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0697 - accuracy: 0.5559 - val_loss: 1.1518 - val_accuracy: 0.6288\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9234 - accuracy: 0.5725 - val_loss: 1.2646 - val_accuracy: 0.5865\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2831 - accuracy: 0.5006 - val_loss: 1.4285 - val_accuracy: 0.5005\n",
      "Epoch 253/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0934 - accuracy: 0.5028 - val_loss: 1.3100 - val_accuracy: 0.5620\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1185 - accuracy: 0.5228 - val_loss: 1.3117 - val_accuracy: 0.5499\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3739 - accuracy: 0.4706 - val_loss: 1.3528 - val_accuracy: 0.5400\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9089 - accuracy: 0.5597 - val_loss: 1.1543 - val_accuracy: 0.6199\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8720 - accuracy: 0.5867 - val_loss: 1.0564 - val_accuracy: 0.6451\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8880 - accuracy: 0.5848 - val_loss: 1.0311 - val_accuracy: 0.6579\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8204 - accuracy: 0.5921 - val_loss: 1.0785 - val_accuracy: 0.6558\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8013 - accuracy: 0.6077 - val_loss: 1.1000 - val_accuracy: 0.6316\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9906 - accuracy: 0.5666 - val_loss: 1.1099 - val_accuracy: 0.6387\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8998 - accuracy: 0.5873 - val_loss: 1.0596 - val_accuracy: 0.6536\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0631 - accuracy: 0.5622 - val_loss: 1.2123 - val_accuracy: 0.5947\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0705 - accuracy: 0.5562 - val_loss: 1.1239 - val_accuracy: 0.6210\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8643 - accuracy: 0.5894 - val_loss: 1.0456 - val_accuracy: 0.6462\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9967 - accuracy: 0.5852 - val_loss: 1.7215 - val_accuracy: 0.4728\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9947 - accuracy: 0.5593 - val_loss: 1.1038 - val_accuracy: 0.6359\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0568 - accuracy: 0.5579 - val_loss: 1.3479 - val_accuracy: 0.5595\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1125 - accuracy: 0.5644 - val_loss: 1.1551 - val_accuracy: 0.6099\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8783 - accuracy: 0.5798 - val_loss: 1.1202 - val_accuracy: 0.6185\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8092 - accuracy: 0.6036 - val_loss: 1.0979 - val_accuracy: 0.6352\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5949 - accuracy: 0.4750 - val_loss: 1.4494 - val_accuracy: 0.4831\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2110 - accuracy: 0.5118 - val_loss: 1.2604 - val_accuracy: 0.5844\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8905 - accuracy: 0.5796 - val_loss: 1.1475 - val_accuracy: 0.6366\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1406 - accuracy: 0.5626 - val_loss: 1.5975 - val_accuracy: 0.5240\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9529 - accuracy: 0.5680 - val_loss: 1.0749 - val_accuracy: 0.6409\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9048 - accuracy: 0.5907 - val_loss: 1.0640 - val_accuracy: 0.6409\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9539 - accuracy: 0.5649 - val_loss: 1.0762 - val_accuracy: 0.6373\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8740 - accuracy: 0.5843 - val_loss: 1.0221 - val_accuracy: 0.6604\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7778 - accuracy: 0.6214 - val_loss: 1.0645 - val_accuracy: 0.6508\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7643 - accuracy: 0.6241 - val_loss: 1.2069 - val_accuracy: 0.6004\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8041 - accuracy: 0.6198 - val_loss: 1.0754 - val_accuracy: 0.6465\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8688 - accuracy: 0.5988 - val_loss: 1.2301 - val_accuracy: 0.5950\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4653 - accuracy: 0.5462 - val_loss: 1.1849 - val_accuracy: 0.6011\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9717 - accuracy: 0.5905 - val_loss: 1.1575 - val_accuracy: 0.6160\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7956 - accuracy: 0.6145 - val_loss: 0.9947 - val_accuracy: 0.6750\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7987 - accuracy: 0.6163 - val_loss: 1.0455 - val_accuracy: 0.6412\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0056 - accuracy: 0.5716 - val_loss: 1.0653 - val_accuracy: 0.6433\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.5692 - val_loss: 1.3158 - val_accuracy: 0.5709\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1511 - accuracy: 0.5365 - val_loss: 1.2974 - val_accuracy: 0.5801\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0639 - accuracy: 0.5579 - val_loss: 1.2484 - val_accuracy: 0.5741\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9241 - accuracy: 0.5818 - val_loss: 1.2512 - val_accuracy: 0.5890\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8733 - accuracy: 0.5806 - val_loss: 1.1086 - val_accuracy: 0.6366\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1714 - accuracy: 0.5583 - val_loss: 1.0724 - val_accuracy: 0.6469\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4611 - accuracy: 0.5456 - val_loss: 1.2374 - val_accuracy: 0.5801\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9033 - accuracy: 0.5830 - val_loss: 1.1362 - val_accuracy: 0.6245\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9385 - accuracy: 0.5832 - val_loss: 1.1673 - val_accuracy: 0.6064\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8260 - accuracy: 0.5909 - val_loss: 1.0625 - val_accuracy: 0.6654\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9385 - accuracy: 0.5890 - val_loss: 1.2785 - val_accuracy: 0.5808\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8326 - accuracy: 0.5957 - val_loss: 1.0919 - val_accuracy: 0.6348\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9290 - accuracy: 0.5912 - val_loss: 1.5619 - val_accuracy: 0.4924\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1766 - accuracy: 0.5661 - val_loss: 1.3591 - val_accuracy: 0.5520\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1725 - accuracy: 0.5368 - val_loss: 1.0739 - val_accuracy: 0.6469\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9323 - accuracy: 0.5784 - val_loss: 1.4039 - val_accuracy: 0.5471\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8700 - accuracy: 0.5845 - val_loss: 1.2854 - val_accuracy: 0.5599\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9400 - accuracy: 0.5649 - val_loss: 1.2345 - val_accuracy: 0.5968\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8354 - accuracy: 0.5912 - val_loss: 1.1053 - val_accuracy: 0.6284\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0749 - accuracy: 0.5396 - val_loss: 1.2721 - val_accuracy: 0.5670\n",
      "Epoch 309/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9959 - accuracy: 0.5572 - val_loss: 1.1683 - val_accuracy: 0.6114\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7883 - accuracy: 0.6122 - val_loss: 1.0314 - val_accuracy: 0.6583\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7913 - accuracy: 0.6087 - val_loss: 1.0024 - val_accuracy: 0.6700\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7334 - accuracy: 0.6321 - val_loss: 1.0144 - val_accuracy: 0.6483\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8319 - accuracy: 0.6020 - val_loss: 1.0693 - val_accuracy: 0.6330\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0706 - accuracy: 0.5598 - val_loss: 1.1874 - val_accuracy: 0.5964\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 0.9545 - accuracy: 0.5608 - val_loss: 1.2474 - val_accuracy: 0.5744\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1304 - accuracy: 0.5853 - val_loss: 1.1763 - val_accuracy: 0.6078\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4665 - accuracy: 0.5266 - val_loss: 1.4029 - val_accuracy: 0.5503\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0628 - accuracy: 0.5518 - val_loss: 1.2116 - val_accuracy: 0.5979\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9402 - accuracy: 0.5879 - val_loss: 1.0323 - val_accuracy: 0.6604\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8776 - accuracy: 0.5959 - val_loss: 1.0356 - val_accuracy: 0.6412\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1119 - accuracy: 0.5576 - val_loss: 1.0487 - val_accuracy: 0.6469\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9129 - accuracy: 0.5998 - val_loss: 1.0875 - val_accuracy: 0.6199\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7732 - accuracy: 0.6099 - val_loss: 1.0431 - val_accuracy: 0.6611\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7793 - accuracy: 0.6172 - val_loss: 0.9931 - val_accuracy: 0.6597\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1364 - accuracy: 0.5375 - val_loss: 1.3444 - val_accuracy: 0.5677\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0609 - accuracy: 0.5395 - val_loss: 1.5401 - val_accuracy: 0.5126\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4059 - accuracy: 0.5438 - val_loss: 1.5728 - val_accuracy: 0.4966\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3572 - accuracy: 0.5045 - val_loss: 1.2866 - val_accuracy: 0.5780\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5016 - accuracy: 0.5084 - val_loss: 1.6277 - val_accuracy: 0.4732\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7018 - accuracy: 0.5166 - val_loss: 1.3853 - val_accuracy: 0.5414\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9950 - accuracy: 0.5343 - val_loss: 1.1552 - val_accuracy: 0.6146\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9329 - accuracy: 0.5836 - val_loss: 1.1579 - val_accuracy: 0.6135\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8403 - accuracy: 0.5959 - val_loss: 1.2210 - val_accuracy: 0.5957\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0178 - accuracy: 0.5343 - val_loss: 1.1399 - val_accuracy: 0.6220\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8324 - accuracy: 0.5950 - val_loss: 1.0629 - val_accuracy: 0.6494\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0083 - accuracy: 0.5846 - val_loss: 1.2015 - val_accuracy: 0.6121\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9968 - accuracy: 0.5678 - val_loss: 1.1515 - val_accuracy: 0.6330\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8243 - accuracy: 0.6105 - val_loss: 1.0481 - val_accuracy: 0.6579\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8906 - accuracy: 0.5870 - val_loss: 1.1152 - val_accuracy: 0.6266\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9696 - accuracy: 0.5796 - val_loss: 1.2783 - val_accuracy: 0.5851\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9107 - accuracy: 0.5968 - val_loss: 1.1820 - val_accuracy: 0.6046\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1218 - accuracy: 0.5559 - val_loss: 1.0837 - val_accuracy: 0.6515\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8823 - accuracy: 0.5918 - val_loss: 1.3229 - val_accuracy: 0.5737\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8565 - accuracy: 0.5929 - val_loss: 1.1192 - val_accuracy: 0.6256\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7734 - accuracy: 0.6140 - val_loss: 1.1093 - val_accuracy: 0.6355\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0677 - accuracy: 0.5494 - val_loss: 1.1696 - val_accuracy: 0.6213\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9431 - accuracy: 0.5821 - val_loss: 1.0835 - val_accuracy: 0.6526\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8692 - accuracy: 0.6049 - val_loss: 1.1256 - val_accuracy: 0.6181\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9522 - accuracy: 0.5885 - val_loss: 1.1308 - val_accuracy: 0.6387\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8827 - accuracy: 0.5897 - val_loss: 1.1956 - val_accuracy: 0.6025\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9532 - accuracy: 0.5812 - val_loss: 1.1880 - val_accuracy: 0.5943\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9815 - accuracy: 0.5821 - val_loss: 1.4763 - val_accuracy: 0.5570\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1399 - accuracy: 0.5277 - val_loss: 1.1600 - val_accuracy: 0.6131\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9544 - accuracy: 0.5878 - val_loss: 1.3475 - val_accuracy: 0.5609\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4427 - accuracy: 0.5115 - val_loss: 1.3972 - val_accuracy: 0.5218\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5318 - accuracy: 0.5284 - val_loss: 1.1750 - val_accuracy: 0.6181\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8781 - accuracy: 0.5899 - val_loss: 1.0962 - val_accuracy: 0.6341\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9623 - accuracy: 0.5961 - val_loss: 1.0563 - val_accuracy: 0.6465\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8423 - accuracy: 0.6141 - val_loss: 1.0559 - val_accuracy: 0.6544\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8687 - accuracy: 0.6131 - val_loss: 1.0884 - val_accuracy: 0.6440\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9980 - accuracy: 0.5718 - val_loss: 1.1793 - val_accuracy: 0.6092\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7990 - accuracy: 0.6033 - val_loss: 1.0323 - val_accuracy: 0.6565\n",
      "\n",
      "Validation 3, fold 5 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8630 - accuracy: 0.0667 - val_loss: 2.8176 - val_accuracy: 0.1187\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7855 - accuracy: 0.1420 - val_loss: 2.5744 - val_accuracy: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5692 - accuracy: 0.1751 - val_loss: 2.4097 - val_accuracy: 0.2302\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3695 - accuracy: 0.1939 - val_loss: 2.2853 - val_accuracy: 0.2153\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3008 - accuracy: 0.2214 - val_loss: 2.3439 - val_accuracy: 0.2039\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.2334 - accuracy: 0.2382 - val_loss: 2.1183 - val_accuracy: 0.2671\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1795 - accuracy: 0.2355 - val_loss: 2.0904 - val_accuracy: 0.2579\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1252 - accuracy: 0.2925 - val_loss: 1.9853 - val_accuracy: 0.3620\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0319 - accuracy: 0.2962 - val_loss: 1.9972 - val_accuracy: 0.3034\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9771 - accuracy: 0.3030 - val_loss: 1.9283 - val_accuracy: 0.3684\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1232 - accuracy: 0.2928 - val_loss: 2.0302 - val_accuracy: 0.3542\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9612 - accuracy: 0.3273 - val_loss: 1.9344 - val_accuracy: 0.3456\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8708 - accuracy: 0.3239 - val_loss: 1.8745 - val_accuracy: 0.3865\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7714 - accuracy: 0.3472 - val_loss: 1.6843 - val_accuracy: 0.4412\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6756 - accuracy: 0.3588 - val_loss: 1.6635 - val_accuracy: 0.4156\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6206 - accuracy: 0.3762 - val_loss: 1.8255 - val_accuracy: 0.3901\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5644 - accuracy: 0.3841 - val_loss: 1.5934 - val_accuracy: 0.4497\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6011 - accuracy: 0.3919 - val_loss: 1.6795 - val_accuracy: 0.4448\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6896 - accuracy: 0.3763 - val_loss: 1.9225 - val_accuracy: 0.3787\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5343 - accuracy: 0.3925 - val_loss: 1.5861 - val_accuracy: 0.4419\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4977 - accuracy: 0.3977 - val_loss: 1.5996 - val_accuracy: 0.4302\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4438 - accuracy: 0.4116 - val_loss: 1.5600 - val_accuracy: 0.4813\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5365 - accuracy: 0.4069 - val_loss: 1.5984 - val_accuracy: 0.4494\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5411 - accuracy: 0.3968 - val_loss: 1.7764 - val_accuracy: 0.3805\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5040 - accuracy: 0.4063 - val_loss: 1.7458 - val_accuracy: 0.4167\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4993 - accuracy: 0.4234 - val_loss: 1.5414 - val_accuracy: 0.4831\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3330 - accuracy: 0.4435 - val_loss: 1.4783 - val_accuracy: 0.4892\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3391 - accuracy: 0.4484 - val_loss: 1.5579 - val_accuracy: 0.4686\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3440 - accuracy: 0.4532 - val_loss: 1.8992 - val_accuracy: 0.3645\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4264 - accuracy: 0.4242 - val_loss: 1.5172 - val_accuracy: 0.4895\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3502 - accuracy: 0.4464 - val_loss: 1.4644 - val_accuracy: 0.4849\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2122 - accuracy: 0.4592 - val_loss: 1.4737 - val_accuracy: 0.4881\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2569 - accuracy: 0.4609 - val_loss: 1.5008 - val_accuracy: 0.4885\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2413 - accuracy: 0.4829 - val_loss: 1.5427 - val_accuracy: 0.4888\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3187 - accuracy: 0.4553 - val_loss: 1.4961 - val_accuracy: 0.4888\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4091 - accuracy: 0.4530 - val_loss: 1.4897 - val_accuracy: 0.4938\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2783 - accuracy: 0.4629 - val_loss: 1.4450 - val_accuracy: 0.4970\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2309 - accuracy: 0.4618 - val_loss: 1.4180 - val_accuracy: 0.5059\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3888 - accuracy: 0.4455 - val_loss: 1.6156 - val_accuracy: 0.4423\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3239 - accuracy: 0.4544 - val_loss: 1.5324 - val_accuracy: 0.4938\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2718 - accuracy: 0.4657 - val_loss: 1.8946 - val_accuracy: 0.3723\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4055 - accuracy: 0.4589 - val_loss: 1.6235 - val_accuracy: 0.4636\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2326 - accuracy: 0.4707 - val_loss: 1.3801 - val_accuracy: 0.5286\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1270 - accuracy: 0.4980 - val_loss: 2.6448 - val_accuracy: 0.4096\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3689 - accuracy: 0.4772 - val_loss: 1.3026 - val_accuracy: 0.5488\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1856 - accuracy: 0.4898 - val_loss: 1.3303 - val_accuracy: 0.5506\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1155 - accuracy: 0.5023 - val_loss: 1.3682 - val_accuracy: 0.5403\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1474 - accuracy: 0.4976 - val_loss: 1.3806 - val_accuracy: 0.5325\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3270 - accuracy: 0.4861 - val_loss: 1.4369 - val_accuracy: 0.5101\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2445 - accuracy: 0.4791 - val_loss: 1.4093 - val_accuracy: 0.5112\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1475 - accuracy: 0.5054 - val_loss: 1.3230 - val_accuracy: 0.5538\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2465 - accuracy: 0.5014 - val_loss: 1.2897 - val_accuracy: 0.5581\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3252 - accuracy: 0.4820 - val_loss: 1.6325 - val_accuracy: 0.4405\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3087 - accuracy: 0.4766 - val_loss: 1.3596 - val_accuracy: 0.5350\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1698 - accuracy: 0.4980 - val_loss: 1.3014 - val_accuracy: 0.5577\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0652 - accuracy: 0.5126 - val_loss: 1.3296 - val_accuracy: 0.5503\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0241 - accuracy: 0.5180 - val_loss: 1.2792 - val_accuracy: 0.5492\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0467 - accuracy: 0.5333 - val_loss: 1.8752 - val_accuracy: 0.4153\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4996 - accuracy: 0.4465 - val_loss: 1.5885 - val_accuracy: 0.4508\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2333 - accuracy: 0.4845 - val_loss: 1.3491 - val_accuracy: 0.5442\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1807 - accuracy: 0.4991 - val_loss: 1.3490 - val_accuracy: 0.5478\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0494 - accuracy: 0.5239 - val_loss: 1.2904 - val_accuracy: 0.5538\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2864 - accuracy: 0.4966 - val_loss: 1.3105 - val_accuracy: 0.5474\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2109 - accuracy: 0.4984 - val_loss: 1.3580 - val_accuracy: 0.5243\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5166 - accuracy: 0.4722 - val_loss: 1.3298 - val_accuracy: 0.5520\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1883 - accuracy: 0.5077 - val_loss: 1.3738 - val_accuracy: 0.5282\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0518 - accuracy: 0.5194 - val_loss: 1.2447 - val_accuracy: 0.5737\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0797 - accuracy: 0.5349 - val_loss: 1.3445 - val_accuracy: 0.5385\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0529 - accuracy: 0.5266 - val_loss: 1.2907 - val_accuracy: 0.5499\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1026 - accuracy: 0.5182 - val_loss: 1.3147 - val_accuracy: 0.5432\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1059 - accuracy: 0.5236 - val_loss: 1.3905 - val_accuracy: 0.5211\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0390 - accuracy: 0.5218 - val_loss: 1.2087 - val_accuracy: 0.5798\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0051 - accuracy: 0.5401 - val_loss: 1.2384 - val_accuracy: 0.5730\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9430 - accuracy: 0.5472 - val_loss: 1.2661 - val_accuracy: 0.5567\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9782 - accuracy: 0.5393 - val_loss: 1.2644 - val_accuracy: 0.5456\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3519 - accuracy: 0.5053 - val_loss: 1.2184 - val_accuracy: 0.5726\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1297 - accuracy: 0.5182 - val_loss: 1.7596 - val_accuracy: 0.4231\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1446 - accuracy: 0.5024 - val_loss: 1.4184 - val_accuracy: 0.5052\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0496 - accuracy: 0.5361 - val_loss: 1.8569 - val_accuracy: 0.4192\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4985 - accuracy: 0.4658 - val_loss: 1.4221 - val_accuracy: 0.5165\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2743 - accuracy: 0.4821 - val_loss: 1.5480 - val_accuracy: 0.4941\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3886 - accuracy: 0.4760 - val_loss: 1.3294 - val_accuracy: 0.5524\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1654 - accuracy: 0.4934 - val_loss: 1.2949 - val_accuracy: 0.5460\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6196 - accuracy: 0.4876 - val_loss: 1.4615 - val_accuracy: 0.5183\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1412 - accuracy: 0.5146 - val_loss: 1.2166 - val_accuracy: 0.5837\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0712 - accuracy: 0.5169 - val_loss: 1.4414 - val_accuracy: 0.5062\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1384 - accuracy: 0.5223 - val_loss: 1.2385 - val_accuracy: 0.5773\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0492 - accuracy: 0.5210 - val_loss: 1.3259 - val_accuracy: 0.5279\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2376 - accuracy: 0.5050 - val_loss: 2.0040 - val_accuracy: 0.3883\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3058 - accuracy: 0.4781 - val_loss: 1.4483 - val_accuracy: 0.5044\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0374 - accuracy: 0.5252 - val_loss: 1.2595 - val_accuracy: 0.5552\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0870 - accuracy: 0.5263 - val_loss: 1.2054 - val_accuracy: 0.5762\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9996 - accuracy: 0.5480 - val_loss: 1.1713 - val_accuracy: 0.6028\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9889 - accuracy: 0.5375 - val_loss: 1.2191 - val_accuracy: 0.5723\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9890 - accuracy: 0.5457 - val_loss: 1.1864 - val_accuracy: 0.5812\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0422 - accuracy: 0.5239 - val_loss: 1.2861 - val_accuracy: 0.5659\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0037 - accuracy: 0.5316 - val_loss: 1.2170 - val_accuracy: 0.5670\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3544 - accuracy: 0.4881 - val_loss: 1.4239 - val_accuracy: 0.5105\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.7243 - accuracy: 0.4290 - val_loss: 1.7169 - val_accuracy: 0.4409\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3342 - accuracy: 0.4852 - val_loss: 1.3117 - val_accuracy: 0.5460\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2206 - accuracy: 0.5101 - val_loss: 1.2280 - val_accuracy: 0.5684\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1753 - accuracy: 0.5190 - val_loss: 1.3394 - val_accuracy: 0.5410\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9764 - accuracy: 0.5400 - val_loss: 1.1914 - val_accuracy: 0.5865\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9564 - accuracy: 0.5563 - val_loss: 1.1986 - val_accuracy: 0.5758\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1097 - accuracy: 0.5405 - val_loss: 1.2168 - val_accuracy: 0.5819\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0559 - accuracy: 0.5285 - val_loss: 1.3409 - val_accuracy: 0.5421\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3821 - accuracy: 0.4978 - val_loss: 1.3893 - val_accuracy: 0.5226\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6095 - accuracy: 0.4836 - val_loss: 1.3569 - val_accuracy: 0.5371\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2398 - accuracy: 0.5107 - val_loss: 1.3087 - val_accuracy: 0.5421\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5645 - accuracy: 0.4745 - val_loss: 1.3015 - val_accuracy: 0.5496\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2674 - accuracy: 0.5043 - val_loss: 1.6518 - val_accuracy: 0.4753\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3857 - accuracy: 0.4829 - val_loss: 1.3350 - val_accuracy: 0.5552\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2151 - accuracy: 0.4936 - val_loss: 1.2443 - val_accuracy: 0.5652\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1284 - accuracy: 0.5189 - val_loss: 1.4012 - val_accuracy: 0.5158\n",
      "Epoch 115/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0446 - accuracy: 0.5320 - val_loss: 1.1966 - val_accuracy: 0.5829\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2390 - accuracy: 0.5143 - val_loss: 1.4065 - val_accuracy: 0.5492\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2329 - accuracy: 0.5022 - val_loss: 1.2878 - val_accuracy: 0.5467\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0037 - accuracy: 0.5363 - val_loss: 1.1862 - val_accuracy: 0.5908\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0510 - accuracy: 0.5393 - val_loss: 1.1778 - val_accuracy: 0.5989\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2530 - accuracy: 0.4883 - val_loss: 1.3653 - val_accuracy: 0.5346\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0532 - accuracy: 0.5206 - val_loss: 1.2103 - val_accuracy: 0.5812\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1594 - accuracy: 0.5282 - val_loss: 1.4148 - val_accuracy: 0.5112\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3563 - accuracy: 0.4748 - val_loss: 1.2422 - val_accuracy: 0.5719\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1891 - accuracy: 0.5103 - val_loss: 1.5279 - val_accuracy: 0.4906\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1204 - accuracy: 0.5237 - val_loss: 1.2507 - val_accuracy: 0.5631\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9971 - accuracy: 0.5356 - val_loss: 1.1602 - val_accuracy: 0.5933\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0651 - accuracy: 0.5349 - val_loss: 1.2729 - val_accuracy: 0.5421\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1696 - accuracy: 0.4858 - val_loss: 1.3885 - val_accuracy: 0.5023\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0168 - accuracy: 0.5389 - val_loss: 1.2124 - val_accuracy: 0.5872\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9251 - accuracy: 0.5516 - val_loss: 1.1915 - val_accuracy: 0.5766\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0810 - accuracy: 0.5373 - val_loss: 1.2219 - val_accuracy: 0.5769\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9391 - accuracy: 0.5503 - val_loss: 1.1420 - val_accuracy: 0.6114\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0555 - accuracy: 0.5437 - val_loss: 1.2765 - val_accuracy: 0.5496\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1938 - accuracy: 0.5206 - val_loss: 1.3549 - val_accuracy: 0.5410\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0238 - accuracy: 0.5377 - val_loss: 1.2725 - val_accuracy: 0.5641\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9298 - accuracy: 0.5669 - val_loss: 1.1427 - val_accuracy: 0.5986\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0397 - accuracy: 0.5533 - val_loss: 1.1700 - val_accuracy: 0.5865\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9617 - accuracy: 0.5510 - val_loss: 1.2074 - val_accuracy: 0.5829\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9278 - accuracy: 0.5589 - val_loss: 1.1484 - val_accuracy: 0.5933\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8995 - accuracy: 0.5675 - val_loss: 1.1743 - val_accuracy: 0.5964\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0304 - accuracy: 0.5499 - val_loss: 1.1162 - val_accuracy: 0.6163\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9481 - accuracy: 0.5605 - val_loss: 1.2280 - val_accuracy: 0.5666\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9835 - accuracy: 0.5579 - val_loss: 1.2244 - val_accuracy: 0.5929\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9353 - accuracy: 0.5623 - val_loss: 1.1352 - val_accuracy: 0.5947\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9048 - accuracy: 0.5695 - val_loss: 1.1386 - val_accuracy: 0.5936\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3058 - accuracy: 0.5346 - val_loss: 1.2602 - val_accuracy: 0.5613\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2500 - accuracy: 0.5195 - val_loss: 1.2842 - val_accuracy: 0.5602\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5014 - accuracy: 0.4953 - val_loss: 1.3818 - val_accuracy: 0.5382\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1933 - accuracy: 0.5016 - val_loss: 1.1833 - val_accuracy: 0.5897\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0003 - accuracy: 0.5401 - val_loss: 1.1376 - val_accuracy: 0.6053\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2302 - accuracy: 0.5089 - val_loss: 1.5570 - val_accuracy: 0.4636\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1447 - accuracy: 0.4895 - val_loss: 1.2791 - val_accuracy: 0.5510\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0356 - accuracy: 0.5209 - val_loss: 1.2504 - val_accuracy: 0.5666\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0223 - accuracy: 0.5421 - val_loss: 1.2203 - val_accuracy: 0.5837\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9890 - accuracy: 0.5428 - val_loss: 1.2351 - val_accuracy: 0.5659\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9296 - accuracy: 0.5466 - val_loss: 1.1461 - val_accuracy: 0.6099\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9778 - accuracy: 0.5545 - val_loss: 1.2849 - val_accuracy: 0.5577\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2650 - accuracy: 0.5114 - val_loss: 1.1935 - val_accuracy: 0.5915\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0922 - accuracy: 0.5356 - val_loss: 1.6552 - val_accuracy: 0.4469\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1977 - accuracy: 0.4916 - val_loss: 1.2269 - val_accuracy: 0.5734\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5693 - accuracy: 0.5104 - val_loss: 1.3503 - val_accuracy: 0.5378\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6390 - accuracy: 0.5070 - val_loss: 2.0114 - val_accuracy: 0.3663\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7856 - accuracy: 0.4826 - val_loss: 1.3584 - val_accuracy: 0.5663\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2285 - accuracy: 0.4811 - val_loss: 1.3213 - val_accuracy: 0.5336\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2226 - accuracy: 0.5196 - val_loss: 1.2611 - val_accuracy: 0.5552\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0997 - accuracy: 0.5346 - val_loss: 1.2497 - val_accuracy: 0.5648\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9577 - accuracy: 0.5640 - val_loss: 1.1070 - val_accuracy: 0.6192\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9604 - accuracy: 0.5669 - val_loss: 1.1294 - val_accuracy: 0.5954\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8762 - accuracy: 0.5698 - val_loss: 1.0982 - val_accuracy: 0.6117\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9594 - accuracy: 0.5613 - val_loss: 1.2389 - val_accuracy: 0.5833\n",
      "Epoch 171/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8814 - accuracy: 0.5764 - val_loss: 1.1332 - val_accuracy: 0.6000\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9962 - accuracy: 0.5396 - val_loss: 1.2093 - val_accuracy: 0.5506\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.1101 - val_accuracy: 0.6139\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8590 - accuracy: 0.5742 - val_loss: 1.2304 - val_accuracy: 0.5694\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8703 - accuracy: 0.5710 - val_loss: 1.2481 - val_accuracy: 0.5634\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1827 - accuracy: 0.5197 - val_loss: 1.3127 - val_accuracy: 0.5417\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0685 - accuracy: 0.5357 - val_loss: 1.1648 - val_accuracy: 0.5964\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1971 - accuracy: 0.5392 - val_loss: 1.1654 - val_accuracy: 0.5883\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9862 - accuracy: 0.5485 - val_loss: 1.1597 - val_accuracy: 0.5922\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2667 - accuracy: 0.5266 - val_loss: 1.3417 - val_accuracy: 0.5350\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9424 - accuracy: 0.5390 - val_loss: 1.1758 - val_accuracy: 0.5940\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8790 - accuracy: 0.5649 - val_loss: 1.1185 - val_accuracy: 0.5968\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8854 - accuracy: 0.5737 - val_loss: 1.7373 - val_accuracy: 0.4774\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3810 - accuracy: 0.5161 - val_loss: 1.5414 - val_accuracy: 0.5201\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0906 - accuracy: 0.5401 - val_loss: 1.2837 - val_accuracy: 0.5474\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4458 - accuracy: 0.4927 - val_loss: 1.5101 - val_accuracy: 0.4948\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2706 - accuracy: 0.5117 - val_loss: 1.2771 - val_accuracy: 0.5531\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9804 - accuracy: 0.5400 - val_loss: 1.1598 - val_accuracy: 0.5968\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1272 - accuracy: 0.5433 - val_loss: 1.2514 - val_accuracy: 0.5666\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9504 - accuracy: 0.5567 - val_loss: 1.4571 - val_accuracy: 0.5101\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0624 - accuracy: 0.5390 - val_loss: 1.1585 - val_accuracy: 0.6011\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1052 - accuracy: 0.5460 - val_loss: 1.2688 - val_accuracy: 0.5666\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2100 - accuracy: 0.5243 - val_loss: 1.4083 - val_accuracy: 0.5261\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1026 - accuracy: 0.5203 - val_loss: 1.1531 - val_accuracy: 0.6078\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0518 - accuracy: 0.5407 - val_loss: 1.2029 - val_accuracy: 0.5933\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0383 - accuracy: 0.5523 - val_loss: 1.2825 - val_accuracy: 0.5570\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1694 - accuracy: 0.5464 - val_loss: 1.2143 - val_accuracy: 0.5666\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2914 - accuracy: 0.4936 - val_loss: 1.2852 - val_accuracy: 0.5535\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9268 - accuracy: 0.5480 - val_loss: 1.1654 - val_accuracy: 0.5975\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8999 - accuracy: 0.5687 - val_loss: 1.2503 - val_accuracy: 0.5581\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0476 - accuracy: 0.5430 - val_loss: 1.2964 - val_accuracy: 0.5549\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0527 - accuracy: 0.5310 - val_loss: 1.1493 - val_accuracy: 0.5979\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8993 - accuracy: 0.5589 - val_loss: 1.0983 - val_accuracy: 0.6256\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0835 - accuracy: 0.5519 - val_loss: 1.1980 - val_accuracy: 0.5886\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0716 - accuracy: 0.5446 - val_loss: 1.3665 - val_accuracy: 0.5218\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2273 - accuracy: 0.5053 - val_loss: 1.1854 - val_accuracy: 0.5865\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9628 - accuracy: 0.5503 - val_loss: 1.1693 - val_accuracy: 0.5872\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0350 - accuracy: 0.5436 - val_loss: 1.2225 - val_accuracy: 0.5805\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8745 - accuracy: 0.5864 - val_loss: 1.1239 - val_accuracy: 0.6210\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9692 - accuracy: 0.5791 - val_loss: 1.1282 - val_accuracy: 0.6156\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9613 - accuracy: 0.5624 - val_loss: 1.0584 - val_accuracy: 0.6295\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8349 - accuracy: 0.5870 - val_loss: 1.0886 - val_accuracy: 0.6096\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0176 - accuracy: 0.5509 - val_loss: 1.1468 - val_accuracy: 0.5982\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9392 - accuracy: 0.5583 - val_loss: 1.1233 - val_accuracy: 0.6039\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8871 - accuracy: 0.5807 - val_loss: 1.3375 - val_accuracy: 0.5371\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8851 - accuracy: 0.5773 - val_loss: 1.2522 - val_accuracy: 0.5694\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1307 - accuracy: 0.5329 - val_loss: 1.3819 - val_accuracy: 0.5158\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0821 - accuracy: 0.5306 - val_loss: 1.1735 - val_accuracy: 0.5961\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9036 - accuracy: 0.5700 - val_loss: 1.0941 - val_accuracy: 0.6206\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9796 - accuracy: 0.5663 - val_loss: 1.0907 - val_accuracy: 0.6252\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8696 - accuracy: 0.5791 - val_loss: 1.1264 - val_accuracy: 0.6142\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9168 - accuracy: 0.5719 - val_loss: 1.2783 - val_accuracy: 0.5609\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1024 - accuracy: 0.5361 - val_loss: 1.3183 - val_accuracy: 0.5432\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9418 - accuracy: 0.5425 - val_loss: 1.1698 - val_accuracy: 0.5904\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9726 - accuracy: 0.5586 - val_loss: 1.1793 - val_accuracy: 0.5847\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8718 - accuracy: 0.5760 - val_loss: 1.1351 - val_accuracy: 0.5993\n",
      "Epoch 227/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9370 - accuracy: 0.5627 - val_loss: 1.2056 - val_accuracy: 0.5904\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8837 - accuracy: 0.5700 - val_loss: 1.1073 - val_accuracy: 0.6171\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8702 - accuracy: 0.5839 - val_loss: 1.1340 - val_accuracy: 0.6007\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8678 - accuracy: 0.5761 - val_loss: 1.1804 - val_accuracy: 0.5911\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8663 - accuracy: 0.5801 - val_loss: 1.1315 - val_accuracy: 0.6163\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9361 - accuracy: 0.5769 - val_loss: 1.1757 - val_accuracy: 0.5933\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8387 - accuracy: 0.5767 - val_loss: 1.0772 - val_accuracy: 0.6220\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2475 - accuracy: 0.5005 - val_loss: 1.2362 - val_accuracy: 0.5858\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9690 - accuracy: 0.5612 - val_loss: 1.1230 - val_accuracy: 0.6334\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9512 - accuracy: 0.5807 - val_loss: 1.1492 - val_accuracy: 0.6167\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8794 - accuracy: 0.5796 - val_loss: 1.1265 - val_accuracy: 0.6139\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5064 - accuracy: 0.5243 - val_loss: 1.4530 - val_accuracy: 0.4920\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0832 - accuracy: 0.5284 - val_loss: 1.2738 - val_accuracy: 0.5371\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9515 - accuracy: 0.5668 - val_loss: 1.3285 - val_accuracy: 0.5456\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2146 - accuracy: 0.5286 - val_loss: 1.3090 - val_accuracy: 0.5584\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1887 - accuracy: 0.5431 - val_loss: 1.4361 - val_accuracy: 0.5073\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0900 - accuracy: 0.5141 - val_loss: 1.3080 - val_accuracy: 0.5584\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9363 - accuracy: 0.5670 - val_loss: 1.2987 - val_accuracy: 0.5591\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9118 - accuracy: 0.5656 - val_loss: 1.3579 - val_accuracy: 0.5638\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8927 - accuracy: 0.5702 - val_loss: 1.1890 - val_accuracy: 0.5861\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9224 - accuracy: 0.5669 - val_loss: 1.3655 - val_accuracy: 0.5286\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9359 - accuracy: 0.5583 - val_loss: 1.2022 - val_accuracy: 0.5822\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0188 - accuracy: 0.5282 - val_loss: 1.1899 - val_accuracy: 0.5719\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9758 - accuracy: 0.5528 - val_loss: 1.1566 - val_accuracy: 0.5979\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9804 - accuracy: 0.5631 - val_loss: 1.2213 - val_accuracy: 0.5613\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4856 - accuracy: 0.5492 - val_loss: 1.2702 - val_accuracy: 0.5638\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3317 - accuracy: 0.5101 - val_loss: 1.3205 - val_accuracy: 0.5634\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6598 - accuracy: 0.4571 - val_loss: 1.3766 - val_accuracy: 0.5318\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2336 - accuracy: 0.5062 - val_loss: 1.4216 - val_accuracy: 0.5290\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2839 - accuracy: 0.5296 - val_loss: 1.2262 - val_accuracy: 0.5826\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9207 - accuracy: 0.5615 - val_loss: 1.1842 - val_accuracy: 0.5989\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0960 - accuracy: 0.5157 - val_loss: 1.3566 - val_accuracy: 0.5368\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1294 - accuracy: 0.5213 - val_loss: 1.3322 - val_accuracy: 0.5496\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9553 - accuracy: 0.5570 - val_loss: 1.1451 - val_accuracy: 0.6114\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8615 - accuracy: 0.5841 - val_loss: 1.1695 - val_accuracy: 0.5883\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8154 - accuracy: 0.5925 - val_loss: 1.0995 - val_accuracy: 0.6171\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9463 - accuracy: 0.5660 - val_loss: 1.1877 - val_accuracy: 0.5822\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9547 - accuracy: 0.5745 - val_loss: 1.3406 - val_accuracy: 0.5467\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1044 - accuracy: 0.5308 - val_loss: 1.1749 - val_accuracy: 0.5883\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2832 - accuracy: 0.5254 - val_loss: 1.1919 - val_accuracy: 0.6018\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0644 - accuracy: 0.5622 - val_loss: 1.1523 - val_accuracy: 0.6135\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8305 - accuracy: 0.5883 - val_loss: 1.0921 - val_accuracy: 0.6103\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9459 - accuracy: 0.5540 - val_loss: 1.1316 - val_accuracy: 0.6050\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9764 - accuracy: 0.5685 - val_loss: 1.1885 - val_accuracy: 0.5901\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8496 - accuracy: 0.5877 - val_loss: 1.0441 - val_accuracy: 0.6277\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8071 - accuracy: 0.5991 - val_loss: 1.0846 - val_accuracy: 0.6206\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9277 - accuracy: 0.5743 - val_loss: 1.0525 - val_accuracy: 0.6167\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9378 - accuracy: 0.5843 - val_loss: 1.1262 - val_accuracy: 0.6046\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0962 - accuracy: 0.5575 - val_loss: 1.5332 - val_accuracy: 0.5158\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0181 - accuracy: 0.5467 - val_loss: 1.1340 - val_accuracy: 0.6089\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1561 - accuracy: 0.5292 - val_loss: 1.3318 - val_accuracy: 0.5400\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0550 - accuracy: 0.5337 - val_loss: 1.2391 - val_accuracy: 0.5741\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8966 - accuracy: 0.5690 - val_loss: 1.1095 - val_accuracy: 0.6220\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8609 - accuracy: 0.5736 - val_loss: 1.0484 - val_accuracy: 0.6437\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9426 - accuracy: 0.5834 - val_loss: 1.3986 - val_accuracy: 0.5268\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1538 - accuracy: 0.5256 - val_loss: 1.3036 - val_accuracy: 0.5734\n",
      "Epoch 283/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9695 - accuracy: 0.5102 - val_loss: 1.2575 - val_accuracy: 0.5858\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1718 - accuracy: 0.5299 - val_loss: 1.2556 - val_accuracy: 0.5837\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7925 - accuracy: 0.5056 - val_loss: 1.4150 - val_accuracy: 0.5208\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1237 - accuracy: 0.5426 - val_loss: 1.1576 - val_accuracy: 0.6242\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1205 - accuracy: 0.5374 - val_loss: 1.2289 - val_accuracy: 0.5798\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2218 - accuracy: 0.5302 - val_loss: 1.3253 - val_accuracy: 0.5382\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9159 - accuracy: 0.5729 - val_loss: 1.1337 - val_accuracy: 0.6121\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8855 - accuracy: 0.5785 - val_loss: 1.0889 - val_accuracy: 0.6213\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1103 - accuracy: 0.5465 - val_loss: 1.0701 - val_accuracy: 0.6270\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2463 - accuracy: 0.5123 - val_loss: 1.1664 - val_accuracy: 0.5915\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9288 - accuracy: 0.5653 - val_loss: 1.2162 - val_accuracy: 0.5954\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8703 - accuracy: 0.6003 - val_loss: 1.1233 - val_accuracy: 0.6174\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8395 - accuracy: 0.5897 - val_loss: 1.2963 - val_accuracy: 0.5670\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3884 - accuracy: 0.5294 - val_loss: 1.7391 - val_accuracy: 0.4252\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1086 - accuracy: 0.5099 - val_loss: 1.2341 - val_accuracy: 0.5719\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8691 - accuracy: 0.5692 - val_loss: 1.1964 - val_accuracy: 0.5844\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9844 - accuracy: 0.5583 - val_loss: 1.2086 - val_accuracy: 0.5911\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8176 - accuracy: 0.5814 - val_loss: 1.0732 - val_accuracy: 0.6263\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0369 - accuracy: 0.5685 - val_loss: 1.9168 - val_accuracy: 0.4302\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4863 - accuracy: 0.4989 - val_loss: 1.5905 - val_accuracy: 0.5258\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3903 - accuracy: 0.5330 - val_loss: 1.3263 - val_accuracy: 0.5602\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2235 - accuracy: 0.5008 - val_loss: 1.3958 - val_accuracy: 0.5165\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9967 - accuracy: 0.5397 - val_loss: 1.2559 - val_accuracy: 0.5492\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0558 - accuracy: 0.5376 - val_loss: 1.2710 - val_accuracy: 0.5751\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9232 - accuracy: 0.5718 - val_loss: 1.1205 - val_accuracy: 0.6249\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8407 - accuracy: 0.5940 - val_loss: 1.0470 - val_accuracy: 0.6426\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7793 - accuracy: 0.6113 - val_loss: 1.0694 - val_accuracy: 0.6181\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7846 - accuracy: 0.6044 - val_loss: 1.0972 - val_accuracy: 0.6153\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4128 - accuracy: 0.4583 - val_loss: 1.2869 - val_accuracy: 0.5513\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1274 - accuracy: 0.5304 - val_loss: 1.4195 - val_accuracy: 0.5336\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0227 - accuracy: 0.5419 - val_loss: 1.2848 - val_accuracy: 0.5659\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2317 - accuracy: 0.5171 - val_loss: 1.3230 - val_accuracy: 0.5535\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.9605 - accuracy: 0.4745 - val_loss: 1.4992 - val_accuracy: 0.5194\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1978 - accuracy: 0.5326 - val_loss: 1.4814 - val_accuracy: 0.5293\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8004 - accuracy: 0.5019 - val_loss: 1.3889 - val_accuracy: 0.5265\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0041 - accuracy: 0.5613 - val_loss: 1.1299 - val_accuracy: 0.6149\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9897 - accuracy: 0.5475 - val_loss: 1.2074 - val_accuracy: 0.5869\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9348 - accuracy: 0.5667 - val_loss: 1.1567 - val_accuracy: 0.5908\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9845 - accuracy: 0.5607 - val_loss: 1.0886 - val_accuracy: 0.6192\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8031 - accuracy: 0.5909 - val_loss: 1.0580 - val_accuracy: 0.6277\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9151 - accuracy: 0.5694 - val_loss: 1.2795 - val_accuracy: 0.5613\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9839 - accuracy: 0.5498 - val_loss: 1.1939 - val_accuracy: 0.5897\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8541 - accuracy: 0.5712 - val_loss: 1.1515 - val_accuracy: 0.6007\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2853 - accuracy: 0.5426 - val_loss: 1.1924 - val_accuracy: 0.5883\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8366 - accuracy: 0.5963 - val_loss: 1.1993 - val_accuracy: 0.5933\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8422 - accuracy: 0.5971 - val_loss: 1.0987 - val_accuracy: 0.6121\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8432 - accuracy: 0.5909 - val_loss: 1.0753 - val_accuracy: 0.6320\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9123 - accuracy: 0.5895 - val_loss: 1.3954 - val_accuracy: 0.5187\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9119 - accuracy: 0.5602 - val_loss: 1.0651 - val_accuracy: 0.6398\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0985 - accuracy: 0.4847 - val_loss: 1.6711 - val_accuracy: 0.4586\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5554 - accuracy: 0.4961 - val_loss: 1.3966 - val_accuracy: 0.5414\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9801 - accuracy: 0.5583 - val_loss: 1.2020 - val_accuracy: 0.5993\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9326 - accuracy: 0.5747 - val_loss: 1.2123 - val_accuracy: 0.5879\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.0458 - accuracy: 0.5610 - val_loss: 1.1922 - val_accuracy: 0.6039\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9641 - accuracy: 0.5702 - val_loss: 1.1735 - val_accuracy: 0.6089\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0749 - accuracy: 0.5471 - val_loss: 1.1582 - val_accuracy: 0.5936\n",
      "Epoch 339/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8672 - accuracy: 0.5808 - val_loss: 1.1346 - val_accuracy: 0.6156\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1092 - accuracy: 0.5563 - val_loss: 1.2092 - val_accuracy: 0.5702\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1936 - accuracy: 0.5675 - val_loss: 1.4776 - val_accuracy: 0.4970\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2667 - accuracy: 0.5135 - val_loss: 1.2010 - val_accuracy: 0.5925\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1169 - accuracy: 0.5281 - val_loss: 1.2097 - val_accuracy: 0.5744\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1629 - accuracy: 0.5538 - val_loss: 1.2965 - val_accuracy: 0.5588\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.3515 - accuracy: 0.5366 - val_loss: 1.3464 - val_accuracy: 0.5393\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9473 - accuracy: 0.5604 - val_loss: 1.2135 - val_accuracy: 0.5922\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9895 - accuracy: 0.5439 - val_loss: 1.1159 - val_accuracy: 0.6153\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2567 - accuracy: 0.5020 - val_loss: 1.2531 - val_accuracy: 0.5645\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9897 - accuracy: 0.5460 - val_loss: 1.2638 - val_accuracy: 0.5783\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9337 - accuracy: 0.5677 - val_loss: 1.3294 - val_accuracy: 0.5449\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8970 - accuracy: 0.5770 - val_loss: 1.0983 - val_accuracy: 0.6309\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1895 - accuracy: 0.5630 - val_loss: 1.1770 - val_accuracy: 0.5954\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6789 - accuracy: 0.4885 - val_loss: 1.4337 - val_accuracy: 0.5027\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0331 - accuracy: 0.5450 - val_loss: 1.1515 - val_accuracy: 0.5986\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0196 - accuracy: 0.5380 - val_loss: 1.1948 - val_accuracy: 0.5734\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9640 - accuracy: 0.5715 - val_loss: 1.6422 - val_accuracy: 0.4970\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9254 - accuracy: 0.5598 - val_loss: 1.1625 - val_accuracy: 0.5993\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8721 - accuracy: 0.5814 - val_loss: 1.1373 - val_accuracy: 0.6089\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9314 - accuracy: 0.5815 - val_loss: 1.2250 - val_accuracy: 0.5879\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8154 - accuracy: 0.5947 - val_loss: 1.5813 - val_accuracy: 0.5069\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7996 - accuracy: 0.5872 - val_loss: 1.0691 - val_accuracy: 0.6167\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8302 - accuracy: 0.5876 - val_loss: 1.0505 - val_accuracy: 0.6313\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0801 - accuracy: 0.5713 - val_loss: 1.5374 - val_accuracy: 0.4693\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1135 - accuracy: 0.5242 - val_loss: 1.6370 - val_accuracy: 0.4710\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8089 - accuracy: 0.4403 - val_loss: 1.6353 - val_accuracy: 0.4057\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2224 - accuracy: 0.4814 - val_loss: 1.3559 - val_accuracy: 0.5336\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9874 - accuracy: 0.5490 - val_loss: 1.2833 - val_accuracy: 0.5737\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9773 - accuracy: 0.5633 - val_loss: 1.0790 - val_accuracy: 0.6359\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3841 - accuracy: 0.5227 - val_loss: 1.4551 - val_accuracy: 0.5197\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7933 - accuracy: 0.3962 - val_loss: 1.7178 - val_accuracy: 0.4107\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.0147 - accuracy: 0.4150 - val_loss: 1.7109 - val_accuracy: 0.4359\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5332 - accuracy: 0.4529 - val_loss: 1.4917 - val_accuracy: 0.4892\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5537 - accuracy: 0.4557 - val_loss: 1.3610 - val_accuracy: 0.5449\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4748 - accuracy: 0.4916 - val_loss: 1.3310 - val_accuracy: 0.5425\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4457 - accuracy: 0.4948 - val_loss: 1.4287 - val_accuracy: 0.5176\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2848 - accuracy: 0.4917 - val_loss: 1.5772 - val_accuracy: 0.4742\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1117 - accuracy: 0.5210 - val_loss: 1.2460 - val_accuracy: 0.5712\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3341 - accuracy: 0.4844 - val_loss: 1.7190 - val_accuracy: 0.4036\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2523 - accuracy: 0.4789 - val_loss: 1.2434 - val_accuracy: 0.5652\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0722 - accuracy: 0.5337 - val_loss: 1.3356 - val_accuracy: 0.5364\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3284 - accuracy: 0.4893 - val_loss: 1.2460 - val_accuracy: 0.5709\n",
      "Epoch 382/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9819 - accuracy: 0.5450 - val_loss: 1.1819 - val_accuracy: 0.5957\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9283 - accuracy: 0.5603 - val_loss: 1.2233 - val_accuracy: 0.5783\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8408 - accuracy: 0.5759 - val_loss: 1.2167 - val_accuracy: 0.5680\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2431 - accuracy: 0.5278 - val_loss: 1.3490 - val_accuracy: 0.5254\n",
      "Epoch 386/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0771 - accuracy: 0.5298 - val_loss: 1.3247 - val_accuracy: 0.5471\n",
      "Epoch 387/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0991 - accuracy: 0.5497 - val_loss: 1.2171 - val_accuracy: 0.5851\n",
      "Epoch 388/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1672 - accuracy: 0.5290 - val_loss: 1.1779 - val_accuracy: 0.5982\n",
      "Epoch 389/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9979 - accuracy: 0.5575 - val_loss: 1.1654 - val_accuracy: 0.6043\n",
      "Epoch 390/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3443 - accuracy: 0.4962 - val_loss: 1.4779 - val_accuracy: 0.5005\n",
      "Epoch 391/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5701 - accuracy: 0.4548 - val_loss: 1.2973 - val_accuracy: 0.5400\n",
      "Epoch 392/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5319 - accuracy: 0.5234 - val_loss: 1.1947 - val_accuracy: 0.5936\n",
      "Epoch 393/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0698 - accuracy: 0.5433 - val_loss: 1.2089 - val_accuracy: 0.5723\n",
      "Epoch 394/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9584 - accuracy: 0.5636 - val_loss: 1.1670 - val_accuracy: 0.5883\n",
      "Epoch 395/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9105 - accuracy: 0.5664 - val_loss: 1.1656 - val_accuracy: 0.5758\n",
      "Epoch 396/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9054 - accuracy: 0.5685 - val_loss: 1.1480 - val_accuracy: 0.5972\n",
      "Epoch 397/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0716 - accuracy: 0.5519 - val_loss: 1.3948 - val_accuracy: 0.5066\n",
      "Epoch 398/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1179 - accuracy: 0.5241 - val_loss: 1.2350 - val_accuracy: 0.5726\n",
      "Epoch 399/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9156 - accuracy: 0.5694 - val_loss: 1.1124 - val_accuracy: 0.6156\n",
      "Epoch 400/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0104 - accuracy: 0.5569 - val_loss: 1.2062 - val_accuracy: 0.5869\n",
      "Epoch 401/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9187 - accuracy: 0.5805 - val_loss: 1.2145 - val_accuracy: 0.5627\n",
      "Epoch 402/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9126 - accuracy: 0.5681 - val_loss: 1.1381 - val_accuracy: 0.5972\n",
      "Epoch 403/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7948 - accuracy: 0.5909 - val_loss: 1.0601 - val_accuracy: 0.6174\n",
      "Epoch 404/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0829 - accuracy: 0.5243 - val_loss: 1.2083 - val_accuracy: 0.5769\n",
      "Epoch 405/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0412 - accuracy: 0.5440 - val_loss: 1.2102 - val_accuracy: 0.5762\n",
      "Epoch 406/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0172 - accuracy: 0.5320 - val_loss: 1.7436 - val_accuracy: 0.4526\n",
      "Epoch 407/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1263 - accuracy: 0.5364 - val_loss: 1.3060 - val_accuracy: 0.5648\n",
      "Epoch 408/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5028 - accuracy: 0.4973 - val_loss: 1.2590 - val_accuracy: 0.5591\n",
      "Epoch 409/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0346 - accuracy: 0.5212 - val_loss: 1.2376 - val_accuracy: 0.5595\n",
      "Epoch 410/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0285 - accuracy: 0.5373 - val_loss: 1.5353 - val_accuracy: 0.5076\n",
      "Epoch 411/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2277 - accuracy: 0.5060 - val_loss: 1.2864 - val_accuracy: 0.5432\n",
      "Epoch 412/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8712 - accuracy: 0.5687 - val_loss: 1.1347 - val_accuracy: 0.5968\n",
      "Epoch 413/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9407 - accuracy: 0.5669 - val_loss: 1.1731 - val_accuracy: 0.5890\n",
      "Epoch 414/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8251 - accuracy: 0.5851 - val_loss: 1.0436 - val_accuracy: 0.6348\n",
      "Epoch 415/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1359 - accuracy: 0.5202 - val_loss: 1.1752 - val_accuracy: 0.5933\n",
      "Epoch 416/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9138 - accuracy: 0.5735 - val_loss: 1.0811 - val_accuracy: 0.6245\n",
      "Epoch 417/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9201 - accuracy: 0.5782 - val_loss: 1.1581 - val_accuracy: 0.5986\n",
      "Epoch 418/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8278 - accuracy: 0.5903 - val_loss: 1.1151 - val_accuracy: 0.6220\n",
      "Epoch 419/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4566 - accuracy: 0.5473 - val_loss: 1.5831 - val_accuracy: 0.4654\n",
      "Epoch 420/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9368 - accuracy: 0.5519 - val_loss: 1.2064 - val_accuracy: 0.5922\n",
      "Epoch 421/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7003 - accuracy: 0.4629 - val_loss: 1.3421 - val_accuracy: 0.5666\n",
      "Epoch 422/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4569 - accuracy: 0.5018 - val_loss: 1.4158 - val_accuracy: 0.5016\n",
      "\n",
      "Validation 4, fold 1 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 3.1049 - accuracy: 0.0548 - val_loss: 2.7987 - val_accuracy: 0.0526\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.6397 - accuracy: 0.1375 - val_loss: 2.4303 - val_accuracy: 0.1890\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2850 - accuracy: 0.1941 - val_loss: 2.2205 - val_accuracy: 0.2000\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.1435 - accuracy: 0.2216 - val_loss: 2.2171 - val_accuracy: 0.1854\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2277 - accuracy: 0.2290 - val_loss: 2.2279 - val_accuracy: 0.1794\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1031 - accuracy: 0.2061 - val_loss: 2.0759 - val_accuracy: 0.2345\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9633 - accuracy: 0.2455 - val_loss: 2.0292 - val_accuracy: 0.2853\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9165 - accuracy: 0.2673 - val_loss: 2.0142 - val_accuracy: 0.2856\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8024 - accuracy: 0.2960 - val_loss: 1.9477 - val_accuracy: 0.3517\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.6695 - accuracy: 0.3422 - val_loss: 1.9119 - val_accuracy: 0.3357\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6743 - accuracy: 0.3619 - val_loss: 1.9627 - val_accuracy: 0.3545\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5554 - accuracy: 0.3828 - val_loss: 2.2991 - val_accuracy: 0.3080\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4800 - accuracy: 0.4099 - val_loss: 1.7899 - val_accuracy: 0.3904\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6009 - accuracy: 0.3960 - val_loss: 1.6090 - val_accuracy: 0.4742\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5434 - accuracy: 0.3910 - val_loss: 1.7710 - val_accuracy: 0.4256\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5213 - accuracy: 0.4176 - val_loss: 1.5878 - val_accuracy: 0.4746\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4049 - accuracy: 0.4396 - val_loss: 1.4826 - val_accuracy: 0.5112\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3441 - accuracy: 0.4579 - val_loss: 1.7136 - val_accuracy: 0.4227\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3362 - accuracy: 0.4614 - val_loss: 1.4582 - val_accuracy: 0.5009\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3237 - accuracy: 0.4784 - val_loss: 1.4953 - val_accuracy: 0.5023\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4114 - accuracy: 0.4543 - val_loss: 1.5723 - val_accuracy: 0.4842\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2555 - accuracy: 0.4730 - val_loss: 1.4988 - val_accuracy: 0.5020\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2044 - accuracy: 0.4754 - val_loss: 1.4919 - val_accuracy: 0.5023\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1701 - accuracy: 0.4948 - val_loss: 1.4159 - val_accuracy: 0.5236\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2466 - accuracy: 0.4753 - val_loss: 1.4467 - val_accuracy: 0.5076\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2436 - accuracy: 0.4890 - val_loss: 1.3715 - val_accuracy: 0.5474\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2952 - accuracy: 0.4698 - val_loss: 1.6598 - val_accuracy: 0.4348\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2021 - accuracy: 0.4812 - val_loss: 1.4025 - val_accuracy: 0.5240\n",
      "Epoch 29/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1818 - accuracy: 0.4929 - val_loss: 1.5840 - val_accuracy: 0.4444\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1673 - accuracy: 0.4964 - val_loss: 1.3514 - val_accuracy: 0.5499\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0921 - accuracy: 0.5098 - val_loss: 1.3135 - val_accuracy: 0.5581\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1304 - accuracy: 0.5123 - val_loss: 1.3168 - val_accuracy: 0.5623\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0899 - accuracy: 0.5177 - val_loss: 1.4387 - val_accuracy: 0.5233\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0515 - accuracy: 0.5254 - val_loss: 1.3215 - val_accuracy: 0.5560\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6296 - accuracy: 0.4758 - val_loss: 1.4295 - val_accuracy: 0.5254\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4424 - accuracy: 0.4505 - val_loss: 1.4360 - val_accuracy: 0.5336\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3908 - accuracy: 0.4729 - val_loss: 1.4749 - val_accuracy: 0.4980\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7785 - accuracy: 0.4375 - val_loss: 1.7083 - val_accuracy: 0.4380\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3203 - accuracy: 0.4600 - val_loss: 1.4512 - val_accuracy: 0.5211\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2481 - accuracy: 0.4924 - val_loss: 1.3122 - val_accuracy: 0.5645\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1127 - accuracy: 0.5127 - val_loss: 1.4716 - val_accuracy: 0.5290\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1857 - accuracy: 0.5089 - val_loss: 1.5664 - val_accuracy: 0.4980\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2415 - accuracy: 0.5029 - val_loss: 1.3366 - val_accuracy: 0.5584\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0902 - accuracy: 0.5237 - val_loss: 1.6056 - val_accuracy: 0.4824\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4013 - accuracy: 0.4918 - val_loss: 1.4812 - val_accuracy: 0.5236\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1775 - accuracy: 0.4979 - val_loss: 1.3970 - val_accuracy: 0.5368\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0407 - accuracy: 0.5218 - val_loss: 1.3478 - val_accuracy: 0.5428\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0781 - accuracy: 0.5189 - val_loss: 1.2533 - val_accuracy: 0.5748\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0014 - accuracy: 0.5406 - val_loss: 1.2949 - val_accuracy: 0.5705\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9943 - accuracy: 0.5419 - val_loss: 1.3287 - val_accuracy: 0.5616\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0145 - accuracy: 0.5330 - val_loss: 1.2584 - val_accuracy: 0.5815\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1219 - accuracy: 0.5246 - val_loss: 1.6228 - val_accuracy: 0.4583\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.7426 - accuracy: 0.4767 - val_loss: 1.4607 - val_accuracy: 0.5290\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3824 - accuracy: 0.4819 - val_loss: 1.5480 - val_accuracy: 0.4686\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1863 - accuracy: 0.5016 - val_loss: 2.5855 - val_accuracy: 0.4167\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3887 - accuracy: 0.4849 - val_loss: 1.4896 - val_accuracy: 0.5201\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0959 - accuracy: 0.5238 - val_loss: 1.3025 - val_accuracy: 0.5627\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0675 - accuracy: 0.5313 - val_loss: 1.2993 - val_accuracy: 0.5627\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0935 - accuracy: 0.5345 - val_loss: 1.4798 - val_accuracy: 0.5151\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1492 - accuracy: 0.5084 - val_loss: 1.4460 - val_accuracy: 0.5151\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1207 - accuracy: 0.5170 - val_loss: 1.4042 - val_accuracy: 0.5314\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4298 - accuracy: 0.4815 - val_loss: 1.2841 - val_accuracy: 0.5691\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0742 - accuracy: 0.5238 - val_loss: 1.2992 - val_accuracy: 0.5737\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9756 - accuracy: 0.5433 - val_loss: 1.2672 - val_accuracy: 0.5741\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9950 - accuracy: 0.5417 - val_loss: 1.3791 - val_accuracy: 0.5350\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0138 - accuracy: 0.5442 - val_loss: 1.5824 - val_accuracy: 0.5062\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3908 - accuracy: 0.4917 - val_loss: 1.3611 - val_accuracy: 0.5471\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3567 - accuracy: 0.5042 - val_loss: 1.7877 - val_accuracy: 0.4295\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2156 - accuracy: 0.4878 - val_loss: 2.0509 - val_accuracy: 0.4007\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5571 - accuracy: 0.4813 - val_loss: 1.5369 - val_accuracy: 0.4988\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1217 - accuracy: 0.5142 - val_loss: 1.4567 - val_accuracy: 0.5080\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1374 - accuracy: 0.5017 - val_loss: 1.2727 - val_accuracy: 0.5741\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0110 - accuracy: 0.5419 - val_loss: 1.2701 - val_accuracy: 0.5858\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9549 - accuracy: 0.5576 - val_loss: 1.2865 - val_accuracy: 0.5833\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1785 - accuracy: 0.5147 - val_loss: 1.4495 - val_accuracy: 0.5208\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1419 - accuracy: 0.5111 - val_loss: 1.4597 - val_accuracy: 0.4899\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5011 - accuracy: 0.4984 - val_loss: 1.4830 - val_accuracy: 0.5211\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2102 - accuracy: 0.5078 - val_loss: 1.4015 - val_accuracy: 0.5226\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1189 - accuracy: 0.5147 - val_loss: 1.2516 - val_accuracy: 0.5805\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0511 - accuracy: 0.5392 - val_loss: 1.5537 - val_accuracy: 0.4995\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9744 - accuracy: 0.5538 - val_loss: 1.2364 - val_accuracy: 0.5922\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1478 - accuracy: 0.5067 - val_loss: 1.4974 - val_accuracy: 0.4874\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0949 - accuracy: 0.5163 - val_loss: 1.2552 - val_accuracy: 0.5847\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9482 - accuracy: 0.5552 - val_loss: 1.4178 - val_accuracy: 0.5222\n",
      "Epoch 85/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9754 - accuracy: 0.5424 - val_loss: 1.2242 - val_accuracy: 0.5972\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0181 - accuracy: 0.5489 - val_loss: 1.2605 - val_accuracy: 0.5670\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9907 - accuracy: 0.5506 - val_loss: 1.3262 - val_accuracy: 0.5389\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9666 - accuracy: 0.5607 - val_loss: 1.3056 - val_accuracy: 0.5666\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9169 - accuracy: 0.5607 - val_loss: 1.2565 - val_accuracy: 0.5776\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0080 - accuracy: 0.5527 - val_loss: 1.3358 - val_accuracy: 0.5535\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9596 - accuracy: 0.5492 - val_loss: 1.1566 - val_accuracy: 0.6110\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9209 - accuracy: 0.5699 - val_loss: 1.1655 - val_accuracy: 0.6117\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0446 - accuracy: 0.5573 - val_loss: 1.2885 - val_accuracy: 0.5588\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9552 - accuracy: 0.5586 - val_loss: 1.2016 - val_accuracy: 0.5950\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0895 - accuracy: 0.5146 - val_loss: 1.4344 - val_accuracy: 0.5009\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9572 - accuracy: 0.5493 - val_loss: 1.2526 - val_accuracy: 0.5762\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0629 - accuracy: 0.5409 - val_loss: 1.2473 - val_accuracy: 0.5886\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1462 - accuracy: 0.5063 - val_loss: 1.5410 - val_accuracy: 0.4536\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1572 - accuracy: 0.5060 - val_loss: 1.1907 - val_accuracy: 0.6007\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9690 - accuracy: 0.5628 - val_loss: 1.1744 - val_accuracy: 0.5876\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9576 - accuracy: 0.5577 - val_loss: 1.2549 - val_accuracy: 0.5691\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0841 - accuracy: 0.5221 - val_loss: 1.2765 - val_accuracy: 0.5567\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9726 - accuracy: 0.5608 - val_loss: 1.2145 - val_accuracy: 0.5840\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8910 - accuracy: 0.5790 - val_loss: 1.2215 - val_accuracy: 0.5840\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8799 - accuracy: 0.5729 - val_loss: 1.2282 - val_accuracy: 0.5961\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9084 - accuracy: 0.5833 - val_loss: 1.3683 - val_accuracy: 0.5361\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9432 - accuracy: 0.5595 - val_loss: 1.1623 - val_accuracy: 0.6103\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9718 - accuracy: 0.5341 - val_loss: 1.4532 - val_accuracy: 0.5073\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6307 - accuracy: 0.4934 - val_loss: 1.4478 - val_accuracy: 0.5101\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3217 - accuracy: 0.5074 - val_loss: 1.2078 - val_accuracy: 0.5943\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2122 - accuracy: 0.5313 - val_loss: 1.4177 - val_accuracy: 0.5034\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4378 - accuracy: 0.5215 - val_loss: 1.3097 - val_accuracy: 0.5623\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1464 - accuracy: 0.5342 - val_loss: 1.2478 - val_accuracy: 0.5901\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0899 - accuracy: 0.5543 - val_loss: 1.2882 - val_accuracy: 0.5758\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0137 - accuracy: 0.5396 - val_loss: 1.2090 - val_accuracy: 0.5968\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1324 - accuracy: 0.5509 - val_loss: 1.2854 - val_accuracy: 0.5655\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1108 - accuracy: 0.5456 - val_loss: 1.2585 - val_accuracy: 0.5815\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9024 - accuracy: 0.5716 - val_loss: 1.1863 - val_accuracy: 0.5893\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9137 - accuracy: 0.5642 - val_loss: 1.2238 - val_accuracy: 0.5865\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9778 - accuracy: 0.5506 - val_loss: 1.5315 - val_accuracy: 0.5094\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9402 - accuracy: 0.5489 - val_loss: 1.2423 - val_accuracy: 0.5616\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9311 - accuracy: 0.5633 - val_loss: 1.1845 - val_accuracy: 0.6025\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8628 - accuracy: 0.5901 - val_loss: 1.0930 - val_accuracy: 0.6412\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0062 - accuracy: 0.5572 - val_loss: 1.1620 - val_accuracy: 0.6025\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0256 - accuracy: 0.5377 - val_loss: 1.7912 - val_accuracy: 0.3915\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1600 - accuracy: 0.5127 - val_loss: 1.2601 - val_accuracy: 0.5854\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2778 - accuracy: 0.5435 - val_loss: 1.6647 - val_accuracy: 0.4917\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2787 - accuracy: 0.5188 - val_loss: 1.5549 - val_accuracy: 0.4771\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0988 - accuracy: 0.5278 - val_loss: 1.3112 - val_accuracy: 0.5623\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9885 - accuracy: 0.5502 - val_loss: 1.2520 - val_accuracy: 0.5716\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0254 - accuracy: 0.5406 - val_loss: 1.2670 - val_accuracy: 0.5829\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1320 - accuracy: 0.5380 - val_loss: 1.2259 - val_accuracy: 0.5972\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9162 - accuracy: 0.5583 - val_loss: 1.1618 - val_accuracy: 0.5908\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1429 - accuracy: 0.5162 - val_loss: 1.4732 - val_accuracy: 0.4831\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1653 - accuracy: 0.5039 - val_loss: 1.2786 - val_accuracy: 0.5542\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0679 - accuracy: 0.5321 - val_loss: 1.4661 - val_accuracy: 0.5311\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1191 - accuracy: 0.5464 - val_loss: 1.3642 - val_accuracy: 0.5275\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0632 - accuracy: 0.5298 - val_loss: 1.2228 - val_accuracy: 0.5890\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9301 - accuracy: 0.5640 - val_loss: 1.1385 - val_accuracy: 0.6263\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9004 - accuracy: 0.5776 - val_loss: 1.1583 - val_accuracy: 0.6192\n",
      "Epoch 141/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9559 - accuracy: 0.5574 - val_loss: 1.1297 - val_accuracy: 0.6160\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8608 - accuracy: 0.5811 - val_loss: 1.2483 - val_accuracy: 0.5798\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8347 - accuracy: 0.5906 - val_loss: 1.1702 - val_accuracy: 0.6096\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8630 - accuracy: 0.5803 - val_loss: 1.1215 - val_accuracy: 0.6146\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9967 - accuracy: 0.5667 - val_loss: 1.4495 - val_accuracy: 0.5421\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9508 - accuracy: 0.5715 - val_loss: 1.1346 - val_accuracy: 0.6171\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9478 - accuracy: 0.5810 - val_loss: 1.2364 - val_accuracy: 0.5840\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8950 - accuracy: 0.5757 - val_loss: 1.1880 - val_accuracy: 0.5837\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2792 - accuracy: 0.5058 - val_loss: 1.3871 - val_accuracy: 0.5378\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9971 - accuracy: 0.5411 - val_loss: 1.1999 - val_accuracy: 0.5698\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8967 - accuracy: 0.5649 - val_loss: 1.2660 - val_accuracy: 0.5694\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9174 - accuracy: 0.5797 - val_loss: 1.1548 - val_accuracy: 0.6114\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1032 - accuracy: 0.5349 - val_loss: 1.1668 - val_accuracy: 0.6011\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9858 - accuracy: 0.5504 - val_loss: 1.1699 - val_accuracy: 0.5936\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7456 - accuracy: 0.5503 - val_loss: 1.3622 - val_accuracy: 0.5517\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3058 - accuracy: 0.5476 - val_loss: 1.3420 - val_accuracy: 0.5453\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9915 - accuracy: 0.5680 - val_loss: 1.1857 - val_accuracy: 0.5890\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9259 - accuracy: 0.5726 - val_loss: 1.2555 - val_accuracy: 0.5709\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8486 - accuracy: 0.5961 - val_loss: 1.1723 - val_accuracy: 0.5986\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8365 - accuracy: 0.6004 - val_loss: 1.0998 - val_accuracy: 0.6202\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8154 - accuracy: 0.5988 - val_loss: 1.1570 - val_accuracy: 0.6135\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9790 - accuracy: 0.5756 - val_loss: 1.2186 - val_accuracy: 0.5940\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8066 - accuracy: 0.5963 - val_loss: 1.0306 - val_accuracy: 0.6568\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9926 - accuracy: 0.5429 - val_loss: 1.2016 - val_accuracy: 0.6163\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2276 - accuracy: 0.5044 - val_loss: 1.3042 - val_accuracy: 0.5620\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9751 - accuracy: 0.5613 - val_loss: 1.2189 - val_accuracy: 0.5908\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3133 - accuracy: 0.5284 - val_loss: 1.2165 - val_accuracy: 0.5844\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1269 - accuracy: 0.5396 - val_loss: 1.2011 - val_accuracy: 0.5854\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9384 - accuracy: 0.5567 - val_loss: 1.3559 - val_accuracy: 0.5290\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9543 - accuracy: 0.5674 - val_loss: 1.2064 - val_accuracy: 0.5861\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3645 - accuracy: 0.5455 - val_loss: 1.1592 - val_accuracy: 0.6135\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0329 - accuracy: 0.5396 - val_loss: 1.2013 - val_accuracy: 0.6039\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8797 - accuracy: 0.5868 - val_loss: 1.0920 - val_accuracy: 0.6334\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0011 - accuracy: 0.5535 - val_loss: 1.3099 - val_accuracy: 0.5481\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8363 - accuracy: 0.5958 - val_loss: 1.1097 - val_accuracy: 0.6366\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8089 - accuracy: 0.6012 - val_loss: 1.1460 - val_accuracy: 0.6149\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7815 - accuracy: 0.6056 - val_loss: 1.1545 - val_accuracy: 0.6053\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9233 - accuracy: 0.5755 - val_loss: 1.1489 - val_accuracy: 0.6174\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8000 - accuracy: 0.6051 - val_loss: 1.0417 - val_accuracy: 0.6512\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7897 - accuracy: 0.6088 - val_loss: 1.0757 - val_accuracy: 0.6355\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5840 - accuracy: 0.4886 - val_loss: 1.4426 - val_accuracy: 0.4941\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0602 - accuracy: 0.5271 - val_loss: 1.2068 - val_accuracy: 0.5893\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.6624 - accuracy: 0.5088 - val_loss: 1.4305 - val_accuracy: 0.4995\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5411 - accuracy: 0.5217 - val_loss: 1.3845 - val_accuracy: 0.5417\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9480 - accuracy: 0.5642 - val_loss: 1.1244 - val_accuracy: 0.6202\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0275 - accuracy: 0.5726 - val_loss: 1.3084 - val_accuracy: 0.5666\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4311 - accuracy: 0.5064 - val_loss: 1.2788 - val_accuracy: 0.5798\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9493 - accuracy: 0.5639 - val_loss: 1.2076 - val_accuracy: 0.5886\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8818 - accuracy: 0.5806 - val_loss: 1.1112 - val_accuracy: 0.6256\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9095 - accuracy: 0.5821 - val_loss: 1.3374 - val_accuracy: 0.5492\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8078 - accuracy: 0.5950 - val_loss: 1.1072 - val_accuracy: 0.6309\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8056 - accuracy: 0.5989 - val_loss: 1.1484 - val_accuracy: 0.6185\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8036 - accuracy: 0.6031 - val_loss: 1.1163 - val_accuracy: 0.6245\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7973 - accuracy: 0.6001 - val_loss: 1.1237 - val_accuracy: 0.6163\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3353 - accuracy: 0.5673 - val_loss: 2.1054 - val_accuracy: 0.3371\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4140 - accuracy: 0.4998 - val_loss: 1.3127 - val_accuracy: 0.5698\n",
      "Epoch 197/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3618 - accuracy: 0.5168 - val_loss: 1.3460 - val_accuracy: 0.5478\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5620 - accuracy: 0.4775 - val_loss: 1.6345 - val_accuracy: 0.4458\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3730 - accuracy: 0.4887 - val_loss: 1.2503 - val_accuracy: 0.5979\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9682 - accuracy: 0.5591 - val_loss: 1.2124 - val_accuracy: 0.6004\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9448 - accuracy: 0.5782 - val_loss: 1.1323 - val_accuracy: 0.6291\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8503 - accuracy: 0.5901 - val_loss: 1.2070 - val_accuracy: 0.5957\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9344 - accuracy: 0.5848 - val_loss: 1.1815 - val_accuracy: 0.6131\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0519 - accuracy: 0.5542 - val_loss: 1.4645 - val_accuracy: 0.4902\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.3334 - accuracy: 0.4803 - val_loss: 1.4993 - val_accuracy: 0.5098\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0278 - accuracy: 0.5573 - val_loss: 1.2731 - val_accuracy: 0.5829\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8992 - accuracy: 0.5821 - val_loss: 1.1478 - val_accuracy: 0.6149\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8766 - accuracy: 0.5835 - val_loss: 1.3950 - val_accuracy: 0.5112\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4768 - accuracy: 0.5245 - val_loss: 1.4292 - val_accuracy: 0.5211\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5114 - accuracy: 0.5221 - val_loss: 1.4210 - val_accuracy: 0.5226\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3341 - accuracy: 0.5287 - val_loss: 1.3714 - val_accuracy: 0.5385\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0547 - accuracy: 0.5367 - val_loss: 1.2300 - val_accuracy: 0.5918\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8949 - accuracy: 0.5877 - val_loss: 1.1025 - val_accuracy: 0.6337\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8368 - accuracy: 0.6002 - val_loss: 1.2168 - val_accuracy: 0.5897\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0309 - accuracy: 0.5550 - val_loss: 1.3147 - val_accuracy: 0.5442\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9089 - accuracy: 0.5738 - val_loss: 1.1664 - val_accuracy: 0.5961\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8901 - accuracy: 0.5794 - val_loss: 1.1635 - val_accuracy: 0.5975\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9677 - accuracy: 0.5708 - val_loss: 1.2518 - val_accuracy: 0.5734\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0392 - accuracy: 0.5676 - val_loss: 1.0412 - val_accuracy: 0.6480\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9351 - accuracy: 0.5626 - val_loss: 1.1813 - val_accuracy: 0.5936\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8389 - accuracy: 0.5987 - val_loss: 1.0417 - val_accuracy: 0.6487\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8333 - accuracy: 0.5922 - val_loss: 1.0966 - val_accuracy: 0.6391\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8552 - accuracy: 0.5946 - val_loss: 1.1267 - val_accuracy: 0.6263\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1527 - accuracy: 0.5407 - val_loss: 1.3546 - val_accuracy: 0.5524\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9859 - accuracy: 0.5487 - val_loss: 1.1957 - val_accuracy: 0.5833\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3806 - accuracy: 0.5435 - val_loss: 1.3670 - val_accuracy: 0.5439\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0104 - accuracy: 0.5567 - val_loss: 1.3455 - val_accuracy: 0.5286\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0948 - accuracy: 0.5593 - val_loss: 1.2114 - val_accuracy: 0.6057\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8687 - accuracy: 0.5742 - val_loss: 1.0849 - val_accuracy: 0.6359\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9877 - accuracy: 0.5467 - val_loss: 1.2209 - val_accuracy: 0.5829\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9742 - accuracy: 0.5632 - val_loss: 1.2590 - val_accuracy: 0.5751\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0290 - accuracy: 0.5599 - val_loss: 1.1915 - val_accuracy: 0.6124\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8950 - accuracy: 0.5839 - val_loss: 1.1531 - val_accuracy: 0.6142\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0568 - accuracy: 0.5261 - val_loss: 1.2528 - val_accuracy: 0.5613\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7948 - accuracy: 0.5868 - val_loss: 1.1478 - val_accuracy: 0.6163\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8715 - accuracy: 0.5971 - val_loss: 1.1707 - val_accuracy: 0.6160\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8168 - accuracy: 0.6025 - val_loss: 1.0955 - val_accuracy: 0.6302\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8471 - accuracy: 0.6045 - val_loss: 1.2593 - val_accuracy: 0.5780\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5853 - accuracy: 0.5231 - val_loss: 1.4153 - val_accuracy: 0.5339\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1142 - accuracy: 0.5535 - val_loss: 1.1470 - val_accuracy: 0.6252\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9619 - accuracy: 0.4829 - val_loss: 1.3816 - val_accuracy: 0.5307\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1293 - accuracy: 0.5465 - val_loss: 1.1779 - val_accuracy: 0.5933\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9403 - accuracy: 0.5629 - val_loss: 1.4010 - val_accuracy: 0.5449\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0307 - accuracy: 0.5411 - val_loss: 1.2200 - val_accuracy: 0.5744\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3408 - accuracy: 0.5694 - val_loss: 1.8915 - val_accuracy: 0.3854\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2376 - accuracy: 0.4773 - val_loss: 1.3034 - val_accuracy: 0.5520\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0794 - accuracy: 0.5388 - val_loss: 1.5464 - val_accuracy: 0.4796\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8972 - accuracy: 0.5591 - val_loss: 1.1774 - val_accuracy: 0.6021\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9196 - accuracy: 0.5724 - val_loss: 1.1948 - val_accuracy: 0.6032\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8562 - accuracy: 0.5758 - val_loss: 1.1827 - val_accuracy: 0.6039\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8113 - accuracy: 0.5939 - val_loss: 1.1027 - val_accuracy: 0.6288\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3218 - accuracy: 0.5577 - val_loss: 1.1923 - val_accuracy: 0.5904\n",
      "Epoch 253/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0142 - accuracy: 0.5567 - val_loss: 1.7976 - val_accuracy: 0.4224\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9878 - accuracy: 0.5420 - val_loss: 1.1890 - val_accuracy: 0.5890\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7967 - accuracy: 0.5641 - val_loss: 1.4904 - val_accuracy: 0.4952\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.8733 - accuracy: 0.4554 - val_loss: 1.3698 - val_accuracy: 0.5336\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9904 - accuracy: 0.5661 - val_loss: 1.2690 - val_accuracy: 0.5783\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8290 - accuracy: 0.5980 - val_loss: 1.1170 - val_accuracy: 0.6245\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8338 - accuracy: 0.5782 - val_loss: 1.1554 - val_accuracy: 0.6018\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8058 - accuracy: 0.6005 - val_loss: 1.1036 - val_accuracy: 0.6242\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.7713 - accuracy: 0.6062 - val_loss: 1.0928 - val_accuracy: 0.6309\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9823 - accuracy: 0.5827 - val_loss: 1.2096 - val_accuracy: 0.5886\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8124 - accuracy: 0.5937 - val_loss: 1.0721 - val_accuracy: 0.6295\n",
      "\n",
      "Validation 4, fold 2 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8769 - accuracy: 0.0806 - val_loss: 2.8014 - val_accuracy: 0.1080\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7837 - accuracy: 0.1081 - val_loss: 2.6347 - val_accuracy: 0.1751\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 2.5242 - accuracy: 0.1792 - val_loss: 2.2798 - val_accuracy: 0.2366\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4626 - accuracy: 0.1893 - val_loss: 2.1782 - val_accuracy: 0.2863\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1709 - accuracy: 0.2413 - val_loss: 2.1673 - val_accuracy: 0.2899\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1068 - accuracy: 0.2457 - val_loss: 2.0724 - val_accuracy: 0.2810\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0777 - accuracy: 0.2663 - val_loss: 1.9929 - val_accuracy: 0.3005\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0909 - accuracy: 0.2677 - val_loss: 2.1131 - val_accuracy: 0.2416\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8857 - accuracy: 0.3029 - val_loss: 1.8126 - val_accuracy: 0.3890\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9354 - accuracy: 0.3190 - val_loss: 2.0061 - val_accuracy: 0.3204\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1832 - accuracy: 0.2931 - val_loss: 2.0521 - val_accuracy: 0.3233\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9780 - accuracy: 0.3227 - val_loss: 1.8699 - val_accuracy: 0.3428\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8343 - accuracy: 0.3440 - val_loss: 1.8572 - val_accuracy: 0.3581\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8321 - accuracy: 0.3349 - val_loss: 1.8041 - val_accuracy: 0.3794\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7106 - accuracy: 0.3790 - val_loss: 1.7323 - val_accuracy: 0.3964\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6104 - accuracy: 0.3814 - val_loss: 1.6707 - val_accuracy: 0.4377\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6531 - accuracy: 0.3962 - val_loss: 1.7133 - val_accuracy: 0.4590\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6703 - accuracy: 0.4156 - val_loss: 1.8075 - val_accuracy: 0.4036\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5116 - accuracy: 0.4167 - val_loss: 1.5662 - val_accuracy: 0.4757\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5594 - accuracy: 0.4273 - val_loss: 1.5946 - val_accuracy: 0.4561\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.5531 - accuracy: 0.4130 - val_loss: 1.6554 - val_accuracy: 0.4526\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3988 - accuracy: 0.4343 - val_loss: 1.7725 - val_accuracy: 0.4089\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3903 - accuracy: 0.4337 - val_loss: 1.6062 - val_accuracy: 0.4355\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3392 - accuracy: 0.4441 - val_loss: 1.6073 - val_accuracy: 0.4465\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3221 - accuracy: 0.4448 - val_loss: 1.5405 - val_accuracy: 0.4888\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3180 - accuracy: 0.4430 - val_loss: 1.5785 - val_accuracy: 0.4639\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3407 - accuracy: 0.4464 - val_loss: 1.9030 - val_accuracy: 0.3787\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2529 - accuracy: 0.4606 - val_loss: 1.4603 - val_accuracy: 0.5144\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2490 - accuracy: 0.4711 - val_loss: 1.4665 - val_accuracy: 0.4970\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3138 - accuracy: 0.4574 - val_loss: 1.4624 - val_accuracy: 0.5002\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2601 - accuracy: 0.4725 - val_loss: 1.6442 - val_accuracy: 0.4487\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1954 - accuracy: 0.4787 - val_loss: 1.4176 - val_accuracy: 0.5332\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1784 - accuracy: 0.4830 - val_loss: 1.4150 - val_accuracy: 0.5442\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3334 - accuracy: 0.4483 - val_loss: 1.4669 - val_accuracy: 0.4853\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1779 - accuracy: 0.4900 - val_loss: 1.5450 - val_accuracy: 0.4966\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1848 - accuracy: 0.4883 - val_loss: 1.3642 - val_accuracy: 0.5503\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1161 - accuracy: 0.5047 - val_loss: 1.3696 - val_accuracy: 0.5485\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0993 - accuracy: 0.5099 - val_loss: 1.3204 - val_accuracy: 0.5510\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1652 - accuracy: 0.4991 - val_loss: 1.3595 - val_accuracy: 0.5503\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1068 - accuracy: 0.5082 - val_loss: 1.3066 - val_accuracy: 0.5670\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1392 - accuracy: 0.5087 - val_loss: 1.5100 - val_accuracy: 0.4835\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2140 - accuracy: 0.4851 - val_loss: 1.4026 - val_accuracy: 0.5396\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2952 - accuracy: 0.4876 - val_loss: 1.4298 - val_accuracy: 0.5329\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1735 - accuracy: 0.5048 - val_loss: 1.4230 - val_accuracy: 0.5211\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0756 - accuracy: 0.5190 - val_loss: 1.7091 - val_accuracy: 0.4462\n",
      "Epoch 46/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1546 - accuracy: 0.4832 - val_loss: 1.4006 - val_accuracy: 0.5265\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2223 - accuracy: 0.5019 - val_loss: 1.5633 - val_accuracy: 0.4828\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1685 - accuracy: 0.5036 - val_loss: 1.2791 - val_accuracy: 0.5776\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1759 - accuracy: 0.5123 - val_loss: 1.3090 - val_accuracy: 0.5641\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0957 - accuracy: 0.5196 - val_loss: 1.2698 - val_accuracy: 0.5790\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9943 - accuracy: 0.5263 - val_loss: 1.2827 - val_accuracy: 0.5591\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2919 - accuracy: 0.4870 - val_loss: 1.3585 - val_accuracy: 0.5393\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0653 - accuracy: 0.5146 - val_loss: 1.3180 - val_accuracy: 0.5453\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0668 - accuracy: 0.5266 - val_loss: 1.3264 - val_accuracy: 0.5456\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1011 - accuracy: 0.5185 - val_loss: 1.2053 - val_accuracy: 0.5904\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0315 - accuracy: 0.5420 - val_loss: 1.2489 - val_accuracy: 0.5798\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0263 - accuracy: 0.5349 - val_loss: 1.2366 - val_accuracy: 0.5794\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9799 - accuracy: 0.5428 - val_loss: 1.2744 - val_accuracy: 0.5705\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9324 - accuracy: 0.5528 - val_loss: 1.2063 - val_accuracy: 0.5808\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5941 - accuracy: 0.5126 - val_loss: 1.6789 - val_accuracy: 0.4547\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4286 - accuracy: 0.4456 - val_loss: 1.6177 - val_accuracy: 0.4700\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2010 - accuracy: 0.4944 - val_loss: 1.3891 - val_accuracy: 0.5215\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0632 - accuracy: 0.5072 - val_loss: 1.2893 - val_accuracy: 0.5520\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0921 - accuracy: 0.5207 - val_loss: 1.3533 - val_accuracy: 0.5361\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0238 - accuracy: 0.5297 - val_loss: 1.9352 - val_accuracy: 0.4529\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0908 - accuracy: 0.5107 - val_loss: 1.2579 - val_accuracy: 0.5691\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0494 - accuracy: 0.5303 - val_loss: 1.2703 - val_accuracy: 0.5755\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9367 - accuracy: 0.5523 - val_loss: 1.2140 - val_accuracy: 0.5758\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0998 - accuracy: 0.5325 - val_loss: 1.3281 - val_accuracy: 0.5496\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0260 - accuracy: 0.5228 - val_loss: 1.2666 - val_accuracy: 0.5755\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0364 - accuracy: 0.5303 - val_loss: 1.3108 - val_accuracy: 0.5517\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9605 - accuracy: 0.5464 - val_loss: 1.1394 - val_accuracy: 0.6181\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.4963 - accuracy: 0.5193 - val_loss: 1.4843 - val_accuracy: 0.4984\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 2.0172 - accuracy: 0.4077 - val_loss: 1.5474 - val_accuracy: 0.4806\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5137 - accuracy: 0.4770 - val_loss: 1.3329 - val_accuracy: 0.5599\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2574 - accuracy: 0.5025 - val_loss: 1.3286 - val_accuracy: 0.5456\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1188 - accuracy: 0.5124 - val_loss: 1.3260 - val_accuracy: 0.5453\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1191 - accuracy: 0.5171 - val_loss: 1.3422 - val_accuracy: 0.5513\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0221 - accuracy: 0.5279 - val_loss: 1.1679 - val_accuracy: 0.6007\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9793 - accuracy: 0.5377 - val_loss: 1.3392 - val_accuracy: 0.5581\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0334 - accuracy: 0.5313 - val_loss: 1.2072 - val_accuracy: 0.5734\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9651 - accuracy: 0.5457 - val_loss: 1.3183 - val_accuracy: 0.5574\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1750 - accuracy: 0.5282 - val_loss: 1.3002 - val_accuracy: 0.5464\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9953 - accuracy: 0.5239 - val_loss: 1.2415 - val_accuracy: 0.5780\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8996 - accuracy: 0.5579 - val_loss: 1.2042 - val_accuracy: 0.5876\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9400 - accuracy: 0.5454 - val_loss: 1.1902 - val_accuracy: 0.5989\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1136 - accuracy: 0.5341 - val_loss: 1.2202 - val_accuracy: 0.5861\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0272 - accuracy: 0.5414 - val_loss: 1.2504 - val_accuracy: 0.5769\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9275 - accuracy: 0.5540 - val_loss: 1.2113 - val_accuracy: 0.5798\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0326 - accuracy: 0.5225 - val_loss: 1.3706 - val_accuracy: 0.5357\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0718 - accuracy: 0.5369 - val_loss: 1.2242 - val_accuracy: 0.5844\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0137 - accuracy: 0.5571 - val_loss: 1.7368 - val_accuracy: 0.5208\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9791 - accuracy: 0.5542 - val_loss: 1.1873 - val_accuracy: 0.6036\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9822 - accuracy: 0.5448 - val_loss: 1.2964 - val_accuracy: 0.5698\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0181 - accuracy: 0.5286 - val_loss: 1.1878 - val_accuracy: 0.5886\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9189 - accuracy: 0.5466 - val_loss: 1.2171 - val_accuracy: 0.5858\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8921 - accuracy: 0.5636 - val_loss: 1.1908 - val_accuracy: 0.5947\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9505 - accuracy: 0.5555 - val_loss: 1.4116 - val_accuracy: 0.5552\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1135 - accuracy: 0.5365 - val_loss: 1.4495 - val_accuracy: 0.5311\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9601 - accuracy: 0.5390 - val_loss: 1.1896 - val_accuracy: 0.6036\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9067 - accuracy: 0.5592 - val_loss: 1.1751 - val_accuracy: 0.6060\n",
      "Epoch 102/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0216 - accuracy: 0.5476 - val_loss: 1.1653 - val_accuracy: 0.6142\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0602 - accuracy: 0.5484 - val_loss: 1.3507 - val_accuracy: 0.5538\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9002 - accuracy: 0.5786 - val_loss: 1.1542 - val_accuracy: 0.6028\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9882 - accuracy: 0.5530 - val_loss: 1.1903 - val_accuracy: 0.5918\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0394 - accuracy: 0.5374 - val_loss: 1.3225 - val_accuracy: 0.5577\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2963 - accuracy: 0.5020 - val_loss: 1.4086 - val_accuracy: 0.5336\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0475 - accuracy: 0.5293 - val_loss: 1.2222 - val_accuracy: 0.5901\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9119 - accuracy: 0.5615 - val_loss: 1.1794 - val_accuracy: 0.6067\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8405 - accuracy: 0.5767 - val_loss: 1.1491 - val_accuracy: 0.6039\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9135 - accuracy: 0.5601 - val_loss: 1.2195 - val_accuracy: 0.5893\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0915 - accuracy: 0.5438 - val_loss: 1.2385 - val_accuracy: 0.5634\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1352 - accuracy: 0.5322 - val_loss: 1.2120 - val_accuracy: 0.5801\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9634 - accuracy: 0.5444 - val_loss: 1.4602 - val_accuracy: 0.5229\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.2072 - accuracy: 0.5093 - val_loss: 1.2209 - val_accuracy: 0.5837\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8748 - accuracy: 0.5597 - val_loss: 1.2291 - val_accuracy: 0.5762\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0824 - accuracy: 0.5314 - val_loss: 1.8330 - val_accuracy: 0.4394\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1456 - accuracy: 0.5077 - val_loss: 1.4435 - val_accuracy: 0.5485\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1110 - accuracy: 0.5325 - val_loss: 1.4000 - val_accuracy: 0.5492\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9103 - accuracy: 0.5663 - val_loss: 1.1743 - val_accuracy: 0.6053\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8604 - accuracy: 0.5687 - val_loss: 1.1501 - val_accuracy: 0.6167\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9503 - accuracy: 0.5617 - val_loss: 1.2236 - val_accuracy: 0.5751\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8693 - accuracy: 0.5745 - val_loss: 1.1257 - val_accuracy: 0.6149\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8224 - accuracy: 0.5893 - val_loss: 1.1704 - val_accuracy: 0.5961\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8157 - accuracy: 0.5772 - val_loss: 1.1132 - val_accuracy: 0.6252\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3332 - accuracy: 0.5329 - val_loss: 1.3441 - val_accuracy: 0.5577\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3326 - accuracy: 0.5151 - val_loss: 1.2081 - val_accuracy: 0.5876\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0301 - accuracy: 0.5366 - val_loss: 1.2485 - val_accuracy: 0.5730\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9766 - accuracy: 0.5415 - val_loss: 1.2317 - val_accuracy: 0.5897\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8947 - accuracy: 0.5639 - val_loss: 1.5991 - val_accuracy: 0.4725\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0464 - accuracy: 0.5328 - val_loss: 1.4101 - val_accuracy: 0.5453\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9368 - accuracy: 0.5573 - val_loss: 1.2018 - val_accuracy: 0.5908\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8619 - accuracy: 0.5746 - val_loss: 1.1642 - val_accuracy: 0.5915\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.8707 - accuracy: 0.5758 - val_loss: 1.1029 - val_accuracy: 0.6266\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8125 - accuracy: 0.5909 - val_loss: 1.0999 - val_accuracy: 0.6313\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8544 - accuracy: 0.5883 - val_loss: 1.2141 - val_accuracy: 0.5858\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8477 - accuracy: 0.5907 - val_loss: 1.1391 - val_accuracy: 0.6121\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8904 - accuracy: 0.5679 - val_loss: 1.2962 - val_accuracy: 0.5641\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9706 - accuracy: 0.5685 - val_loss: 1.1891 - val_accuracy: 0.6018\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0535 - accuracy: 0.5488 - val_loss: 1.3076 - val_accuracy: 0.5599\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8784 - accuracy: 0.5810 - val_loss: 1.1578 - val_accuracy: 0.6171\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1320 - accuracy: 0.5335 - val_loss: 1.4575 - val_accuracy: 0.5140\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2450 - accuracy: 0.5340 - val_loss: 1.2174 - val_accuracy: 0.5954\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9619 - accuracy: 0.5590 - val_loss: 1.4794 - val_accuracy: 0.5307\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8664 - accuracy: 0.5769 - val_loss: 1.2109 - val_accuracy: 0.5897\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9484 - accuracy: 0.5582 - val_loss: 1.1755 - val_accuracy: 0.6060\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7959 - accuracy: 0.5994 - val_loss: 1.2629 - val_accuracy: 0.5925\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9151 - accuracy: 0.5780 - val_loss: 1.2549 - val_accuracy: 0.5655\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0308 - accuracy: 0.5014 - val_loss: 1.3997 - val_accuracy: 0.5254\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3183 - accuracy: 0.4800 - val_loss: 1.3850 - val_accuracy: 0.5353\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2649 - accuracy: 0.5070 - val_loss: 1.2632 - val_accuracy: 0.5918\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3173 - accuracy: 0.5177 - val_loss: 1.4123 - val_accuracy: 0.5115\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0665 - accuracy: 0.5300 - val_loss: 1.1710 - val_accuracy: 0.6014\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0239 - accuracy: 0.5427 - val_loss: 1.2451 - val_accuracy: 0.5950\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8907 - accuracy: 0.5664 - val_loss: 1.1375 - val_accuracy: 0.6227\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8250 - accuracy: 0.5947 - val_loss: 1.2800 - val_accuracy: 0.5776\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8654 - accuracy: 0.5840 - val_loss: 1.1699 - val_accuracy: 0.6110\n",
      "Epoch 158/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8222 - accuracy: 0.5811 - val_loss: 1.0873 - val_accuracy: 0.6330\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0147 - accuracy: 0.5729 - val_loss: 1.2835 - val_accuracy: 0.5616\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0076 - accuracy: 0.5433 - val_loss: 1.1437 - val_accuracy: 0.6075\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9911 - accuracy: 0.5457 - val_loss: 1.2424 - val_accuracy: 0.5915\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8593 - accuracy: 0.5777 - val_loss: 1.1673 - val_accuracy: 0.6028\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8513 - accuracy: 0.5933 - val_loss: 1.2881 - val_accuracy: 0.5901\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4977 - accuracy: 0.5265 - val_loss: 1.3214 - val_accuracy: 0.5570\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3415 - accuracy: 0.5115 - val_loss: 1.1990 - val_accuracy: 0.6036\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9548 - accuracy: 0.5624 - val_loss: 1.2687 - val_accuracy: 0.5854\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0068 - accuracy: 0.5489 - val_loss: 1.3541 - val_accuracy: 0.5187\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8933 - accuracy: 0.5646 - val_loss: 1.1363 - val_accuracy: 0.6199\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8024 - accuracy: 0.5873 - val_loss: 1.1793 - val_accuracy: 0.5979\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8818 - accuracy: 0.5829 - val_loss: 1.3802 - val_accuracy: 0.5012\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8309 - accuracy: 0.5795 - val_loss: 1.0814 - val_accuracy: 0.6256\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9170 - accuracy: 0.5781 - val_loss: 1.1512 - val_accuracy: 0.6039\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8471 - accuracy: 0.5809 - val_loss: 1.1716 - val_accuracy: 0.6007\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9552 - accuracy: 0.5610 - val_loss: 1.4159 - val_accuracy: 0.5265\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8618 - accuracy: 0.5722 - val_loss: 1.2305 - val_accuracy: 0.5815\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8945 - accuracy: 0.5677 - val_loss: 1.1747 - val_accuracy: 0.6082\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9092 - accuracy: 0.5847 - val_loss: 1.2259 - val_accuracy: 0.5787\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8154 - accuracy: 0.5857 - val_loss: 1.0951 - val_accuracy: 0.6270\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1946 - accuracy: 0.5300 - val_loss: 1.3602 - val_accuracy: 0.5631\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0437 - accuracy: 0.5497 - val_loss: 1.2483 - val_accuracy: 0.5812\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2829 - accuracy: 0.5375 - val_loss: 1.2874 - val_accuracy: 0.5677\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8785 - accuracy: 0.5818 - val_loss: 1.1662 - val_accuracy: 0.6117\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9173 - accuracy: 0.5781 - val_loss: 1.4230 - val_accuracy: 0.5268\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0681 - accuracy: 0.5393 - val_loss: 1.1548 - val_accuracy: 0.6124\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9676 - accuracy: 0.5782 - val_loss: 1.1871 - val_accuracy: 0.6075\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9108 - accuracy: 0.5683 - val_loss: 1.2640 - val_accuracy: 0.5755\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9406 - accuracy: 0.5757 - val_loss: 1.1059 - val_accuracy: 0.6348\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9339 - accuracy: 0.5641 - val_loss: 1.0898 - val_accuracy: 0.6192\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8066 - accuracy: 0.6013 - val_loss: 1.0779 - val_accuracy: 0.6341\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8190 - accuracy: 0.6025 - val_loss: 1.1927 - val_accuracy: 0.6039\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7460 - accuracy: 0.6137 - val_loss: 1.1248 - val_accuracy: 0.6089\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8171 - accuracy: 0.5884 - val_loss: 1.2521 - val_accuracy: 0.5798\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9496 - accuracy: 0.5921 - val_loss: 1.3379 - val_accuracy: 0.5577\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0650 - accuracy: 0.5337 - val_loss: 1.2318 - val_accuracy: 0.5858\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0200 - accuracy: 0.5617 - val_loss: 1.2590 - val_accuracy: 0.5780\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1141 - accuracy: 0.5257 - val_loss: 1.2676 - val_accuracy: 0.5702\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9771 - accuracy: 0.5615 - val_loss: 1.2259 - val_accuracy: 0.6092\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8489 - accuracy: 0.5917 - val_loss: 1.0961 - val_accuracy: 0.6220\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7936 - accuracy: 0.6004 - val_loss: 1.1808 - val_accuracy: 0.6043\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9933 - accuracy: 0.5498 - val_loss: 1.2758 - val_accuracy: 0.5663\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8326 - accuracy: 0.5881 - val_loss: 1.1158 - val_accuracy: 0.6128\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0006 - accuracy: 0.5536 - val_loss: 1.1945 - val_accuracy: 0.6071\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9531 - accuracy: 0.5492 - val_loss: 1.1075 - val_accuracy: 0.6369\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8656 - accuracy: 0.5917 - val_loss: 1.2039 - val_accuracy: 0.5808\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9024 - accuracy: 0.5708 - val_loss: 1.1549 - val_accuracy: 0.5986\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7798 - accuracy: 0.5990 - val_loss: 1.1089 - val_accuracy: 0.6195\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8833 - accuracy: 0.5889 - val_loss: 1.1709 - val_accuracy: 0.5957\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9236 - accuracy: 0.5785 - val_loss: 1.7632 - val_accuracy: 0.4899\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1050 - accuracy: 0.5135 - val_loss: 1.2800 - val_accuracy: 0.5734\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2293 - accuracy: 0.5359 - val_loss: 1.2237 - val_accuracy: 0.5918\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9430 - accuracy: 0.5606 - val_loss: 1.2671 - val_accuracy: 0.5549\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9809 - accuracy: 0.5654 - val_loss: 1.1188 - val_accuracy: 0.6192\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0087 - accuracy: 0.5536 - val_loss: 1.1525 - val_accuracy: 0.6149\n",
      "Epoch 214/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0689 - accuracy: 0.5761 - val_loss: 1.1642 - val_accuracy: 0.6043\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9804 - accuracy: 0.5720 - val_loss: 1.1451 - val_accuracy: 0.6085\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9125 - accuracy: 0.5781 - val_loss: 1.2246 - val_accuracy: 0.5858\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8771 - accuracy: 0.5992 - val_loss: 1.2232 - val_accuracy: 0.5911\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8163 - accuracy: 0.5900 - val_loss: 1.1287 - val_accuracy: 0.6131\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7686 - accuracy: 0.6006 - val_loss: 1.0753 - val_accuracy: 0.6430\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7960 - accuracy: 0.6009 - val_loss: 1.1852 - val_accuracy: 0.6007\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7654 - accuracy: 0.6075 - val_loss: 1.0954 - val_accuracy: 0.6394\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7583 - accuracy: 0.6036 - val_loss: 1.0156 - val_accuracy: 0.6519\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7795 - accuracy: 0.6109 - val_loss: 1.1102 - val_accuracy: 0.6249\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7436 - accuracy: 0.6237 - val_loss: 1.3396 - val_accuracy: 0.5545\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8239 - accuracy: 0.5937 - val_loss: 1.1118 - val_accuracy: 0.6352\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8296 - accuracy: 0.6043 - val_loss: 1.3234 - val_accuracy: 0.5538\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0483 - accuracy: 0.5448 - val_loss: 1.1231 - val_accuracy: 0.6188\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9423 - accuracy: 0.5768 - val_loss: 1.4158 - val_accuracy: 0.5368\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9030 - accuracy: 0.5789 - val_loss: 1.1485 - val_accuracy: 0.6263\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2299 - accuracy: 0.5562 - val_loss: 1.1895 - val_accuracy: 0.6142\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8794 - accuracy: 0.5863 - val_loss: 1.0757 - val_accuracy: 0.6387\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1385 - accuracy: 0.5630 - val_loss: 1.1938 - val_accuracy: 0.5940\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9011 - accuracy: 0.5831 - val_loss: 1.0932 - val_accuracy: 0.6426\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8003 - accuracy: 0.5966 - val_loss: 1.0641 - val_accuracy: 0.6487\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7780 - accuracy: 0.6167 - val_loss: 1.0581 - val_accuracy: 0.6586\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8615 - accuracy: 0.5910 - val_loss: 1.1955 - val_accuracy: 0.6039\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8460 - accuracy: 0.5982 - val_loss: 1.1365 - val_accuracy: 0.6355\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1873 - accuracy: 0.5282 - val_loss: 1.1572 - val_accuracy: 0.6334\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8189 - accuracy: 0.5963 - val_loss: 1.2484 - val_accuracy: 0.5798\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8622 - accuracy: 0.5926 - val_loss: 1.0548 - val_accuracy: 0.6515\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7367 - accuracy: 0.6250 - val_loss: 1.1000 - val_accuracy: 0.6416\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7227 - accuracy: 0.6269 - val_loss: 1.0311 - val_accuracy: 0.6554\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7564 - accuracy: 0.6117 - val_loss: 1.0688 - val_accuracy: 0.6391\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8785 - accuracy: 0.5731 - val_loss: 1.0706 - val_accuracy: 0.6465\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8433 - accuracy: 0.5916 - val_loss: 1.1298 - val_accuracy: 0.6192\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7510 - accuracy: 0.6072 - val_loss: 1.1285 - val_accuracy: 0.6419\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2244 - accuracy: 0.5466 - val_loss: 1.2051 - val_accuracy: 0.6128\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8941 - accuracy: 0.5799 - val_loss: 1.2262 - val_accuracy: 0.5993\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8356 - accuracy: 0.5914 - val_loss: 1.0777 - val_accuracy: 0.6529\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8291 - accuracy: 0.6067 - val_loss: 1.1130 - val_accuracy: 0.6270\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8372 - accuracy: 0.6028 - val_loss: 1.1907 - val_accuracy: 0.6000\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7873 - accuracy: 0.6175 - val_loss: 1.0884 - val_accuracy: 0.6238\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8187 - accuracy: 0.6107 - val_loss: 1.0976 - val_accuracy: 0.6579\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9614 - accuracy: 0.5975 - val_loss: 1.4653 - val_accuracy: 0.5378\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8233 - accuracy: 0.5980 - val_loss: 1.0911 - val_accuracy: 0.6284\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1276 - accuracy: 0.5888 - val_loss: 1.1091 - val_accuracy: 0.6309\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0617 - accuracy: 0.5423 - val_loss: 1.2306 - val_accuracy: 0.5972\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8554 - accuracy: 0.5912 - val_loss: 1.1727 - val_accuracy: 0.6178\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8991 - accuracy: 0.5999 - val_loss: 1.0782 - val_accuracy: 0.6497\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8493 - accuracy: 0.6013 - val_loss: 1.2691 - val_accuracy: 0.5904\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0255 - accuracy: 0.5927 - val_loss: 1.4775 - val_accuracy: 0.4934\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8053 - accuracy: 0.5920 - val_loss: 1.1355 - val_accuracy: 0.6302\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8287 - accuracy: 0.6042 - val_loss: 1.1228 - val_accuracy: 0.6309\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8358 - accuracy: 0.5994 - val_loss: 1.2121 - val_accuracy: 0.6149\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7334 - accuracy: 0.6243 - val_loss: 1.2218 - val_accuracy: 0.5936\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7404 - accuracy: 0.6164 - val_loss: 1.0312 - val_accuracy: 0.6604\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7081 - accuracy: 0.6340 - val_loss: 1.1101 - val_accuracy: 0.6362\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7711 - accuracy: 0.6107 - val_loss: 1.1075 - val_accuracy: 0.6291\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8087 - accuracy: 0.6097 - val_loss: 1.1065 - val_accuracy: 0.6330\n",
      "Epoch 270/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8675 - accuracy: 0.5757 - val_loss: 1.1802 - val_accuracy: 0.6192\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7625 - accuracy: 0.6227 - val_loss: 1.0444 - val_accuracy: 0.6494\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7724 - accuracy: 0.6155 - val_loss: 1.0518 - val_accuracy: 0.6593\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8718 - accuracy: 0.5384 - val_loss: 1.2305 - val_accuracy: 0.5993\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0070 - accuracy: 0.5740 - val_loss: 1.1557 - val_accuracy: 0.6121\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8761 - accuracy: 0.5988 - val_loss: 1.1699 - val_accuracy: 0.6014\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7435 - accuracy: 0.6212 - val_loss: 1.0637 - val_accuracy: 0.6526\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7738 - accuracy: 0.6118 - val_loss: 1.1094 - val_accuracy: 0.6291\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7522 - accuracy: 0.6075 - val_loss: 1.0987 - val_accuracy: 0.6309\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7639 - accuracy: 0.6136 - val_loss: 0.9995 - val_accuracy: 0.6671\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.6948 - accuracy: 0.6290 - val_loss: 1.0051 - val_accuracy: 0.6639\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8714 - accuracy: 0.6099 - val_loss: 1.0557 - val_accuracy: 0.6451\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0192 - accuracy: 0.5699 - val_loss: 1.1358 - val_accuracy: 0.6174\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8606 - accuracy: 0.5925 - val_loss: 1.1111 - val_accuracy: 0.6313\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8253 - accuracy: 0.6011 - val_loss: 1.0920 - val_accuracy: 0.6405\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7057 - accuracy: 0.6282 - val_loss: 0.9922 - val_accuracy: 0.6718\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1849 - accuracy: 0.5714 - val_loss: 1.2910 - val_accuracy: 0.5726\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3091 - accuracy: 0.5429 - val_loss: 1.4061 - val_accuracy: 0.5492\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7907 - accuracy: 0.4968 - val_loss: 1.2492 - val_accuracy: 0.5925\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9691 - accuracy: 0.5665 - val_loss: 1.1380 - val_accuracy: 0.6185\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8900 - accuracy: 0.5845 - val_loss: 1.1449 - val_accuracy: 0.6210\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8918 - accuracy: 0.5842 - val_loss: 1.0788 - val_accuracy: 0.6366\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9105 - accuracy: 0.6012 - val_loss: 1.1880 - val_accuracy: 0.6181\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9045 - accuracy: 0.5972 - val_loss: 1.1980 - val_accuracy: 0.5993\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7975 - accuracy: 0.6132 - val_loss: 1.0233 - val_accuracy: 0.6618\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8071 - accuracy: 0.6170 - val_loss: 1.0539 - val_accuracy: 0.6519\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7891 - accuracy: 0.6102 - val_loss: 1.0625 - val_accuracy: 0.6423\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8311 - accuracy: 0.5845 - val_loss: 1.0996 - val_accuracy: 0.6337\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8227 - accuracy: 0.5921 - val_loss: 1.2680 - val_accuracy: 0.5893\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7941 - accuracy: 0.5966 - val_loss: 0.9916 - val_accuracy: 0.6813\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7188 - accuracy: 0.6253 - val_loss: 1.0263 - val_accuracy: 0.6515\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0621 - accuracy: 0.5686 - val_loss: 1.4211 - val_accuracy: 0.5499\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9423 - accuracy: 0.5646 - val_loss: 1.1500 - val_accuracy: 0.6160\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8823 - accuracy: 0.5829 - val_loss: 1.0876 - val_accuracy: 0.6419\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7927 - accuracy: 0.6035 - val_loss: 1.1016 - val_accuracy: 0.6291\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7430 - accuracy: 0.6192 - val_loss: 1.0531 - val_accuracy: 0.6458\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8562 - accuracy: 0.5965 - val_loss: 1.2188 - val_accuracy: 0.5787\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9914 - accuracy: 0.5802 - val_loss: 1.1628 - val_accuracy: 0.5996\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7835 - accuracy: 0.6052 - val_loss: 1.0842 - val_accuracy: 0.6387\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8804 - accuracy: 0.5990 - val_loss: 1.1524 - val_accuracy: 0.6064\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3038 - accuracy: 0.5750 - val_loss: 1.2709 - val_accuracy: 0.5826\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8403 - accuracy: 0.5211 - val_loss: 1.2632 - val_accuracy: 0.5751\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0981 - accuracy: 0.5549 - val_loss: 1.0796 - val_accuracy: 0.6419\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9642 - accuracy: 0.5871 - val_loss: 1.0455 - val_accuracy: 0.6554\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7803 - accuracy: 0.6083 - val_loss: 1.0906 - val_accuracy: 0.6384\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9329 - accuracy: 0.5758 - val_loss: 1.1334 - val_accuracy: 0.6213\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8610 - accuracy: 0.6004 - val_loss: 1.3588 - val_accuracy: 0.5357\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8680 - accuracy: 0.5976 - val_loss: 0.9714 - val_accuracy: 0.6813\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7624 - accuracy: 0.6219 - val_loss: 1.0799 - val_accuracy: 0.6451\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7645 - accuracy: 0.6191 - val_loss: 1.0307 - val_accuracy: 0.6714\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7281 - accuracy: 0.6251 - val_loss: 1.0565 - val_accuracy: 0.6430\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7941 - accuracy: 0.6044 - val_loss: 1.0251 - val_accuracy: 0.6682\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7537 - accuracy: 0.6167 - val_loss: 1.1300 - val_accuracy: 0.6306\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7002 - accuracy: 0.6279 - val_loss: 0.9847 - val_accuracy: 0.6750\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8682 - accuracy: 0.6145 - val_loss: 1.2106 - val_accuracy: 0.6149\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9387 - accuracy: 0.5929 - val_loss: 1.2642 - val_accuracy: 0.5794\n",
      "Epoch 326/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0515 - accuracy: 0.4129 - val_loss: 1.4985 - val_accuracy: 0.4895\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4126 - accuracy: 0.5107 - val_loss: 1.1682 - val_accuracy: 0.6199\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2945 - accuracy: 0.5710 - val_loss: 1.2734 - val_accuracy: 0.5869\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0836 - accuracy: 0.5798 - val_loss: 1.2545 - val_accuracy: 0.6039\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9304 - accuracy: 0.5877 - val_loss: 1.0618 - val_accuracy: 0.6501\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8016 - accuracy: 0.6098 - val_loss: 1.1476 - val_accuracy: 0.6366\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4376 - accuracy: 0.5407 - val_loss: 1.3508 - val_accuracy: 0.5584\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8938 - accuracy: 0.5825 - val_loss: 1.0680 - val_accuracy: 0.6494\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7733 - accuracy: 0.6163 - val_loss: 1.1074 - val_accuracy: 0.6366\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9866 - accuracy: 0.5678 - val_loss: 1.1939 - val_accuracy: 0.6160\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0419 - accuracy: 0.5607 - val_loss: 1.1774 - val_accuracy: 0.6124\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8780 - accuracy: 0.5856 - val_loss: 1.2121 - val_accuracy: 0.5947\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8475 - accuracy: 0.6067 - val_loss: 1.0167 - val_accuracy: 0.6661\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7830 - accuracy: 0.6168 - val_loss: 1.2087 - val_accuracy: 0.6103\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8355 - accuracy: 0.6017 - val_loss: 1.0127 - val_accuracy: 0.6657\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8106 - accuracy: 0.6184 - val_loss: 1.0943 - val_accuracy: 0.6419\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7343 - accuracy: 0.6243 - val_loss: 1.0248 - val_accuracy: 0.6636\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7851 - accuracy: 0.6241 - val_loss: 1.1337 - val_accuracy: 0.6213\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7574 - accuracy: 0.6231 - val_loss: 1.0800 - val_accuracy: 0.6341\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0112 - accuracy: 0.5640 - val_loss: 1.2782 - val_accuracy: 0.5748\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0847 - accuracy: 0.5354 - val_loss: 1.1402 - val_accuracy: 0.6252\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2918 - accuracy: 0.5917 - val_loss: 1.1845 - val_accuracy: 0.6085\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4820 - accuracy: 0.4757 - val_loss: 1.4488 - val_accuracy: 0.5229\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6764 - accuracy: 0.4656 - val_loss: 1.5433 - val_accuracy: 0.4874\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4505 - accuracy: 0.4929 - val_loss: 1.2999 - val_accuracy: 0.5737\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6316 - accuracy: 0.4932 - val_loss: 1.3795 - val_accuracy: 0.5353\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1303 - accuracy: 0.5292 - val_loss: 1.4584 - val_accuracy: 0.5268\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1003 - accuracy: 0.5471 - val_loss: 1.2414 - val_accuracy: 0.5989\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9955 - accuracy: 0.5714 - val_loss: 1.0964 - val_accuracy: 0.6512\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8423 - accuracy: 0.6119 - val_loss: 1.1445 - val_accuracy: 0.6394\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7907 - accuracy: 0.6140 - val_loss: 1.0896 - val_accuracy: 0.6455\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7793 - accuracy: 0.6281 - val_loss: 0.9624 - val_accuracy: 0.6870\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8658 - accuracy: 0.6083 - val_loss: 1.1538 - val_accuracy: 0.6309\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0019 - accuracy: 0.5807 - val_loss: 1.1653 - val_accuracy: 0.6110\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9109 - accuracy: 0.5898 - val_loss: 1.3115 - val_accuracy: 0.5702\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8202 - accuracy: 0.6060 - val_loss: 1.3430 - val_accuracy: 0.5776\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8079 - accuracy: 0.6028 - val_loss: 1.0707 - val_accuracy: 0.6568\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3131 - accuracy: 0.5420 - val_loss: 1.3924 - val_accuracy: 0.5414\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2359 - accuracy: 0.5372 - val_loss: 1.2507 - val_accuracy: 0.6085\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8605 - accuracy: 0.5216 - val_loss: 1.4369 - val_accuracy: 0.5343\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2550 - accuracy: 0.5503 - val_loss: 1.2047 - val_accuracy: 0.6135\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9958 - accuracy: 0.5713 - val_loss: 1.1197 - val_accuracy: 0.6348\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8689 - accuracy: 0.5949 - val_loss: 1.0985 - val_accuracy: 0.6316\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8930 - accuracy: 0.6041 - val_loss: 1.1476 - val_accuracy: 0.6298\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0660 - accuracy: 0.5937 - val_loss: 1.3953 - val_accuracy: 0.5609\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1482 - accuracy: 0.5304 - val_loss: 1.1378 - val_accuracy: 0.6430\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8244 - accuracy: 0.6005 - val_loss: 1.0775 - val_accuracy: 0.6433\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7907 - accuracy: 0.6155 - val_loss: 1.1395 - val_accuracy: 0.6213\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8342 - accuracy: 0.6089 - val_loss: 1.0558 - val_accuracy: 0.6472\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7562 - accuracy: 0.6193 - val_loss: 1.0354 - val_accuracy: 0.6618\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8385 - accuracy: 0.6012 - val_loss: 1.2673 - val_accuracy: 0.5883\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0347 - accuracy: 0.5698 - val_loss: 1.1737 - val_accuracy: 0.6135\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4651 - accuracy: 0.4944 - val_loss: 1.3870 - val_accuracy: 0.5336\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3595 - accuracy: 0.4923 - val_loss: 1.2705 - val_accuracy: 0.5503\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9457 - accuracy: 0.5643 - val_loss: 1.2176 - val_accuracy: 0.5925\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8568 - accuracy: 0.5888 - val_loss: 1.1789 - val_accuracy: 0.6025\n",
      "Epoch 382/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3832 - accuracy: 0.5522 - val_loss: 1.4784 - val_accuracy: 0.5044\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2877 - accuracy: 0.5286 - val_loss: 1.3440 - val_accuracy: 0.5694\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0558 - accuracy: 0.5722 - val_loss: 1.2713 - val_accuracy: 0.5897\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1683 - accuracy: 0.5594 - val_loss: 1.2856 - val_accuracy: 0.5961\n",
      "Epoch 386/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1517 - accuracy: 0.5516 - val_loss: 1.1975 - val_accuracy: 0.6227\n",
      "Epoch 387/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9531 - accuracy: 0.5782 - val_loss: 1.1050 - val_accuracy: 0.6444\n",
      "Epoch 388/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8236 - accuracy: 0.5974 - val_loss: 1.0969 - val_accuracy: 0.6451\n",
      "Epoch 389/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8685 - accuracy: 0.5865 - val_loss: 1.1172 - val_accuracy: 0.6366\n",
      "Epoch 390/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0815 - accuracy: 0.5939 - val_loss: 1.4626 - val_accuracy: 0.5229\n",
      "Epoch 391/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0383 - accuracy: 0.5547 - val_loss: 1.3941 - val_accuracy: 0.5378\n",
      "Epoch 392/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9845 - accuracy: 0.5469 - val_loss: 1.1951 - val_accuracy: 0.6128\n",
      "Epoch 393/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8548 - accuracy: 0.5949 - val_loss: 1.1060 - val_accuracy: 0.6455\n",
      "Epoch 394/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8184 - accuracy: 0.6116 - val_loss: 1.0271 - val_accuracy: 0.6845\n",
      "Epoch 395/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8970 - accuracy: 0.6053 - val_loss: 1.1985 - val_accuracy: 0.6316\n",
      "Epoch 396/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9987 - accuracy: 0.5673 - val_loss: 1.2568 - val_accuracy: 0.6046\n",
      "Epoch 397/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8784 - accuracy: 0.5870 - val_loss: 1.0834 - val_accuracy: 0.6611\n",
      "Epoch 398/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8575 - accuracy: 0.6005 - val_loss: 1.1569 - val_accuracy: 0.6405\n",
      "Epoch 399/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7488 - accuracy: 0.6235 - val_loss: 1.0176 - val_accuracy: 0.6785\n",
      "Epoch 400/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7070 - accuracy: 0.6294 - val_loss: 0.9831 - val_accuracy: 0.6821\n",
      "Epoch 401/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9885 - accuracy: 0.5728 - val_loss: 1.1589 - val_accuracy: 0.6139\n",
      "Epoch 402/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2727 - accuracy: 0.5295 - val_loss: 1.2066 - val_accuracy: 0.6178\n",
      "Epoch 403/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1124 - accuracy: 0.5612 - val_loss: 1.1089 - val_accuracy: 0.6451\n",
      "Epoch 404/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9337 - accuracy: 0.5647 - val_loss: 1.1537 - val_accuracy: 0.6394\n",
      "Epoch 405/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8310 - accuracy: 0.6004 - val_loss: 1.1065 - val_accuracy: 0.6387\n",
      "Epoch 406/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9793 - accuracy: 0.5849 - val_loss: 1.2742 - val_accuracy: 0.5606\n",
      "Epoch 407/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9894 - accuracy: 0.5665 - val_loss: 1.1085 - val_accuracy: 0.6409\n",
      "Epoch 408/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0844 - accuracy: 0.5660 - val_loss: 1.7230 - val_accuracy: 0.4838\n",
      "Epoch 409/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3801 - accuracy: 0.4725 - val_loss: 1.2782 - val_accuracy: 0.5663\n",
      "Epoch 410/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5238 - accuracy: 0.5158 - val_loss: 1.3102 - val_accuracy: 0.5766\n",
      "Epoch 411/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8889 - accuracy: 0.5541 - val_loss: 1.1332 - val_accuracy: 0.6220\n",
      "Epoch 412/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8342 - accuracy: 0.5855 - val_loss: 1.2663 - val_accuracy: 0.6039\n",
      "Epoch 413/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8575 - accuracy: 0.5904 - val_loss: 1.1938 - val_accuracy: 0.6089\n",
      "Epoch 414/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8074 - accuracy: 0.6009 - val_loss: 1.0637 - val_accuracy: 0.6565\n",
      "Epoch 415/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0854 - accuracy: 0.5571 - val_loss: 1.3135 - val_accuracy: 0.5460\n",
      "Epoch 416/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9036 - accuracy: 0.5742 - val_loss: 1.1232 - val_accuracy: 0.6369\n",
      "Epoch 417/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9116 - accuracy: 0.5981 - val_loss: 1.0880 - val_accuracy: 0.6600\n",
      "Epoch 418/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3701 - accuracy: 0.5314 - val_loss: 1.3635 - val_accuracy: 0.5595\n",
      "Epoch 419/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1081 - accuracy: 0.5453 - val_loss: 1.2447 - val_accuracy: 0.5975\n",
      "Epoch 420/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0378 - accuracy: 0.5572 - val_loss: 1.1438 - val_accuracy: 0.6401\n",
      "Epoch 421/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1683 - accuracy: 0.5451 - val_loss: 1.4289 - val_accuracy: 0.5304\n",
      "Epoch 422/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2987 - accuracy: 0.5180 - val_loss: 1.3010 - val_accuracy: 0.5723\n",
      "Epoch 423/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2033 - accuracy: 0.5434 - val_loss: 1.1462 - val_accuracy: 0.6274\n",
      "Epoch 424/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8791 - accuracy: 0.5845 - val_loss: 1.0596 - val_accuracy: 0.6423\n",
      "Epoch 425/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0589 - accuracy: 0.5715 - val_loss: 1.3956 - val_accuracy: 0.5321\n",
      "Epoch 426/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0230 - accuracy: 0.5274 - val_loss: 1.1177 - val_accuracy: 0.6348\n",
      "Epoch 427/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8943 - accuracy: 0.5774 - val_loss: 1.3840 - val_accuracy: 0.5737\n",
      "Epoch 428/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9645 - accuracy: 0.5673 - val_loss: 1.1647 - val_accuracy: 0.6298\n",
      "Epoch 429/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1413 - accuracy: 0.5603 - val_loss: 1.1274 - val_accuracy: 0.6316\n",
      "Epoch 430/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8823 - accuracy: 0.5981 - val_loss: 1.0611 - val_accuracy: 0.6416\n",
      "Epoch 431/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0782 - accuracy: 0.5812 - val_loss: 1.2275 - val_accuracy: 0.5858\n",
      "Epoch 432/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2369 - accuracy: 0.5531 - val_loss: 1.2209 - val_accuracy: 0.5940\n",
      "Epoch 433/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2599 - accuracy: 0.5390 - val_loss: 1.2012 - val_accuracy: 0.5989\n",
      "Epoch 434/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8313 - accuracy: 0.5818 - val_loss: 1.1645 - val_accuracy: 0.6131\n",
      "Epoch 435/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7615 - accuracy: 0.6091 - val_loss: 1.1011 - val_accuracy: 0.6369\n",
      "Epoch 436/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8814 - accuracy: 0.5834 - val_loss: 1.2170 - val_accuracy: 0.6011\n",
      "Epoch 437/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8791 - accuracy: 0.5870 - val_loss: 1.3065 - val_accuracy: 0.5680\n",
      "Epoch 438/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8884 - accuracy: 0.5888 - val_loss: 1.1561 - val_accuracy: 0.6117\n",
      "Epoch 439/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8994 - accuracy: 0.5980 - val_loss: 1.0697 - val_accuracy: 0.6515\n",
      "Epoch 440/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2770 - accuracy: 0.5797 - val_loss: 1.1425 - val_accuracy: 0.6124\n",
      "Epoch 441/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2449 - accuracy: 0.5520 - val_loss: 1.0679 - val_accuracy: 0.6501\n",
      "Epoch 442/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0413 - accuracy: 0.5665 - val_loss: 1.2430 - val_accuracy: 0.5901\n",
      "Epoch 443/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1979 - accuracy: 0.5456 - val_loss: 1.9447 - val_accuracy: 0.4202\n",
      "Epoch 444/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5125 - accuracy: 0.4723 - val_loss: 1.2723 - val_accuracy: 0.5847\n",
      "Epoch 445/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1133 - accuracy: 0.5350 - val_loss: 1.2818 - val_accuracy: 0.5638\n",
      "Epoch 446/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0265 - accuracy: 0.5523 - val_loss: 1.1985 - val_accuracy: 0.6000\n",
      "Epoch 447/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8273 - accuracy: 0.5872 - val_loss: 1.0808 - val_accuracy: 0.6440\n",
      "Epoch 448/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9422 - accuracy: 0.5583 - val_loss: 1.4040 - val_accuracy: 0.5275\n",
      "Epoch 449/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0057 - accuracy: 0.5399 - val_loss: 1.1679 - val_accuracy: 0.6021\n",
      "Epoch 450/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8219 - accuracy: 0.5963 - val_loss: 1.1633 - val_accuracy: 0.6433\n",
      "Epoch 451/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8229 - accuracy: 0.5984 - val_loss: 1.1582 - val_accuracy: 0.6117\n",
      "Epoch 452/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8386 - accuracy: 0.6001 - val_loss: 1.1160 - val_accuracy: 0.6337\n",
      "Epoch 453/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3925 - accuracy: 0.5594 - val_loss: 1.5935 - val_accuracy: 0.4895\n",
      "Epoch 454/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3255 - accuracy: 0.5060 - val_loss: 1.3401 - val_accuracy: 0.5659\n",
      "Epoch 455/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9673 - accuracy: 0.5686 - val_loss: 1.1977 - val_accuracy: 0.5751\n",
      "Epoch 456/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2475 - accuracy: 0.5488 - val_loss: 1.1370 - val_accuracy: 0.6195\n",
      "Epoch 457/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9646 - accuracy: 0.5855 - val_loss: 1.2599 - val_accuracy: 0.5744\n",
      "Epoch 458/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8633 - accuracy: 0.5869 - val_loss: 1.1966 - val_accuracy: 0.6057\n",
      "Epoch 459/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0044 - accuracy: 0.5772 - val_loss: 1.1535 - val_accuracy: 0.6171\n",
      "Epoch 460/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8107 - accuracy: 0.6035 - val_loss: 1.0359 - val_accuracy: 0.6615\n",
      "Epoch 461/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7787 - accuracy: 0.6070 - val_loss: 1.1322 - val_accuracy: 0.6181\n",
      "Epoch 462/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7589 - accuracy: 0.6146 - val_loss: 1.0591 - val_accuracy: 0.6348\n",
      "Epoch 463/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8616 - accuracy: 0.5949 - val_loss: 1.2578 - val_accuracy: 0.6202\n",
      "Epoch 464/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1183 - accuracy: 0.4661 - val_loss: 1.3427 - val_accuracy: 0.5798\n",
      "Epoch 465/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9505 - accuracy: 0.5726 - val_loss: 1.2987 - val_accuracy: 0.5634\n",
      "Epoch 466/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9961 - accuracy: 0.5655 - val_loss: 1.2317 - val_accuracy: 0.5968\n",
      "Epoch 467/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8746 - accuracy: 0.5983 - val_loss: 1.0596 - val_accuracy: 0.6625\n",
      "Epoch 468/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8231 - accuracy: 0.6006 - val_loss: 1.2092 - val_accuracy: 0.6014\n",
      "Epoch 469/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7927 - accuracy: 0.6034 - val_loss: 1.0621 - val_accuracy: 0.6533\n",
      "Epoch 470/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9761 - accuracy: 0.5667 - val_loss: 1.1986 - val_accuracy: 0.6011\n",
      "Epoch 471/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9499 - accuracy: 0.5795 - val_loss: 1.0868 - val_accuracy: 0.6483\n",
      "Epoch 472/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7879 - accuracy: 0.6130 - val_loss: 1.1693 - val_accuracy: 0.6306\n",
      "Epoch 473/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7395 - accuracy: 0.6198 - val_loss: 1.1019 - val_accuracy: 0.6345\n",
      "Epoch 474/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8273 - accuracy: 0.6139 - val_loss: 1.1338 - val_accuracy: 0.6391\n",
      "Epoch 475/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1476 - accuracy: 0.5560 - val_loss: 1.2828 - val_accuracy: 0.5766\n",
      "Epoch 476/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0208 - accuracy: 0.4980 - val_loss: 1.4219 - val_accuracy: 0.5304\n",
      "Epoch 477/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4674 - accuracy: 0.4945 - val_loss: 1.3592 - val_accuracy: 0.5663\n",
      "Epoch 478/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0465 - accuracy: 0.5488 - val_loss: 1.1680 - val_accuracy: 0.6103\n",
      "Epoch 479/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9185 - accuracy: 0.5874 - val_loss: 1.1355 - val_accuracy: 0.6206\n",
      "Epoch 480/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8073 - accuracy: 0.6052 - val_loss: 1.0538 - val_accuracy: 0.6533\n",
      "Epoch 481/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8487 - accuracy: 0.5936 - val_loss: 1.0788 - val_accuracy: 0.6494\n",
      "Epoch 482/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8085 - accuracy: 0.6096 - val_loss: 1.1288 - val_accuracy: 0.6238\n",
      "Epoch 483/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7674 - accuracy: 0.6152 - val_loss: 1.0306 - val_accuracy: 0.6575\n",
      "Epoch 484/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9875 - accuracy: 0.5892 - val_loss: 1.1546 - val_accuracy: 0.6242\n",
      "Epoch 485/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9115 - accuracy: 0.6014 - val_loss: 1.1653 - val_accuracy: 0.6181\n",
      "Epoch 486/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7717 - accuracy: 0.6101 - val_loss: 1.0903 - val_accuracy: 0.6391\n",
      "Epoch 487/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7497 - accuracy: 0.6199 - val_loss: 1.0241 - val_accuracy: 0.6639\n",
      "Epoch 488/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0061 - accuracy: 0.5539 - val_loss: 1.5549 - val_accuracy: 0.4757\n",
      "Epoch 489/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0227 - accuracy: 0.5325 - val_loss: 1.1428 - val_accuracy: 0.6181\n",
      "Epoch 490/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8660 - accuracy: 0.5890 - val_loss: 1.1019 - val_accuracy: 0.6369\n",
      "Epoch 491/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8052 - accuracy: 0.5935 - val_loss: 1.1496 - val_accuracy: 0.6213\n",
      "Epoch 492/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9382 - accuracy: 0.5918 - val_loss: 1.3375 - val_accuracy: 0.5552\n",
      "Epoch 493/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9356 - accuracy: 0.5866 - val_loss: 1.0419 - val_accuracy: 0.6540\n",
      "Epoch 494/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0803 - accuracy: 0.5599 - val_loss: 1.2392 - val_accuracy: 0.5972\n",
      "Epoch 495/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1922 - accuracy: 0.5433 - val_loss: 1.3130 - val_accuracy: 0.5634\n",
      "Epoch 496/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 3.3898 - accuracy: 0.5095 - val_loss: 1.4824 - val_accuracy: 0.4920\n",
      "Epoch 497/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4181 - accuracy: 0.5052 - val_loss: 1.2363 - val_accuracy: 0.5957\n",
      "Epoch 498/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8895 - accuracy: 0.5870 - val_loss: 1.2007 - val_accuracy: 0.6028\n",
      "Epoch 499/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9229 - accuracy: 0.5881 - val_loss: 1.2818 - val_accuracy: 0.5822\n",
      "Epoch 500/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8700 - accuracy: 0.5849 - val_loss: 1.1096 - val_accuracy: 0.6373\n",
      "\n",
      "Validation 4, fold 3 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8635 - accuracy: 0.0466 - val_loss: 2.8099 - val_accuracy: 0.0639\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7344 - accuracy: 0.0909 - val_loss: 2.5716 - val_accuracy: 0.1744\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.5561 - accuracy: 0.1519 - val_loss: 2.3810 - val_accuracy: 0.1769\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3548 - accuracy: 0.1861 - val_loss: 2.1145 - val_accuracy: 0.2952\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2247 - accuracy: 0.2248 - val_loss: 2.1567 - val_accuracy: 0.2416\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3307 - accuracy: 0.2332 - val_loss: 2.3159 - val_accuracy: 0.2440\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0931 - accuracy: 0.2535 - val_loss: 1.9484 - val_accuracy: 0.3393\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0948 - accuracy: 0.2793 - val_loss: 2.1715 - val_accuracy: 0.2487\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0882 - accuracy: 0.2777 - val_loss: 2.2481 - val_accuracy: 0.2551\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9655 - accuracy: 0.2935 - val_loss: 2.1306 - val_accuracy: 0.2867\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8463 - accuracy: 0.3171 - val_loss: 1.9444 - val_accuracy: 0.3389\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8178 - accuracy: 0.3287 - val_loss: 1.9125 - val_accuracy: 0.3556\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7844 - accuracy: 0.3481 - val_loss: 1.8800 - val_accuracy: 0.3393\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6865 - accuracy: 0.3603 - val_loss: 1.6623 - val_accuracy: 0.4380\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6987 - accuracy: 0.3651 - val_loss: 2.0877 - val_accuracy: 0.2980\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6908 - accuracy: 0.3604 - val_loss: 1.6645 - val_accuracy: 0.4067\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5860 - accuracy: 0.3891 - val_loss: 1.6804 - val_accuracy: 0.4107\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5833 - accuracy: 0.3789 - val_loss: 1.8867 - val_accuracy: 0.3474\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6935 - accuracy: 0.3658 - val_loss: 1.6870 - val_accuracy: 0.4256\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5605 - accuracy: 0.3870 - val_loss: 1.6722 - val_accuracy: 0.4313\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3920 - accuracy: 0.4356 - val_loss: 1.5827 - val_accuracy: 0.4636\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7192 - accuracy: 0.3824 - val_loss: 1.6836 - val_accuracy: 0.4224\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4779 - accuracy: 0.4072 - val_loss: 1.7188 - val_accuracy: 0.4213\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5418 - accuracy: 0.4156 - val_loss: 1.8716 - val_accuracy: 0.3925\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6306 - accuracy: 0.4099 - val_loss: 1.7556 - val_accuracy: 0.4007\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4235 - accuracy: 0.4286 - val_loss: 1.5577 - val_accuracy: 0.4664\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3718 - accuracy: 0.4472 - val_loss: 1.7273 - val_accuracy: 0.4202\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4600 - accuracy: 0.4365 - val_loss: 1.6248 - val_accuracy: 0.4423\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3465 - accuracy: 0.4649 - val_loss: 1.5820 - val_accuracy: 0.4842\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3112 - accuracy: 0.4591 - val_loss: 1.5563 - val_accuracy: 0.4732\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3223 - accuracy: 0.4718 - val_loss: 1.4028 - val_accuracy: 0.5133\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2059 - accuracy: 0.4889 - val_loss: 1.4594 - val_accuracy: 0.5066\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2154 - accuracy: 0.4821 - val_loss: 1.4205 - val_accuracy: 0.5254\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3126 - accuracy: 0.4722 - val_loss: 1.4091 - val_accuracy: 0.5297\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3120 - accuracy: 0.4735 - val_loss: 1.4128 - val_accuracy: 0.5222\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3247 - accuracy: 0.4824 - val_loss: 1.5046 - val_accuracy: 0.5005\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2804 - accuracy: 0.4810 - val_loss: 1.3949 - val_accuracy: 0.5325\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1768 - accuracy: 0.4806 - val_loss: 1.4097 - val_accuracy: 0.5229\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4052 - accuracy: 0.4694 - val_loss: 1.2958 - val_accuracy: 0.5712\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3655 - accuracy: 0.4704 - val_loss: 1.5781 - val_accuracy: 0.4792\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4718 - accuracy: 0.4758 - val_loss: 1.3900 - val_accuracy: 0.5258\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2191 - accuracy: 0.4798 - val_loss: 1.4882 - val_accuracy: 0.4902\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2555 - accuracy: 0.4756 - val_loss: 1.4194 - val_accuracy: 0.5176\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2600 - accuracy: 0.4839 - val_loss: 1.4784 - val_accuracy: 0.4980\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1812 - accuracy: 0.4951 - val_loss: 1.3776 - val_accuracy: 0.5304\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3603 - accuracy: 0.4891 - val_loss: 1.4997 - val_accuracy: 0.4963\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3838 - accuracy: 0.4541 - val_loss: 1.4898 - val_accuracy: 0.5083\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1864 - accuracy: 0.4862 - val_loss: 1.3522 - val_accuracy: 0.5471\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1449 - accuracy: 0.5274 - val_loss: 1.2977 - val_accuracy: 0.5623\n",
      "Epoch 50/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2140 - accuracy: 0.5020 - val_loss: 1.2701 - val_accuracy: 0.5677\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2723 - accuracy: 0.4948 - val_loss: 1.3090 - val_accuracy: 0.5552\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2468 - accuracy: 0.5036 - val_loss: 1.3347 - val_accuracy: 0.5464\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1722 - accuracy: 0.5068 - val_loss: 1.4093 - val_accuracy: 0.5272\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1900 - accuracy: 0.5082 - val_loss: 1.2899 - val_accuracy: 0.5574\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0816 - accuracy: 0.5317 - val_loss: 1.3103 - val_accuracy: 0.5517\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1411 - accuracy: 0.5235 - val_loss: 1.4553 - val_accuracy: 0.5407\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2262 - accuracy: 0.5122 - val_loss: 1.3630 - val_accuracy: 0.5456\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0643 - accuracy: 0.5186 - val_loss: 1.5303 - val_accuracy: 0.4778\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1020 - accuracy: 0.5210 - val_loss: 1.2779 - val_accuracy: 0.5645\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1901 - accuracy: 0.5262 - val_loss: 1.3234 - val_accuracy: 0.5560\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4606 - accuracy: 0.4832 - val_loss: 1.4984 - val_accuracy: 0.5187\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1559 - accuracy: 0.5282 - val_loss: 1.3083 - val_accuracy: 0.5719\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1664 - accuracy: 0.5327 - val_loss: 1.3227 - val_accuracy: 0.5606\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0404 - accuracy: 0.5456 - val_loss: 1.2065 - val_accuracy: 0.5883\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9687 - accuracy: 0.5557 - val_loss: 1.1761 - val_accuracy: 0.5982\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0508 - accuracy: 0.5359 - val_loss: 1.2739 - val_accuracy: 0.5730\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0078 - accuracy: 0.5551 - val_loss: 1.2327 - val_accuracy: 0.5940\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6556 - accuracy: 0.4903 - val_loss: 1.5052 - val_accuracy: 0.4824\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4199 - accuracy: 0.4691 - val_loss: 1.6109 - val_accuracy: 0.4796\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1974 - accuracy: 0.5020 - val_loss: 1.2202 - val_accuracy: 0.5801\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1117 - accuracy: 0.5385 - val_loss: 1.2602 - val_accuracy: 0.5712\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0311 - accuracy: 0.5420 - val_loss: 1.2264 - val_accuracy: 0.5773\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0101 - accuracy: 0.5454 - val_loss: 1.5993 - val_accuracy: 0.4675\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9986 - accuracy: 0.5523 - val_loss: 1.3911 - val_accuracy: 0.5155\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5844 - accuracy: 0.4870 - val_loss: 1.4744 - val_accuracy: 0.5119\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3067 - accuracy: 0.4898 - val_loss: 1.4850 - val_accuracy: 0.5020\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2263 - accuracy: 0.5131 - val_loss: 1.3877 - val_accuracy: 0.5485\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1914 - accuracy: 0.5276 - val_loss: 1.6176 - val_accuracy: 0.4377\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3479 - accuracy: 0.5265 - val_loss: 1.3955 - val_accuracy: 0.5240\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0844 - accuracy: 0.5377 - val_loss: 1.2394 - val_accuracy: 0.5918\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9225 - accuracy: 0.5666 - val_loss: 1.1530 - val_accuracy: 0.6103\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9327 - accuracy: 0.5636 - val_loss: 1.1475 - val_accuracy: 0.5872\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9488 - accuracy: 0.5597 - val_loss: 1.3232 - val_accuracy: 0.5467\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0382 - accuracy: 0.5362 - val_loss: 1.2195 - val_accuracy: 0.5794\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0893 - accuracy: 0.5387 - val_loss: 1.2418 - val_accuracy: 0.5726\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9761 - accuracy: 0.5599 - val_loss: 1.1180 - val_accuracy: 0.6036\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0391 - accuracy: 0.5320 - val_loss: 1.1876 - val_accuracy: 0.6043\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0984 - accuracy: 0.5318 - val_loss: 1.2493 - val_accuracy: 0.5723\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0527 - accuracy: 0.5418 - val_loss: 1.2295 - val_accuracy: 0.5726\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9757 - accuracy: 0.5633 - val_loss: 1.2133 - val_accuracy: 0.5819\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9228 - accuracy: 0.5727 - val_loss: 1.2395 - val_accuracy: 0.5790\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9368 - accuracy: 0.5758 - val_loss: 1.2642 - val_accuracy: 0.5549\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0116 - accuracy: 0.5510 - val_loss: 1.4342 - val_accuracy: 0.5208\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1112 - accuracy: 0.5381 - val_loss: 1.5764 - val_accuracy: 0.4828\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1521 - accuracy: 0.5132 - val_loss: 1.3965 - val_accuracy: 0.5435\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1037 - accuracy: 0.5369 - val_loss: 1.3541 - val_accuracy: 0.5417\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9441 - accuracy: 0.5667 - val_loss: 1.5930 - val_accuracy: 0.4838\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3595 - accuracy: 0.5095 - val_loss: 1.4499 - val_accuracy: 0.5357\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2825 - accuracy: 0.4916 - val_loss: 1.3062 - val_accuracy: 0.5762\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2382 - accuracy: 0.5430 - val_loss: 1.2619 - val_accuracy: 0.5865\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0695 - accuracy: 0.5435 - val_loss: 1.1769 - val_accuracy: 0.5982\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9229 - accuracy: 0.5582 - val_loss: 1.2106 - val_accuracy: 0.5858\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9796 - accuracy: 0.5642 - val_loss: 1.1591 - val_accuracy: 0.6060\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8661 - accuracy: 0.5881 - val_loss: 1.1732 - val_accuracy: 0.5940\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8702 - accuracy: 0.5902 - val_loss: 1.2873 - val_accuracy: 0.5901\n",
      "Epoch 106/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9786 - accuracy: 0.5694 - val_loss: 1.2905 - val_accuracy: 0.5719\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8818 - accuracy: 0.5806 - val_loss: 1.1474 - val_accuracy: 0.6103\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9720 - accuracy: 0.5481 - val_loss: 1.1743 - val_accuracy: 0.6131\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8755 - accuracy: 0.5914 - val_loss: 1.1618 - val_accuracy: 0.6146\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1792 - accuracy: 0.5431 - val_loss: 1.1392 - val_accuracy: 0.6224\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9629 - accuracy: 0.5714 - val_loss: 1.1928 - val_accuracy: 0.5950\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0026 - accuracy: 0.5757 - val_loss: 1.2149 - val_accuracy: 0.5943\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9517 - accuracy: 0.5707 - val_loss: 1.0658 - val_accuracy: 0.6398\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1639 - accuracy: 0.5397 - val_loss: 1.2545 - val_accuracy: 0.5680\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9305 - accuracy: 0.5668 - val_loss: 1.1328 - val_accuracy: 0.6067\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0988 - accuracy: 0.5526 - val_loss: 1.3655 - val_accuracy: 0.5428\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3346 - accuracy: 0.4640 - val_loss: 1.2764 - val_accuracy: 0.5822\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2596 - accuracy: 0.5148 - val_loss: 1.3949 - val_accuracy: 0.5290\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3068 - accuracy: 0.5093 - val_loss: 1.3775 - val_accuracy: 0.5471\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2630 - accuracy: 0.5217 - val_loss: 1.2195 - val_accuracy: 0.5780\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0061 - accuracy: 0.5615 - val_loss: 1.6059 - val_accuracy: 0.4963\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8520 - accuracy: 0.5023 - val_loss: 1.7574 - val_accuracy: 0.4067\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8165 - accuracy: 0.4542 - val_loss: 1.4619 - val_accuracy: 0.5211\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5059 - accuracy: 0.5134 - val_loss: 1.5819 - val_accuracy: 0.4860\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4074 - accuracy: 0.5172 - val_loss: 1.2651 - val_accuracy: 0.5808\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1260 - accuracy: 0.5329 - val_loss: 1.5233 - val_accuracy: 0.5105\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1177 - accuracy: 0.5274 - val_loss: 1.3087 - val_accuracy: 0.5552\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1359 - accuracy: 0.5356 - val_loss: 1.3402 - val_accuracy: 0.5588\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9096 - accuracy: 0.5688 - val_loss: 1.0742 - val_accuracy: 0.6451\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0193 - accuracy: 0.5447 - val_loss: 1.1261 - val_accuracy: 0.6146\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1093 - accuracy: 0.5619 - val_loss: 1.4697 - val_accuracy: 0.5052\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3508 - accuracy: 0.5361 - val_loss: 1.2759 - val_accuracy: 0.5744\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9980 - accuracy: 0.5605 - val_loss: 1.2893 - val_accuracy: 0.5535\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0755 - accuracy: 0.5415 - val_loss: 1.1885 - val_accuracy: 0.5940\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9090 - accuracy: 0.5712 - val_loss: 1.1277 - val_accuracy: 0.6171\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1025 - accuracy: 0.5528 - val_loss: 2.1628 - val_accuracy: 0.4650\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0726 - accuracy: 0.5409 - val_loss: 1.1586 - val_accuracy: 0.6043\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9038 - accuracy: 0.5807 - val_loss: 1.1363 - val_accuracy: 0.6089\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9932 - accuracy: 0.5691 - val_loss: 1.1875 - val_accuracy: 0.6089\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4644 - accuracy: 0.4862 - val_loss: 1.5045 - val_accuracy: 0.4767\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0503 - accuracy: 0.5237 - val_loss: 1.1273 - val_accuracy: 0.6092\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1099 - accuracy: 0.5575 - val_loss: 1.3308 - val_accuracy: 0.5517\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1556 - accuracy: 0.5164 - val_loss: 1.2872 - val_accuracy: 0.5677\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2159 - accuracy: 0.5476 - val_loss: 1.2814 - val_accuracy: 0.5570\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.5528 - val_loss: 1.1441 - val_accuracy: 0.6174\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0157 - accuracy: 0.5649 - val_loss: 1.1442 - val_accuracy: 0.6071\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0313 - accuracy: 0.5698 - val_loss: 1.1657 - val_accuracy: 0.6039\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0673 - accuracy: 0.5717 - val_loss: 1.4829 - val_accuracy: 0.5336\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9782 - accuracy: 0.5586 - val_loss: 1.2524 - val_accuracy: 0.5787\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0912 - accuracy: 0.5522 - val_loss: 1.1578 - val_accuracy: 0.6057\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0392 - accuracy: 0.5632 - val_loss: 1.1299 - val_accuracy: 0.6352\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8998 - accuracy: 0.5729 - val_loss: 1.3351 - val_accuracy: 0.5741\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1597 - accuracy: 0.5677 - val_loss: 1.3460 - val_accuracy: 0.5616\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2252 - accuracy: 0.5399 - val_loss: 1.2432 - val_accuracy: 0.5712\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9041 - accuracy: 0.5811 - val_loss: 1.1628 - val_accuracy: 0.6007\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8385 - accuracy: 0.5951 - val_loss: 1.0746 - val_accuracy: 0.6288\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8945 - accuracy: 0.5891 - val_loss: 1.1114 - val_accuracy: 0.6043\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9710 - accuracy: 0.5456 - val_loss: 1.1469 - val_accuracy: 0.5982\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9257 - accuracy: 0.5778 - val_loss: 1.1574 - val_accuracy: 0.5922\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9646 - accuracy: 0.5716 - val_loss: 1.3140 - val_accuracy: 0.5790\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8491 - accuracy: 0.5947 - val_loss: 1.2796 - val_accuracy: 0.5737\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0707 - accuracy: 0.5181 - val_loss: 1.5317 - val_accuracy: 0.4984\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0970 - accuracy: 0.5202 - val_loss: 1.2314 - val_accuracy: 0.5790\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9042 - accuracy: 0.5732 - val_loss: 1.1459 - val_accuracy: 0.6149\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9151 - accuracy: 0.5612 - val_loss: 1.1481 - val_accuracy: 0.6092\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0702 - accuracy: 0.5479 - val_loss: 1.2067 - val_accuracy: 0.5798\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1168 - accuracy: 0.5239 - val_loss: 1.2606 - val_accuracy: 0.5652\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0425 - accuracy: 0.5284 - val_loss: 1.1908 - val_accuracy: 0.5716\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9177 - accuracy: 0.5639 - val_loss: 1.4796 - val_accuracy: 0.5211\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0083 - accuracy: 0.5529 - val_loss: 1.2856 - val_accuracy: 0.5726\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8797 - accuracy: 0.5845 - val_loss: 1.2539 - val_accuracy: 0.5737\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8550 - accuracy: 0.5996 - val_loss: 1.1190 - val_accuracy: 0.6167\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8044 - accuracy: 0.6111 - val_loss: 1.0435 - val_accuracy: 0.6469\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8426 - accuracy: 0.6012 - val_loss: 1.1236 - val_accuracy: 0.6163\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3469 - accuracy: 0.5087 - val_loss: 1.2454 - val_accuracy: 0.5556\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2363 - accuracy: 0.5231 - val_loss: 1.4375 - val_accuracy: 0.5464\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9575 - accuracy: 0.5688 - val_loss: 1.1304 - val_accuracy: 0.6249\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8534 - accuracy: 0.5903 - val_loss: 1.1917 - val_accuracy: 0.6039\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8120 - accuracy: 0.6034 - val_loss: 1.1098 - val_accuracy: 0.6217\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9007 - accuracy: 0.5974 - val_loss: 1.1068 - val_accuracy: 0.6291\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8245 - accuracy: 0.6035 - val_loss: 1.1306 - val_accuracy: 0.6067\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8958 - accuracy: 0.5817 - val_loss: 1.0212 - val_accuracy: 0.6437\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8776 - accuracy: 0.6009 - val_loss: 1.0344 - val_accuracy: 0.6554\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9698 - accuracy: 0.5797 - val_loss: 1.2541 - val_accuracy: 0.5879\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8948 - accuracy: 0.5822 - val_loss: 1.4042 - val_accuracy: 0.5165\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9792 - accuracy: 0.5755 - val_loss: 1.1238 - val_accuracy: 0.6171\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8819 - accuracy: 0.5977 - val_loss: 1.1504 - val_accuracy: 0.6202\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9249 - accuracy: 0.5936 - val_loss: 1.0787 - val_accuracy: 0.6330\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2336 - accuracy: 0.5509 - val_loss: 1.2240 - val_accuracy: 0.5822\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0715 - accuracy: 0.5346 - val_loss: 1.2874 - val_accuracy: 0.5421\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6631 - accuracy: 0.5436 - val_loss: 1.4330 - val_accuracy: 0.5407\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1703 - accuracy: 0.5304 - val_loss: 1.2245 - val_accuracy: 0.5723\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0803 - accuracy: 0.5329 - val_loss: 1.2746 - val_accuracy: 0.5588\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0948 - accuracy: 0.5646 - val_loss: 1.2132 - val_accuracy: 0.6036\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9883 - accuracy: 0.5212 - val_loss: 1.2909 - val_accuracy: 0.5368\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9438 - accuracy: 0.5623 - val_loss: 1.1142 - val_accuracy: 0.6146\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8983 - accuracy: 0.5752 - val_loss: 1.2222 - val_accuracy: 0.5815\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9818 - accuracy: 0.5739 - val_loss: 1.1233 - val_accuracy: 0.6053\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9137 - accuracy: 0.5875 - val_loss: 1.0992 - val_accuracy: 0.6188\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7969 - accuracy: 0.6063 - val_loss: 1.3718 - val_accuracy: 0.5314\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1591 - accuracy: 0.5290 - val_loss: 1.1924 - val_accuracy: 0.5865\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8952 - accuracy: 0.5771 - val_loss: 1.1387 - val_accuracy: 0.6114\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8402 - accuracy: 0.5908 - val_loss: 1.1787 - val_accuracy: 0.5925\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9278 - accuracy: 0.5782 - val_loss: 1.0943 - val_accuracy: 0.6494\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9759 - accuracy: 0.5730 - val_loss: 1.0757 - val_accuracy: 0.6476\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0076 - accuracy: 0.5597 - val_loss: 1.0749 - val_accuracy: 0.6377\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0549 - accuracy: 0.5797 - val_loss: 1.1273 - val_accuracy: 0.6309\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0025 - accuracy: 0.5661 - val_loss: 1.3875 - val_accuracy: 0.5641\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7721 - accuracy: 0.5471 - val_loss: 1.1256 - val_accuracy: 0.6259\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8910 - accuracy: 0.5893 - val_loss: 1.0873 - val_accuracy: 0.6369\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3515 - accuracy: 0.5380 - val_loss: 1.3290 - val_accuracy: 0.5599\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1687 - accuracy: 0.5500 - val_loss: 1.2596 - val_accuracy: 0.5709\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0023 - accuracy: 0.5591 - val_loss: 1.1308 - val_accuracy: 0.6185\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8843 - accuracy: 0.5893 - val_loss: 1.2104 - val_accuracy: 0.5904\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8102 - accuracy: 0.5917 - val_loss: 1.0960 - val_accuracy: 0.6124\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3112 - accuracy: 0.5015 - val_loss: 1.3095 - val_accuracy: 0.5734\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.0418 - accuracy: 0.5462 - val_loss: 1.4363 - val_accuracy: 0.5119\n",
      "Epoch 218/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0185 - accuracy: 0.5620 - val_loss: 1.1452 - val_accuracy: 0.6103\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9324 - accuracy: 0.5817 - val_loss: 1.1132 - val_accuracy: 0.6249\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8953 - accuracy: 0.5888 - val_loss: 1.7975 - val_accuracy: 0.4618\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9871 - accuracy: 0.5671 - val_loss: 1.1937 - val_accuracy: 0.5964\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8372 - accuracy: 0.5983 - val_loss: 1.0970 - val_accuracy: 0.6252\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8644 - accuracy: 0.5996 - val_loss: 1.1968 - val_accuracy: 0.5822\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0633 - accuracy: 0.5627 - val_loss: 1.3481 - val_accuracy: 0.5670\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9918 - accuracy: 0.5555 - val_loss: 1.4567 - val_accuracy: 0.5179\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1212 - accuracy: 0.5672 - val_loss: 1.2882 - val_accuracy: 0.5794\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9195 - accuracy: 0.5354 - val_loss: 1.2025 - val_accuracy: 0.5943\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2961 - accuracy: 0.5346 - val_loss: 1.4735 - val_accuracy: 0.5144\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4160 - accuracy: 0.5297 - val_loss: 1.6679 - val_accuracy: 0.4462\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0635 - accuracy: 0.5478 - val_loss: 1.1649 - val_accuracy: 0.6085\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9542 - accuracy: 0.5869 - val_loss: 1.1362 - val_accuracy: 0.6135\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8925 - accuracy: 0.5849 - val_loss: 1.1019 - val_accuracy: 0.6199\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9596 - accuracy: 0.5902 - val_loss: 1.0840 - val_accuracy: 0.6252\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0455 - accuracy: 0.5744 - val_loss: 1.2285 - val_accuracy: 0.5801\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2833 - accuracy: 0.4975 - val_loss: 1.4640 - val_accuracy: 0.4842\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1288 - accuracy: 0.5297 - val_loss: 1.2535 - val_accuracy: 0.5723\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2474 - accuracy: 0.5364 - val_loss: 1.2420 - val_accuracy: 0.5993\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0005 - accuracy: 0.5485 - val_loss: 1.1261 - val_accuracy: 0.6266\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8979 - accuracy: 0.5852 - val_loss: 1.1374 - val_accuracy: 0.6011\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9352 - accuracy: 0.5902 - val_loss: 1.1650 - val_accuracy: 0.5982\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8579 - accuracy: 0.5912 - val_loss: 1.0467 - val_accuracy: 0.6515\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9658 - accuracy: 0.5963 - val_loss: 1.3313 - val_accuracy: 0.5474\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9173 - accuracy: 0.5752 - val_loss: 1.0429 - val_accuracy: 0.6615\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0904 - accuracy: 0.5663 - val_loss: 1.1886 - val_accuracy: 0.5989\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8862 - accuracy: 0.5916 - val_loss: 1.1735 - val_accuracy: 0.6039\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2014 - accuracy: 0.5244 - val_loss: 1.7190 - val_accuracy: 0.4497\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2825 - accuracy: 0.5094 - val_loss: 1.5448 - val_accuracy: 0.5023\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0134 - accuracy: 0.5280 - val_loss: 1.1175 - val_accuracy: 0.6171\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9687 - accuracy: 0.5763 - val_loss: 1.1510 - val_accuracy: 0.6036\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1027 - accuracy: 0.5351 - val_loss: 1.3451 - val_accuracy: 0.5560\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9375 - accuracy: 0.5580 - val_loss: 1.1659 - val_accuracy: 0.6004\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9814 - accuracy: 0.5783 - val_loss: 1.1878 - val_accuracy: 0.5798\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8562 - accuracy: 0.5939 - val_loss: 1.0627 - val_accuracy: 0.6277\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8083 - accuracy: 0.6053 - val_loss: 1.0677 - val_accuracy: 0.6266\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8115 - accuracy: 0.6072 - val_loss: 1.0220 - val_accuracy: 0.6444\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9016 - accuracy: 0.5953 - val_loss: 1.2110 - val_accuracy: 0.5815\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0648 - accuracy: 0.5404 - val_loss: 2.0241 - val_accuracy: 0.3908\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3930 - accuracy: 0.4887 - val_loss: 1.2584 - val_accuracy: 0.5808\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0839 - accuracy: 0.5266 - val_loss: 1.2411 - val_accuracy: 0.5776\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0765 - accuracy: 0.5554 - val_loss: 1.1562 - val_accuracy: 0.5922\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0280 - accuracy: 0.5370 - val_loss: 1.1752 - val_accuracy: 0.5968\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8620 - accuracy: 0.5885 - val_loss: 1.2581 - val_accuracy: 0.5638\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1100 - accuracy: 0.5502 - val_loss: 1.2484 - val_accuracy: 0.5694\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8380 - accuracy: 0.5877 - val_loss: 1.0552 - val_accuracy: 0.6536\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8674 - accuracy: 0.6018 - val_loss: 1.0253 - val_accuracy: 0.6512\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8258 - accuracy: 0.6083 - val_loss: 1.1396 - val_accuracy: 0.6114\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1619 - accuracy: 0.5564 - val_loss: 1.1884 - val_accuracy: 0.5957\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0784 - accuracy: 0.5554 - val_loss: 1.1320 - val_accuracy: 0.6146\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8744 - accuracy: 0.5986 - val_loss: 1.1224 - val_accuracy: 0.6213\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9367 - accuracy: 0.5790 - val_loss: 1.0771 - val_accuracy: 0.6227\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9701 - accuracy: 0.5716 - val_loss: 1.1258 - val_accuracy: 0.6199\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9204 - accuracy: 0.5972 - val_loss: 1.1710 - val_accuracy: 0.5904\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8951 - accuracy: 0.5952 - val_loss: 1.0070 - val_accuracy: 0.6575\n",
      "Epoch 274/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8529 - accuracy: 0.6002 - val_loss: 1.0753 - val_accuracy: 0.6295\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7833 - accuracy: 0.6160 - val_loss: 1.0428 - val_accuracy: 0.6352\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7327 - accuracy: 0.6250 - val_loss: 1.0103 - val_accuracy: 0.6519\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8356 - accuracy: 0.6010 - val_loss: 1.0017 - val_accuracy: 0.6632\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7716 - accuracy: 0.6179 - val_loss: 1.0353 - val_accuracy: 0.6504\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0448 - accuracy: 0.5861 - val_loss: 1.1694 - val_accuracy: 0.6103\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9206 - accuracy: 0.5714 - val_loss: 1.1292 - val_accuracy: 0.6242\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7233 - accuracy: 0.4937 - val_loss: 1.4103 - val_accuracy: 0.5346\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1895 - accuracy: 0.5342 - val_loss: 1.1152 - val_accuracy: 0.6394\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2965 - accuracy: 0.5309 - val_loss: 1.5106 - val_accuracy: 0.5123\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2089 - accuracy: 0.5402 - val_loss: 1.2448 - val_accuracy: 0.5861\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9715 - accuracy: 0.5696 - val_loss: 1.1163 - val_accuracy: 0.6433\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9535 - accuracy: 0.5781 - val_loss: 1.1536 - val_accuracy: 0.6195\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9973 - accuracy: 0.5998 - val_loss: 1.1963 - val_accuracy: 0.6004\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9238 - accuracy: 0.5898 - val_loss: 1.0473 - val_accuracy: 0.6636\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7937 - accuracy: 0.6268 - val_loss: 1.0438 - val_accuracy: 0.6593\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8951 - accuracy: 0.5859 - val_loss: 1.2897 - val_accuracy: 0.5307\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9100 - accuracy: 0.5807 - val_loss: 1.0644 - val_accuracy: 0.6366\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9144 - accuracy: 0.5963 - val_loss: 1.2162 - val_accuracy: 0.5844\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9971 - accuracy: 0.5639 - val_loss: 1.2270 - val_accuracy: 0.5734\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8529 - accuracy: 0.6019 - val_loss: 1.0291 - val_accuracy: 0.6607\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8263 - accuracy: 0.6060 - val_loss: 1.0540 - val_accuracy: 0.6398\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8249 - accuracy: 0.6048 - val_loss: 1.0482 - val_accuracy: 0.6480\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1406 - accuracy: 0.5286 - val_loss: 1.1748 - val_accuracy: 0.5911\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1090 - accuracy: 0.5570 - val_loss: 1.2090 - val_accuracy: 0.5808\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0350 - accuracy: 0.5552 - val_loss: 1.2128 - val_accuracy: 0.5911\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8817 - accuracy: 0.5917 - val_loss: 1.2560 - val_accuracy: 0.5780\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3604 - accuracy: 0.5790 - val_loss: 1.2616 - val_accuracy: 0.5904\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1563 - accuracy: 0.5447 - val_loss: 1.1552 - val_accuracy: 0.6075\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9031 - accuracy: 0.5878 - val_loss: 1.1425 - val_accuracy: 0.6050\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9059 - accuracy: 0.5877 - val_loss: 1.0648 - val_accuracy: 0.6373\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9572 - accuracy: 0.5838 - val_loss: 1.4295 - val_accuracy: 0.5460\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9727 - accuracy: 0.5811 - val_loss: 1.2023 - val_accuracy: 0.5897\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9730 - accuracy: 0.5778 - val_loss: 1.0907 - val_accuracy: 0.6391\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9170 - accuracy: 0.5963 - val_loss: 1.1909 - val_accuracy: 0.5993\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8771 - accuracy: 0.6028 - val_loss: 1.1927 - val_accuracy: 0.6011\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8266 - accuracy: 0.5970 - val_loss: 1.0279 - val_accuracy: 0.6458\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8017 - accuracy: 0.6202 - val_loss: 1.0719 - val_accuracy: 0.6309\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9121 - accuracy: 0.5853 - val_loss: 1.1691 - val_accuracy: 0.6032\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0061 - accuracy: 0.5681 - val_loss: 1.0543 - val_accuracy: 0.6384\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8440 - accuracy: 0.5917 - val_loss: 1.0243 - val_accuracy: 0.6497\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9770 - accuracy: 0.5848 - val_loss: 1.0414 - val_accuracy: 0.6345\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8840 - accuracy: 0.5899 - val_loss: 1.0537 - val_accuracy: 0.6462\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5660 - accuracy: 0.5076 - val_loss: 1.1659 - val_accuracy: 0.6039\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1820 - accuracy: 0.5618 - val_loss: 1.0637 - val_accuracy: 0.6373\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1530 - accuracy: 0.5560 - val_loss: 1.3536 - val_accuracy: 0.5769\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0808 - accuracy: 0.5683 - val_loss: 1.0777 - val_accuracy: 0.6440\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4647 - accuracy: 0.5215 - val_loss: 1.3162 - val_accuracy: 0.5712\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5399 - accuracy: 0.4956 - val_loss: 1.3249 - val_accuracy: 0.5837\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1916 - accuracy: 0.5406 - val_loss: 1.2811 - val_accuracy: 0.5702\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0674 - accuracy: 0.5534 - val_loss: 1.1675 - val_accuracy: 0.6075\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8744 - accuracy: 0.5800 - val_loss: 1.1456 - val_accuracy: 0.6057\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1721 - accuracy: 0.5632 - val_loss: 1.1565 - val_accuracy: 0.6018\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9501 - accuracy: 0.5634 - val_loss: 1.1954 - val_accuracy: 0.5812\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8271 - accuracy: 0.5904 - val_loss: 1.0517 - val_accuracy: 0.6377\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8727 - accuracy: 0.6098 - val_loss: 1.0711 - val_accuracy: 0.6409\n",
      "Epoch 330/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8399 - accuracy: 0.5925 - val_loss: 1.2217 - val_accuracy: 0.5975\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0897 - accuracy: 0.5733 - val_loss: 1.0528 - val_accuracy: 0.6455\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0878 - accuracy: 0.5749 - val_loss: 1.5020 - val_accuracy: 0.5147\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1055 - accuracy: 0.5650 - val_loss: 1.2587 - val_accuracy: 0.5950\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8383 - accuracy: 0.6071 - val_loss: 1.2550 - val_accuracy: 0.6089\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8009 - accuracy: 0.6234 - val_loss: 1.0227 - val_accuracy: 0.6512\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8172 - accuracy: 0.6085 - val_loss: 1.1025 - val_accuracy: 0.6330\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2779 - accuracy: 0.5903 - val_loss: 1.0497 - val_accuracy: 0.6554\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8021 - accuracy: 0.6155 - val_loss: 0.9623 - val_accuracy: 0.6774\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8317 - accuracy: 0.6104 - val_loss: 1.0199 - val_accuracy: 0.6533\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0452 - accuracy: 0.5641 - val_loss: 1.1402 - val_accuracy: 0.6263\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8810 - accuracy: 0.5964 - val_loss: 1.0229 - val_accuracy: 0.6565\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8641 - accuracy: 0.5877 - val_loss: 1.1551 - val_accuracy: 0.6156\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8382 - accuracy: 0.6114 - val_loss: 1.0513 - val_accuracy: 0.6440\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8236 - accuracy: 0.5933 - val_loss: 1.0642 - val_accuracy: 0.6483\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8530 - accuracy: 0.6020 - val_loss: 1.0195 - val_accuracy: 0.6494\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7843 - accuracy: 0.6218 - val_loss: 1.1422 - val_accuracy: 0.6227\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1351 - accuracy: 0.5572 - val_loss: 1.3820 - val_accuracy: 0.5492\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1453 - accuracy: 0.5504 - val_loss: 1.2036 - val_accuracy: 0.5979\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3618 - accuracy: 0.5175 - val_loss: 1.3092 - val_accuracy: 0.5584\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0586 - accuracy: 0.5701 - val_loss: 1.0947 - val_accuracy: 0.6369\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9015 - accuracy: 0.5818 - val_loss: 1.2434 - val_accuracy: 0.5858\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3473 - accuracy: 0.5296 - val_loss: 1.3790 - val_accuracy: 0.5503\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0631 - accuracy: 0.5412 - val_loss: 1.1208 - val_accuracy: 0.6160\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0379 - accuracy: 0.5472 - val_loss: 1.2640 - val_accuracy: 0.5670\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9408 - accuracy: 0.5770 - val_loss: 1.2335 - val_accuracy: 0.5819\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1587 - accuracy: 0.5585 - val_loss: 1.1241 - val_accuracy: 0.6362\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0597 - accuracy: 0.5846 - val_loss: 1.1398 - val_accuracy: 0.6263\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0512 - accuracy: 0.5820 - val_loss: 1.1086 - val_accuracy: 0.6327\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8496 - accuracy: 0.5977 - val_loss: 1.1167 - val_accuracy: 0.6188\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9805 - accuracy: 0.5873 - val_loss: 1.7636 - val_accuracy: 0.5108\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5596 - accuracy: 0.5017 - val_loss: 1.2396 - val_accuracy: 0.6032\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4940 - accuracy: 0.4619 - val_loss: 1.7346 - val_accuracy: 0.3837\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9750 - accuracy: 0.4465 - val_loss: 1.4129 - val_accuracy: 0.5375\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2555 - accuracy: 0.5075 - val_loss: 1.3774 - val_accuracy: 0.5435\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2304 - accuracy: 0.5127 - val_loss: 1.1964 - val_accuracy: 0.6067\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2308 - accuracy: 0.5337 - val_loss: 1.2394 - val_accuracy: 0.5826\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1211 - accuracy: 0.5476 - val_loss: 1.5250 - val_accuracy: 0.4938\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2306 - accuracy: 0.5214 - val_loss: 1.4773 - val_accuracy: 0.4970\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0113 - accuracy: 0.5476 - val_loss: 1.1609 - val_accuracy: 0.6007\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8899 - accuracy: 0.5821 - val_loss: 1.2119 - val_accuracy: 0.6039\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1056 - accuracy: 0.5528 - val_loss: 1.3085 - val_accuracy: 0.5737\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8692 - accuracy: 0.5957 - val_loss: 1.0365 - val_accuracy: 0.6668\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8071 - accuracy: 0.6093 - val_loss: 1.0033 - val_accuracy: 0.6661\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8819 - accuracy: 0.5933 - val_loss: 1.0070 - val_accuracy: 0.6664\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8846 - accuracy: 0.5837 - val_loss: 1.0544 - val_accuracy: 0.6533\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8623 - accuracy: 0.6043 - val_loss: 1.4405 - val_accuracy: 0.5151\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0436 - accuracy: 0.5682 - val_loss: 1.0060 - val_accuracy: 0.6654\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7978 - accuracy: 0.6155 - val_loss: 1.0288 - val_accuracy: 0.6668\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0672 - accuracy: 0.6088 - val_loss: 1.2487 - val_accuracy: 0.5741\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1521 - accuracy: 0.4851 - val_loss: 1.2152 - val_accuracy: 0.6014\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2561 - accuracy: 0.5259 - val_loss: 1.1449 - val_accuracy: 0.6110\n",
      "Epoch 382/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0451 - accuracy: 0.5456 - val_loss: 1.1878 - val_accuracy: 0.5908\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9476 - accuracy: 0.5643 - val_loss: 1.1511 - val_accuracy: 0.5901\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2060 - accuracy: 0.4929 - val_loss: 1.6011 - val_accuracy: 0.4330\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0600 - accuracy: 0.5245 - val_loss: 1.1653 - val_accuracy: 0.6053\n",
      "Epoch 386/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9025 - accuracy: 0.5766 - val_loss: 1.1118 - val_accuracy: 0.6121\n",
      "Epoch 387/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8375 - accuracy: 0.6035 - val_loss: 1.3511 - val_accuracy: 0.5357\n",
      "Epoch 388/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9248 - accuracy: 0.5777 - val_loss: 1.0546 - val_accuracy: 0.6316\n",
      "Epoch 389/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7879 - accuracy: 0.6080 - val_loss: 0.9944 - val_accuracy: 0.6622\n",
      "Epoch 390/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9190 - accuracy: 0.5957 - val_loss: 1.2586 - val_accuracy: 0.5712\n",
      "Epoch 391/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3389 - accuracy: 0.5382 - val_loss: 1.2154 - val_accuracy: 0.5819\n",
      "Epoch 392/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9643 - accuracy: 0.5674 - val_loss: 1.1027 - val_accuracy: 0.6277\n",
      "Epoch 393/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8382 - accuracy: 0.5965 - val_loss: 1.2037 - val_accuracy: 0.5801\n",
      "Epoch 394/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1346 - accuracy: 0.5287 - val_loss: 1.4499 - val_accuracy: 0.5023\n",
      "Epoch 395/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9732 - accuracy: 0.5512 - val_loss: 1.1542 - val_accuracy: 0.6117\n",
      "Epoch 396/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8694 - accuracy: 0.5976 - val_loss: 1.3146 - val_accuracy: 0.5531\n",
      "Epoch 397/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9811 - accuracy: 0.5573 - val_loss: 1.3923 - val_accuracy: 0.5513\n",
      "Epoch 398/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0574 - accuracy: 0.5358 - val_loss: 1.2360 - val_accuracy: 0.5858\n",
      "Epoch 399/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1097 - accuracy: 0.5424 - val_loss: 1.2830 - val_accuracy: 0.5833\n",
      "Epoch 400/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8518 - accuracy: 0.5917 - val_loss: 1.0659 - val_accuracy: 0.6316\n",
      "Epoch 401/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0761 - accuracy: 0.5636 - val_loss: 1.1042 - val_accuracy: 0.6615\n",
      "Epoch 402/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8618 - accuracy: 0.5831 - val_loss: 1.0768 - val_accuracy: 0.6430\n",
      "Epoch 403/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8302 - accuracy: 0.6123 - val_loss: 1.0215 - val_accuracy: 0.6625\n",
      "Epoch 404/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8174 - accuracy: 0.6055 - val_loss: 1.0229 - val_accuracy: 0.6394\n",
      "Epoch 405/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7896 - accuracy: 0.6138 - val_loss: 1.0361 - val_accuracy: 0.6426\n",
      "Epoch 406/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8821 - accuracy: 0.5834 - val_loss: 1.2710 - val_accuracy: 0.5670\n",
      "Epoch 407/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7773 - accuracy: 0.6184 - val_loss: 1.0363 - val_accuracy: 0.6533\n",
      "Epoch 408/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7857 - accuracy: 0.6113 - val_loss: 1.0192 - val_accuracy: 0.6689\n",
      "Epoch 409/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1530 - accuracy: 0.5502 - val_loss: 1.3178 - val_accuracy: 0.5758\n",
      "Epoch 410/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4895 - accuracy: 0.5271 - val_loss: 1.1158 - val_accuracy: 0.6298\n",
      "Epoch 411/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1535 - accuracy: 0.5194 - val_loss: 1.3192 - val_accuracy: 0.5343\n",
      "Epoch 412/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4506 - accuracy: 0.5042 - val_loss: 1.2931 - val_accuracy: 0.5734\n",
      "Epoch 413/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4637 - accuracy: 0.5484 - val_loss: 1.6103 - val_accuracy: 0.4803\n",
      "Epoch 414/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3314 - accuracy: 0.5337 - val_loss: 1.1488 - val_accuracy: 0.6199\n",
      "Epoch 415/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0942 - accuracy: 0.5595 - val_loss: 1.2321 - val_accuracy: 0.5854\n",
      "Epoch 416/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8889 - accuracy: 0.5869 - val_loss: 1.0893 - val_accuracy: 0.6391\n",
      "Epoch 417/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8559 - accuracy: 0.5890 - val_loss: 1.2488 - val_accuracy: 0.5922\n",
      "Epoch 418/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9764 - accuracy: 0.5640 - val_loss: 1.1100 - val_accuracy: 0.6380\n",
      "Epoch 419/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0332 - accuracy: 0.5934 - val_loss: 1.4516 - val_accuracy: 0.5545\n",
      "Epoch 420/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.5018 - accuracy: 0.4672 - val_loss: 1.9460 - val_accuracy: 0.3709\n",
      "Epoch 421/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1405 - accuracy: 0.4248 - val_loss: 1.8655 - val_accuracy: 0.4359\n",
      "Epoch 422/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3598 - accuracy: 0.4757 - val_loss: 1.2662 - val_accuracy: 0.5968\n",
      "Epoch 423/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4665 - accuracy: 0.5141 - val_loss: 1.3470 - val_accuracy: 0.5794\n",
      "Epoch 424/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3865 - accuracy: 0.4555 - val_loss: 1.4863 - val_accuracy: 0.4977\n",
      "Epoch 425/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2795 - accuracy: 0.5115 - val_loss: 1.4804 - val_accuracy: 0.5467\n",
      "Epoch 426/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3022 - accuracy: 0.4952 - val_loss: 1.2725 - val_accuracy: 0.5840\n",
      "Epoch 427/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0742 - accuracy: 0.5290 - val_loss: 1.5709 - val_accuracy: 0.4544\n",
      "Epoch 428/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4173 - accuracy: 0.4984 - val_loss: 1.2777 - val_accuracy: 0.5613\n",
      "Epoch 429/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3437 - accuracy: 0.5128 - val_loss: 1.3292 - val_accuracy: 0.5456\n",
      "Epoch 430/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0399 - accuracy: 0.5501 - val_loss: 1.2244 - val_accuracy: 0.5794\n",
      "Epoch 431/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0896 - accuracy: 0.5655 - val_loss: 1.4269 - val_accuracy: 0.5332\n",
      "Epoch 432/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9879 - accuracy: 0.5667 - val_loss: 1.1852 - val_accuracy: 0.5822\n",
      "Epoch 433/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9762 - accuracy: 0.5705 - val_loss: 1.1075 - val_accuracy: 0.6178\n",
      "Epoch 434/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9221 - accuracy: 0.5829 - val_loss: 1.0969 - val_accuracy: 0.6394\n",
      "Epoch 435/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8168 - accuracy: 0.6016 - val_loss: 1.0881 - val_accuracy: 0.6366\n",
      "Epoch 436/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7820 - accuracy: 0.6127 - val_loss: 1.1500 - val_accuracy: 0.5972\n",
      "Epoch 437/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1605 - accuracy: 0.5249 - val_loss: 1.2748 - val_accuracy: 0.5570\n",
      "Epoch 438/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8938 - accuracy: 0.5750 - val_loss: 1.4695 - val_accuracy: 0.5460\n",
      "\n",
      "Validation 4, fold 4 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.8920 - accuracy: 0.1639 - val_loss: 2.7959 - val_accuracy: 0.2913\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7071 - accuracy: 0.1883 - val_loss: 2.4424 - val_accuracy: 0.2085\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4231 - accuracy: 0.1810 - val_loss: 2.2060 - val_accuracy: 0.3048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3824 - accuracy: 0.2259 - val_loss: 2.1173 - val_accuracy: 0.3115\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1780 - accuracy: 0.2439 - val_loss: 1.9913 - val_accuracy: 0.3233\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2791 - accuracy: 0.2677 - val_loss: 2.1001 - val_accuracy: 0.3076\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2222 - accuracy: 0.2734 - val_loss: 2.2794 - val_accuracy: 0.2561\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1553 - accuracy: 0.2773 - val_loss: 2.1123 - val_accuracy: 0.2988\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0573 - accuracy: 0.2998 - val_loss: 2.1355 - val_accuracy: 0.2881\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0853 - accuracy: 0.3099 - val_loss: 2.0340 - val_accuracy: 0.3115\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1490 - accuracy: 0.3183 - val_loss: 2.1739 - val_accuracy: 0.2725\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0685 - accuracy: 0.2795 - val_loss: 1.8590 - val_accuracy: 0.3762\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8383 - accuracy: 0.3289 - val_loss: 1.8662 - val_accuracy: 0.3520\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7829 - accuracy: 0.3298 - val_loss: 2.1899 - val_accuracy: 0.3183\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8154 - accuracy: 0.3564 - val_loss: 1.7892 - val_accuracy: 0.4000\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9743 - accuracy: 0.3342 - val_loss: 1.8730 - val_accuracy: 0.3577\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7004 - accuracy: 0.3661 - val_loss: 2.0661 - val_accuracy: 0.3293\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9173 - accuracy: 0.3409 - val_loss: 1.7840 - val_accuracy: 0.3950\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6450 - accuracy: 0.3760 - val_loss: 1.6877 - val_accuracy: 0.4192\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5779 - accuracy: 0.3850 - val_loss: 1.6662 - val_accuracy: 0.4213\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6074 - accuracy: 0.3758 - val_loss: 1.7324 - val_accuracy: 0.3954\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5752 - accuracy: 0.3926 - val_loss: 2.2293 - val_accuracy: 0.3140\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5996 - accuracy: 0.3887 - val_loss: 1.5811 - val_accuracy: 0.4558\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4527 - accuracy: 0.4104 - val_loss: 1.5307 - val_accuracy: 0.4693\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4529 - accuracy: 0.4281 - val_loss: 1.5905 - val_accuracy: 0.4632\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3516 - accuracy: 0.4467 - val_loss: 1.4204 - val_accuracy: 0.5147\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4207 - accuracy: 0.4481 - val_loss: 1.7546 - val_accuracy: 0.4259\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6342 - accuracy: 0.4139 - val_loss: 1.5879 - val_accuracy: 0.4682\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3633 - accuracy: 0.4485 - val_loss: 1.6566 - val_accuracy: 0.4508\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3187 - accuracy: 0.4584 - val_loss: 1.6215 - val_accuracy: 0.4877\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3032 - accuracy: 0.4692 - val_loss: 1.5298 - val_accuracy: 0.4767\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3537 - accuracy: 0.4568 - val_loss: 1.4993 - val_accuracy: 0.5069\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3343 - accuracy: 0.4704 - val_loss: 1.4614 - val_accuracy: 0.5144\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3271 - accuracy: 0.4564 - val_loss: 1.6466 - val_accuracy: 0.4409\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2124 - accuracy: 0.4840 - val_loss: 1.4394 - val_accuracy: 0.5211\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2330 - accuracy: 0.4896 - val_loss: 1.4701 - val_accuracy: 0.5115\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1639 - accuracy: 0.4988 - val_loss: 1.4962 - val_accuracy: 0.5048\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2671 - accuracy: 0.4687 - val_loss: 1.4141 - val_accuracy: 0.5037\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3335 - accuracy: 0.4519 - val_loss: 1.6045 - val_accuracy: 0.4320\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2912 - accuracy: 0.4806 - val_loss: 1.4194 - val_accuracy: 0.5499\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4420 - accuracy: 0.4883 - val_loss: 1.4126 - val_accuracy: 0.5215\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2065 - accuracy: 0.5043 - val_loss: 1.4803 - val_accuracy: 0.5091\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3329 - accuracy: 0.4954 - val_loss: 1.4325 - val_accuracy: 0.5357\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1526 - accuracy: 0.4935 - val_loss: 1.3203 - val_accuracy: 0.5606\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2037 - accuracy: 0.4966 - val_loss: 1.2982 - val_accuracy: 0.5634\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1341 - accuracy: 0.5211 - val_loss: 1.3705 - val_accuracy: 0.5638\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0911 - accuracy: 0.5343 - val_loss: 1.3159 - val_accuracy: 0.5538\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1921 - accuracy: 0.5111 - val_loss: 1.3757 - val_accuracy: 0.5499\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7200 - accuracy: 0.4871 - val_loss: 1.9763 - val_accuracy: 0.3712\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5612 - accuracy: 0.4607 - val_loss: 1.3576 - val_accuracy: 0.5641\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2412 - accuracy: 0.4919 - val_loss: 1.4788 - val_accuracy: 0.5062\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4388 - accuracy: 0.4847 - val_loss: 1.4490 - val_accuracy: 0.5222\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6608 - accuracy: 0.4822 - val_loss: 1.6624 - val_accuracy: 0.4629\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1469 - accuracy: 0.5083 - val_loss: 1.5075 - val_accuracy: 0.5098\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1280 - accuracy: 0.5172 - val_loss: 1.3358 - val_accuracy: 0.5535\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1033 - accuracy: 0.5242 - val_loss: 1.3240 - val_accuracy: 0.5687\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2160 - accuracy: 0.4977 - val_loss: 1.3132 - val_accuracy: 0.5684\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1011 - accuracy: 0.5296 - val_loss: 1.2985 - val_accuracy: 0.5680\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0145 - accuracy: 0.5459 - val_loss: 1.2614 - val_accuracy: 0.5865\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9920 - accuracy: 0.5515 - val_loss: 1.2074 - val_accuracy: 0.5954\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0341 - accuracy: 0.5441 - val_loss: 1.3857 - val_accuracy: 0.5442\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1910 - accuracy: 0.5194 - val_loss: 1.2420 - val_accuracy: 0.5940\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1248 - accuracy: 0.5358 - val_loss: 1.3238 - val_accuracy: 0.5719\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0307 - accuracy: 0.5418 - val_loss: 1.2342 - val_accuracy: 0.6014\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4629 - accuracy: 0.4942 - val_loss: 1.3591 - val_accuracy: 0.5311\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 1.1705 - accuracy: 0.5076 - val_loss: 1.3375 - val_accuracy: 0.5464\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5199 - accuracy: 0.4908 - val_loss: 1.3788 - val_accuracy: 0.5456\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1394 - accuracy: 0.5240 - val_loss: 1.2915 - val_accuracy: 0.5829\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1698 - accuracy: 0.5312 - val_loss: 1.3018 - val_accuracy: 0.5773\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0638 - accuracy: 0.5411 - val_loss: 1.3363 - val_accuracy: 0.5567\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1025 - accuracy: 0.5117 - val_loss: 1.2781 - val_accuracy: 0.5631\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2031 - accuracy: 0.5378 - val_loss: 1.1915 - val_accuracy: 0.5989\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0059 - accuracy: 0.5425 - val_loss: 1.4138 - val_accuracy: 0.5396\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9647 - accuracy: 0.5595 - val_loss: 1.1820 - val_accuracy: 0.6028\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1240 - accuracy: 0.5423 - val_loss: 1.2814 - val_accuracy: 0.5854\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0604 - accuracy: 0.5590 - val_loss: 1.2730 - val_accuracy: 0.5773\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0182 - accuracy: 0.5585 - val_loss: 1.2961 - val_accuracy: 0.5766\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9236 - accuracy: 0.5687 - val_loss: 1.1542 - val_accuracy: 0.6160\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9730 - accuracy: 0.5672 - val_loss: 1.1475 - val_accuracy: 0.6249\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9306 - accuracy: 0.5625 - val_loss: 1.1944 - val_accuracy: 0.6050\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9243 - accuracy: 0.5794 - val_loss: 1.1772 - val_accuracy: 0.6092\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1477 - accuracy: 0.5176 - val_loss: 1.3610 - val_accuracy: 0.5350\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0350 - accuracy: 0.5663 - val_loss: 1.1312 - val_accuracy: 0.6423\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0087 - accuracy: 0.5676 - val_loss: 1.3007 - val_accuracy: 0.5652\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9403 - accuracy: 0.5724 - val_loss: 1.1837 - val_accuracy: 0.6128\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0321 - accuracy: 0.5511 - val_loss: 1.2033 - val_accuracy: 0.5915\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2067 - accuracy: 0.5181 - val_loss: 1.5830 - val_accuracy: 0.4476\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5669 - accuracy: 0.4888 - val_loss: 1.5945 - val_accuracy: 0.4774\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3276 - accuracy: 0.5039 - val_loss: 1.3768 - val_accuracy: 0.5254\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1848 - accuracy: 0.5147 - val_loss: 1.3977 - val_accuracy: 0.5165\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2245 - accuracy: 0.5298 - val_loss: 1.2805 - val_accuracy: 0.5854\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1966 - accuracy: 0.5206 - val_loss: 1.3480 - val_accuracy: 0.5538\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1387 - accuracy: 0.5508 - val_loss: 1.3326 - val_accuracy: 0.5609\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1548 - accuracy: 0.5021 - val_loss: 1.2780 - val_accuracy: 0.5812\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2201 - accuracy: 0.5429 - val_loss: 1.3084 - val_accuracy: 0.5666\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1230 - accuracy: 0.5371 - val_loss: 1.3865 - val_accuracy: 0.5215\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1030 - accuracy: 0.5336 - val_loss: 1.2328 - val_accuracy: 0.5844\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0713 - accuracy: 0.5276 - val_loss: 1.2873 - val_accuracy: 0.5741\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4812 - accuracy: 0.4840 - val_loss: 1.4955 - val_accuracy: 0.5165\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5999 - accuracy: 0.5025 - val_loss: 1.3019 - val_accuracy: 0.5744\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2248 - accuracy: 0.5191 - val_loss: 1.2214 - val_accuracy: 0.6007\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1327 - accuracy: 0.5296 - val_loss: 1.2386 - val_accuracy: 0.5815\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9942 - accuracy: 0.5505 - val_loss: 1.1914 - val_accuracy: 0.6121\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0020 - accuracy: 0.5630 - val_loss: 1.1740 - val_accuracy: 0.6075\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4061 - accuracy: 0.5483 - val_loss: 1.5789 - val_accuracy: 0.5265\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0408 - accuracy: 0.5465 - val_loss: 1.2919 - val_accuracy: 0.5794\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0549 - accuracy: 0.5536 - val_loss: 1.1679 - val_accuracy: 0.6153\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0964 - accuracy: 0.5583 - val_loss: 1.4804 - val_accuracy: 0.5119\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0461 - accuracy: 0.5552 - val_loss: 1.1595 - val_accuracy: 0.6195\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9915 - accuracy: 0.5624 - val_loss: 1.1663 - val_accuracy: 0.6131\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9215 - accuracy: 0.5945 - val_loss: 1.2184 - val_accuracy: 0.6050\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9311 - accuracy: 0.5868 - val_loss: 1.1692 - val_accuracy: 0.6163\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8659 - accuracy: 0.5951 - val_loss: 1.1070 - val_accuracy: 0.6391\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1685 - accuracy: 0.5605 - val_loss: 1.3941 - val_accuracy: 0.5506\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2649 - accuracy: 0.5266 - val_loss: 1.1891 - val_accuracy: 0.6266\n",
      "Epoch 116/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9789 - accuracy: 0.5715 - val_loss: 1.1619 - val_accuracy: 0.6217\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0359 - accuracy: 0.5514 - val_loss: 1.4265 - val_accuracy: 0.5503\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3603 - accuracy: 0.4940 - val_loss: 1.6864 - val_accuracy: 0.4440\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3215 - accuracy: 0.4910 - val_loss: 1.3207 - val_accuracy: 0.5666\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2428 - accuracy: 0.5400 - val_loss: 1.6487 - val_accuracy: 0.4522\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2339 - accuracy: 0.5258 - val_loss: 1.2437 - val_accuracy: 0.5961\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0479 - accuracy: 0.5619 - val_loss: 1.1657 - val_accuracy: 0.6099\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9508 - accuracy: 0.5732 - val_loss: 1.2448 - val_accuracy: 0.5822\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9199 - accuracy: 0.5866 - val_loss: 1.1627 - val_accuracy: 0.6199\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0805 - accuracy: 0.5798 - val_loss: 1.4947 - val_accuracy: 0.5147\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0772 - accuracy: 0.5408 - val_loss: 1.1875 - val_accuracy: 0.6178\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9590 - accuracy: 0.5552 - val_loss: 1.1797 - val_accuracy: 0.6153\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0399 - accuracy: 0.5641 - val_loss: 1.1282 - val_accuracy: 0.6316\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9843 - accuracy: 0.5680 - val_loss: 1.1215 - val_accuracy: 0.6220\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8932 - accuracy: 0.5936 - val_loss: 1.2182 - val_accuracy: 0.6114\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9621 - accuracy: 0.5734 - val_loss: 1.3667 - val_accuracy: 0.5599\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0627 - accuracy: 0.5824 - val_loss: 1.1832 - val_accuracy: 0.6195\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9106 - accuracy: 0.5748 - val_loss: 1.2407 - val_accuracy: 0.5964\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8283 - accuracy: 0.6077 - val_loss: 1.0460 - val_accuracy: 0.6519\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9212 - accuracy: 0.6014 - val_loss: 1.3759 - val_accuracy: 0.5798\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9431 - accuracy: 0.5691 - val_loss: 1.1666 - val_accuracy: 0.5986\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8692 - accuracy: 0.5861 - val_loss: 1.1302 - val_accuracy: 0.6213\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9035 - accuracy: 0.5849 - val_loss: 1.1635 - val_accuracy: 0.5989\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9323 - accuracy: 0.5635 - val_loss: 1.1051 - val_accuracy: 0.6188\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2247 - accuracy: 0.5732 - val_loss: 1.1997 - val_accuracy: 0.6121\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9531 - accuracy: 0.5593 - val_loss: 1.1733 - val_accuracy: 0.6046\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9164 - accuracy: 0.5848 - val_loss: 1.0732 - val_accuracy: 0.6497\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9639 - accuracy: 0.5764 - val_loss: 1.1029 - val_accuracy: 0.6316\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9982 - accuracy: 0.5892 - val_loss: 1.2179 - val_accuracy: 0.6078\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1153 - accuracy: 0.5312 - val_loss: 1.3155 - val_accuracy: 0.5332\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1470 - accuracy: 0.5635 - val_loss: 1.0995 - val_accuracy: 0.6345\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9211 - accuracy: 0.5801 - val_loss: 1.1027 - val_accuracy: 0.6256\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0481 - accuracy: 0.5480 - val_loss: 1.2691 - val_accuracy: 0.5492\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3895 - accuracy: 0.5436 - val_loss: 1.8174 - val_accuracy: 0.4238\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8863 - accuracy: 0.4532 - val_loss: 1.3571 - val_accuracy: 0.5556\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1468 - accuracy: 0.5224 - val_loss: 1.2588 - val_accuracy: 0.5961\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9797 - accuracy: 0.5560 - val_loss: 1.2320 - val_accuracy: 0.5844\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9615 - accuracy: 0.5717 - val_loss: 1.1445 - val_accuracy: 0.6210\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0475 - accuracy: 0.5684 - val_loss: 1.1667 - val_accuracy: 0.6078\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9531 - accuracy: 0.5870 - val_loss: 1.2312 - val_accuracy: 0.5883\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1708 - accuracy: 0.5553 - val_loss: 1.2518 - val_accuracy: 0.5847\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0535 - accuracy: 0.5455 - val_loss: 1.1033 - val_accuracy: 0.6298\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8903 - accuracy: 0.5815 - val_loss: 1.0983 - val_accuracy: 0.6274\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8973 - accuracy: 0.5843 - val_loss: 1.1168 - val_accuracy: 0.6146\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9617 - accuracy: 0.5758 - val_loss: 1.2193 - val_accuracy: 0.5851\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8505 - accuracy: 0.5871 - val_loss: 1.1982 - val_accuracy: 0.5964\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9374 - accuracy: 0.5807 - val_loss: 1.2068 - val_accuracy: 0.6032\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9627 - accuracy: 0.5797 - val_loss: 1.2696 - val_accuracy: 0.5599\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0181 - accuracy: 0.5583 - val_loss: 1.1910 - val_accuracy: 0.6071\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0942 - accuracy: 0.5615 - val_loss: 1.2678 - val_accuracy: 0.5940\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9167 - accuracy: 0.5679 - val_loss: 1.1474 - val_accuracy: 0.6181\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8982 - accuracy: 0.5893 - val_loss: 1.1254 - val_accuracy: 0.6224\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1220 - accuracy: 0.5808 - val_loss: 1.2024 - val_accuracy: 0.6142\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8868 - accuracy: 0.5893 - val_loss: 1.1625 - val_accuracy: 0.5996\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8952 - accuracy: 0.5838 - val_loss: 1.1765 - val_accuracy: 0.6153\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9663 - accuracy: 0.5856 - val_loss: 1.0941 - val_accuracy: 0.6234\n",
      "Epoch 172/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8819 - accuracy: 0.5819 - val_loss: 1.0867 - val_accuracy: 0.6256\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8405 - accuracy: 0.6067 - val_loss: 1.0571 - val_accuracy: 0.6274\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4997 - accuracy: 0.5312 - val_loss: 1.2410 - val_accuracy: 0.5737\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1227 - accuracy: 0.5496 - val_loss: 1.1284 - val_accuracy: 0.6007\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8869 - accuracy: 0.5854 - val_loss: 1.1012 - val_accuracy: 0.6224\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8893 - accuracy: 0.5899 - val_loss: 1.5551 - val_accuracy: 0.5030\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9089 - accuracy: 0.5791 - val_loss: 1.0965 - val_accuracy: 0.6234\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2562 - accuracy: 0.5412 - val_loss: 1.1811 - val_accuracy: 0.6096\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5238 - accuracy: 0.5151 - val_loss: 1.3006 - val_accuracy: 0.5652\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3759 - accuracy: 0.5116 - val_loss: 1.2315 - val_accuracy: 0.6053\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9169 - accuracy: 0.5828 - val_loss: 1.1607 - val_accuracy: 0.6178\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0726 - accuracy: 0.5585 - val_loss: 1.1482 - val_accuracy: 0.6202\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8210 - accuracy: 0.6029 - val_loss: 1.1318 - val_accuracy: 0.6153\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8315 - accuracy: 0.5968 - val_loss: 1.1312 - val_accuracy: 0.6252\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8364 - accuracy: 0.5859 - val_loss: 1.0724 - val_accuracy: 0.6519\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9305 - accuracy: 0.5823 - val_loss: 1.0915 - val_accuracy: 0.6377\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8146 - accuracy: 0.6033 - val_loss: 1.1559 - val_accuracy: 0.6185\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8857 - accuracy: 0.5887 - val_loss: 1.1397 - val_accuracy: 0.6242\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8129 - accuracy: 0.5986 - val_loss: 1.4473 - val_accuracy: 0.5080\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0474 - accuracy: 0.5798 - val_loss: 1.2001 - val_accuracy: 0.6089\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8924 - accuracy: 0.5908 - val_loss: 1.2261 - val_accuracy: 0.5787\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8617 - accuracy: 0.5827 - val_loss: 1.1761 - val_accuracy: 0.6107\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9538 - accuracy: 0.5882 - val_loss: 1.1908 - val_accuracy: 0.6057\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8872 - accuracy: 0.5892 - val_loss: 1.1025 - val_accuracy: 0.6341\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8189 - accuracy: 0.6050 - val_loss: 1.1048 - val_accuracy: 0.6213\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9343 - accuracy: 0.5779 - val_loss: 1.3240 - val_accuracy: 0.5293\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0861 - accuracy: 0.5535 - val_loss: 1.1548 - val_accuracy: 0.6167\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9593 - accuracy: 0.5906 - val_loss: 1.6164 - val_accuracy: 0.4654\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9514 - accuracy: 0.5761 - val_loss: 1.0874 - val_accuracy: 0.6352\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8904 - accuracy: 0.5490 - val_loss: 1.2161 - val_accuracy: 0.5950\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5690 - accuracy: 0.5045 - val_loss: 1.2465 - val_accuracy: 0.5876\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2885 - accuracy: 0.5575 - val_loss: 1.1485 - val_accuracy: 0.6096\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0785 - accuracy: 0.5592 - val_loss: 1.2626 - val_accuracy: 0.5755\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3112 - accuracy: 0.5148 - val_loss: 1.2469 - val_accuracy: 0.5915\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1148 - accuracy: 0.5658 - val_loss: 1.2117 - val_accuracy: 0.6085\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0339 - accuracy: 0.5895 - val_loss: 1.3286 - val_accuracy: 0.5311\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2514 - accuracy: 0.5211 - val_loss: 1.1917 - val_accuracy: 0.6014\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4165 - accuracy: 0.5028 - val_loss: 1.3010 - val_accuracy: 0.5744\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2306 - accuracy: 0.5412 - val_loss: 1.1336 - val_accuracy: 0.6163\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0549 - accuracy: 0.5473 - val_loss: 1.2596 - val_accuracy: 0.5773\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1964 - accuracy: 0.5242 - val_loss: 1.1664 - val_accuracy: 0.5979\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4532 - accuracy: 0.5476 - val_loss: 1.1947 - val_accuracy: 0.5947\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9884 - accuracy: 0.5711 - val_loss: 1.0984 - val_accuracy: 0.6313\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8667 - accuracy: 0.5950 - val_loss: 1.1121 - val_accuracy: 0.6199\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1562 - accuracy: 0.5530 - val_loss: 1.3705 - val_accuracy: 0.5137\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1753 - accuracy: 0.5292 - val_loss: 1.1966 - val_accuracy: 0.6021\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0308 - accuracy: 0.5525 - val_loss: 1.2103 - val_accuracy: 0.5933\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9956 - accuracy: 0.5575 - val_loss: 1.3346 - val_accuracy: 0.5506\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8804 - accuracy: 0.5940 - val_loss: 1.1037 - val_accuracy: 0.6295\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8411 - accuracy: 0.5954 - val_loss: 1.1032 - val_accuracy: 0.6316\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0155 - accuracy: 0.5644 - val_loss: 1.1639 - val_accuracy: 0.5993\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9948 - accuracy: 0.5448 - val_loss: 1.3350 - val_accuracy: 0.5520\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9815 - accuracy: 0.4747 - val_loss: 1.9879 - val_accuracy: 0.3595\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1411 - accuracy: 0.4266 - val_loss: 1.6544 - val_accuracy: 0.4909\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6650 - accuracy: 0.4845 - val_loss: 1.3018 - val_accuracy: 0.5829\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1756 - accuracy: 0.5386 - val_loss: 1.2990 - val_accuracy: 0.5783\n",
      "Epoch 228/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1510 - accuracy: 0.5233 - val_loss: 1.2153 - val_accuracy: 0.5886\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2342 - accuracy: 0.5313 - val_loss: 1.1931 - val_accuracy: 0.5876\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0076 - accuracy: 0.5585 - val_loss: 1.1979 - val_accuracy: 0.5872\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0681 - accuracy: 0.5480 - val_loss: 1.1557 - val_accuracy: 0.6195\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9500 - accuracy: 0.5687 - val_loss: 1.2150 - val_accuracy: 0.5890\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0681 - accuracy: 0.5396 - val_loss: 1.2415 - val_accuracy: 0.5840\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9888 - accuracy: 0.5819 - val_loss: 1.4638 - val_accuracy: 0.5176\n",
      "\n",
      "Validation 4, fold 5 :\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.9045 - accuracy: 0.0651 - val_loss: 2.8062 - val_accuracy: 0.2913\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7643 - accuracy: 0.2158 - val_loss: 2.6598 - val_accuracy: 0.2650\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.6928 - accuracy: 0.1344 - val_loss: 2.5535 - val_accuracy: 0.1165\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.6474 - accuracy: 0.1145 - val_loss: 2.3741 - val_accuracy: 0.2149\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.5926 - accuracy: 0.1827 - val_loss: 2.3720 - val_accuracy: 0.1918\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.4157 - accuracy: 0.1913 - val_loss: 2.2482 - val_accuracy: 0.2561\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2517 - accuracy: 0.2259 - val_loss: 2.1344 - val_accuracy: 0.2707\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2158 - accuracy: 0.2528 - val_loss: 2.0464 - val_accuracy: 0.3474\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2496 - accuracy: 0.2676 - val_loss: 1.9972 - val_accuracy: 0.3339\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9837 - accuracy: 0.2971 - val_loss: 1.8650 - val_accuracy: 0.3865\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2211 - accuracy: 0.3238 - val_loss: 1.9976 - val_accuracy: 0.3485\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1080 - accuracy: 0.3140 - val_loss: 1.9191 - val_accuracy: 0.3535\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8484 - accuracy: 0.3509 - val_loss: 1.7869 - val_accuracy: 0.4245\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9805 - accuracy: 0.3486 - val_loss: 2.1545 - val_accuracy: 0.2721\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8312 - accuracy: 0.3541 - val_loss: 1.7469 - val_accuracy: 0.4536\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7403 - accuracy: 0.3793 - val_loss: 1.6350 - val_accuracy: 0.4632\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6658 - accuracy: 0.3896 - val_loss: 1.6052 - val_accuracy: 0.4760\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6173 - accuracy: 0.4098 - val_loss: 1.5810 - val_accuracy: 0.4821\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5674 - accuracy: 0.4072 - val_loss: 1.6256 - val_accuracy: 0.4693\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5774 - accuracy: 0.4119 - val_loss: 1.6184 - val_accuracy: 0.4821\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5080 - accuracy: 0.4259 - val_loss: 1.5602 - val_accuracy: 0.4579\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4571 - accuracy: 0.4475 - val_loss: 1.4531 - val_accuracy: 0.5080\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4103 - accuracy: 0.4575 - val_loss: 1.5076 - val_accuracy: 0.5240\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6093 - accuracy: 0.4182 - val_loss: 1.5099 - val_accuracy: 0.4892\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3852 - accuracy: 0.4544 - val_loss: 1.6917 - val_accuracy: 0.4583\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3667 - accuracy: 0.4704 - val_loss: 1.4379 - val_accuracy: 0.5218\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3681 - accuracy: 0.4660 - val_loss: 1.4708 - val_accuracy: 0.5179\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3673 - accuracy: 0.4625 - val_loss: 1.4336 - val_accuracy: 0.5297\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3002 - accuracy: 0.4739 - val_loss: 1.3990 - val_accuracy: 0.5336\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2879 - accuracy: 0.4731 - val_loss: 1.3409 - val_accuracy: 0.5584\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2504 - accuracy: 0.4890 - val_loss: 1.3827 - val_accuracy: 0.5329\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2554 - accuracy: 0.4742 - val_loss: 1.4194 - val_accuracy: 0.5343\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2044 - accuracy: 0.4884 - val_loss: 1.4694 - val_accuracy: 0.5155\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3705 - accuracy: 0.4799 - val_loss: 1.3754 - val_accuracy: 0.5552\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2157 - accuracy: 0.4904 - val_loss: 1.4568 - val_accuracy: 0.5243\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2752 - accuracy: 0.4948 - val_loss: 1.4466 - val_accuracy: 0.5094\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1689 - accuracy: 0.4922 - val_loss: 1.3715 - val_accuracy: 0.5336\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1606 - accuracy: 0.4950 - val_loss: 1.4959 - val_accuracy: 0.4970\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2110 - accuracy: 0.5034 - val_loss: 1.3407 - val_accuracy: 0.5531\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2852 - accuracy: 0.4861 - val_loss: 1.4617 - val_accuracy: 0.5176\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3190 - accuracy: 0.4822 - val_loss: 1.7392 - val_accuracy: 0.4742\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1748 - accuracy: 0.5017 - val_loss: 1.3679 - val_accuracy: 0.5531\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0632 - accuracy: 0.5225 - val_loss: 1.2524 - val_accuracy: 0.5744\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0712 - accuracy: 0.5189 - val_loss: 1.3760 - val_accuracy: 0.5520\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1798 - accuracy: 0.5138 - val_loss: 1.3980 - val_accuracy: 0.5410\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1233 - accuracy: 0.5033 - val_loss: 1.3083 - val_accuracy: 0.5584\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9967 - accuracy: 0.5312 - val_loss: 1.2443 - val_accuracy: 0.5879\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1745 - accuracy: 0.5157 - val_loss: 1.2911 - val_accuracy: 0.5677\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0771 - accuracy: 0.5247 - val_loss: 1.2576 - val_accuracy: 0.5805\n",
      "Epoch 50/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0460 - accuracy: 0.5286 - val_loss: 1.2885 - val_accuracy: 0.5677\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1189 - accuracy: 0.5266 - val_loss: 1.4822 - val_accuracy: 0.4948\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2153 - accuracy: 0.4958 - val_loss: 1.3401 - val_accuracy: 0.5474\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0937 - accuracy: 0.5170 - val_loss: 1.5326 - val_accuracy: 0.5012\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8137 - accuracy: 0.4629 - val_loss: 1.4694 - val_accuracy: 0.5293\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1846 - accuracy: 0.3800 - val_loss: 1.5777 - val_accuracy: 0.4451\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4255 - accuracy: 0.4477 - val_loss: 1.5624 - val_accuracy: 0.4600\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4080 - accuracy: 0.4742 - val_loss: 1.3387 - val_accuracy: 0.5311\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2280 - accuracy: 0.5046 - val_loss: 1.3715 - val_accuracy: 0.5545\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3014 - accuracy: 0.5068 - val_loss: 1.5510 - val_accuracy: 0.4764\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2894 - accuracy: 0.4593 - val_loss: 1.4074 - val_accuracy: 0.5385\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1611 - accuracy: 0.4959 - val_loss: 1.3497 - val_accuracy: 0.5488\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0580 - accuracy: 0.5226 - val_loss: 1.2383 - val_accuracy: 0.5904\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6151 - accuracy: 0.4569 - val_loss: 1.4588 - val_accuracy: 0.5286\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3511 - accuracy: 0.4775 - val_loss: 1.3687 - val_accuracy: 0.5329\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1516 - accuracy: 0.5079 - val_loss: 1.3062 - val_accuracy: 0.5620\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2266 - accuracy: 0.4909 - val_loss: 1.4799 - val_accuracy: 0.5194\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4147 - accuracy: 0.4676 - val_loss: 1.5052 - val_accuracy: 0.4995\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2057 - accuracy: 0.4841 - val_loss: 1.2685 - val_accuracy: 0.5702\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1633 - accuracy: 0.5237 - val_loss: 1.2809 - val_accuracy: 0.5851\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1058 - accuracy: 0.5296 - val_loss: 1.3658 - val_accuracy: 0.5464\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1001 - accuracy: 0.5182 - val_loss: 1.2687 - val_accuracy: 0.5851\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2609 - accuracy: 0.5328 - val_loss: 1.7724 - val_accuracy: 0.4629\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4231 - accuracy: 0.4795 - val_loss: 1.6955 - val_accuracy: 0.4803\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4759 - accuracy: 0.4724 - val_loss: 1.3950 - val_accuracy: 0.5400\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1329 - accuracy: 0.5116 - val_loss: 1.3755 - val_accuracy: 0.5375\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1394 - accuracy: 0.4945 - val_loss: 1.2694 - val_accuracy: 0.5687\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0135 - accuracy: 0.5383 - val_loss: 1.2245 - val_accuracy: 0.5833\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2717 - accuracy: 0.5055 - val_loss: 1.2624 - val_accuracy: 0.5854\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2923 - accuracy: 0.4796 - val_loss: 1.4394 - val_accuracy: 0.5052\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0852 - accuracy: 0.5143 - val_loss: 1.2875 - val_accuracy: 0.5577\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9843 - accuracy: 0.5465 - val_loss: 1.2804 - val_accuracy: 0.5652\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9547 - accuracy: 0.5565 - val_loss: 1.1980 - val_accuracy: 0.5780\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0771 - accuracy: 0.5539 - val_loss: 1.3229 - val_accuracy: 0.5734\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1068 - accuracy: 0.5380 - val_loss: 1.2397 - val_accuracy: 0.5947\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0224 - accuracy: 0.5340 - val_loss: 1.3263 - val_accuracy: 0.5574\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1863 - accuracy: 0.5053 - val_loss: 1.2677 - val_accuracy: 0.5723\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0400 - accuracy: 0.5392 - val_loss: 1.2756 - val_accuracy: 0.5524\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3089 - accuracy: 0.5048 - val_loss: 1.2959 - val_accuracy: 0.5613\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4688 - accuracy: 0.4893 - val_loss: 1.3624 - val_accuracy: 0.5265\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4036 - accuracy: 0.4933 - val_loss: 1.3691 - val_accuracy: 0.5435\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2036 - accuracy: 0.4996 - val_loss: 1.2533 - val_accuracy: 0.5833\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0794 - accuracy: 0.5314 - val_loss: 1.2938 - val_accuracy: 0.5840\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7290 - accuracy: 0.4949 - val_loss: 1.3745 - val_accuracy: 0.5428\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1395 - accuracy: 0.5193 - val_loss: 1.3399 - val_accuracy: 0.5421\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3100 - accuracy: 0.5184 - val_loss: 1.3810 - val_accuracy: 0.5528\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3761 - accuracy: 0.4962 - val_loss: 1.4707 - val_accuracy: 0.4710\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1738 - accuracy: 0.5117 - val_loss: 1.1836 - val_accuracy: 0.6014\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1893 - accuracy: 0.5213 - val_loss: 1.4410 - val_accuracy: 0.5179\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2271 - accuracy: 0.5043 - val_loss: 1.2759 - val_accuracy: 0.5918\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1216 - accuracy: 0.5158 - val_loss: 1.2788 - val_accuracy: 0.5691\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0779 - accuracy: 0.5292 - val_loss: 1.2902 - val_accuracy: 0.5705\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0159 - accuracy: 0.5439 - val_loss: 1.1357 - val_accuracy: 0.6306\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9686 - accuracy: 0.5546 - val_loss: 1.2435 - val_accuracy: 0.5929\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0578 - accuracy: 0.5197 - val_loss: 1.3223 - val_accuracy: 0.5265\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1292 - accuracy: 0.5172 - val_loss: 1.1835 - val_accuracy: 0.5975\n",
      "Epoch 106/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2841 - accuracy: 0.5152 - val_loss: 1.2363 - val_accuracy: 0.5787\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0992 - accuracy: 0.5217 - val_loss: 1.2029 - val_accuracy: 0.6067\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0011 - accuracy: 0.5386 - val_loss: 1.2008 - val_accuracy: 0.5975\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1769 - accuracy: 0.5230 - val_loss: 1.2300 - val_accuracy: 0.5847\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0315 - accuracy: 0.5358 - val_loss: 1.2927 - val_accuracy: 0.5869\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0725 - accuracy: 0.5388 - val_loss: 1.1907 - val_accuracy: 0.5929\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9793 - accuracy: 0.5555 - val_loss: 1.1567 - val_accuracy: 0.6053\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9191 - accuracy: 0.5717 - val_loss: 1.1902 - val_accuracy: 0.6213\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9629 - accuracy: 0.5557 - val_loss: 1.1498 - val_accuracy: 0.6345\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9847 - accuracy: 0.5192 - val_loss: 1.5025 - val_accuracy: 0.5073\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6229 - accuracy: 0.5004 - val_loss: 1.1759 - val_accuracy: 0.6039\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5243 - accuracy: 0.5112 - val_loss: 1.2261 - val_accuracy: 0.5890\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0982 - accuracy: 0.5366 - val_loss: 1.1506 - val_accuracy: 0.6259\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3640 - accuracy: 0.5159 - val_loss: 1.1812 - val_accuracy: 0.6039\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2592 - accuracy: 0.5414 - val_loss: 1.2440 - val_accuracy: 0.5893\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0511 - accuracy: 0.5176 - val_loss: 1.1871 - val_accuracy: 0.6004\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0515 - accuracy: 0.5488 - val_loss: 1.1741 - val_accuracy: 0.5961\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9792 - accuracy: 0.5495 - val_loss: 1.1800 - val_accuracy: 0.5961\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0490 - accuracy: 0.5448 - val_loss: 1.1108 - val_accuracy: 0.6387\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9905 - accuracy: 0.5589 - val_loss: 1.3204 - val_accuracy: 0.5723\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0123 - accuracy: 0.5509 - val_loss: 1.1202 - val_accuracy: 0.6337\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9267 - accuracy: 0.5632 - val_loss: 1.1016 - val_accuracy: 0.6391\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8892 - accuracy: 0.5709 - val_loss: 1.0534 - val_accuracy: 0.6575\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8738 - accuracy: 0.5808 - val_loss: 1.1302 - val_accuracy: 0.6284\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9255 - accuracy: 0.5496 - val_loss: 1.1147 - val_accuracy: 0.6146\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8761 - accuracy: 0.5702 - val_loss: 1.1219 - val_accuracy: 0.6355\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9725 - accuracy: 0.5608 - val_loss: 1.1356 - val_accuracy: 0.6266\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1747 - accuracy: 0.5239 - val_loss: 1.2849 - val_accuracy: 0.5726\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0033 - accuracy: 0.5424 - val_loss: 1.2450 - val_accuracy: 0.5719\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6269 - accuracy: 0.4907 - val_loss: 1.8261 - val_accuracy: 0.4231\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2687 - accuracy: 0.4909 - val_loss: 1.4401 - val_accuracy: 0.5126\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0671 - accuracy: 0.5369 - val_loss: 1.1780 - val_accuracy: 0.6174\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9119 - accuracy: 0.5679 - val_loss: 1.1009 - val_accuracy: 0.6359\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9918 - accuracy: 0.5668 - val_loss: 1.2808 - val_accuracy: 0.6099\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9750 - accuracy: 0.5619 - val_loss: 1.0827 - val_accuracy: 0.6579\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0891 - accuracy: 0.5495 - val_loss: 1.1915 - val_accuracy: 0.6227\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9984 - accuracy: 0.5640 - val_loss: 1.1894 - val_accuracy: 0.6060\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0324 - accuracy: 0.5396 - val_loss: 1.1320 - val_accuracy: 0.6256\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9219 - accuracy: 0.5651 - val_loss: 1.1900 - val_accuracy: 0.6018\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9207 - accuracy: 0.5677 - val_loss: 1.0746 - val_accuracy: 0.6487\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8277 - accuracy: 0.5882 - val_loss: 1.0582 - val_accuracy: 0.6561\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0399 - accuracy: 0.5601 - val_loss: 1.2337 - val_accuracy: 0.5986\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9436 - accuracy: 0.5705 - val_loss: 1.1374 - val_accuracy: 0.6288\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5830 - accuracy: 0.5365 - val_loss: 1.3145 - val_accuracy: 0.5570\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2965 - accuracy: 0.5059 - val_loss: 1.6283 - val_accuracy: 0.4494\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3687 - accuracy: 0.4982 - val_loss: 1.6737 - val_accuracy: 0.4519\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0741 - accuracy: 0.5256 - val_loss: 1.1985 - val_accuracy: 0.6135\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9725 - accuracy: 0.5560 - val_loss: 1.1153 - val_accuracy: 0.6313\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0840 - accuracy: 0.5258 - val_loss: 1.2388 - val_accuracy: 0.5911\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9432 - accuracy: 0.5537 - val_loss: 1.1557 - val_accuracy: 0.6234\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0037 - accuracy: 0.5550 - val_loss: 1.1344 - val_accuracy: 0.6217\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0285 - accuracy: 0.5750 - val_loss: 1.2957 - val_accuracy: 0.5869\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0430 - accuracy: 0.5417 - val_loss: 1.3715 - val_accuracy: 0.5250\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5346 - accuracy: 0.5067 - val_loss: 1.2477 - val_accuracy: 0.5890\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0414 - accuracy: 0.5428 - val_loss: 1.1637 - val_accuracy: 0.6043\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0979 - accuracy: 0.5418 - val_loss: 1.1452 - val_accuracy: 0.6195\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9258 - accuracy: 0.5671 - val_loss: 1.1001 - val_accuracy: 0.6348\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0072 - accuracy: 0.5578 - val_loss: 1.1126 - val_accuracy: 0.6401\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9452 - accuracy: 0.5686 - val_loss: 1.1148 - val_accuracy: 0.6384\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8746 - accuracy: 0.5878 - val_loss: 1.0405 - val_accuracy: 0.6575\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8342 - accuracy: 0.5972 - val_loss: 1.1154 - val_accuracy: 0.6362\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0276 - accuracy: 0.5668 - val_loss: 1.2035 - val_accuracy: 0.5904\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9974 - accuracy: 0.5438 - val_loss: 1.1297 - val_accuracy: 0.6362\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2238 - accuracy: 0.5348 - val_loss: 1.2364 - val_accuracy: 0.5893\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9590 - accuracy: 0.5668 - val_loss: 1.1810 - val_accuracy: 0.6146\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9147 - accuracy: 0.5812 - val_loss: 1.1277 - val_accuracy: 0.6288\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9252 - accuracy: 0.5709 - val_loss: 1.2587 - val_accuracy: 0.5790\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8448 - accuracy: 0.5885 - val_loss: 1.0323 - val_accuracy: 0.6547\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0340 - accuracy: 0.5563 - val_loss: 1.4356 - val_accuracy: 0.5343\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5209 - accuracy: 0.5445 - val_loss: 1.5698 - val_accuracy: 0.4813\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2907 - accuracy: 0.4993 - val_loss: 1.1048 - val_accuracy: 0.6512\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0098 - accuracy: 0.5648 - val_loss: 1.1088 - val_accuracy: 0.6252\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8341 - accuracy: 0.5909 - val_loss: 1.0983 - val_accuracy: 0.6384\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.7992 - accuracy: 0.5883 - val_loss: 1.0599 - val_accuracy: 0.6433\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8682 - accuracy: 0.5831 - val_loss: 1.0849 - val_accuracy: 0.6568\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9751 - accuracy: 0.5697 - val_loss: 1.1564 - val_accuracy: 0.6199\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8614 - accuracy: 0.5876 - val_loss: 1.0664 - val_accuracy: 0.6565\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8887 - accuracy: 0.5808 - val_loss: 1.0662 - val_accuracy: 0.6540\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6257 - accuracy: 0.5408 - val_loss: 1.3757 - val_accuracy: 0.5393\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2786 - accuracy: 0.5216 - val_loss: 1.2305 - val_accuracy: 0.5996\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3952 - accuracy: 0.5213 - val_loss: 1.2316 - val_accuracy: 0.5947\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0821 - accuracy: 0.5229 - val_loss: 1.3597 - val_accuracy: 0.5215\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0807 - accuracy: 0.5409 - val_loss: 1.2305 - val_accuracy: 0.5748\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9157 - accuracy: 0.5634 - val_loss: 1.2521 - val_accuracy: 0.5897\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9890 - accuracy: 0.5543 - val_loss: 1.2122 - val_accuracy: 0.5844\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9020 - accuracy: 0.5733 - val_loss: 1.0615 - val_accuracy: 0.6593\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9093 - accuracy: 0.5821 - val_loss: 1.4040 - val_accuracy: 0.5215\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9755 - accuracy: 0.5615 - val_loss: 1.1703 - val_accuracy: 0.5968\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1048 - accuracy: 0.5607 - val_loss: 1.6933 - val_accuracy: 0.4494\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0574 - accuracy: 0.5343 - val_loss: 1.2404 - val_accuracy: 0.5933\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9484 - accuracy: 0.5744 - val_loss: 1.2080 - val_accuracy: 0.6078\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9034 - accuracy: 0.5782 - val_loss: 1.1361 - val_accuracy: 0.6387\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3156 - accuracy: 0.5837 - val_loss: 1.2338 - val_accuracy: 0.5954\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0249 - accuracy: 0.5557 - val_loss: 1.3941 - val_accuracy: 0.5332\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0190 - accuracy: 0.5709 - val_loss: 1.2259 - val_accuracy: 0.5883\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9327 - accuracy: 0.5693 - val_loss: 1.1010 - val_accuracy: 0.6274\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5721 - accuracy: 0.5061 - val_loss: 1.4715 - val_accuracy: 0.4973\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2480 - accuracy: 0.4908 - val_loss: 1.3599 - val_accuracy: 0.5591\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1303 - accuracy: 0.5452 - val_loss: 1.2409 - val_accuracy: 0.5989\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9134 - accuracy: 0.5603 - val_loss: 1.1348 - val_accuracy: 0.6288\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1788 - accuracy: 0.5699 - val_loss: 1.1406 - val_accuracy: 0.6149\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8508 - accuracy: 0.5873 - val_loss: 1.0605 - val_accuracy: 0.6490\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8703 - accuracy: 0.5845 - val_loss: 1.1875 - val_accuracy: 0.6021\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0114 - accuracy: 0.5662 - val_loss: 1.1749 - val_accuracy: 0.6185\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1451 - accuracy: 0.5648 - val_loss: 1.6760 - val_accuracy: 0.4437\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8920 - accuracy: 0.4761 - val_loss: 1.3330 - val_accuracy: 0.5325\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0175 - accuracy: 0.5357 - val_loss: 1.1614 - val_accuracy: 0.6117\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0498 - accuracy: 0.5469 - val_loss: 1.1225 - val_accuracy: 0.6188\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9492 - accuracy: 0.5675 - val_loss: 1.1377 - val_accuracy: 0.6107\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9546 - accuracy: 0.5663 - val_loss: 1.2084 - val_accuracy: 0.5940\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0395 - accuracy: 0.5429 - val_loss: 1.3828 - val_accuracy: 0.5297\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9842 - accuracy: 0.5433 - val_loss: 1.0742 - val_accuracy: 0.6433\n",
      "Epoch 218/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9559 - accuracy: 0.5740 - val_loss: 1.0792 - val_accuracy: 0.6497\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8231 - accuracy: 0.5931 - val_loss: 1.0926 - val_accuracy: 0.6316\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9297 - accuracy: 0.5782 - val_loss: 1.9619 - val_accuracy: 0.5346\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0005 - accuracy: 0.5581 - val_loss: 1.1203 - val_accuracy: 0.6355\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1657 - accuracy: 0.5426 - val_loss: 1.0987 - val_accuracy: 0.6377\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9014 - accuracy: 0.5834 - val_loss: 1.0628 - val_accuracy: 0.6504\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9039 - accuracy: 0.5732 - val_loss: 1.3272 - val_accuracy: 0.5652\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9918 - accuracy: 0.5520 - val_loss: 1.2420 - val_accuracy: 0.5698\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0300 - accuracy: 0.5264 - val_loss: 1.2206 - val_accuracy: 0.6046\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8630 - accuracy: 0.5835 - val_loss: 1.0667 - val_accuracy: 0.6419\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0582 - accuracy: 0.5643 - val_loss: 1.3657 - val_accuracy: 0.5563\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0934 - accuracy: 0.5290 - val_loss: 1.2711 - val_accuracy: 0.5719\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1357 - accuracy: 0.5305 - val_loss: 1.1654 - val_accuracy: 0.6082\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8906 - accuracy: 0.5664 - val_loss: 1.0769 - val_accuracy: 0.6490\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8484 - accuracy: 0.5813 - val_loss: 1.0537 - val_accuracy: 0.6448\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5968 - accuracy: 0.4633 - val_loss: 1.3801 - val_accuracy: 0.5293\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0846 - accuracy: 0.5478 - val_loss: 1.2584 - val_accuracy: 0.5680\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0310 - accuracy: 0.5483 - val_loss: 1.1650 - val_accuracy: 0.6050\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8864 - accuracy: 0.5788 - val_loss: 1.1485 - val_accuracy: 0.6053\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8396 - accuracy: 0.5864 - val_loss: 0.9900 - val_accuracy: 0.6689\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8221 - accuracy: 0.5971 - val_loss: 1.1019 - val_accuracy: 0.6249\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8642 - accuracy: 0.5992 - val_loss: 1.0177 - val_accuracy: 0.6728\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1788 - accuracy: 0.5540 - val_loss: 1.3474 - val_accuracy: 0.5584\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5143 - accuracy: 0.4988 - val_loss: 1.4509 - val_accuracy: 0.5350\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2766 - accuracy: 0.4889 - val_loss: 1.1762 - val_accuracy: 0.6213\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0876 - accuracy: 0.5494 - val_loss: 1.1707 - val_accuracy: 0.6039\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.6490 - accuracy: 0.4969 - val_loss: 1.2483 - val_accuracy: 0.5975\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4887 - accuracy: 0.5123 - val_loss: 1.2619 - val_accuracy: 0.5904\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0696 - accuracy: 0.5528 - val_loss: 1.1552 - val_accuracy: 0.6121\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1062 - accuracy: 0.5463 - val_loss: 1.4803 - val_accuracy: 0.5020\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9223 - accuracy: 0.5723 - val_loss: 1.0580 - val_accuracy: 0.6604\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1986 - accuracy: 0.5338 - val_loss: 1.2752 - val_accuracy: 0.5968\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9567 - accuracy: 0.5774 - val_loss: 1.2148 - val_accuracy: 0.5972\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2546 - accuracy: 0.5181 - val_loss: 1.4208 - val_accuracy: 0.5449\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1538 - accuracy: 0.5234 - val_loss: 1.1238 - val_accuracy: 0.6306\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1914 - accuracy: 0.5341 - val_loss: 1.1014 - val_accuracy: 0.6398\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3724 - accuracy: 0.5560 - val_loss: 1.1353 - val_accuracy: 0.6274\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9677 - accuracy: 0.5657 - val_loss: 1.0715 - val_accuracy: 0.6405\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9186 - accuracy: 0.5807 - val_loss: 1.2803 - val_accuracy: 0.5623\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8933 - accuracy: 0.5702 - val_loss: 1.2343 - val_accuracy: 0.5773\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8644 - accuracy: 0.5869 - val_loss: 1.1529 - val_accuracy: 0.6128\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2160 - accuracy: 0.5128 - val_loss: 1.2480 - val_accuracy: 0.5890\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2665 - accuracy: 0.4994 - val_loss: 1.1859 - val_accuracy: 0.6085\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5076 - accuracy: 0.5144 - val_loss: 1.1537 - val_accuracy: 0.6323\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1647 - accuracy: 0.5439 - val_loss: 1.1091 - val_accuracy: 0.6355\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0018 - accuracy: 0.5427 - val_loss: 1.1391 - val_accuracy: 0.6202\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8831 - accuracy: 0.5785 - val_loss: 1.0578 - val_accuracy: 0.6487\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9287 - accuracy: 0.5698 - val_loss: 1.0979 - val_accuracy: 0.6234\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9132 - accuracy: 0.5802 - val_loss: 1.0989 - val_accuracy: 0.6455\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8403 - accuracy: 0.5899 - val_loss: 1.0292 - val_accuracy: 0.6593\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8935 - accuracy: 0.6085 - val_loss: 1.1695 - val_accuracy: 0.5993\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0635 - accuracy: 0.5274 - val_loss: 1.3205 - val_accuracy: 0.5332\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0877 - accuracy: 0.5242 - val_loss: 1.2477 - val_accuracy: 0.5950\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0543 - accuracy: 0.5504 - val_loss: 1.3617 - val_accuracy: 0.5705\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2547 - accuracy: 0.5242 - val_loss: 1.4211 - val_accuracy: 0.5368\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1587 - accuracy: 0.5328 - val_loss: 1.2482 - val_accuracy: 0.5705\n"
     ]
    }
   ],
   "source": [
    "model_name = \"january_to_april_2018_every_usable_labels\"\n",
    "\n",
    "# images have all the same shapes, take the shape of the first image\n",
    "image_width = len(dataset[0][1][0][0])\n",
    "image_height = len(dataset[0][1][0])\n",
    "image_depth = len(bands)\n",
    "nb_outputs = len(labels)\n",
    "\n",
    "# Create model\n",
    "model = Sequential([\n",
    "    Rescaling(0.0000275, offset=0.2, input_shape=(image_width, image_height, image_depth)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    SpatialDropout2D(0.25),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(nb_outputs, activation='softmax'),\n",
    "])\n",
    "\n",
    "mean_loss, mean_accuracy, histories, conf_matrix = cross_validation(model, dataset, bands, labels, EPOCHS, NB_TESTS, early_stopping=True, with_model_checkpoint=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifth-minority",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, history in enumerate(histories):\n",
    "    pl.plot(history.history['loss'], label='Training', color=\"blue\")\n",
    "    pl.plot(history.history['val_loss'], label='Testing', color=\"orange\")\n",
    "    \n",
    "    if i == 0:\n",
    "        pl.legend()\n",
    "        \n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "natural-hopkins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, history in enumerate(histories):\n",
    "    pl.plot(history.history['f1_score_train'], label='Training', color=\"blue\")\n",
    "    pl.plot(history.history['f1_score_val'], label='Testing', color=\"orange\")\n",
    "    \n",
    "    if i == 0:\n",
    "        pl.legend()\n",
    "        \n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "static-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA14AAANgCAYAAAA8qLkvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAxOAAAMTgF/d4wjAAEAAElEQVR4nOzddZwU9R/H8dfngo4DbDEIxZ+B2CKdgoD6U2z92R2g2N2KiWJ3dzd2txKKYCfdecRxn98fM3fs3e0eB7IzA/d+Ph77YGJ3583c7Ox+Z75h7o6IiIiIiIhkT07cAURERERERFZ3KniJiIiIiIhkmQpeIiIiIiIiWaaCl4iIiIiISJap4CUiIiIiIpJlKniJiIiIiIhkmQpeIiIiIiIiWaaCl4iIiKw0ZvaMmR0WTl9qZgct4/ltzGz/FdxWPTNLOyCpmV1sZkOq8B5Vel6a1z1gZgOX93UiUn3lxR1AREREksvM8ty9aEVe6+4XVuFpbYA9gSdWZBsiIqsK3fESERGphszMzexyMxtuZj+l3pkK111iZl8BV5lZfTO728y+NLNRZnaXmdUIn7uZmX1qZqPN7AWgQcr7lN4VMrMaZnatmX1vZiPN7A0zWwu4FOhiZiPM7I7wuTuY2btm9nWYb5+U9zzWzH42s+HAqVX8v25lZh+b2bdm9oOZnV/uKRuE2xtrZi+bWZPwdflmdnX4/x5hZk+ZWaPl39siIip4iYiIVGfu7tsAvYChZrZxyrol7r6Du58BXA985O47AlsT/H4YED7vYeBed98CuADolGFb5wCbAtu5+9bAIe4+GbgQeM/d27j7cWZWANwFHOTu2wM9gOvNbH0z2xK4BOgY5q5dxf/nH0A3d98W2A7Y28x2TlnfATjQ3TcD/gauCpefAcxz9x3dvQ3wHXB5FbcpIlKGqhqKiIhUX/cAuPtvZvYh0JGgkAJwX8rz9gTamtlp4XxtYImZNSCoKvhA+D7fmdnHGbbVFzjL3ReGz52S4Xm7AM2B180sdXkrYEvgdXefEC67naBAtyy1gdvMrA1QDGwQ5v48XP+qu08Mp+8Cngun9wQamtne4XwNlu4fEZHlooKXiIiIlEjtqGJuyrQBe7v7T6lPDgtelb3HijBgtLvvUmFFcMdrRbZ1JTAV2Mbdi8zsOaBWJc8veV8DTnb3N6u4HRGRjFTVUEREpPo6HCCsYtgB+CjD814AzjKzvPD5jcyspbvPBoYD/wuXbwG0z/AeLwEDzKxm+Nw1w+WzgYYpz/sUaGZm3UsWhD0f1gDeBXqZ2TrhquOq+P9sBPwTFrpaEVRfTLWbma0dTh8FvJ3y/z7VzOqEOeqE/0cRkeWmgpeIiEj1lRt2UvEmcIq7/5HheacChcAIMxsFvANsHK77H3CMmX1P0P7pwwzvMRj4CfjWzEYAD4bL3wFqhp123OHuM4A+wLlhJxw/AFcDOe7+PXAx8FGYe2EV/5+XA4eH2a8mKMCl+gh4zMzGAhsB56Zk/gr4Inzt5wRVFEVElpu5/9saASIiIrKqCce/auTuM+POIiJSHeiOl4iIiIiISJbpjpeIiIiIiEiW6Y6XiIiIiIhIlqngJSIiIiIikmUqeImIiIiIiGSZCl4iIiIiIiJZpoKXiIiIiIhklZkdEHeGuKlXQxERERERySoz+9bdt407R5x0x0tERERERCTLdMdLRERERESyyswmA49kWu/up0UYJxZ5cQcQEREREZHV3hJgVtwh4qQ7XiIiIiIiklVq46U2XiIiIiIikn0Wd4C4qeAlIiIiIiLZdmHcAeKmgpeIiIiIiGRbXTNrUTJjZkPNbKaZfWNm/4kzWFRU8BIRERERkWw7F5gIYGZ9gD2BXYH7gBviixUdFbxERERERCTb3N3nhdO9gPvd/Qt3vxVYN8ZckVHBS0REREREsi213LEz8GmGdastjeMlIiIiIiLZNsLMrgcmAM2ADwDMrCDOUFGqFqVLERERERGJ1UlADaAd0N/dC8PlOwAPxBUqShpAWUREREREJMt0x0tERERERLLKzIamTA8ot+7x6BNFTwUvERERERHJtnYp04eWW7dZlEHiooKXiIiIiIhkm2WYBqgWbZ9U8BIRERERkWzzDNPVhrqTFxERERGRbGtuZs+lmTaC7uVXe+rVUEREREREssrMyrfrKsPdH4wqS1xU8BIRERERkdiYWS13XxB3jmxTGy8REREREck6CzRJma9hZgOB3+JLFR0VvEREREREJKvMbDdgJjDZzN4ysx2BH4EDgf3jzBYVFbxERERERCTbriAoZNUFHgLeBe5z9x3d/cNYk0VEbbxERERERCSrzGyEu7dJmf/T3TeKMVLkdMdLRERERESyrbjc/LRYUsRId7xERERERCSrzKwImJ2yqEE4b4C7e+NYgkVIAyiLiIiIiEi2tYg7QNx0x0tERERERCJT0qW8u1er6oZq4yUiIiIiIllnZoeb2Z/AFIJu5f8wsyPizhUVVTUUEREREZGsMrP/AWcAxwGfhYt3Aa4zsyXu/mBs4SKiqoYiIiIiIpJVZjYS6Ofuf5VbvjHwkru3jiVYhFTVUEREREREsi2vfKELwN3/AHKjjxM9FbxERERERCTbaphZrfILzaw2UDOGPJFTwUtERERERLLtOeBhMysoWWBmjYCHwnWrPRW8REREREQk284HFgP/mNlwMxsO/A0UAefFmiwi6lxDREREREQiYWYtgW3C2eHu/kuceaKkgpeIiIiIiGSVmfV191fCafNqWAhRVUMREREREcm2S1Omv4ktRYxU8BIRERERkWyzDNPVhgpeIiIiIiKSbZ5hutpQGy8REREREckqM5sPjA1nN0uZBsDdt408VMTy4g4gIiIiIiKrvd5xB4ib7niJiIiIiEgimNlgdz8r7hzZoDZeIiKrATMbmjI9oNy6x6NPJCIiskJ6xB0gW1TwEhFZPbRLmT603LpWUQYRERH5F1bbHg9V8BIRWT1U+256RURktbDatoNSwUtEZPVQ7bvpFRERSTL1aigisnpobmbPpZk2oFlMmURERJbXaltrQ70aioisBsysfLuuMtz9waiyiIhUZ2a2J3AusHm46Hvgand/Ia5MSWJm/wG2CGe/d/ex5dav6e5Tok+WfSp4iYis5syslrsviDuHiMjqzsx2A+4FLga+ILh7syNwEXCku78eX7p4mVkt4EmgO/Azwb5pCbwJ7O/uC2OMFwm18RIRWU1YoEnKfA0zGwj8Fl8qEZFqZQBBIeJOdx/h7sPd/U5gP+DUmLPF7czw3/XdvY27bw00JWiXvFqO21WeCl4iIquB8CrrTGCymb1lZjsCPwIHAvvHmU1EpBpp5u4flF/o7h8BG8WQJ0n+S3DXb2bJAnefARwbrlvtqeAlIrJ6uIKgkFUXeAh4F7jP3Xd09w9jTSYiUn3MrWTdvMhSJFNNd59afmHYnqtWDHkip14NRURWD+bur4bTD5vZ5e5+WayJRESqnwIz60f6nvkaRh0mYQorWTc/shQxUsFLRGT1UFxuflosKUREqre/gNMqWVedtUgZ6iSVAc2jDhMH9WooIrIaMLMiYHbKogbhvAHu7o1jCSYiIoKGPQEVvEREVgtmVmmjbXf/M6osIiIiUpE61xARWQ24+5+VPeLOJyJSHZhZsZktSXmkzhfFnS9OZjY0ZXpAuXWPR58oemrjJSKyGjCz4QRjoZRwYDLBwJQ3u/uSWIKJiFQv9dMs2wO4HI2p2C5l+lDgppT5zSLOEgsVvEREVg8D0yxbAzgSWBs4O9I0IiLVkLuXdhlvZm2BwQTDfBzr7m/FFiwZLMM0lL1wuNpSwUtEZDWQbsBOADN7BfgCFbxERCJhZpsBVwNbAhe4e7WoRlcF5WtlVDsqeImIrMbcfaGZle9qXkREssDM7gZ6A1cBe6uadxnNU7qTT502oFlMmSKlXg1FRFZjZtYauN3d2y3zySIi8q+EF7rmA4spe1en2g/toe7kdcdLRGS1YGbPU7HqxhrApsC+0ScSEamWqsWdmxVRHQpWy6I7XiIiq4E0VxIdmAJ84e7TY4gkIiIhM2sCHOLuQ+LOEicz2wE4HdgiXPQ9cJ27fx1fqujojpeIyOqhtbsPijuEiIgsZWa7EvQu24tgeI8hsQaKUdjL42vAHcDjBNUvdwTeNLPe7v5FnPmioDteIiKrATP71t23jTuHiEh1Z2YbERS2DiUYT3FjoKW7z4ozV9zCKvEPufvz5ZbvARzu7nvGEixCOXEHEBERERFZHZjZW8CXBAMp93X3HYC51b3QFdqifKELwN1fBDaPIU/kVNVQRGT1sJmZfZtppe6GicjKYmadMo0dKLQExgE/An+Ey1S9LDC/knXzKlm32lDBS0Rk9TAOODXuECJSLdwI6GJOGu7ezMy6EVQ1vMLMXgdqxRwrKWqa2VYEbbvKqxb7SAUvEZHVw5xMV6DNbKeow4jIai3dD2cJufs7wDtm1gg4CNjCzP4GnnD3M+JNF6vawEtxh4iTOtcQEVkNmNlwd98mw7q/3H3DqDOJyOrJzP4Brsm03t1vjjDOKsHMtiPoQOKkuLNIfHTHS0Rk9bBbJet0dVpEVqbaQNoLPag9U1ru/o2ZnRl3jqQxsxygD3BkdejVUAUvEZHVgLtPqGx1ZEFEpDr4y90PjzvEKqht3AGSwsw2IWgHdwjwF/BYvImioYKXiMhqwMx2r2R1tWi0LCKScNW69oGZ1Qb2AY4i6P3xUaDY3atNgVQFLxGR1UNlPRqOjiyFiFQHd8QdYBVV3WsfTARGANcDr7p7kZntHW+kaKngJSKyGnD3LnFnEJFq40cza+ru/wCY2SCCKmO/Aicto+rzas3MhpO+gGXAWhHHSZoXgL7AAQRjer0Va5oYqFdDEZHVgJm1LrfIgcnuPimOPCKy+goHa+/u7tPNrAPBD+oTCDrcaOHu+8SZL05m1qmy9dV94Gkzq09Q8DoSWBeoB+zk7j/HGiwiKniJiKwGzOz3NIvXILgCvU91+VITkewzs1Hu3jqcvg7A3U83MwNGlqwTqUw4mPKRBGOd/eHuO8QcKetU1VBEZDXg7s3SLTez/wE3UXl38yIiyyP1qv1OBG12cHc3s2p9Rd/MbqhsvbufFlWWpHP374CBYTf7e8SdJwo5cQcQEZHscfeHgHXiziEiq5U/zGyAmfUHtgbeg9Je6/JjTRa/WSmP/cvNz4oxVyKYWX8zG2RmrcL5XYHPgMviTRYNVTUUEVnNmdlId9867hwisnows6bA7UBTYLC7PxEu7wN0cncNFEzQ0Ya7ZxpoutoJ7wbuAXwFtAZeJ6hqeAFwu7sXxRgvEip4iYisBsysQZrFTYBjgfXc/X8RRxIRqdbM7Ft33zbuHElhZmOAHd19jpmtC/wBbB9WOawWVNVQRGT1MBOYEf5bMv0ZQa9RA2PKJCKrITM7J2V6n3Lrro8+kawiCt19DkA45MBP1anQBepcQ0RkteDuupAmIlHZB7gqnD4HeDplXbUeU9DMTkmZXavcPO5+c8SRkqTAzHZPma+TOu/uL8WQKVIqeImIrAbMbAuCKoVvlVveHRjn7mPiSSYiqyHLMJ1uvrpJbdP1Vrn56t6+5y/g1AzzDqjgJSIiq4QrgYvTLJ9KcGV6zyjDiMhqzTNMp5uvVtz98LgzJJW7d447Q9xU8BIRWT2s5+7Dyy909xFm1iKOQCKy2mqaMl5V6rQB68eUKRHMbE1gnrvPD+d3AfYFfgFuc/fiOPMliZn9h6XDD/zk7gvizBMFtQkQEVk91KtknS6yicjKdCtLx6VKnZ4J3BZfrER4jrDwaWabAMOAmkB/4JoYc8XOzM41s6tTFr0FvAi8QtkqiKstfRmLiKwe5ppZK3f/MXVhOEjlvJgyScKZ2TnuflU4vY+7P52y7np3HxRfOkkqd78k7gwJ1tjdfw6n9wOed/fjw8GlvwJOjy9a7PYGuqXMT3H3bcysBvAOSztsWW3pjpeIyOrhOuBFM9vVzBqGj17A8+E6kXRSuwI/p9y6at07nSw/M9vDzCpUea5mFqZMtwXeBnD3QmBxLImSo9jdZ6bMvwXg7otYWuVwtaY7XiIiqwF3f9LM6gB3AU3Dxf8Al7j7E/Elk4RT73Sy3MxsJ+A+YEPgCYLOfR4jqGJ3fozRkmCBmW0NTAI6AMelrKsdT6TEaJw64+5npsyuGXGWWOiOl4jIasLd73f3jYB1gHXcfSN3vy/uXJJo6p1OVsQQgrZcOxB0Cf4FMApo5e4PxZgrCc4B3iXYL/e6+98AYQ2EsXEGS4Afzax3+YXhvvk5zfNXO+au86qIyKrOzFpXtt7dR0WVRVYdZjYZeCScPThl2oAD3X3tWIJJopnZSHffOmV+AtDU3ZfEGCsxzCwXqJ9arc7M6hL87p4bW7CYmdn2wOvA3QSFdYCdgKOA3dz967iyRUUFLxGR1YCZ/V7Janf35pGFkVWGmV1U2Xp1oiDpmNm37r5tpvnqLM1FMAcmu/ukOPIkjZltBZwJlBwvw4FrqsvFQRW8RERERKTKzGw+ZavNbZY6X50LYRkugq0B/Arsk9LjoVRD6lxDRGQ1ZmY1gRPc/ca4s0jyqDt5WUEV2ulIwN2bpVtuZv8DbgJ2izZRcpjZUHc/OZwe4O43pax73N0PiC/dUmb2ibu3y8p7646XiKwKzGwTXSnMzMxqAScBGwHPuvv7ZnYscBEwxt27VfoGUi2lVhFT9TGR7Krun6lV5XxjZn+7+wbZeG/1aigiq4on4w6QcHcBexIMlny1mT1N0LvWsSp0SSXUnbysEDPrZmYfmNmc8PGBmXWPO1fC5cYdIGaVnW+SJGt3pVTVUERWFUk+SSfB9sDW7r7YzBoCE4FN3P2fmHNJsqk7eVluYZfgdwNXAAPCxbsAD5jZMe7+WmzhYmZmDdIsbgIcC4yMOE7SVHa+qRZU8BKRVUVDM+tHhgKYu78UcZ6kWeDuiwHcfZaZ/aRCl1RBUzO7Ic20EQyGK5LOxUAfd08tSIwws08J7r5X24IXMJOgUJH6XTUZGAYMjCFPkjQ3s+fSTBuQtm1ctpjZDNIX/gyon7Xtqo2XiKwKzGwO8BXpC17u7l0jjpQoZvYPcE3KojOAa0tm3P3myENJ4qk7eVkRZvaDu2+eYd0Yd/9P1Jkk+czs0MrWu/uDEWbZaBlZ/szKdlXwEpFVgZkNd/dt4s6RVGZ2fyWr3d2PiCyMiKzWzOxXgqrMxeWW5wI/a9zApcKeZbcE/nD3aXHnkXip4CUiqwQVvESiY2Z7ABfrMyfpmNkdwEJgkLsXhctygRuBWu5+TJz54mRmbQm6jZ8OnAs8D9QC6gIHu/sL8aWLn5ntAJwObBEu+h64zt2/jjjH81TSzszd98rGdtXGS0RWFdW9DVelzCwfqO/u08P5ngRf9gAfufuM2MJJYpnZTsB9wIbAE8CVwGME7bvOjzGaJNuZBO24fjOzb8Jl2wF/ozG+hgDXAwUE7br2c/d3zWxr4H7ghdiSxSwslL4G3AE8TtB0YEfgTTPr7e5fRBjnhQi3VUp3vERklWBmmwOT3X1qOL8PcBDwK3CRu8+NM1/czGwwMNvdrwjn/wR+Iyh8ve/u58SZT5LJzD4DHgHeAfYBTia4Qj/Q3QvjzCbJZ2bdgJKxl74F3vVq/sPSzEa4e5tw+rfUapep66qj8C7TQ+7+fLnlewCHu/uesQSLkApeIrJKMLMvgL3cfZyZtQE+JOjKuDVBj35HxpkvbmY2HNil5MdySdVMM8sBPnT39vEmlCQys5HuvnXK/ASgqbsviTGWJJyZbevu38adI4lWlUGC4xD2trvp8q7LYp7NCe7ebhcu+ha4xt1HZ2ubqmooIquKOu4+LpzuDzzi7oPNLA8YHmOupCgud4fiQQB3Lw4bd4ukU76ANUGFLqmCewjvdJnZ6+5e3asXptIQDZnNr2TdvMhSUFrN+mWC6p8XhIt3Ad4zs37ZqvaogpeIrCqKUqZ3Ivjix92LzEw/FIP2BKXcfUjKbJNIk8iqZDMz+zbTfHW+Oi+VSh3WY53YUiTTrRmmAW6LMkgC1TSzrUg/LEytNMuy6Wpgf3d/N2XZC2b2BjAY6JyNjargJSKriulmtjswHmgLHAgQ3vHSHR34xswOc/cHUhea2f8Iqk+IpKM7FbIiPMN0tVfVse/MbB93fzrbeRKmNpk7yor6OFqvXKErCBF0hHJ7tjaqgpeIrCoGEPSCtD5wobtPCZf3JRhYubo7B/g47M2wpIrETkBXoENsqSTpdnf3QXGHkFVOczN7Ls00kL2uuFcz5wDVquDl7htX5XlmVtPdF2Y5TmVloPxsbVSda4iIrCbMbB3gRJb2MjYcuNXdJ8SXSpKsujf2lxVjZodWtt7dH4wqy6pKY1NmFsV5ycweB75x9+vKLT8D2N7d98vKdlXwEpFVgZkdWvJlbmbt3P2TlHWD3P36+NIlV1if/kh3Hxh3FkkeFbwkm8xsgLvfFHeOJNJnL7MoCqVmth7wPsFA15+Fi3cBGgOdUzrzWqlysvGmIiJZMCBlemi5dQdFGSTpzKy+mR1rZl8Cb1C2YxKJkZkNTZkeUG7d49EnCjrTyPSIIY+sXiq9MyaSQdbvCrn7eKANcDdQI3zcBWydrUIXqI2XiKw6LMN0uvlqycw6AkcRtHt7B9iAoAGxqjYkR7uU6UOB1LsBrSLOAjAOODWG7Ur1oHNzZto3MXP3+cC94QMzKwiXZY0KXiKyqqisF61qX7Aws5+AhQTd7J/q7tPM7HcVuhKnsgsIcZjj7h/EHUJWW9X6/GNmawC4+9Q0q8+NOM6qJOvnRjMbCAxz9zFmlgO8CPQxs2kEnQ59VukbrCBVNRSRVcVaZnaKmZ2SOh3Orxl3uASYQFA3fd3wX6jmP3oSKmndcCeh8CeyWjGzgWY2EZgETDKzCeWrFrv76/Gki4+ZbVTFp36e1SCBo4Bfw+l9gE0Ivj8PIxjHKytU8BKRVcVbwDbhI3V6G+DtGHMlgrt3AjoBxcD7ZvYxUM/M6sebTMppbmbPhd1vl06b2fNAsxjy7FaVJ5nZO9kOIqulalewN7ODgeMIqhI3AdYg+DF/rJlF3h7ZzHYwsyfN7Pvw8YSZbR91jtBnZnbEsp7k7sdHkKXI3ReF092Ah9x9kru/CmTte1O9GoqIrGbCahO7AUcSfKEMc/d94k0lsOp2w62ur6Uy4UD2WwJ/u/u0lOVbu/vI+JJFz8w+BE4u//82s9bALe7eMcIsbYHXgDsIxnc0YEfgWKC3u39Rycuzkac5cB8wl6C33UlRbr9clu+BrdzdzWw0cKK7v1+yzt23zMp2VfASkVWZmW0NXOrue8SdJYnMbG3gf+5+bThfpit+kapQ19eSyswGA4+4+3dmVgv4BGhO0HfAAe7+SoRZNgcml7SjMrN9CHq6/RW4yN3nRpUl3P5P7r5phnU/untkneiEd9Ifcvfnyy3fAzjc3feMKku57Z8CDAJeAJaULHf30yLMcBNB1cLJwO5Ac3cvCsfDfNXdt8vGdlXVUERWCWbW0sxeNbPvzOxcM2tkZk8AHwJfx50vqcKqE9emLCrfFb9EKIHdyYusiH7A6HD6AIIqzmsD7YELI85yP1ATwMzaEPRQ9xmwDmV7DY3KnErWzYssRWCL8oUuAHd/Edg84ixAaY2MhgTHzKxyjygNIrgLuBjo5e4lw65sAtyQrY2qV0MRWVXcCXxLUHD4L8EJ8ydgM3efEGewVUy1a3ORMJV1J79ZxFlEVtRCdy8OpzsDT4TtZUaG1Q6jVCdl3KX+BHfiBoc5hkecBWDt8I5OOlF3BFVZ1+hRFwJL7k4+BPwIbOvuM6LOUCIsaF2fZvlH2dyuCl4isqpYy93PADCzN4EpQH93XxBvrFWO6pfHq7Lu5JP8t/k77gCSKHlmViMsbLUHbk9ZVyviLKkDxO9EMKQGYbWxJelfklUlnT+lE3VHUDXNbCvSX3CL+u8Ewb4Z6O5Px7DtMszsWXffO5we7O5npaz7IOywaqVTwUtEVhWLSybcvdjM/lShS1ZBSetOnrCNzv5ASZuGb4HHUz9fakMp5TwNvGdm04EFBDUQSjpPiLrK2HQz2x0YD7QFDgyz5BFWQYySux8e9TYrURt4KcO6OM4/26brUMPM9iRojxdlBz7NU6Z7AGelzDfI1kZV8BKRVUXzsAvutPPuvlcMmVZFqmoYr9TjNnXaiKE7+bAh+fsEP5ZLBgw9DjjbzDqrGq+k4+6XmtkPwPoE1QxLfsQ3Ai6KOM4A4PEwy4XuPiVc3hf4KuIsmNmGla1397+iyuLuG0e1rSrayMzeBTYk+JtdBTxG8Lc7P8ZckdU+UK+GIrJKWFW74U4CMxvo7kPC6SPd/d6YI1VbSTuOzexRYKS7X1Nu+ZnANu5+QJR5RFZ1ZjaF4Id76o95J7j7Vs/dc2MJlgBm9hnwCPAOwaDFJwPPE1Q/LIw4S2lPreV7bc1mL64qeImIrObM7C93r/QqrMTPzGpFXX3WzH5x95YZ1v3q7i2izCOrBjMbTsVqs5OBYcBQd4+sbZWZHVpywaL8cBlmNsjdK3SgECUzyweOB84h6Kb8qAi3/TuZ79541J9vMxvp7lunzE8AmkZ5vKRsez4wNpzdLGXagE3dvW42tquqhiKyygh7RDqTsm1RrnH30ZlfJah6YaKYmQGNSwaaNbMawAkEx/Z6Ecep7AdPUSXrpHobmGbZGgSDtq8DnB1hlgFAyZ3ioUDqnYqDSNNzXVTM7ADgMmAU0NXdx0QcoW+aZdsAl5LSbjpC5c83E+IodIV6x7FRFbxEZJVgZjsBLxOM2XJBuHgXggbe/dz9i9jCJZ+qNiSEme1G0LahXtjW4TzgSYJeOvePIdKEsC3X+6kLzawLUKERvAiAu3+QbrmZvULQ0UaUBa/KegqN5aKTmfUEriYY0+sQd/9sGS/JitSLkma2EXAF0JGgMHhfDJE2M7NvM81HOUh7pmMYwMzWzdZ2VfASkVXF1cD+7v5uyrIXzOwNYDDBWDLVlpllGvDRCAarlGS4gqDXtZI2Du8Cg939spjynAu8aGYlg85CcEHjCEA9GcpycfeFZla87Geu3M1mmE43n3XhcCctCAaSfjlcVtpLnrvPjjhP4zDLAcAQ4Oio21OliOUuUyZmtjbQlKCda5GZrUlwMewwoCAb21TBS0RWFeuVK3QB4O7vmtnt6V5QzVTWhXOmQplEz9z91XD6YTO7PMZCF+7+qZl1A84ArgwXfwt0d/eRceWSVZOZtQai/lG/VsqAxanTEP2AxQDdw38fJn0nG5F1rmFm5xF0YPEw0MrdZ0a17XQquVOaC/SLMouZHQbcCcwAppjZ+QRVVt8Gts/adtW5hoisCipr6G9mv7l783TrBMxszZQuliVGUfaeJZItZvY8Fe8mrQFsCuzr7h9GmOX+ytYnbFytSIV3HycSVBuu8IM/7nOPmbUiaBf4P+Afd89agSfNtr8HDnT3UWbWiaDAdVS2e5ZVwUtEVglm9jjwjbtfV275GcD27r5fPMmSKezAoTdwFNDD3evHHEkAM1tC2buTDYDZBFfF3d0bR5znf5Wtd/eHosoiq440wyI4QTvFL9x9egyREs/MtgKOdPeBEW6zU2XrK2vnlC1mVgfYj+C7qRnBIM9t3X1spS9c+TlGuHublPmf3X2TbG9XVQ1FZFUxCHjfzPqztC1KW6AJ1bx9Vyoza05wBfFQgn1zKsEXnCRD0u7Mpqve4wRVbTYCVPCSCpI0bmKSu5M3s/oEbTqPJBgk+PEot5+kqn3hdu8G9gI+JGi3/Trwc9SFrqVxrD5Lq4LOT53PVls83fESkVVGeKXsAJZ2F/wt8Li7z48vVTKY2UEEX+5bENTnfwB42d2bxZlLyjKzx5M8KHFY9ecqoA1wobs/Em8iSaqwbeCFlD0fX+bub0ecI5aBcJeRqSPBBa++BB3ptCdopxzrj+44q/aF258DfE3QIdYwd/e4mgqE1TDLt8Er4dka6Fp3vERklWBm67j7RODe8CFlPUxQR30rd58MYGa6spY8m8UdIB0zW4dgbJ8+BD+K9nf3RfGmkqQys97A3QS9dA4IF+8C3G9mx7r7a1HGyTCdbj7rzOwnYCFwD3Cqu08zs9/jKnQlpWpfaN0wy4XAXWb2EJAfQw7cPSeO7cayURGRFVD6RR52fS1ldSNoQD3GzB41s+5o4OQkSlRh2Mzqm9mVwAhgArCZu9+sQpcsw8VAH3e/3d1HhI/bCKqvXRxxlkR1J0/wOWpMUMgoabMZV6HrbuBvYHeCqn0bAjNjKnTh7nPd/V533wXoBdQCapjZp2Z2QhyZyjOzrcxsSLbeX3e8RGRVkVqI2Ca2FAnl7u8RDCbdkKBNwdXA+uGP6kdTB9KUWLU2s3SdD8TSuQbwO0FnHxcS9H7WJeiXJeDuL0WcR1YN9dMNN+DuI8J2MlFKVHfy7t7JzFoSjIX3vpn9TjBgen13nxNxnP0JqvbdydKqfYm4+OPuPwCnm9nZBGMGHgHcFkeWKNviqY2XiKwSKqvHL+mZ2dYE1UsOcPc14s4jYGajgd0yrXf3PyOMg5m9T+ar8e7uXSOMI6sIM/sV2MTdi8stzyXoLCGyNjtJ7k7ezHIIPu9HEtRKGObu+0S4/XoEVfuOJBgo+CHgUHffIKoMaTLVBw4maI8M8B3wWAyF0lja4qngJSKrBDObDJQ09D84ZRoAdz8t8lAZmNm67j4h7hwlzKymuy+MO4esuhcNzKyZu/8edw5JBjO7g6Ad0yB3LwqX5QI3ArXc/Zg48yWRma0NHFJ+SJQIt785wV2lQ4BfCWpC3BpxhvWBT4FxwJcEd/p3ILjL1Nbdx0eYJbUt3iMpbfGy2iGVCl4iskows4sqW+/ul0SVpUT4RdoUGOnuRWa2JnAecJi7F0Sc5X4qv3NxZJR5JD0zG+7uy6wqm7TC8qpaYJTsMLMGBO1uNwS+CRdvR9CeqHe2uuJeHuEd/0vdfY+4s5Qws0/cvV3MGfIIqvYd7u59I972ncBEd7+o3PKLgPWjLLCb2QdAS4KOqe5195+j6GFRbbxEZJVQ1YKVme3j7k9nO4+ZHUZQb34GMMXMzgceJOhZMNIuekNfp1lWBzgeWI+gqonErCqFrtBnLO2mOwnUUYuUCgtW7cNOfEqO6VuAd6PuvS9sT3UTQSHwceD28NEbiOXuUiViq+JXIrxD+ayZtY1h8x2A1mmWXwmMijJIXG3xdMdLRNIysy1KOmQof/XdzDrFMeJ9VUR1Zd7MvgcOdPdRZtaJoMB1VBIGFrWgd4QjCTpM+Bg4T9XEVi1VvTMWFd3xkqQys3cIxhB7B/gv0AX4CTg6SVW+AczsL3ffMO4cEE8WMxvl7ukKXpjZd+6+VZR5UradQzCUxpFAV7LYFk/dyYtIJg+nTH9Wbt2NUQZZTlFdmS9y91EAYSH0j4QUuvYARgP9gT3c/UAVulZJuiqawswSUwgVMLMZZjY95THNzMaY2U1hhw5RWsvdz3D3Nwju8DcB+iet0JVAcdzFLqpk3eLIUpTj7sXu/rK77wlsQtD+LCtU1VBEMknUoJTLIaofrBb2zlSyL+anzkfdxsHM2hEMfJsPnBh2Ly+yskTymTez7YGNgPfDxu5bEAzS244YugaXjNqkWbYGcCxwffhvVEp/sLt7sZn96e4LItx+GWY2g/TfQwZE3dV+ZeK4uFPZcBpRF9gxs7rAYndfZGZtCHqeHOvu12Zrmyp4iUgmSRuUMmm2AmZS9gfprPBfB3IjzvMRwZhMLwP9zKxf6sok9fooVZK0ixvPZXsDZnYWcA4wFrjKzIYSXEy4DTgs29uXqssw7MGfZnYcQbW/KDU3s+cyzbv7XhHnaRPx9jIys+fJXAhsEnEcgBYxbDMtMzuKoF3i3HAssfOBL4DjzWw7d780G9tVwUtEMqltZlsRnKBTpwFqxxdrmSL5weruSauqfSkJKRCbWaXtBtz9r6iyrMI+j2IjZjbU3U8Opwe4+00p6x539wMA3P2yCOIcBmzu7uPNbDPge2BXd38ngm3LShDecSpe9jNXqgHl5l+MePtlRD0W3zK8sILrsiJh+2YAQUGwIUHPnC3Cc09Dgi7vVfASkUjVBl5KmU+dTsQP/BJmVtfd54Wz50a0zUbuPiPDuk3c/ecocpRw94uj3N4yfENwjKQWgh2oSVCdJOq7gRWEbeEuTkoHFuXzuPvxEW06tWvrQwl6hyvRKqIMJRaUjOPj7mPN7CcVulYtZtYLSFeVLJvWcPfrI95mRuGwIqcT9Hh7K3A/sCvwI8HgxaOjypKEdsepEjbsSZG7jwPGhd3Il5x7ZpnZomxtVAUvEUnL3TeOO0MqM/vM3duG0w+7+yEpqz8i7Hrb3V+PKNI7Jds0s3fcvVvKuieJoStwM1sLOIFgPB0Iqvzc6u6To8zh7mXa4phZPkGj93OArHf1X27bOwH3sbSr6auAxwgG7Dw/yixJzEPlbTmjVqvcnXVLnS/pzEbiZ2bDqfgDuglBe6v/RhznIIJ2ZUlxP/AXsC7Bd9MLwAVAd4KqbV2iCmJmnYFf3P2fcH4QSwdQPimGDkiSNOxJ6vFbfszErF1cVsFLRNJKYHfytVKmtyi3Lo4fjKnbbFzJukiYWSvgfeBDgkIhQFtgVPj3+jHqTGGuA4DLCMZo6eruYyKOMISgjdA7wD4EdfifD7MURpwliXkqa8sZtfJ32UmZdyCrA5vKchlYbt6BKcDP4ThR1dnG7t43HKh4fEpthDFhu6Io3UBQ4MPMOhDUCDmBYOy1mwnOQZFx91tLplOGPTmLcNiTKLMAm5nZt2mmDdg0WxtVwUtEMnmYpXdtyg/meiPxDu5avmATxw/GpHU+ci1wqrs/kbJsSFjwuR7oG2UYM+sJXA3MAQ5x9/JDEkSlTsqX/WVmdgJwgrsvUR6gbEcEqdMGNIsySNLusktmqRfezGyNcNnUmOKU71yjjBg611gUbrfIzP4pty7qz3meu5dU/dwDuN/dnzSzp4CREWcpFVatvorgzuAe7j48hhi9Y9imCl4iklHSupNP0pV5gNyU7uNTpyGeNkz/KVfoAsDdHzezrDQSzsTM3iRotHwhQS+LmFmDlExRdrVf/ofOhBgLOZC8PKkdE5TvlOCFCHMk8S67VMLMBgJnE3bzb2aTgatTO2iJyCxi7lCjnIKwV1kDGprZ7inrGkacJfW7cifCKpnu7mYW+fdokoY9qer5xMwGu/tZK2u75p6E3y8ikjRm9q27b1t+Ot18RHmKgJIf7A1Spg2o5+75EecpJn0HEkbwvRZp4cvMfnH3lhnW/erukXXjW65Xswr7KMp9Y2bzCbonL7FZ6nwMx3HS8rRx9xFRbjOTpJ1zJDMzO5igTeIAguqyBuxIUBviCnd/NMIsiTo2zOx9Krk46O5RtvF6EXgXGEfQtnSDsPOI2sA37r55VFnCPMUsHfakQu+XSRz2ZGUfX7rjJSKZJK07+cSM/wGJ7E5+rJnt5+5Ppi40s/0JetOKTML2TSzVSSqRtDxvmtnfwD3AY+4+a1kvyKKk3WWXzI4B9nP31Opqw8LzzS1AZAUvEnZsuHvnuDOkOBG4HWgKHJPy+e4KvBJDnsQMe7IcVurxpTteIpKWmf1B5d2+xt7Q3cwK3H1m3DlKmFkTd58W07b/Q9C5xnsEbfIAdgE6A51j6NSigrDwfqS7D4w7iwTCHif3AA4HOhB0ZnFvHFWAdMdr1RF29Z+2AwIz+9HdIxuKIBzs9psqPK98b7jZytO63CIHJrv7pGxvW1a+lX3uSdJVSRFJEHff2N2bZXhEXugys4Fh4QIzyzGzV4DpZjbFzNrGkGdTM3vKzO4wsw3N7CtgiplNMrP2UecJC1ZtgJ+BnuHjJ2CbOAtdZlbfzI41sy+BN4BIezwzs2dTpgeXWxd5m6Gk5XH3xe7+jLv3Af4D/ADcYWa/mFkkY+KlqG1mW4U/XEunS+YjziKVm1PJunmVrFvpqlLoCpXvDTdbXiz3eAn4xcxGmNkmEWUAwMw2L+n8JJzfx8xeMLPrzaxelFlSMqxlZheb2cvh4xILhkKpFnTHS0TSMrO+7v5KOG0e88nCzL4HtnX3RWa2H3Axwd2c7YGz3L1jxHneB14naG92UJjnSYKue89z952jzJM0ZtYROIqgN8V3gPbAelEfR2Y23MNBidPcRSldV13zpGNm2xFUT9rW3SNrkrAq3GWXQNhb3zUZVp/h7htEmacq4r5ramb/A/Z3990i3OYXwF7uPs7M2hAMN3IF0JpgwPIox80qP+xJSc2MtkAnoJPHNOxJZVb2eVl3vEQkk9Se8Kp6RTGbity9ZDT5bsDD7j7J3V8F6seQp7G7DyZoYJ7n7g+4e6G7v0zZMcciYWb7m1mLlPmhZjbTzL4puVMYYZafgFsJjptN3H0fgi/5uK/0JWEYglSJyWNmjc3sFAsGxn2e4O5kpFfnk3aXXSr1FsFYUOkeb8eYK7Hc/SFgnYg3W8fdx4XT/YFHwu+tQwk6Q4laybAn+7n7kPCxH3AqEQ+CbWZbpEzXLLeuU8psz5W5XXWuISKZVNbQPQ55KXfe2gGPpayLtEfDUBGUdss7udy6Cr01ReBcgiuHmFkfYE9gV4I7gjcQbacOE4CWwLoEg0tPI75CRdKGIUhUHjPbDTiC4MfFMILjaJi7R34Mm1kucBzQCvg6/KEqCeTuh8edYRUV9VAjqVW7dyLoRKdkjLE4hrFIzLAnVHGsUnefsjI3qoKXiGSSqB+IBNXVngwLOfUJRrrHzNYBFlb2wixZy8xOSTMN4bg2EXN3L2lb0YtgoMwvgC/M7OiIg3Qys5YEP+jfN7PfgXpmVt/dK2sbkg2bmdm3aaYNSNs5QDXLcy1wL3D8yv6BsQJuJWin+AEwyMw2cPcr4o0k6aTpQKIMdx8VVZblEElBw1LGLEzRBDiW6Actnm7BOGLjCS7MHQhgZnlAzcpemCWVXcSNuhZeLL2oquAlIplk+oEIRD/eEDCIYMyYpkAvdy+5krcJwR2dqJVUtSk/DfFUtUn90toZuCDDuki4+y/AuWZ2PtAHOBIYZ2bDwqqHUUla9+2JyuPuUXU4UBUdgTZhO86rCT5XKngRVB1295PD6QGeMkixmT3u7gdEHKmyAYsdiKxqqJn1cPe3wulm7v57yroD3P1xAHffIaJIMyk7fqEDUwjuKA+MKEOJAcDjwPrAhSkXV/oCX0WcBRI07AmVX1zO2sVmda4hImmVq+NcgVdx1HeJhpk9DEwmqOZ3NsFAmYVmVgB86O6VXqGOgpmtDfzP3a+NcJvXu/ugqLa3qgnbdFU22GtkF1jSdDaiLuRDpq72M9K+WTFmlpdyATOqbSZm2BMzGwPsS1BAfjJlGuBJd89K22jd8RKRtJJWsDKzCytZ7e5+WWRhQmZWF1gcXqFvQ9Dpx9iww4+onQRcTtD+rb+7F4bLdwAeiDpMJfsmskJXqEvE26uUmVV6d9bdT4sqS2hgxNurTPkqu2Xm3f3mGDIlRaLa3IYdE6xXcqcpZXl3YFzEQ1isEgNvhx04nODuN8acY3OCHmcPAtaOctvuPib8PjiBpZ1WfEvQ4cb4KLMQDFHxUsp86nTW7kqp4CUiaZW7iniZu1+wrNdkWaaeC/cGNgIiLXiZ2VHALcBcMzuboHfDL4DjLRjQM9KGwu4+Czg5zfK3zCzStjtJ2zcJMytl+ljgzriChHZP0B3B8lV2U+ere/WcpLW5vZJgCI3ypgJXEXTuE5VYqoxlYma1CC6EbQQ86+7vm9mxwEXAGIKOG6LOVA/Yn6DAtQ1B9fzuMeTIBWaV/z1hZnXMLCfKTn3cfeOotpVKVQ1FJK3KxhtKgvDK6tUEHWuc5e4fR7z97wg6sWhI0G16C3cfb2YNgU/jbjsT5jiI4It2XXdfN8JtJ2bfmNl8YGym9TGP67NSx4dZwQyJ+2wnlZk1Ag4BjnD3NhFveybwbjjbNWXaCKpoNYo4z1eZ2kyZ2XfuvlWEWX4jaMtkBIWaU1NW3+juLdK+MHt5HiJo4/YxQRW6vwlqHpwcDjcSZZZ2BO1r/0vQQdX9wK2xFTrMrgF+cfe7yi0/Gmjp7mfFkStKuuMlIpkk8qpMWE3hGmA9goGKK2vknU1F4fgo48zst5JqEu4+y8wWLeO1WWNmXQgKW7sRnOP3IbhzEKUk7ZtxlP0hliSJ/IzFxcyaEvxwbgV8DZzu7tPjTVV6kadkMPCXKdtxTVQGpEyXP+e9EGGOEvUqWRf1b8u/gNNSpk8tty5q2wNbu/vi8GLTRILxDP+JIctHBJ09/cfdJ0LQUUsMOUp0A85Js/w+gh4fIyt4hb3tVjZge1YK7Cp4iUgmlXWXHnl7CzPbmKCHs3bAJcCDcYw1lCL1hF2+O/s4qrecBxwOzCHoHvwUgrGQ3og6C8naN3OS1l4xYSr0WJoq4rthdwI/E/wI24fgAstREW6/lJltQDAcwuEE1efuB9rG0HsgAO7+YBzbrcRcM2vl7mV6ojOzVsC8DK/JCnfvHOX2qmCBuy+G0otNP8VU6ILgbtcRwFfhnbgHYspRIsfdK3Tr7+5LzCzq7/O+aZZtA1wKLM7WRlXwEpFMKusuPY4r9T8C/wC3E7T3OslsabvpGBreJ208pksJqpKc4u5jAcwsrjsqSdo3aRvXm1kT4BB3HxJpmEo6j4BYjuMk3RHcyN37AJjZm8TT3XWJ3wl6XtvD3UeGmWJrCxe2lZzn7kPLLT8ZqO3u10Qc6TrgRTMbAHweLmtL0HaoOrfhhIqf68ZxdRLj7vcD94cF4iOAD4GGYdW+Z9x9RlRZQvXMrKa7l7kgF3Y8UifKIO4+OmX7GxFc2O1I0F78vmxtV228RGSVYGYPUHm1gCMijJO47vbNrBnBF+thBG0K7gMucPeNoswRZknMvjGzdd19Qsr8rgRXgXsBb7p7/6iyhNu/v5LVcRzHiWnjlaSuwM3sEuBQgmpi9wJPACPdPbLxqcrl+Rpo7+4Lyi2vDXwWdZuzcNuHE3Sw0TRc9A9wibtn7UdrhhzFlP1usJR5d/dIbzIk7TOeKuzcoh/Bd0VXd6+symg2tn8jQQHrxJKu7C0YzPlmgl5wB1T2+izkaQxcCBwADAGGpPQInJ1tquAlIpmEvTPtD2wXLvoGeKL8l78kh5nlACWFiz7A88CjMXVxX0H5glBE29yIYH8cSjDW2cYEDblnVfa6LGXplKSqj5k6+IjjjmC5DiSgbCcSuPteUWUJ8xjQg+DY6QnkEvSi+k7U1ZzN7Bt33y7DupHuvnWUecptf00AXzo4b9Tbr5tm8R4Ew2v85u6R996XdGa2DnCpux8T8XbrAq8SdD7yTbh4W4I7zH3cPbJqqmH1/JOBh4Er3H1mJNtVwUtE0glPzO8TdH9dMtBhW6CAoBetqH88H1rSzsHM2rn7JynrBrn79RHneZ6K3RhPJriL8nyUWTIxszUIChuHu/uWEW97bYIr4SPdvSj8cXYecJi7F0SY4y2gNfAYcJ+7f2dmv7t7s6gylMuTmDtMkKw7gmZ2aGXr42znFF4Z/x/BnYI1o+wlNNz+rwQXC7zc8hyCXuIivROXtPNxyrbbAoOBusDZXm6csYgyVDpYvbuPijDLmgTd2G9EcNf2aYKqoCcAT7v7kVFlKZerKykXdN393cqen6UMxQR3tCeRpjZNts7TKniJSFpm9ijBj+Zryi0/E9gm6kbmVnZcsdirJGX4kbgGQRfuj8ZQEGyUqb6+mW3q7j9FmOUwgo4SZgBTCMbxepCgd62z3f2XCLP8Hua4i+DvMifsaTGuKmNp7zDFKUl3BFcFZraDu0fa/szM7gN+93IDxYdX7Vu6++ER50na+XgzguFFtiSoYv14lNsvl+X3lNl1gdSLlB7lucfMXiDo4Og9gs4kCoBawFHuPiKqHCl5Kvue2sTdf44wSyxV4lXwEpG0zOwXd2+ZYd2vHv3YKKU/WMv/eE3Sj1kzawB8GHWbi3I/hN5x927p1kWU5XvgQHcfFX65vU3wRR/LHQsz60ZQsNgVeJ2gbcN6MWX5h6C3vrSibHgPybojaGZD3f3kcHqAu9+Usu7xKC/2JClLuM01gQ+A2SytgbAzwQ/pTu4+OeI8iTkfm9ndQG+CgZvv8DS95sUl7u8mM/vB3TcPp2sSXAjbMKpqdWnyJOZ7Ki7q1VBEMqnsy6soshRLla/Wl2ldrNx9tkXfLS6U7b2vcSXrolBUUp3G3T8wsz/irCbm7u8A74TVxQ4EtjCzv4HH3f3MiOPUpmwPoaniOI5bEvRs+CPwR4w5IBgqosShwE0p85slKEuriLPg7lPMbFuCO+olP07vJjiGs9oZQKZIGabTzWfbkcB8gjZdl9nS3m6N4A5T+fNhlOL+biptj+3uC8MLqjNjzJOY7ykzu6Gy9e5+WmXrV5QKXiKSyQQz6+zu76cutGCA3kkx5KlsXLE1Y8iTlgXj/8RxxTVJP4TMzOqz9It0fuq8u8+OMEgX4BN3X+TBYLy3ALeY2XYE7XWi9lfU1cIq4+7NUu4IXmFmrxNURYqDZZiGGI7hDNPp5iPhQadG94aPuCXpfBxLe81VRNNyBYwy89kqXFQiSd9TsVSlVsFLRDI5l2CclntZWrVlF4Ifq3vEkKeyccXejjpMhqtlTYDuBD0lRS03pXCTW67gkxtxlq2AmZT9gVryJecR57kN2MjMPifoIe894At3/4alvWpVayl3BBsR3FGJ645gZT/KopakH4jpOvMpwyPu8ZEEnY/d/c8ot7csYXXzEuXPxZFeeAJuXcZ81BLzPeXul0S5vRJq4yUiGYW9M53B0qot3wLXeTigaHVmZheVW+QE9effdfcfY8hTMpZNuqvx7u5RF74SI+yhszPQJfx3PeATgm7Br404y7HufmeU21wRJXcE3f3ECLc5k6Xdx6d2JW8EPak2qo5ZwjyJ7fExbkkrlOpcnFmS9o2Z7V7Zend/KSvbVcFLRFYV4dWxg4EtwkXfAY+5+5z4UlVkZrVcY50lUtjAfB/gAoLe4CL/EWRmmwNnsrQ75W+Ba9x9dNRZkiRJhYskZVmWuM43STkfr0p/q6iFd7HXd/fvw/kjCbraB3jO3f+JLVzMwkLgKGA6aao2u3vXrGxXBS8RScfMzgbmufvQcstPBmp7uW7mI8izPvApQUcAXxKcKHcA1gd2cfdxUeYJMxnQ2N2nhfM1CMZHOTOuXvNSsuURdK38V9i2KcptzyDDGGfAee4+N8IsNQh6f+sSPtYHPgc+BD7wCLvZD/PsBLwM3E/Z8fEOB/q5+xcR5ym5Al26KGXe3T3yJglm1jjqYzZNhtjGosokSeebhJ6PYz9u0on5XHwbwbAwd4bzvxH0jlkHmOLuJ0WZJ02+OPfNJcD+BBe+7vOoxnxzdz300EOPCg/ga6BWmuW1gREx5LkTuCTN8ouAu2LIsxtBu6UlBG0cdgR+J/gR0jGGPIOBrcLpWuGXyQxgDtA34iwbpXlsRzCW1p0RZykk+IF4ONAs6r9LmjzvEXRnX355V+D9GPLUTfM4EPgNeDviLJ0JCuhLws/SljH+nb6N+1gplydp55vEnI+TdNyEeZJ0Lh4B5KXMD0+Z/rg675swgwE9gMcJena9GFg3q9uM+j+phx56rBoPgtHkM60bGUOeH1K/QFKW5wNjYsgzHOgTfnkcAswlGLgzrr/XD0BOOH048BVQA9ga+DLOYyklYw4RF9oJBm9+G/iVYKyqY4BNY9wHP67IuoiytSW4E/gN0COG7X8F/Jfg4s6RwMsx7oukFbySeL5JxPk4ScdNyr5JxLk4taAVzu+bMp3xO7467Js02foQFODPyOZ21KuhiGRSYGbm4RmphJnlAPVjyFPk7hXGD3P3xWYWx7hi5u6vhtMPm9nl7n5ZDDlKLHT3kvHDOgNPuPsiYGRYnSN27l4c9Rhn7n45cLmZ5RNUOewM3G5mGxH0bnhQlHmovDfh/MhSpDCzzYCrCar8XODuj8eRA8h39+fD6XvNLM5qUM3N7LlMKz36XgSTdr5J0vk4SccNJOtc3CD1e9zdn4LS7/FIO4gJJWnflAxMfmj4+Bs4CXghm9vMyeabi8gq7QOCuwXlnROui1plX+aLI0uxVPkCxLQYMqTKC9t8ALQn6LWvRFzjMpVhZr0IGjJHzt0XE1Sf+51goOB8oG8MUb40s9PLLzSzMwiu/kbKzO4muCP4FtAqxkIXVPxMxdkIfRbwYiWPqCXtfJOk83GSjhtI1rn4fYKhYco7i3i+xxOzb8LeMN8n+C7Y1d13c/enwoJg9rZb7mK2iAhQeiXoA2A2SzsB2BkoADq5++SI8xSFWSqsAuq5e6R3C9LkaRDOG0GnBI0jznMhsCtBwaY5QTsHN7PmwKPu3jbCLMOp+OOnCcEPsv+6+3cRZjmQpV3Jr0vwRf8+QVurr9w90sGuzWy9cPvTKdu5RhOCbsoj7ZQgvAM5n+BvU6GTjSiP4yR9pszsW3ffdtnPjEaS9k2GPKWriPh8nMB9k6Rz8VoE1YenAyUd9+wIrEHQNnBSVFnCPEnaN8WUHV+ydBVZPG5U8BKRjMysFkFD+5Jur78hGFS1MIYsG1W23iMeRDNpeQDMbG+gKUH1jUnhsu2AJu7+ZoQ5OpVbVDLG2c/pqidlOUvJoMklAyfHcXe0DDOrAxxA2fHxHnf3+TFkScxxnLAsw919m2U/MxpJ2jeQrDxJylIiKeficLu1Cb7HS843wwm6/Y/8fBPmScS+ieu4UcFLREREJIWZbefu38SdQ0RWL2rjJSLLzcyOiTtDKuWpXJLyKEtmypNZ1FkqK3Qlab+A8lQmSVkgWXmSlAWSlSebWVTwEpEVsX7cAcpRnsolKY+yZKY8mSlLZsqTWZKyQLLyJCkLJCtP1rKoqqGIiIiIiEiWJWJsFxFJHjNrUNl6d0/Xo1XWKE/lkpRHWTJTHmVZEcqzamSBZOVJUhZIVp64suiOl4ikFXa16gRdq5YomXd3z1Ue5VEW5VEW5YkzT5KyJC1PkrIkLU9cWVTwEhERERERyTJ1riEiy2Rm25nZIeF0gZmtqzzKoyzKoyzKk6Q8ScqStDxJypK0PJFmcXc99NBDj4wP4ARgJPBrON8CeE95lEdZlEdZlCcpeZKUJWl5kpQlaXmizqI7XiKyLMcAOwOzAdz9V2BN5VEeZVEeZVGeBOVJUpak5UlSlqTliTSLCl4isiwL3b2w3LKiWJIElKdyScqjLJkpT2bKkpnyZJakLJCsPEnKAsnKE2kWFbxEZFmmmNmmBL39YGaHAX8pj/Ioi/Ioi/IkKE+SsiQtT5KyJC1PpFnUq6GIVMrMWgKPA1sA0whux/d199+VR3mURXmURXmSkCdJWZKWJ0lZkpYn6iwqeInIMplZDtCKYHyLH919ifIoj7Ioj7IoT5LyJClL0vIkKUvS8kSZJS9bbywiq5Udge4Et+LfBr6IN47yLEOS8ihLZsqjLCtCeVaNLJCsPEnKAsnKE1kWtfESkUqZ2enAk0ATYA3gSTM7TXmUR1mUR1mUJyl5kpQlaXmSlCVpeaLOoqqGIlIpM/sJaOvu08L5xsDn7r6p8iiPsiiPsihPEvIkKUvS8iQpS9LyRJ1Fd7xEZFlml5yQANx9OuF4F8qjPMqiPMqiPAnJk6QsScuTpCxJyxNpFrXxEpG0zKx1OPmumT0A3BvOH0ZQB1p5lEdZlEdZlCfWPEnKkrQ8ScqStDxxZVFVQxFJy8wq60rV3b15ZGFQnmVJUh5lyUx5lGVFKM+qkQWSlSdJWSBZeeLKooKXiIiIiIhIlqmqoYhUiZnVBGqWzLt7nPXDlWcZkpRHWTJTHmVZEcqzamSBZOVJUhZIVp6osqhzDRGplJntbGZjgPnAjJSH8iiPsiiPsihPIvIkKUvS8iQpS9LyRJ1Fd7xEZFluImhsegfQETgFWKA8yqMsyqMsypOgPEnKkrQ8ScqStDzRZnF3PfTQQ4+MD+Db8N/vUpZ9pTzKoyzKoyzKk5Q8ScqStDxJypK0PFFnUVVDEVmWxeG/08xsWzNbE1hTeZRHWZRHWZQnQXmSlCVpeZKUJWl5Is2igpeILMsTZtYEuBL4APgbuEd5lEdZlEdZlCdBeZKUJWl5kpQlaXkizaLu5EWkyswsH6gNfO/uGyqP8iiL8iiL8iQtT5KyJC1PkrIkLU8UWdS5hohUmbsvBhabmcWdBZRnWZKUR1kyUx5lWRHKs2pkgWTlSVIWSFaeKLKoqqGIrIik3SpXnsolKY+yZKY8mSlLZsqTWZKyQLLyJCkLJCtP1rLojpeIpGVmrStZnR9ZkJDyVC5JeZQlM+XJTFkyU57MkpQFkpUnSVkgWXniyqI2XiKSlpn9Xslqd/fmkYVBeZYlSXmUJTPlUZYVoTyrRhZIVp4kZYFk5YkriwpeIiIiIiIiWaY2XiIiIiIiIlmmgpeIVJmZnRZ3hlRJypOkLJCsPEnKAspTmSRlgWTlSVIWSFaeJGWBZOVJUhZIVp4kZYFo8qiqoYhUmZn94+5N485RIkl5kpQFkpUnSVlAeSqTpCyQrDxJygLJypOkLJCsPEnKAsnKk6QsEE0e3fESERERERHJMhW8REREREREskxVDUWqCcvJdfJq/7s3WbIYcv/98Bbrrlnwr98DYN7cudStV+9fv8/KOA/OmzeXunX/fRaAHLN//R5z586l3krYN8X/+h1g3tw51K1XfyW8EytlWMt58+ZQt+5KyrMSrKw8K+GwWWmfqfmLlvz7MMDCwnnUrF13pbzXv7WystTOz10JaVbecZOzEi7Bz50zl3r1V8L5ZmWccFg9P1PFK+n3+vx5c6mzkr6r/q2VtW9yc1bCH4qV9705fty4Re5eM906DaAsUl3k1abWFofFnQKAUR8NiTtCGbMLF8cdoYw16qc9X8dizoKiuCOUlaCLhclJEqhTY+X8oF8Z7vv6r7gjJNYBrdePO0IZDetEPo5uRrPmJ+tcXKdmcn4mT5+7KO4IZRQVJ+cMuGGTf3lReSWrUyNnSqZ1qmooIiIiIiKSZSp4iYiIiIiIZJkKXiIiIiIiIlmmgpeIiIiIiEiWqeAlIiIiIiKSZSp4iYiIiIiIZJkKXiIiIiIiIlmmgpeIiIiIiEiWqeAlIiIiIiKSZSp4iYiIiIiIZJkKXiIiIiIiIlmmgpeIiIiIiEiW5cUdQCQTM/sD2NPdR2Tj+Smvc6CRu89Ms24tYDDQCZgFOPCMu18Zrt8FuApYD8gFvgBOc/cJ4foHgB7AlJL3dPc2ZtYZeB34MWVzF7r7S+H/YyFQmLLuEHf/rrJ1y/N/Blgw8k6szloA5K25Nb5kIUsmfQ359QCo0aIflpOHFxWy+J8PoagQcvKo0bwvxQtns/iPN/CFM6jRYg9y6q5T4f2L509m8biPwJ28NVuT22jTZWb6688/OO6IQ8jLz6eoqIhrh9zCRx+8x3NPP0FeXj6t22zD1dfdBMDUKVM4+/QBTJs6hdq16/DYMy+Wea/CwkIGnHA048f9w0YbN+PGW+6kRo0ay7WPRn77FYMvPR+AuXPngDtPvfIuZw08jonjx7HBRs248oZbqVGjBo89eA/PPvEweXn5nHLGebTr2KXs/i4sTPu6qpo/fz679+7BTz+O4Yabb6P/vvsDcMO1g3n/vXdYUlTE+RddStt27Xn04Qe4647byM3Jpe/ue3LaGWeVea/i4mLOOO0URn/3HY0aN+KOex6kYcOGy7VvAFquV0CbbXcA4MjjTiI3J4crLzmP8eP+4ad/ppc+r3/fHixetIj8GjXYuV0HTj/nwjLvU1hYyOknHcOE8ePYcONmXHPT7cv9t2q5fiPabLt9kOXYkxj39188/+yT5OflseXW23D54BsBeOqxh3jgnjvIycmlV9/dOWngGRX2zQVnncqY0d9R0KgxQ26/lwYNln/fbJKS54hjT6J33z24dci1fPzBuxQVFXHGeRez487tAFi8eDFd27Zh/4MP48RyeQoLCzn95GDfbLRxMwYPWb59M/aH0Zw24ARyLIfcvDxuuvVOnn7iMT764D0Afv31F0459XSOPeFkHnvkQe658zZyc3Pp029PBg46s8K+OWvQAH74/jsKGjfm9rvup0EVjpuJv//Es9efj+XkkJObyz5nXMXYz99n5HuvUuzFNFlvQ/Y9czC5eXnce9YRLFpQyKIFhXTa90jadOvHH6O/5ZXbriQ3rwZmsP+511Ow1rpltvH32FG8eMtleLHTfq//sU333f91FoAlRYu57tBd2WG3fel60HGl7/PL8M+489SDueDZz2nQZM0VypJOVY7jRYsWceDefUpf882XnzP8x78oKGhUuiz1uNlw42Zcs5zHzfz58+nbuwc/jR3DkKHB+ebWoTfx9JOPk5eXT5tttuG6G28uff7ixYvZoc2WHHLYEQwqd74pLCzkhGOOZNy4cWzcrBm33H7Xcn++q7pvioqKOHS/PZk/fx5LlhRz6pnn0aV7zwp5/s2+GfPDaE475XhycnLIy83jptvuYuNmzQG46vKLeeHZp/li+GgAHrj3Lh59+AHy8/M569wL6dSlW4UsJx93FOPH/8PGGzdnyK0r+D11WfA9NW/uHNydQ486gVuuv4p1m24AwH2PvUCt2rV59omHefi+O8jNyaXHbrtz3Cmnl3mv4uJiLjn3NH784XsaFjTiulvuof5ynv8uPfc0Ro8aTvGSJZxyxvl06NqT5596hBeffoziYufAw4+hV9//Ujh/PldccDr//PUHS5YUc+cjz1KnTt0yWS4/b1CQpVEjBt9893JnSfXnH39w2P8OIj/8fXHT0Nv44P13efKJx8nPD47pG4YMrfC6+++7h4ceuJ+cnBxuGnobW2611QpnADB3/1dvIJItcRe8zKw28C3wJHCZuy8xszrA0e5+k5m1Bt4F9nP3d8LXnAUcAWzj7vPDgtcIdx9S7r07A0Pcvc3y/D9W9P8IYDXqea0tDiudXzjmUWr+56DS+aJpY6BoPnlrb1fmdYv+fJu8tbcjp9bSL3UvLoLiIhaP+4S8NbZIW/Ba+NOz1Ni4J+TVZtFPz1Bjk72w3OAL5e+PhqTNWFRURE5ODjk5OXz0wXs8dP89nHPBJTRr3gIz4+jDDuKwo46lXfuOnHjMYQwcdDabtNos7Xvde9dtzJk9h4Gnn8UVl1xA8xYtOeDgQ9M+d3bh4rTLU91/5y0sWFBIvXr1mTt3DscPOIPrrryIjZu3pHO3XTn64L15+tX3WLhgAYf0342nX32P3Nzc0tc/fO8dFV7Xf/9D0m5rjfo1KyxbsmQJU6dM4b577mSTTVvRf9/9eWvY63z5xeecd+ElZZ7bZotN+eTL4dSuXZtddmjDsHc/KlOwGvb6q7z26svcdMsdPHDf3UwYP55zzr8obZY5C4oy7pNOO27FB18uLfPPmD6N2nXqsmvHHcos79+3B7fd+zBrrV3xOAF44O7bmTtnDieddiaDL7uQZi1asu+B/0u/0QzfWZ12as0HX4wqnf/9t1/ZuFlzzIwTjjyEQ444mrbtOtJuu81568OvqFW7Nj3ab8/zb7xXpmD1zpuv8+brrzD4xlt59MF7mThhPIPOviB9lIx7Bjrv1Jr3U/K899Ywvvnqc04/t+J+fuDu2/ng3bfYfqe2FQpeD9xzB3PnzOakU89k8OUX0qx55n1Tp0ZuhWVTJk+mZs2aNGjYkHfeGsbzzz7FLXfcW7q+S7sdePTpF1hvvfXZvvVmfPDZN9SuXZsOO23L629/UKZg9eYbr/HGqy9zw9Dbeej+e5gwfjxnnXdhhW0C3Pf1X6XTc2dMJTe/JrXr1WfsFx8w8r1X2XvQ5eTlB+eDx68cxDbddmeznTpRtHgRefk1WDBvDjcdswdnPfpu6TKAL197mql//85ux5YtFN5yYn8OuvBm6hU0YegJe3Pi0CepmfIjbkWyAHzy3EP8+NVHbLzldqUFL3fn/nOPYc70KRx+5d0VCl7LynJA6/XT7jOo+nFcYvR3I7ny4vN49NlXyrzP8hw3DevkV1hWcr659+472bRVcL759ddfaB6eiw875ACOOvo42ncM9tOdt9/K228NY+e27SoUvO664zZmz57N6WeezSUXnk+Lli05+H+Hpc0ya37mc3FV9s1Obdvz15+/s3GzFsyYPo29+3Tn3c+Gr/C+qVOz4v2J1M/U22++wfPPPs2td97L5EmTOPfM0/hu1Ai+GD6aKZMnc0D/3Xnj3Y9ZsGABe/bpwbB3Py7zvXDPnbcxZ/ZsTj3jbC6/+Hyat9iEAw9J/z01fe6ijPumRMn31Fprr8OUyZMqFKy67rQlr7z7BbVq16ZP5x156pV3yhRm3nvrdd4Z9iqXX3cLTzx8H5MmjmfAGeen3VZRccUz4K8/jeWy807jgadfY8rkiRx78N4MHno3991+E1feeAdmVvrc6y4/n/adu7Nz+85p3//9t9/g3WGvcum1Q3nqkfuZNHE8J59+Xtrnbtik9rJ2TZnfF++/9y733XM3F11yGc1bBMf0/w46gKOPPY4O4TENMH36dPr27skHH3/G77/9xoCTT+D1N99Z5rbq1MgZ5+5N061TVUNZpZjZaWb2lZmNCP9tW+4pB5nZN2b2i5mdkfK6Tczs1fA1o8zspCps7kBgjrtf7O5LANx9vrvfFK4/E7ivpNAVrh9McGds/3/1H42AL57Hwp+fZ9Efw/DF8wFYMn0sC39+jqLJ3wbP8WJ8wXSKJn3Lwp+fp2jaDwBYTh6WVyvzexcXgS/BatTHcvLIqbsuXjgl4/NL5OXlkZMTnJbmzJ7NFlu2pnmLlqUn6/z8PHJzcliyZAljx/zATTdcw+69uvLwA/dWeK/PP/2Enr13A6B3n358+vGHy7F3KnrpuSfp9999+eqLT+naozcAPXr15ctPP2Lc33/SctP/kJeXR9169ahTtx5//fFbmdene93yyM3NZe11yhZcnn/2aebPm0e/3j04/ujDmTNnDgCtNtuMeXPnsnDhQvJr1KBmzbIFuU8/+ZhevYMr5n367sEnH63Yvpk0cQJ79+nOCUcczNQpk2nUuAm1alU8LsyM4w47kAP+25sR335dYf2Xn31Ct12Dv1XP3frx+SfLt28AJk2YwN59u3PCkYcwdcrk0sI6QF5+XumPnU023Yx585bumxo1yu6bLz77hO5hll1368fny/l3Ss3TPyXPyy88w/z589l/z16ceuJRzA3/VvPmzuW9t4fRu9+ead+nzL7pvfz7Zs211iotPOXl5Zf50Tf2h9E0aFjAeusFBYFNWy09bmrUyKdGuePms08/pmd43PTus3uVP1P1Gq1B7Xr1AcjNyyMnJ7e0oOPu4LDG+hsFGcPlixYUsvbGm5RZBrBw3lzWbVn2YsvihQtZsngxjdZej/yaNdl4y23556fv/3WWhfPnMfbLD9iq465l3mPU+6/RaocO1KhVp8L7L0+WdKp6HJd47ukn2LP/fhXe598eN+nONy1Sz8V5+eSEWebOncubw15njz33Svten37yEb13C883/Xbn4xU931Rh3+Tk5LBxsxYA1KxZq8wP/RIr8zOVn7/0M3Xd4Cs49fSlhc6//vqDVpttTl5eHvXq1aNe3Xr8/tuvZd7rs08/ZteSz1Tf3fnkX35PvRx+TwE8+8TD7NevG3ffemPp+habtGL+vLksWriQ/Br5Fc5/X33+KV3KfE99vFzbX3PtdahZsxZFRUXMmTWLRo2bMOyVF6hZsxZH7NeXk488kCmTJwLwxScf8u6wVzlkr17cfuPgCu/1zRef0DnM0q1XH776bPmylJf6+2L27Nls1bo1LVqm/r7Ir/D5+vqrL+nYqRP5+fls2qoV06ZOpbi4+F/lUMFLVjUPu/sO4Z2ik4H7y61fG9ge2Bk42cx2MbNc4HFgkLvvEK47xsx2WMa2tgM+q2T9thnWfxa+tsQZYUFxhJldkbK8VcryEWHOEk+WW1e7iuuqrObmh1Bzk/+S27AZi8d/Qm7D5tTY7ABqtNiD4rnjWTLnbygqxAunkrdWG2q02J0l08ZQvHDWst98yUIsN+WEnlcTL1pYpVzfjRpB767tOfv0AXTsvLS63ueffsyE8ePZqW07pkyZzOjvRnHigNN4+sXXefzhByp8oc2cMb206k3DgkbMnDGjSttP5/dffyY/vwZNN9yIWTNm0KCgAIAGBY2YNXMGGzVrwehRI5g7dw6TJ03gh+9GVtheutf9WxMmjCcvP5+XX3+LrVq34ZabbgBg7/770X7nbdlh683Zc6/+FQpDM1L2TUGjRsyYMb3Ce1fFp8PH8uyrb9Ojd18uPf+sjM+784HHeO71d7n8miGcesKRlK9pMXPmdBqG+6ZhQQEzVyDPp8PH8Owrb9Ojdx8uvWBpli8//4SJE8azw067ALD7Xvuwa6ed6LxTa/rusVeFfTNzRmqWFT9uPhk+hmfCPJddcBaTJk4gPz+fJ154gy223Jq7bh0CwB1Db+DI4zJfB5o5YzoFDYM8BQWNmLmCx01hYSGDr7yEY48/uXTZ0089XlplFeC//fel8y7bs/O2W7L7fyseNzOnT6cg3DcrctwsXriAN++/ifb9DwPg3Ufv4JpDujN/zkwarLF26fNuH3AANxzRh/+07Vq6bOwXH3DTsXvy2UuPskGr1mXed/6cmdSq16B0vnb9BsyfM/NfZ3n/ybvp0P/wMq9bUrSYL159ip36pb+2tiJZUlX1OIagKtaw116id989K7zPzBnTaRgeNw3/xXGTNuMnHzN+/Hja7hJUlb3phus48aQBGZ8/Y/rKOt9Ufd8AXHbh2Rxx7IkV3mdl7ZvCwkKuvuISjjvhZH795WfmzZ3LFlstPTabN2/JyBHDmTNnDhMnTGDUqBEV/u8zpk+nYaNw3xQ0WqFzX4nff/2Z/BrB91SP3v1446NvefjZ1/ny04/49MOganHfPfehX7ed6dm+Db377UXNcp/xWTOn0zD8W63I91T9Bg1Zf8ON6dVua/63dy+OPnkQkydOYPbsmdz35Cvs0f8Arr8iuEs+9ofv6NClBw8+8xo/fDeCLz4tW+icOWNG6d+pQcNGzJq54vumxMgRI+jcYRdOG3gynbsurfYZHNPjSo/pEqnHLkC9+vWZNasKv4EqoYKXrGq2MbMPzOx74A6CwktqweNeD0wFngO6A62ALYAnzGwE8ClQH9g8oszXunub8JF6n/zHlOVtSu6qhfYrt66wiutKhXcH/yl5sKRsFQ7LC3ZbTkFLvHAqllcTsxwsJ5echs2DO1S5NbEa9cip3SRYXm89fEEVTn65NfElKQWtJQuxvIrV59LZqnUbXn/3Yx5+8jnOPj34Mv9p7BguveAc7nnwccyMgoJGrN90A/6z+ZbUrFmTndt14McxP5R5n4YFjZg1ayYAs2fNpKBRo/KbqrIXn3mC3fcKriI2KChgdnjinTNrJg0LGlHQqDGnnH4uRx+0N5ecM4j/bNmatdcp2wYl3ev+rUaNGtO9Z3A1vnvPXfn+u1HMmTOHwVddztcjxzByzC988dknjBxRtqpNQcq+mTVzJo0aNV6h7TdusgYA/f7bn9GjRizzeS02aUXjxmswfdrUMusbFjQq3TezZ82iYAXylGbZsz+jR40E4Ocfx3LFRedxx32PYmbMnTOHIddeyQdfjOLT4WP56ovP+L5c7rJZVvy4Sc3z/aiRFDRqROduPQDo3K0nY374nimTJ/H9dyPp2KV7xvcJjuMgz6xZM8v8CKiqoqIijjn8EE485TQ23zJon+DuvPzi8+y+594AzJkzh2uvvoLPh4/m2+9/4svPP2XUyLLHTcNGKVmW87hZUlTEo5cNpNN+R7Fu81YAdD3oOM58+G3WWH8jvn7j2dLnHn/T45z5yNu899gdFM4N7gxutlMnBtz5Ar2PPoPX77m+zHvXqd+QBXNnl84Xzp1DnfoF/yrLnOlTGf/zD2y6ffsyr/385SfYtsceZe7C/Zss5VXlOC7x2ScfsuVWbahXv36F96lwHK+E8w3A2LFjuOC8s3nw0ScwMyZPmsTIkcPp2r1HxtcUNFrJ55sq7Jvbbr6e2rXrcNChR1Z4n5Wxb4LP1MGcNGAQm2+5FYOvuJTTzy5bDa5R48acee4FHNB/d846fQBbbbU16667XpnnFDRqxKyZM4Hw872C+wbgxWefoF/J91TDAnJzc6lRowY9++zB6O+CC4O33HAVb346kve+/IFvv/yM0d+NKPMewb4J8sxege+pTz54h6mTJ/HmZ9/xygffcOUFZ9CwoBHtO3fHzOjQpQc//RDcAW7UuAntOncnJyeHdp268eMPZe8MNywoYPbs1O/MFd83JbZu04b3P/qUp597kdMGBBehxo4Zw3nnnMXDjz1Z4Q5p6rELMHfOnBVqD51KBS9ZZZhZDYLC1OnuviVQUtG9sl/0DhgwvVxhpZm7P7iMTX5DcHcsk2+B8lUdCZd9u4z3zjp3v8Hdm5Y8yF1aj9+XLMY9uF1ePHc8VqNhmYJSsKwAy8mD/Pr4orm4O144Bau57JOO5eSB5QavK15C8byJWO01l/m6hQuXZmjQoCG1a9fhn7//4qTjjuD2ex+iyRrBF2+tWrVousGGTBg/Dnfnu5HDadaiRZn3atuuPW8PewMI2jTt0r4jK+q1l55jtz2CH6g77tyO998eBsA7w15jx106ANCr3548/uKbXHL1jdSqVYv1wkbNJTK97t9o37ETw7/5BoDh335N8xYtycnJoUaNGtStW5fc3FwKCipeYW7XvgNvDnsdgNdfe5l2HZZ/38yfN48lS4JrBV98+hEbN2+R8blzZgc/RKdNncLkyRNp1LhJmfU7tW3Pu28Fed5641V2brd8+yZdlnH//MXAE49i6F33l/5gy8nJIT+/BnXCfZPu7trOu7Tn3bfeWJplBf5O6fK0bd+RkcOD08KoEd+wcbMWjP3he6ZPncrB/ftx16038dRjD/H+O2+Vea+ddmnPe28Hed5egX3j7gw48Ri6du9Bn357lC7/4rNPaNXqP6V393JycqiRn1963DQsKGDG9LJXu3dp14G3wuNm2OuvVPkz5e48fe05tNqhI1t2CDo6KFoUfNbNjFp165NfsxbFS5awpChoU1ijZi3yatQkv0aN0ucC1K5Xn/xyVSDza9YiNz+fWVMmUrRoIX+NHs76m27xr7JM+O1H5s6czt1nHMaHT93L1288w49ffsjE33/i27de5O4zDmPCb2N57PKBZaoeLU+W8qp6HJd4/ukn+O8+6e+87bRLe959O+U4Xs7jJp2///qL4446nHvvf5g1wnPx6O+/Y+rUqfy3X2+G3nQjjzz0AG+/NazM69q178iwN8Lzzauv0H4lnW8y7ZsnHnmA0d+N5ILLrk77Xv9237g7A044hq7de5Z+pv744zfOOPVk+u+xG+PH/cMF5wQtHXbfcy9eGfYe194wlFq1a9N0gw3LvNcu7TrwdviZeuO1V2j3L76nXn/pOXbbPbyQMnvpXZkvP/uYjZu1IMfC81+d4DPeoKARs8rd0d9h53a8/07w93v3zdfYcZeyFx6Wxd1pWNCInJwc6tarz6JFi2iz3Y58H17E+X7kt2wYVgXdfud2pRfsvh/1LRuFHZSU2H7n9nwYZnnvrdfYoe3yZSkv9fdFwwYNqVOnDn//9RdHH3kY9z/4SOkxnWqHHXfi448+oqioiF9/+YUma6xRWl1xRalzDUms8h1JmFkDYCqwgbtPMrPzgMsJO8YIn/+eux9uZo2B4cABwJfAd8A17n5/+F4tCQpj0yvpXKNO+B6PAFeGnWvUJuhc42YzawO8A+yb0rnGmcDRwNZJ7lyjeP5kFv/9HuTkY5ZD3gadWTL9R4rn/AUYOXXWIm/9DpgZxfOnsHjcx+DF5DbYkLx1dsCLi1j826sUL5iO1ahHbsPm5K29HUXTxmA16pNbvynF8yaxePzHQa+Ga2xFbuNWpVkyda7x0Qfvcc2Vl5Kbm4u7c+lV13LLkOsZ/s1XrB8WZE457Uy69diVUSOHc/5ZgyhavJhuPXsx6KzzmDRpIncMHcJFl1/N/PnzOeX4o5g0cQIbbLghQ269O2NvUZV1rjHimy8Zev1V3PvY8wAUzp/PmQOOZcqkiazfdEOuCnvEOvW4w5k8eSJ16tThvEuvYePmLZgyaSL33jGUsy+6IuPr0knXuQbAwfv3Z9TIEdStW5fOXbpx8eVXcfLxRzN+3Dhq1qrJnfc8yBprrsmdt93Ck48/Sl5eHpu0asXQ2+4iJyeHY488lDvvfZDi4mIGDTyJsT/8QMOChtxxz4OlVcjKy9S5xqgR33LmgOOpW7ceefl5XH3jrcyYPp1rLr+Qb776gu122IljThxI52496dN1F2rVqs3iosWcdtb5dO3Ri8mTJnLXrTdx/qVXUTh/PqeddDSTJ05k/Q025LqhlfTsleY7a9SIbzlz4AnUrVuXvPx8rr7hVq694mJGfPtVaQH4xAFn0KV7T+676zaee+px8vJyabFJK6696XZycnIYcPwR3HT7fRQXF3PeGQP4aewPNGhYwJDb7y2t7lIhSvqEjBrxLWcNPIE6deuSn5/PVTfcynrrN+XMAccxYfw4atasxZDb76XJGksvRjz12ENMmTyJEweeweRJE7n7tps575Irw31zDJMnTaDpBhty7c2Z9026zjXeeWsYhx64D9tuF9Ss3rL11lx5zQ0MGnAiHTt1YY+9+pc+967bb+HpJx8LjptNWzHkljvJycnh+KMP4/a7Hwh6wzz1ZH4c8wMNCwq47a77Swtu5aV2rjH2iw946MIT2GCzrQFYr+V/yMnN5Z8fv8e9mMbrNqX/6VeycP48HrrwBMBYUrSIXfY8hG177MG3b73IF68Ed1hy8vLpP+gKGq/blK9ef4ZGa69Hy2134a8xI3np1svxYmeXPQ9mu557ps1V1Sypd7S+ev0Z5kyfWqZXQ4DbBxzIQRfeRIMmay5XlkydayzPcbxw4UK67Lw1738xqvR4mDxpInfddjPnlztu1t9gQ66r5LhJ17kGwEH792fUiBHUqVuXLl27MXHiBL756qvSwsNpZ5xJj569Sp//yEMPMGnSJAadcRaTJk5k6M03cvmVg5k/fz7HH3MEEydMZMMNN+TWO+/JmCVT5xpV3Tc77rwLmzdbmzbb7kB+jeD/9czLb63wvknXucbbb74RfKa2Dz9TW7XhqmtvKF2/0zZblPZqeMzhhzBp4gTq1K3LFYOvp3mLlkyaOJHbht7IJVcE++ak444Mvqc22Iibb8/8PVVZ5xojvvmSW264inseDb6nhgy+lI/eexvLyaF1m+244IrrMDMeuud2XnzmcXLz8mjeclOuvOE2cnJyOP2ko7julnsoLi7m4rMH8vOPY6jfoCHX3XIPDTKc/9J1rrFkyRLOO+14/v7jdxYuXMB/9zuYAw87hqsuPJMxo4MOly6//lY2ataCcX//xQWnn8DCBQtp2eo/XDz4JsyMs04+isFDgyyXnnMqv/w4hvoNGzL45rszZqlK5xrvv/cuV1x2Senvi6uvvZ4br7uWr7/+kg3CY3rQGWfRc9denDFoIOecdyGNGzfm3nvu4pGHHiQnJ4cbb7qF1ltvvcxtVda5hgpeklhhIaM2kHomvgs4kqAA9gRwDWULXk8B3YCGwJ3ufm34Xi2AIcBGBN2+TwUOdPdxqQUvM7sUGO/ud4SvWwe4mqA7+bkEv7Uec/erw/XtCbqTX4dgeIYvCbqTHxeuf4AVK3iV7zL+VHd/r7J1lezK4H3L9WoYp0wFr7hUpVfDKGUqeMWhsl4NY5Gg76zkJAmkK3jFJbXgJWVV1qthHDIVvOJQWa+GcUhX8IpLVXo1jFK6gldcqlLwipIKXiKiglclVPDKTAWvzJKTJKCC16pBBa/MVPDKTAWvzFalgpfaeImIiIiIiGSZCl4iIiIiIiJZpoKXiIiIiIhIlqngJSIiIiIikmUqeImIiIiIiGSZCl4iIiIiIiJZpoKXiIiIiIhIlqngJSIiIiIikmUqeImIiIiIiGSZCl4iIiIiIiJZpoKXiIiIiIhIlqngJSIiIiIikmXm7nFnEJEIrN+0qf/0299xxwBg7YMfjDtCGVMePTTuCGWYWdwRpArmLiiKO0IZdWvmxh2hlI7hzJL2uytJf6v5C5P1maqVn5zPVHHCjpuFi4vjjlCqToLOfQB1auSMc/em6dbpjpeIiIiIiEiWqeAlIiIiIiKSZSp4iYiIiIiIZJkKXiIiIiIiIlmmgpeIiIiIiEiWqeAlIiIiIiKSZSp4iYiIiIiIZJkKXiIiIiIiIlmmgpeIiIiIiEiWqeAlIiIiIiKSZSp4iYiIiIiIZJkKXiIiIiIiIlmmgpeIiIiIiEiWqeAlIgB8/dWX9OrRhV49utB+5+1pt9N2XHXFpaXLNmnWlNtuubnC6x647x66dWpHjy4d+P7771Z4+8VzJjLvmaNYMu1XFv3wIoXvX03h+1cz/+VTWfzzWwD4wtks+Ow2Ct8fzIKPhwTLihay4LNbg2WfDsUXza/w3kum/07hu1dQ+M7lFP312XJn+/OPP+jSsR09u3Wma6f2fDdqFIWFhRx68IF079KRo484jEWLFlV43f333UOXju3o1rkD33+34vumMj+MHk3XTu3p3qUjvXp05ffffiuz/vfffmPX7l3o0rEdN95wXVYylJg/fz6d2rdlnTUKeOrJJyqsjzJLiYGnnESn9m1p33ZH3hz2Rpl106ZN47+796Fb5w6cefppK22bf/35B7t168DuvbqyW/eOjP5+FPfceSt9e3Zmt+4dOfGYwygqKgJgj97d2K1bB/bo3Y3BV1xS4b0KCws55vCD6duzMycec3ja46yq0h3Ht992C927dKRrp/YcdfihpblSRXEcN25Qh57dOtOzW2defOH5MuuiOG7SHbt//P473bt0pGe3zvTbbVdmzpxZ4XWvv/Yqndq3pVP7trz/3rsrLc8Po0fTrXMHenTtRO+e3cp8ri+75CLabPmftK+L4m91/7330LnDLnTt1L7CNrL1txr7w2h269GJvj27sMduPfjj92B/DLn+Gv7bd1d279WNzz/9GICBJx3L5i02YNApJ6R9r8LCQo4+7GD69OjMCf/yMwWwRkHd0u/Jl158np9/+olePbrQu2dXzjrjNNy9wmseuO8eunZqR/d/+b0JwbHbtVM7mq7dmGeeCo7dV195ie223oJ1mjQo89y99+hDr+5d6NRup9LnpiosLOTwQw6kZ9dOHHNk+u+1yvz15x/07taBfinnvjtuvYkenduyW/eOnH36gNLn7r93P/r16kr3Tjvz3DNPps1y9Eo690H6z9QtNw+hwy470bVTe04beHLa1630z5S766GHHtXgsd766/vchcVVegy+9ga/+LIryizbus02/tNvf5dZ9teEqd5mm219xtyF/u2oMd6xc5cqvX/dfe6v8MjdsK3nrLW51+p6fpnlOQUbeu2+N3jdfe73vI128dq7XllmfY2tD/Aarff1uvvc7zXbnuj5m/Wt8N45TVp47T7XeZ297vKchht4nf/eXmb9/EXFlT5mz1/kcxcU+fxFxf7asLe9/z77+Q03DfVLLrvC5y8q9jPOOsfvvOe+Mq/5Z2Kwb2bNW+gjvhvjnTp3WeZ2Sh6Fi73Kjz/HTfKJU2d64WL3F1953Q/532Fl1v937/7+3oef+vxFxd6+Q0cf89Nvy/X+y/OYu6DIf/97gp93wUX+4COPV1gfZZbCxe7DR/3gnbt09cLF7r//PcG32WbbMusHnna6P/DwY1642H2//Q/0YW+/t1zvP2XO4rSPCTMKfdKshT5lzmJ/7pU3fc+99/Vx0+aVrt/3gIP8iede8SlzFvsu7Tv697/8nfG9rr7+Jj/vost9ypzFPvD0s/3m2+/J+NwVOY5nzl1Quv7Agw7xF15+baUcx8v7t9q0VauM66I4btIdu6edfqbfe/9DXrjY/bIrr/brbripwmu22qq1T5o2y/+ZONW33rpNlf7vVdl/f/wz0SdMmeHzFxX7Cy+/5gf/7zCfv6jYf/97gu+z7/6+6aatKrwmir/VuEnTfJtttvXZ8xf5yO/HeqfOXVbq32ra3MVpH2N/G+e/j5vq0+Yu9qeef8UPOPh//uRzL/vpZ51X4bnf/fSHv/ja237YEUenfa/B19/k5198uU+bu9hPPf1sH3rHPRm3O29h8TIfm27aqsx83357+EeffunzFhb7ccef6C+9OqzM+r/D782Zcxf68PB7syrbmbNgSdrHzHmL/Jc/xvk5513o9z/0qM9ZsMT/GDfZp8yc55ts2qrMc6fNLvQ5C5b4uMkzvEWLlhXe6/ohQ/2iS6/wOQuW+OlnnuO333Vvxu1OnbO4wmPijEKfPGuhT0059305YoxPmb3Ip85Z7Hvuva+/+Po7PnXOYh8/bZ5PnbPYfx83zZu1aFnhvQZff5Off9HlPnVO+He6/Z6025xahXNfps/Udz/85PMWLvH5i4q9/z77+bC331spnyngn0y/xXTHqxoxsz/MrE22np/yOjezgjTLNzazJWY2wsy+M7OxZna3mTVNec4DZjYufE7J4/CUdYvMrHnK868zs4vD6Xwzu9nMRpvZSDP7wcxOS7PtkscXy/h/XGxmU8q9Zr1w3fpm9oSZ/WZmP5vZB2a2c8prDzOzWeFrvjez98xs0yr+P7cys3fD/8P3ZvaVmW1pZpemPHeumf2eMt9qef9OlXnqycfZZ98DSud/+GE0DQsKWG/99cs875uvvqRDx07k5+ezaatWTJs6leLi4uXe3pJpv5JTqyE5tRuVWV48axzk1yGndiPciymeNY7FY1+l8L2rWfzbB8Fz5k4kp1EzAHIaN2PJlDFl3sOXLIbiJeTUaYLl5pOzRkuKZ/yxXPny8vLIyQlOl7Nnz2ar1q359OOP6b1bXwD67r4HH334YZnXfP3Vl3Ts9O/3zbKstdZaNGzYEID8/Hxyc3PLrP9x7Bh2btsWM6PXbn34+KMP073NSpGbm8s666yTcX2UWQDWWXddatWqRVFREbNmzqTJGmuUWf/Jxx+xW5/Uv+EHK2W7qcfLnNmz2WLL1tSoUQNYerGzWfMWAJgZRx6yP/1378Xwb76q8F6ff/oJPXvvBkDvPv349OMV32fpjuPyuVq0aFnmNVEdxxPGj6dH104cctD+TJ48ucy6KI6bdMfuFltsWXqXa9bMmayx5ppl1v/y8880b9mSBg0a0KRJE9ZZd13++uuvlZKn4uc6+LtdfeVlnH7m2WlfE8Xf6uuvvqRDp84Zt5Gtv9Waa61Fg3B/5OUF57kXnnua+fPnsWefnpx47BHMmTMHgPXWW7+yt+LzTz9h117hZ6rvv/tMAUyYMJ5du3fm0IMPYPLkyfz66y+02WZbALbbYUc+/OC9Ms//eiV9b5bIzc1l7XLHbpMmTahVq1aF55Z83ufPm8dmm29eYf2nn3xE7936ANCn3+7L/fdLPcfMnT2bLbdsTfMWLTEzAPLz88gN15dkmTd/HpttVjHLZyvx3AfpP1MtWqZmq/j9mY3PlApeErU57t7G3bcCWgMTgE/NrGHKc64Nn1PyuD9l3TjgigzvPQBYD9ja3bcGtgWGpdl2yWOnKuR9tNxrxptZXeB9YLi7N3f3TYBLgZfNbMuU174XvmZL4BtgSLn3zvT/fBwY6u5bh6/dC5js7heWPBf4Gjg15bU/VuH/UiU///QTNWrUYKONNy5d9tTjj7LvfgdUeO6MGdMpaLS0sFS/fn1mzZq13NtcPOYV8jfrU2F50V+fkbdhUJ71BbMpnvU3+a16UavjIIr++IjiuZPJadiUJROD2/9LJozCF80r8x6+aC7k1ymdt/y6FZ5TFSNHjKBzh104beDJdO7arcz/vVFBI2ZMn17m+TOmT6egYOm+qbeC+6aqCgsLueySizjx5AFllqd+STQqaMT0cjmjFHWWhg0bstHGzdhq803ZtXvnCj9Y58yZTf369YM8jVZunu9GjaB31/acffoAOnbuAsBN11/DzttswYzpM1hn3fUAuPehJ3jlzfe5+rqbOOnYI3EvWy1p5oylx1HDgkbMnDHjX+UqfxwDXHfN1Wy9xWZMnzGddddbr8zzozqOf/jpN9569wP69N2ds88YVGZdXMdwh06duefuO9i+zVa8/eYwdt9jzzLrp0+fTqOUfVOQ5jzwbxUWFnL5pRdz4kkD+OXnn5k3dx5btW6d9rlR/K2mT59Oo0aZt5Htv1VhYSGDr7yEY48/mYkTJpCXn88Lr77JVq235rabb6zSe8yYMZ2G4f+hoKARM/7lZ+r7sb8y7O332a1vP84563Q233wL3n7rTdydN4e9UfG7YUbZfbii35srqlf3Luy8Qxt69a74nZt6DBU0asSMGcv/9/tu1Ah6dW3PWSnnPoDPP/2YCePHs1PbdqXL+vXqSqedt6VnWBBOVf7c92//TiVSP1MlPv3kY8aPH0fbXdqVeW42PlMqeFVzZnZaeEdlRPhv23JPOcjMvjGzX8zsjJTXbWJmr4avGWVmJy3vtt19kbtfSFCYOriKL7sLaGdm26ZZ15SggFIUvv8Cdx+9vLmq4ABghrsPLlng7u8A9wNnZnjNO8BGVXz/pgT7pOS9/3b3yZU8P63wb/tPyWPunLlVet2TTzzKPimFLHfnxeefY8+9+ld4bkFBI2altHuYM2dO6RWlqiqaMJKcxhtjNeuVWe7uFP3zDXlNdwj+PzXqYrUbk9OwKZabT+4arSiePY68Zh3xogUUvj8Ynz8Nq1VQ5n2sRl1YvLTdly+eHyxbTlu3acP7H33K08+9yGkDTi7zf585ayaNGjcu8/yCRo2YNWtm6fzcFdg3VVVUVMShhxzIwNNOZ8uttiqzruRqXknOxuVyRinqLO+8/RaTJk1k9Nhf+HbUD5x+6oAybZjq1avP3LnB52LmzJWbZ6vWbXj93Y95+MnnSts1DBh0Jp8PH02zFi144tEHAUrvwrXctBWNmzRh2tSpZd6nYcHS42j2rJllLnSsiPLHMcDpZ57NyNFjadGiBQ8/9ECZ50d1HK8R7of+++zLyJHDy6yL6xg+/9yzuPTyq/h6xHcMHHQGF5x3Tpn1jRo1YmbKvpmV5jzwbxQVFXHYIQcx4NRBbLnVVlxx2SWcfe75GZ8fxd+qUaNGZdq6ld9GNv9WRUVFHHP4IZx4ymlsvuVWNGrUmG7ddwWga/ddGV3FtlIFBY2YXXInc9bMMoWgFVFy7O7df19GjhjOVYOv47577qLfbrvSsEGDChczCgrK7sMV+d78N954+z2GfzeWG6+7pkIhIvUYmjVzJo0aLf/fb6vWbXjj3Y955MnnOCs89/00dgyXXHAO9z74eJlj5OU33uWL4T9w843XMrtcltRz38r4O0HFzxTA2DFjOO+cs3j4sSfLZIPsfKZU8JKH3X2H8C7KyQSFh1RrA9sDOwMnm9kuZpZLcFdmkLvvEK47xsx2WMEMXwJbpMyfUa4KXoeUdYXAJcBgKrob6GdmY8IqjPuHWUvUL/e+j1Yh20Epzy/ZN9sC6Xpo+AzYrvxCM8sB/guUb8ma6f95GfCemb1jZleY2TZVyFmBu9/g7k1LHvXq11v2i4Dnnnmavfrvu/Q/9ekntPrP5hQUFFR47vY77sQnH39EUVERv/7yC03WWKO0mkFVFc/8iyWTx7Lgw+tZMmk0i0Y8TnHhTIqn/UxOg/WwGsHdKsvNx+o2obhwBu7Okpl/klNvLSwnj5rbHkLtzmdh9dYqLaiVsNwakJMbvG7JYoqn/UJOQVXLwIGFCxeWTjds0JA6derQrkMHhr3xGgCvvfIyHTp2LPOaHXbciY8/+nf7pircneOPOYoePXatcEUeYLP/bM5XX36JuzPs9ddo175DxTeJSNRZ3J3GjRqTk5ND/fr1WbhoYZmCV/sOHXnj9dS/YaeVst3U46VBg4bUrl2ndJmZ0aBBQ2rVqg0EVREBpk6ZwuRJk2jcpEmZ92rbrj1vh52CDHv9VXZpX/Y4W9FcJcdx+Vy1a9cu85oojuN58+axZMkSAD7+6EOal6vuGNcx7O40aRL8qF5rrbWYPm1amfUtN9mE3375hTlz5jBjxgwmjB/PhhtuuNK2fcKxR9O9Z8/Sz/Xvv//GwAEnsXvf3owb9w/nnHV6mddE8bcKtvFhxm1k62/l7gw48Ri6du9Bn357ANCuQ0dGDP8GgBHDv6F5ixZVeq+27drz1pvhZ+q1f/eZKn/stmjRkvWbNuWJp5/j5deGsWDhQnbfc68yr9lhJXxvroglS5aUnv/q1KlDzVq1KlRHbNe+I8PeeB2A1199hfYdlm/fpDv3/fP3X5x43BHcce9DpReaUrPUrlOHmjVrUbNcll3ateetlXTug/Sfqb//+oujjzyM+x98pLQAnSobn6m8f/VqWR1sY2bnAU2AIqCVmdV298Jw/b0e1H2ZambPAd2BmQQFpSdSrg7UBzYHKjZSWDYrN3+tuw+p5PkPAIPMrEfqQncfbWYtgPbALgQFtEOAkvvpc8IC5vJ41N0HLudrSnQxsxHAhsB0oHzVxrT/T3e/3sweAboCHYGPzOxId6/Y7c9K9tWXX9CsWfMyJ6AnH3+UffcvW83wzEEDOfu8C2ncuDGHHn4ku3brRE5ODjfcdMtyb7PGf/rBf/oBsPDLe8hr0YWc2gUs/OGl0mqGpc/d+gAWfn4neBG567Qmp8H6FM/6m4XDHwXLJadhU2q0DgqNi//4mJw6jclda3NqtDmQhZ/dBu7kb7orll+7Qo7KfPbpJ1xx2SXk5ubi7lx97fW0arUZxx51BD26dmLDDTcqvRJ9xqCBnBPum8OOOJIeXYN9c+MK7JuqeOvNYTz7zFP8+ecfPP3UE7Teug09d+3F9OnT2f+AA7ns8qs4/tijWLx4MX1334NmzZsv+03/hf333ZuRI4ZTt05dvvryC3r03DW2LF27deepJx6nW+cOLFiwgBNOPIUfx47l/ffeZcCpp3Ha6Wdy9BGHcvutQ9lm2+1WWsHry88/5ZorLy09Xi696lquvOQCRgz/huLiYjbcaGNOO/NciouL2bNPd2rVqk1R0WKuuOYGcnJymDRpIncMHcJFl1/NAQcfxinHH0W/XbuwwYYbctqZ565wrnTH8cUXnse33wS5Nt64WSzH8Y9jx3LicUdTt1498vPzueW2O3lz2BuRHzflj92zzzmfk088jtzcXIqKirj19rsAuPaaq+nbd3f+s/nmXHjJZfTt3ROAKwdfW+GK+YpK/Vw/89STtN56a97/6NPS9W22/A9XDQ56DYzyb9W4cWMOP+IounfpSE5ODkNuvjWSv9W7b7/Ji889w99//snzzzzFlq235qLLrmLAicewR+/u1KxVi9vuCq6NXnvV5bz+6ktMnjyZ3/ruyrMvvc6UKZO5fegQLr78ag485DBOPu4o+vbsQtMNN2TQWSv+mfrpx7GcePwx1KtXj7y8fIbeegePPfowDz94P2Y57H/gQWyxRdACoczf6fAj6fkvvjfLO2j//owaMYI6devy9Vdfsvc++3HpRRcw7p+/6de7JycPPJXttt+Rg/brj5mxaPEiBp1xFjVr1mTSxIkMvflGLr9yMAf/7zCOP+YIdu3WmQ033JAzzzlvuXJ8Ue7cd9lV13LxBecwfdo0Tj7+KAAGnHYm22y7PYcetA9mxuJFixgw6Mwgy6SJpX+nAw4+jJOPP4q+4blv0L8490H6z9SkiZOYNm0qxx59BACDzjiLnrv2yupnysrXJ5fVl5n9Aezp7iPC+RoEBYIu7v6VmTUAZgGN3H1m+PxD3f2D8PlDgGnAc8Cb7p62BauZecl7lFu+MTDC3QvKLf+M4M7bbWb2QPicIWnet3Sdme0JXEDQ1mqOu1+c5vnrELQhawI0SLftyljQaUdB+YKXmR0FHOPuO5Zbfg2wrrsfYmaHEezrPc2sDvBMmHO/8v+XKuQ4G9jF3XdPWfY+MMTdX6jq/2f9pk39p9/+rurTs2rtgx+MO0IZUx49NO4IZaysH2+SXXMXVOx6PU51a+Yu+0kR0TGcWdJ+dyXpbzV/YbI+U7Xyk/OZKk7YcbNw8crvZGdF1UnQuQ+gTo2cce7eNN06VTWs3moBNYCSbpjSDWJwGICZNSaoLvcO8CMwu6QXvnB9y/A5VWZmNczsIoI2TVWp9lcqLHAsJOh4ouT9OprZuilP246gYDlzed67Ch4HmpjZWSnb7gocAVybJut84Chgt6pUGzSz/5pZfjidR9AJya8rKbuIiIiIxEBVDaufYWa2OGX+cuBLM5tKxTZIAFPM7BugIXCLu38KYGZ9gSFmdiqQC0wFDiz/YjO7FBjv7neEi+qH1e/ygHzgI4K7OamtKs8I7xiVeNTdKxRogLOA1P5FNwwz1QIWAXOBPdy9OLyiV7LtVB3cfU6a987I3eeZWWfgejP7naCK5gRgd3cfleE1483sOoLeD/uFizP9P/cCrjazhQT79kvgouXJKCIiIiLJoqqGItWEqhpmpqqGsiJU1TAzHcOZJe13V5L+VqpqmJmqGmamqoYiIiIiIiJSSlUNpVozs92AK9OsuiqKXgRFREREpHpQwUuqNXd/DXgt7hwiIiIisnpTVUMREREREZEsU8FLREREREQky1TwEhERERERyTIVvERERERERLJMBS8REREREZEsU8FLREREREQky1TwEhERERERyTIVvERERERERLJMAyiLVBPusGDRkrhjADDpkUPjjlDG7Z/+HneEMo5t2yzuCImVm2NxRyhVKz9Z1y6LPe4ESy1ZUhx3hDLmFC6OO0KphnXy445QRm6CDuMcS87nG6DYk/OhWlSUrM9Ubm5y/laWsOOmMgn6uImIiIiIiKyeVPASERERERHJMhW8REREREREskwFLxERERERkSxTwUtERERERCTLVPASERERERHJMhW8REREREREskwFLxERERERkSxTwUtERERERCTLVPASERERERHJMhW8REREREREskwFLxERERERkSxTwUtERERERCTLVPCSRDGzP8ysTbaen/I6N7OCNMs3NrMlZjbCzEaGjz4p6y82syHlXnOYmb0QTnc2s8Lw9SPMbLSZHZ3y3AfMbFy47jsz+9DMNiuX67uU148wsybl1o00sx/M7PDl/X+X99eff9C7Wwf69erKbt07Mvr7Ubz+6su03W4rNlqn7O6ZOmUKRx56IHv26cEB/feo8F6FhYUcffjB9O3ZmROPOZxFixb9q2xff/UlvXp0oVePLrTfeXva7bRd6brLL72Ibbb6T9rXPXDfPXTr1I4eXTrw/fffLfd2J/7+E0NP2pdbT9mf2089iGnj/+Lj5x7ilpP3Y+hJ+/DYlYNYUlQEwFPXnsPFe+3MM9efX+Y93nxwKENP2pc7TjuEmZMnVNjG32NHMfSkfbj5hP58+/ZLy50xrn1T1SyFhYUcdsiB9OjakWOOPCztsZCNLOkMPOUkOrVvS/u2O/LmsDfKrJs2bRr/3b0P3Tp34MzTT1tp25w/fz5dO7Wj6dqNeeapJ4Dg83H4IQfSs2unMvukd4+udOvcnt49unLFpRdXeK9Mr1sR6f5Wf/z+Oz27daJXjy7s0acXM2fOrPC6N157la4dd6Frx114/713V3j7EOyb7p3aseE6S/fNow8/QOv/tKRPz6706dmVwsJCAO675066ddyFXt068f5771R4r8LCQo7434H06taJ445asX3Tcv1G9O/Xg/79evD6Ky9yz+1D6dO9PXv26sz5Z50KQFFREQft3Zf/9u7C7j078d7bb6bNcuJRh7DXbl0ZeMKRK5Ql3XFz69Cb6Nx+Z7p37sDpp55S+twoj5s///iDLh3b0bNbZ7p2as93o0Zx5eWXsmv3LuzavQstNm7KbbfcXOF19993D106tqNb5w58/92/+4yP+WE0vbp35P/s3Xd4FMUbwPHvpFFDEkDpqFTpTURIL4ReFERAERBEUZHepChdQQE7KAiIBbBLJ/QqIBJCEekqkCCQQiChJJnfH3c5roW0uyT6ez/Pc4/czs7um5nZ2Xtv99a24UF0bBPGubNn+GTeh7RpGUirUH9e7N+HlJQUbt++TfvWIabX/d5FiI+Ls9hWcnIy/Xo/TZuWgQx8PnfnKq01rwwcQKvQIDq3b835v//OUtsv/mwBoUF+tAwO4Ggu57/jx47StmUg7cOD6dS2JefOnmHWjKl0bB1Kx9ah1Kn+APM/ep+UlBS6dmpL25aBtArxY1PEepttJScn83yfZ2jXMoiXcnAe//3YUVqHBtC25d1+WrNqJc0a1aXifV6m9VJSUujSsQ2tQwMID/Jl44Z1Ntsy9VNY7vsJDMdXoF9zypb2ZsVyw/G1dMliatWoQnhoEOGhQaa5x9yihQsI8m9BSKBfrscxgNJa53ojQjiKUuoc0FlrHemM9c3qacBHax1vtfxBIFJr7W183x74yrhuqlLqDcBbaz3ErE4fYwydlVJBwFytdUNjWUXgNFBaa52olFps3P5cY/kYoInW+sl7xWVdppRqAOwHHtBa236yt6N8hYr68B/nLJalpKTg4uKCi4sL27dt4fNFC5j5znsULVaMoBaP8MtvR0zrvjSgD0OHj6F6zYexZ+EnH5F4LZEhI0YzbdIEqlStRo9nettdt7CHa1ZCNvnwvbkk30xmxKixXLp0idEjhnIo8iAHD/9usV5sbCwd24azZccezp45w5BXX2LNetsPbNbm7zlr+ndi3BXc3AtRpLgnx/duI3LLaroOn4qbuwcAX00fTuPQjjzcLJCEyzFcPn+OyM2r6Dp8KmBI3H76aDovzFrMH7/u5LeIn+gxdpbF/t57uSu9Jr5Hce9SvPdSF155fzmFihYzlb/Q/KEC0zbZkR6Lp2cJEhOvMWLUWN6YOI5q1arzzLN9HBKLq4vKcjzHf/+doYNfYe2GTcTExPBEx3bs3nfAVD529EgaNmrMU9170KfX0zzX/3kCAoOyvP2U1DS7y1NTU7ly+TILP51PjZo16dqtO5/M+4hr164xYtQYJk0cT9Vq1Xjm2T60aRnC4qVfUaZsWbvbyqiePUplvW3S+yohPp7aderS4+lezH77LQoXLsJLr9z9gJ+amopvsyZs2LydO3fu0KFNS3btPZDpvlLT7H+2SG+bzxbMp3oNQ9t8uXQxl2IuMWzkaNN6l//5h25PdCRi605u3rxJxzYtidi6E1fXu3PHp/M+4lriNYaPHMPk1w1t83Qv+22TmHzH7vLAZvXZtjfK9P7smdM8+FAVlFK81K8XvZ57nmbN/fjrz7M8+FBV4mKv0qVdGJv3HLTYzuIF87ieeI1Xho7irakTeahKNbr1fNbuPr2Kut+zbczHzenTp6hSpSpKKfr06kH/51/ELyDQoeMms2PK/DyxdctmPlvwKZ9/+bWpvPmjTfj2h5+pUKGCaVlsbCzt24SzbafhGB886CXWbsj8GL91x/4xdfmff/AoVAgvLy82bljHD999w5z3P8bDwzAvv9i/D127dScsvLWpzuFDkbwxYSzf/bzWYlufzv+IxGvXGDZyDFPeGE/VqtXp2cv+ucrN9d5ts/LnH9m6eRPvzH2fg78d4IN359CseYt7tn1sbCyd2rVi8/bdnD17hqGDXmb1+o2Zts3tlIzbplChQpTw8mJTxHp++G4FH8xbaCoP9m3Kl9/8SNmy5fjz3FkeqlKV2KtXad8qhN2/HrLY1oL5H5GYmMjQEaOZ+sYEqlSrRs8MzuMudsaNTT99+w1TZsykaLFiBDzWhH2RRwFIS0uziKVdeDB7DkRZbOvTeR+RmGjsp9fHU7Vaxv1U2D3zzxSpqalcvnyZBZ/Mo0bNh+n2VHeWLllMzKUYRo4aY7dObGws7Vu3ZNuuXzh75gyvvjKQdRGZf/lUxF1d0FpXtFcmV7xEgaeUGqaU2m+8+rNfKdXcapWnlVIHlFKnlFIjzepVV0qtNtaJUkq9koPdbwI8gZI5DL8EcAOwOesrwyeXEkCcdVlmtNaHjPXsHthZ5ebmhouLYRq4fu0adevWp2SpUhQuXNhivdTUVI7/fox3Z8+kQ+sQli5eaLOtPbt3Ed6mLQBt2nVg987tuQnNworlX/Nktx4AvDV9CiMymCQP7N+Hf0Ag7u7u1KhZk6tXrpCWZv9klRFPn9IUKe4JgIubG8rF1ZR0aa1BQ+kKDwDgdZ/th54zUb9Su3kwADWa+HL+xBGL8ju3bpF65w4+ZcrjXqgQD9ZtbLNOduRl22Q1lt27dtK6bXsA2nfoxM4dlmMhL2IBKFuuHIULFyYlJYWE+HhKlS5tUb5r5w7atjPG2bETO7Zvc8h+XV1dbT4Q7961gzZtDRfP23XoaGoTpRS9ej5Fx7bhHPh1v822MqqXW+l9VbtOXdNVroT4eErfd5/FeqdOnqRK1WqUKFGCUqVKUbZsOf7+668c79de24DhqlerkADenf02YLga/3CtWri5uVG8eHGKFS/O2TOnLers3rWD1m2MbdO+I7ty0DaXoqPp0j6Ml/r14srlf3jImOQAuLm74erqiouLCw8+VBWAQoUK20069+3ZRWgrw/wX3qYDv+zake1Y7LVN1arVTPtzd3PHxZh45uW4MT9PXLt2jXr165vKjh09ire3t0XSBYarqwGBjjvG77v/fry8DFdM3N3dcXV1NSVdWmu01lSpWs2izorlX9HVODea27N7J62M46Zt+47sysW56tTJkzRqbLjjoGGjxuzetTPTtj/w6z780ue/GjW5ejX3bVPC2DZubu4WX04cP3aUEl7elC9fARcXFx6qYhzHhe2P419276JVa+N5vH32z+P2+sneZwrrWLATi00/5XLuc3V1payduWfpkkWEBPox+51ZNmW/7t+Hf2CQQ89VkniJf4OlWuumxqtIg4BFVuVlgEeAx4BBSqkWSilX4GtguNa6qbFsgFKqaTb33RXYrLW+nI06NY1J4jHgIDBGa33TrHykUioSOA88A0y3qr/D7DbDLfZ2oJQKBK4Ah+yVZ8fhqEhah/gxesRgAoKC7a5z+fI/HD0cxcuDh/HtT2v5aulimw9B8XGxeHv7AODl7UNcXLbzSbtOnjiBh4cHDzz4IKdOnuTGjRvUrVff7rpxcbF4+/iY3nt6epKQkJCj/d65dZP1i94loGsfADZ9OY83e4WRlBhPidJlMqyXlBhP0eKGE49SCm01SSclxlOkeAnT+yKeJUhKjM9RjPnVNpnFEhcbi49xLHh7+xAXG5unsaTz8vLigQcfol7tGrQKC7JJShMTr+HpaUiyfXx8iLWK05HiYu8eH94+PsTFGfb1+VfL2bB5G2/PfZ8X+vfF+i6UjOrlhnlf+QcEsfDT+TzauD4bIzbQoWNny/3HxeLj421676gYzLXr0Jl9B4+wct1Gdu3cxtYtm3ioajUORR4kMTGRmOhoog4dtD+Octk2uw/+znerNtKyTTsmT7h7xW3fL7uIib5I02YtLNafMnEMz73wss124uNi8fLyBgzzX3y8Y+Y/U5y7dnLx4kWat/AF8n7cHIqMJMi/BcOGDCIoJNS0fNnXX9Ktu21yY75/gOIOOsaTk5OZMW0SL7w0CIA5b79F04a1iYuLpWy58qb10tLSWLPqZ9p3etxmG/Gxd+cfb+/ctU2dunXZFLEBrTUbI9Zz+fI/mba9+fwIULy449rmremTeGHgINOyb1Z8Tddu3W3WnfjaKF54yfa76Li4WLws2iZn4zg5OZkZUyfxwsuDMl13wthRvPiS7XrxDji+M9OhU2cORh1jXcRmdm7fxpbNlldlY2Nj8fFx7DiWxEv8GzRSSm1TSh0B5mFIbIqYlS/UBleA74EwoCZQB1hmTHJ2Y7hyVTsL+/M0Jj1/AfOBcWZlGd2ba778D611Q611baAqME4p1disfJaxvALwOvCt1bb8jeUNtdbWmdAOpdQpYDMwXmud4U3PxiuF59NfN65ft7tevfoNWbd5J18s/57RIwbbXcfb24cKFStRq3ZdChUqRHNff47/fsxiHS9vHxIS4gFISIi3mKxyY/myL3nyKcOJffrUSYweOz7Ddb29fUgw+41KYmKi6du37EhNSeGLKUMIeqo/5arUBCD06RcZs3QjpSs8wP5132VYt6inF8nXrwGGb2KVi0uG5QDJ1xMp6umd7Rghf9omK7F4+/gQbz4WSlpeMHZ2LOk2bYzg0qUYjh4/xW9RxxgxdDApxt/ngeEDz3XjcREfH0/Jkjm9sJ05bx+z4yM+Hh8fw75KG6/C1ahRk1KlSnPlypUs1csN876aMG4Mk6ZMZ99vUQweNoLXx4+13L+3D/Hxdz9oOCoGy314m65gdOj0OIcOHqRkyZKMfm0CTz3RkZHDXqVe/YYWH6zTY0tvm/gcxlWylKH9O3TuytEow/dYJ/84zrTXxzHvsy8trgp89N47FClSlKd797PZjpe3D9eMH8iuJcRbJB25dfz470wYN4YlXy4zxZPX46ZBw4Zs3bGbb77/iWGDDR+Stdb89MP3PP5EV5v1zfcPcN0Bx3hKSgrP932GQYOHU6duPQCGjhjN/shjVKlSja++WGJad9eObdRv0ND0xYpNbOlXeRNy1zbhrdpQrXoN2oaHErF+HXXr1c+07c3nR4Dr1x3TNgP69uLlV4dR29g2WmtW/vQDHTt3sVj3vTlvU7RoUZ7t299mO97ePlyzaJvsj+OUlBSe72PZTxl5d/YsihYtQu/n7Mfi6LnPdh93555OnZ/g4MHfLMp9fHwsfvfqiHEsiZco0JRSHhiSqRFa67pAgLGo0D2qaUABsWYJTEOt9UNa6yX3qJcu0Xh17QHgTQzJW/p18stAKav1SwP/2A1E6/PAXiDUXjmwHGiilLovg3Jr/lrrakA/YLFSKsNLL1rr2VrriumvYsWL26xz69Yt079LlPCiSJGidrdVuHBhKlaqTPTFC2itiTp0kCpVq1qs08LXjwjjwwvWr11NC78Ae5vKtu+//YYnunYD4NzZMwwb/Aqd27fh4oXzvDZ6hMW6jzzajF07d5CSksLpU6coVbq06RaZrNJas2LWWGo2DaCefzgAKbcN7aSUonAxT9wLFc6wfpX6TTm+z3DL2qmDe6hYo65FuXuhwri6u5NwOYaU27f48+hBKtSok60Y0+V122Q1Fl8/fzasXQPAmtUr8fO3HAvOjiWd1pqSPiVxcXHB09OTW7dvWSRefv4BrEuPc9VK/AMCHR5DOl+/ANavM/zWZO3qVaY2uXbNkIRfvnyZS5diKFWqVJbq5YZ5X2mtTbdg3nff/TZX/apVr86Z06dITEwkLi6O6OiLVKpcOdcxmDP/BnnXju1UrWa4ZazT411YE7GFd+Z+QJEihW326+sXwAZj26xbswrfbLZN0o0bpKamArB39w4erFKVC+f/YsjL/Xn/k0WmpAxg2ReLOXr4EBOmvGl3W81a+LF5o2H+i1i3msd8/bMVS0b+/usvXuzfl4WLlpqSLcjbcWN+nvAq4UXRoobzxJ7du3i4Vm28vb1t6jR9tBk7dzjuGNda8+pLAwgJC6ddh04WcSmlKOFVgiKF734f+83yr3nyqZ52t9Xc15+I9WbjJpfnqnET32BtxGbatuuAX0Bgpm3/SNNm7E6f/06folSp3LfN4JcHEBLW0tQ2AHv37KJmzVp4mfXPl58v4kjUISZPn2l3W819/YgwPuhi/Zrsn8ct+qmj7UO4zH2xZBGHow4xZYbtLX6GWKz6yQFznzXzuWfH9m1Uq1bdotwwjrc79FwlD9cQBYr1wzKUUiUw3FJXSWt9SSk1DpjK3YdMnAO2aK37KqVKYri1rwewDzgMzNRaLzJuqxqGZCw2Gw/XUBgeYvGl1nqO8QmEW4BmWuu/jPFtA6Zqrb+z83ANL+A3YKjW+mc7D9foAHwGlNFap2X14RrG998Df2ut7V+msmLv4Rrbt21h5vTJuLq6orVmyoxZpNy5w7TJE/l13y888uhjvDRoKGHhrYk6dJBxo4eTcucOoeGtGTF6HJcuxfDx+3N5Y+qbJCUlMWhgfy7FRFOpcmXe/fBT0z341rL6cI39+/by5rQpfPfTKpuyRvVqmR4gMWr4EMaMm0jJkiX5bMEnfLl0CS4uLsx+9wPq1W+Q6X7MH65xfO82Fk98icoPG+qVr1YLF1dXzv9xBK3TKFmuIk+OmI6buwcblrzP0V0RJMZe5f7KVRjwtmG/6xe9y4kDu3Dz8KD76Jn4lCnPvrXf4lOmPNUbt+Cv3w/x04dT0Wka387P0CS8s0U8WXm4Rl61TVZYx5KUlMSLzz9HTEw0lSs/wEfzF+Dh4eGQWLLzcI3U1FRefL4fZ86c5ubNm/R6tg/NW/iydctmBg8dxuXLl3n+ud4kJibSqHETZr0zJ1sPqMjo4RoAT3fvSlRkJEWLFSM4JJSJk6YycMBzxETHULlyZT6cvwA3NzcCfZtRuHARUlLuMHb8RMJbteFSTAzvvzeHqdPfIikpyaZeRsdVVmK37qtjx44y+JWBuLq6kpqSwnsfzadWrdq8M+tN2rbvSK1atVmzaiVvz5wBwITXJxMcGpbpfjJ6uAbAM927EnUokmLFihEUHEpxT082RWzAxcWFxk0e4a135qKUon+fZ4iJiaFYsaJMnzmbqlWrcSkmhg/em8MUY9u8NOA5LsXEUKlyZT6Yl3Hb2Hu4RlTkb4wa8hLFihXDzd2dN2d/yKxpbxD5237KV6wEwMuDR/LoYy2o/VAZGjZuiruH4cEY366M4J9LMXzy0XuMnzSd5KQkhr0ygH8uRVOhUmXefm9+hrFk9HANsB03MTHRHNi/n4qVDEnnsJGjCA0Ld+i4yeyY2rplM9OmTDKdJ96c9Q6NGjXm1VcGEhQUwhNdnzStO3L4EMYaj/GFCz7hi88Nx/icdz+gfoPMj/GMHq6xccM6nu35JI0fMfxaoF69hri5uXLw4AHS0tJ44IGHePdDQ5vfunWLZo3rsu/gUdPffCkmhg/fn8PkaYa2eeXFfsTERFOp0gO8/3HG56rMHq5x5coVevXohpubGxUrVeLtOe+hlLLb9qNHDGX0axPuzn9ffI6LcmH2u+9naf7L6OEamyLW07vnkzRuYmibuvUbMH3mbIYPfpmAwGA6Ga9IXr9+nSoVStP4kaZ4GH+3/PO6Tbbn8RcN5/GKlSvz3kcZt429h2ts3LCOZ3uY9VP9hnR58immTprA/r2/0LTZY7z86lCa+/rzYLlShliM21+1frNtP71g7KfK9+6nrDxcA6B7ty4cijxIsaLFCA4Nw9PTk4gN63FxcaHJI015Z867KKUYMWwIr403juNPP2Hp54txcXFh7nsfZmkc3+vhGpJ4iQLFmEgVwfJhFJ9guMJzBVgGzMQy8VqB4YqSFzBfaz3LuK2qwFwMV65cjfV7aq0vWD0hcDJwUWs9zzrxMm4nEMOVqSpa6ySlVFdgDOCG4arxF1rrmcZ1g4C1wB/G6oWAFVrr143li4GWGK6cKeAWMFJrvc1YroEjQKrZ3/+U1voPO4lXdeAAUEtrfSGztrWXeOWX7D7V0NnME6+CIDtPNfx/k53Ey9nulXjlh+wkjc52r8QrP2T0VMP8cK/EKz8UpGMqo8Qrv2SWeOWljBKv/GIv8covWU288ookXkIISbzuQRKvf4+C9CFREq+MSeKVMUm8MiaJV8Yk8crYvynxkt94CSGEEEIIIYSTSeIlhBBCCCGEEE4miZcQQgghhBBCOJkkXkIIIYQQQgjhZJJ4CSGEEEIIIYSTSeIlhBBCCCGEEE4miZcQQgghhBBCOJkkXkIIIYQQQgjhZJJ4CSGEEEIIIYSTSeIlhBBCCCGEEE4miZcQQgghhBBCOJkkXkIIIYQQQgjhZJJ4CSGEEEIIIYSTueV3AEKIvKEUFCssh7w9Ax57ML9DsBBxPCa/QzAJq1kmv0OwkJKq8zsEEzfXgvXdpdYFp21upqTldwgWfIp55HcIJmkFqJ8AlFL5HYJJYQ/X/A6hwEpNK1jjxsOtYM1//xbSakIIIYQQQgjhZJJ4CSGEEEIIIYSTSeIlhBBCCCGEEE4miZcQQgghhBBCOJkkXkIIIYQQQgjhZJJ4CSGEEEIIIYSTSeIlhBBCCCGEEE4miZcQQgghhBBCOJkkXkIIIYQQQgjhZJJ4CSGEEEIIIYSTSeIlhBBCCCGEEE4miZcQQgghhBBCOJkkXkIIAJKSkgj0a07Z0t6sWL4MgHNnzxIWHEB4aBAd2rYiPj7ept7aNasJ9GtOoF9ztm7Z7LT4Fi1cQJB/C0IC/Thy+LBF2dkzZ2gVFkxwgC9zZr/tsH0mJSUREuhLxTIl+XaFoU1Wr/qZJg3qULZUCYt1u3RqR+uwYAJ9m5nWNZecnEzfXj0JDwlkQL8+3L59O9P930pOYnSvDjzt9zA71v4IwKXzfzGu7+OM79eFSS/24Ma1BABizv/JhH5dGdu7Iz8u+RiAv079wdjenRjX93Em9H+SmPN/2uzDXr2cts2H779LkN9jhAX5M2Loqxbr37lzh4Z1avLOrLcc0jaZxZJRP3326XyCA1oQHhLI1s2bHB5LZk6eOIFnEXf2/vKLxXJnjWFzf547R3CAL+GhQYQE+nE4Koqlny+mds2qtAoLplVYMMnJyTb1Fn22gOAAX0KD/G2Ovez6689ztAn1p0PrENqGBXD0SBRrV6+keZN6PFDW22Ldjm1CaRPqT8c2obw5bZLNtpKTk3m+7zO0Dw/i5QF9c91Xpb2L0bplMK1bBvPzTz8wY9pk0/tqD1Xkow/es6mz+LMFhAT6Ehbsz5EjuWubgnRMWcdlfW54/925+DV/lOAAX4YOHmS33r3mbEfYv28f4aFBhIcG0eLRJjRv2tiiPC+OKXtts3TJYmrVqGKKze4x5cC2SUpKomWQL5XLleK7b5YDcO7cWdq0DKJdqxCe6NjG5tzdrlUIQwe9ZLOttLQ0RgwZRJuwQHo8+TgJCQk5juvY0aOEBvnTMiSQNuGhnD1zhg/em4t/i2aEBPoxbEgG48aB8405e301fepkUz9VeaACH75ve4w7ehxL4iWEAKBQoUIs//YHXnl1iGnZp5/M47l+z7Nh01YCg0P4cunnFnVSU1N5ffxrrFyznu9/WsWYkcPRWjs8ttjYWD6d/zERm7cx75OFjBg22KJ83GujmTRlOpu37WTNqpWcO3vWIfstVKgQXy//jpdeubu/x5r7smvvAcpXqGix7tff/MC6jVtYuTaCqZNet9nW0iWLqFOvPhs2b6NChYqsWPZVpvt38yjEmDkL6fB0f9Oy9d98Tssnnmbqwu+o96gvW1Z+A8Dnc6fx9KtjmL74J/Zvi+DS+b8o4VOK8R8sZdqiH3i870t8M3+OzT7s1ctp27Ru244tO/awcesOrly5zM7t20xlny34hOo1a9rdVk7aJrNY7PXT5X/+4fMli4jYvJ3vf17NpNfHk5qa6tBYMjNj2hT8AwJtljtrDJurULEim7buYMOmrUx8YzKz3poBwHP9nmf9xi2s37iFIkWKWNQxHHvz2LBpKx/PX8DI4UNyFUP5ChVZHbGNles2M2bCJOa8/RbNHmvBll37KVe+os36i7/6hp/XbmLMONtj6quli6hTpx6rNmylfIWKfLfi61zFVqlSZdZFbGFdxBY6dnqcseMmmt7ff38ZOj/exWL92NhYPv1kHus3buWjeblvm4J0TFnHZX1uaNuuPTt272XL9l1cuXKZHWZxQeZztiM0ffRRNmzayoZNW+nxdC+e6PqkRXleHFP22gbguf4DTLHZP6Yc1zaFChXii2XfMfDlu4n5ogXz6d23P6vXbyYgMJhlXy01la1bs4rixT3tbiti/VpSUlJYu3Ebrdu046P35+Y4rtL33cf3P60iYvM2hg4fyYzpU2nTtj3bd/3C5m07uXL5SgbjxnHzjTl7ffXa+Immfipzfxk6P2HnGHfwOJbEy4xS6pxSqqGz1jerp5VS3hmUTVRKHVFKHVJKHVdKzbKqd1gpFWn2KmVWXkUplaaUmmC1TW+l1BfG7UYZ/9vTrLyWUmq1Uuq08bVKKfWwWfkbxn37my17RSm12Go/wcb1elktf0MpNTcH7bRNKXVKKaWslldTSn2jlDqrlDpobKtZSqlCxvLFSqkLxvY5rpRaqpQqalbfot+UUk8ppX5VSv2hlDqglFqplKpnLLPpK/P6SqmtSqnOxn+XN+uXU0qpZLP3c5RSfZRSP1ptK0gpFWn894NKqVTj+oeMr3Zm6/ZRSiVY9f+H2W3XjLi6ulK2bFmLZXXq1DV9U5YQH0/p++6zKD918iRVqlWjRIkSlCpVirLlyvHXX1n74J4dv+7fh39gEO7u7tSoWZOrV66QlpZmKv/j+O881rw5Silat23Hzh3bHbJfV1dXyli1SalSpShcuLDNuh4eHgAk3bjBw7Vr25Tv3rWDNm0N3dmuQ8csxejq6opP6fstllWu9jA3Eg3fQt5IvIZXScMUcP7MSR5u8AhKKR7xD+Xob7/gXao0xTwNV3zc3NxwcXW12Ye9ellhr22qVq1G+uHq7uZu2t/169fZsH4tnTo/YXdbOWmbzGKx109//nmOmg/Xws3NjeLFi1OsWHHOnDnt0FjuZd/evZQpW5YKFWwTDGeNYXNubm64uBhO+9euXaNe/fqA4Rv60CB/5rwzy6bOr/v3ERAYmOGxl5sYrl+7Rt269SmZwTGllKJfr+506dia3w7stynfs3sX4W3aAtCmXQd278xdm0VHX6RVWBC9n+nBP//8Y1p+7NhRvLy9KV+hgsX6v+7fh3+A49qmIB1T1nFZnxuqVrOKy8Vybslszna05cu+ottTPSyW5cUxZa9twJD4hgT6MTuDY8qRbWNv3NSqXZeEhHgAEhLiKV3acO5OS0tjwfyPef6FgXa3tWf3TloZj6m27TuyKxfH1P3334+XlxcA7u7uuLq6WI4bd3dcXW3HjSPnG3MZ9RUYrs55eXtTwd4x7uBxLIlXAaKU6gq0AZpqrRsAdYEvrFbz11o3NHtdNSt7DtgM9LVKVqYCl4F6Wuv6QHNgv3Gf5YFtwJda66pa66rAl8BWpZT5CD0H2N7PYKkfsMn431xRSlUHqgO3gECz5eWAncA6rfVDWutGQAvgGmD+Fc4srXVDoAFQBXglg/30BaYAz2qta2qtmwBvAOWzG7PW+mJ6vwD9gT/M+mloFjeTaFy/ATAO+FopZT4zbbHq/5ezG2d2+AcGseDTeTzSsB4bN6ynY6fOFuWxsbH4ePuY3nt7+xAXG+vwOGJjY/Hxubuf4p6eFrdAmE+EPt4+xDohhqxoHRbMY00b0rpNO5uyuNhYvI1t5e3jQ1xczmKs27Q5679ZyuAuIUTu3sqjwa0B0PpuGxQr4c1140kX4NbNZL7+6G3am105S3evejm1e9dOLl68SPMWvgC8O/ttXn4l428KHdU2malStRqHIg+SmJhITHQ0UYcO2oxXZ8Yy881pjBg1xm5ZXo3hQ5GRBPm3YNiQQQSFhNKhY2d+izrK2g2b2LFjO1usbr80bw+wPfZy4nBUJK1D/Bg9YjABQcEZrvfZ58tYtWErb779Lq+80M/manp83N3YvLx9iIuLy1VcR46fZv3GrbRt34Gxo0eYli//+kuesvpQDxAXZzkveTqgbTJSUI+pXTt3cvHiBVr4+losz2zOdqSTJ07g4eHBAw8+aLE8v84LHTp15mDUMdZFbGbn9m02x1RetI1fQCCLFnxCi6YN2RQRQbsOnQD46ovP6dDpcQrZ+aIDIC42Dm8f83GTu2MKDLe9Tp38hsV4NYznC6bxfHf/jp9vsmLZ11/yVPeeNsud0VeSeGVCKTVMKbXfeHVhv1KqudUqTxuvkpxSSo00q1fdeBVpv/Eqk90P/lYqArHATQCtdYrW+lAW43QF+gCvAolAiNV2o7XxrKW1TtRanzSWvQRs1Vqb7kPQWn8NbDeWpfsZcFdKPZ7B/r2BdsAzQG2lVLWsxH0Pz2FIOhdgmci9bIx3oVm8N7TWU7TWV6w3orW+hSFReyCD/UwChmitj5nVOaC1Xp/L+B1hE4ZksmROKhvH7vn01/Xr17O9jfGvjWby1Bn8GnmYIcNHMmHcWItyHx8f4s0+qCckxONTMkfh3pOPj4/FPerXExNN36QBmH/PEJ8QT0knxJAV6zZu4eDh48x5e6bN5Ozt43P3G8j4eHx8chbj53On8czgsbz73WY69xnIF+8ZbhdT3G2DG4kJFPfyBiA1JYU5Y16mc+8XeaB6LZvtZVQvp44f/50J48aw5MtlKKX459IlDh06SEhYywzrOKptMlOyZEnGjpvAk493ZMSwV6lXvyHlyll+x+KsWNauWU3jJo9QqlQpu+V5NYYbNGzI1h27+eb7nxg2eBDe3t64urri4eFBp86PE3nwN4v1zdsDbI+9nKhXvyHrNu/ki+XfM3pExslDqdKlAaheoyYlS5Xi6hXLKd7L28fiW33zD0g5Udq4vy5du3Eo8iAAWmt++uF7Oj/R1WZ9b2/LeSnRAW1jT0E9po7//jvjxo7ii69XYPldb+ZztiNl9KE5v84LlsfUExy0Oqbyom3eGD+WiZOmsXt/JK8OHc6kieO4efMm3yz/iqef7ZNx7D7eJJjd5ZLbYyolJYU+vZ5m8NDh1K1XD0gfN6NZ+tVym3HjjPkmM1prfvzhOx7vYnuMO6OvJPHK3FKtdVPjVYxBwCKr8jLAI8BjwCClVAtjEvQ1MFxr3dRYNkAp1TSTfS0DHgLOKKU+V0o9p5QqYrXODrPbzLaYLW8FnDcmEAuxTFbeBUYbE8QPlFLtzcoaA3vsxLIHaGL2XgNjgOlWV2DS9QTWa61jMCRMz2Xyt2bIuP3ewGfAUqCDUip9pDcG9mZjW15AEPCdnbL7gUrY//sLgq7AZq31ZbNlwVa3GmZ4JU1rPVtrXTH9Vbx48WwHoLWmVCnDh5H777+f2KtXLcqrVa/OmVOnSExMJC4ujuiLF6lcuXK295OZpo82Y+eO7aSkpHD61ClKlS5tul0J4OFatdm/bx9aa9avXYOvn/89tuZ4qamppKSkAFC0aFEKFS5sc+uUr18A69etBWDt6lX4+QfkaF9aa0p4Gz5AeJUsTWK84RvJilVrcOLwQbTW/LZjM7UbN0NrzYeTRtCwRRDNQtrY3Z69ejn1919/8WL/vixctNT0IfbokcNcuXKFxzu04f135/DF54vZGGH5vYaj2iYrOj3ehXUbtzB77gcULlKYSlbj1VmxRB2KZPu2rXRs15pNmyIYNWIo0dHRpvK8GMO3bt0y/durhBdFixa1+IJg5/btVK1W3aKO4djbkeGxl5sYSpTwokiRohmum3jtGgBXLl/mn0uXKGmVtLbw9SNi/ToA1q9dTQu/nPfVjRs3TL/327ljO1WrGr473LN7Fw/Xqo23t7dNnaaPNmPXTse1jT0F9Zj666+/6P9cbxZ//qUpLnOZzdmO9N23K+jyZDeb5fl1XjA/pnZs30Y1u8eUc9tGa02p0obj5b777iM29ip/njtLQnwCTz3RkdfHjSFi/Vq+/nKpRb0Wvv6mY2rtmlX45uKY0lrz0gvPExYebrpb5u+//uL5fn1YtOSLe4wb5x5T1nbvuvcx7ui+cstV7f8PjZRS44BSQApQUylVRGud/piahcYrSVeUUt8DYUA8UAdYZpbNewK1Md7iZ4/WOsb426JmgC+GK06DlFLNtNbpjyTy11rH26neD0OiAoZbBScrpXy01nFa6y1KqcoYbtlrAcxXSv2Y3dvUtNablFJ/Yz+p6gekXw75DFivlJqgtU61s25m2gLntNbHAZRSGzEkdjaPXDMmHr0xXBUaoLVeZywaqZR6DqgBrAa2WNfNpZw8QSKjOubLPY2/+SoJlMbyyiUYbjXsnIN9Z0n3bl04FHmQYkWLsX/fXsaMHc+gl1/E1dWVlJQUPvz4EwBmzXyT9u07Uqt2bSZOmkL7NuEATH9rls03WI5QsmRJ+j7Xn7DgAFxcXJj73odsWL+O2NhYuvfoyZSpMxj4Qn/u3LlD+46deKhKFYft++nuXYmKjKRosWL8un8fXZ58ismvT+DC+b/p0CacQUOG0uSRR3n6qa4opbh95zbDR46mUKFCXIqJ4f335jB1+ls882wfBg54jlahQVSuXJlRY8dlaf9vDevP2eNHKFSkKCePHOTJ54cwb+poXFxdSU1J4aWJht8Q9Hp1LB9OGkFqyh0eDWpF2YoP8NuuLeza8DP/XPybnet/4qGadeg3ajK/7drC9YQ4Ato+YbdeTtsmJiaaq1euMHCA4XufYSNH0TK8NcGhYQB88fliLl26RFjLVg5pm3vFYq+fwlu1oV/vZ4iJiaFosaLMfGcugMNjsWf02HGMNm7r+ef60H/AixyOOsS2rVucPobT7dm9i2lTJuHq6orWmjdnvcO7c95hY8QGXFxcaPLII3ToaLglaeTwIYwdN5GSJUvS57l+tAwJxMXFhTnvfpCrGPb+spuZ0yebYpgyYxYH9u9l2uSJXLzwN090aMVLg4YSEhZOp3ZhFClchDspd5g+czYuLi5cuhTDx+/P5Y2pb9LjmT4MGtif9q2CqVS5MsNHvZbjuE78cZyXBw6gePHiuLm58/6H8wDDbYbdulveZmjRNn37ER5qaJvZuWwbKFjHlDnrc0NMTDRXr15hQP++AIwYNYbwVq0ZMWwIr42faHfOdoZ9e/fy0ENVTB/i8+q8YM66bTw9PYnYsN54TDU1HVPObJtePZ4k6lAkxYoV49f9exkx+jWGvfqS6Twx94N51Hy4Flt3Gb633rF9K99/s4IeTxt+kv9C/z7MX7CYlq3asH7tGtq0DMLLy5t5CxbnOKaIDev57tsV/PnnOb5dsZz6DRpwKeYSV69e4YXnDR8jh48cTXir1k6bb6xZ99Wsd+YYbiW2umLqzL5SzngC2b+VUuoc0FlrHWl874Hh1r9grfV+pVQJIAHw0VrHG9fvrbXeZlx/LnAV+B7YoLWuYLMTw3o6fRuZxFMIuASEaK1/y6ieUuo+4G8Mv+NKT3TuA0ZrrW1GrVLqMWN8JZRSU4EaWutuVuuswPAbpQlKqTcAb631EKVUY+An4H2gtta6jzI8aGI/cJG7SUQ5oIvWepV5/Xv9vWb7/hHwA9LvjSsC/K21fkQpNQ2oorXuYVVnKzBXa/2jMjz0I1JrPdeYcO4A3tRaf2xc9xzGfjYmki9orddkEMs/QHOt9WmzZdeB6lrraPP9WtULMi5vaLasLTBWa23+kJKuwPNa61ZKqQeNcXsbf6M3AUOS+7DW+qZSqo8x7s6Zt6KtChUr6tPnzuek6n9eSqrzfvSdExv/uJTfIZiE1SyT3yEUWG6uBeumkYJ0Pk+6lZPv3JyniIe9GzXyR1oB6icoeONY2HfrTsE6pjzcCs64ccYXvrlRxF1d0FrbPkUJudUwM4UBDyD9MW32/qcDfQCUUiWBxzH8LucP4JrxwQ0Yy6sZ18mQUuoRpVRVs0UPA+4Ykqp7eRb4UWtdSWv9oNb6QQy3qfUzbjdcKWV+o24TID2R+BjD7WvmTznsgeH2vI+sd6S1/g3Db6bMH4nTD3hHa/2A2f6HkIOHbCilygChQDWzbZUDyiulGgAfAqHGJCS9jguGvrKhtf4LQ79NtHPbJhgepDFbWT7FsZFSKtz4dj3wglnZs8AZrXU02bcXwxXThsZtFcLQRhvsxK0xPPTjCpZtLYQQQggh/oUk8bK1Pv1hBMAxDE8E3KeUOgDY+z8QXjaW7QM+0Frv1lqnAO2BJ4wP1jiK4XdXNh/8lVKTlVIvGt+WAr5UhkegHzTW6Wn1Gx/z33hFKqVqYvjw/qXVpiMwJCuNgXrAdmV8nDzQEcNDMNBaX8CQZPVSSp1RSp0GegGB90guxgEVjPEXBp62s/8VQLgxkQLop8we9KCUGpbBtntjuBoXn75AGx67tgzop7W+CPhj+N3XOWPb78TwZMYd9jaotf4ZOI7lw0LSyxYCkzG0+x/GvpoEXDCuMgQoZ+zHSAy3PD5ptZkFVn+b9QNY0vd1FegGfGTc1n7gMGD7f+zDlHwNx/D7vPQfQlj/xmu5vbpCCCGEEKJgkVsNhfg/IbcaZkxuNcyY3GqYsYJ2i1ZBOp/LrYYZk1sNRU7IrYYZk1sNhRBCCCGEEEKYyFMNRb5QSvXH/v/UeJDW2u4tg0IIIYQQQvxbSeIl8oXWegGG/zmyEEIIIYQQ/3lyq6EQQgghhBBCOJkkXkIIIYQQQgjhZJJ4CSGEEEIIIYSTSeIlhBBCCCGEEE4miZcQQgghhBBCOJkkXkIIIYQQQgjhZJJ4CSGEEEIIIYSTSeIlhBBCCCGEEE4m/wNlIf6PaK3zOwQAlFL5HYIFN9eC9R1Uq1pl8zsEkzXHYvI7BAutHi6T3yGILHBzLVjHeEGaclwoQMGIfw33AnaeKmjn8X+LgtWLQgghhBBCCPEfJImXEEIIIYQQQjiZJF5CCCGEEEII4WSSeAkhhBBCCCGEk0niJYQQQgghhBBOJomXEEIIIYQQQjiZJF5CCCGEEEII4WSSeAkhhBBCCCGEk0niJYQQQgghhBBOJomXEEIIIYQQQjiZJF5CCCGEEEII4WSSeAkhhBBCCCGEk0niJYQQQgghhBBOJomX+NdQSp1TSjV01vpm9bRSytvO8iClVKTVsgeVUvFWdQ8rpQ4ppY4ppfpa1U9WSkUaX0eVUs/b2c82pdQppZSyE9dGq2VXlFIPZvdvtOfPc+cIDvAlPDSIkEA/DkdF8cF7c/Fv0YyQQD+GDRlkt96izxYQHOBLaJA/Rw4fdkQo9vezcAFB/i0ICfSz2c/ZM2doFRZMcIAvc2a/7ZT9JyUlEejXnLKlvVmxfBkAycnJPPtMD0KD/Onftze3b9/OVtw5dezoUUKD/GkZEkib8FDOnjnD9KmTaRUWTKuwYKo+WJGPPnjPNpZc9tWt5CRee7YDz/o9zM51PwJw6cJfTHjucSb268KUgT24cS3Bos7Efl2YP3W0xbKLf57mqUcqcyLqgM0+Lp3/k9f7d2Vc7478tOTjLMWVlJRESKAvFcuU5NsVd/umb6+ehIcEMqBfH27fvs3t27dp0zLE9CrpWZi4uDiLbdmr50gnT5zAs4g7e3/5xWJ5XozhgnCMJyUl0TLIl8rlSvHdN8sBOHXyBO1ahdC+dSivjR6O1hqAJzu3p214MMF+j5nWNZecnEy/3k/TJiyQF5/vm6u+sndMpZsy6XUa1q1lt54z57/S3sVo3TKY1i2D+fmnH5j30Qe0DAkgNMiP/s/1JiUlxabO4s8WEBLoS1iwP0eOOG8+zs9xbM7evJxf8RSUWE6eOIFXMQ/27f2Fc2fPEh4aSOuWwXRs15r4+Hib9detWU1wQAuCA1qwdctmp8X124EDtG8TTquwYN6YON6i7P/qHK61lpe8/hUv4BzQ0Fnrm9XTgLed5UFApNWyB4F4e3WBBsBtoJy9+kBF4BbgabasOnAROAoE2YnrLNDKbNkV4MGs/F3lK1TQSbfTMnxdS7qtr99M0Um30/Sa9Rt11yef0oePndA3bqXqpNtpuuuTT+n1G7dY1Dkfc0U3bNRYJ9y4pSMP/64Dg4LvuY/0V/Idna3XhUtXdaNGjfW1pNv60JHjOjAo2KL88S5d9Zbtu3XS7TTt5x+gfz9xJtv7yOx1/WaKPvt3tB434XW95IuvdfIdree8+4GePHW6Tr6j9agxr+lPFizKVtwZvTJrv3PnY3T05TiddDtN/7hyjX7m2T4W5Q0aNtInz/7tkL76NvKi6bX8wN/6042R+skXhukhb36kv428qDv1eUkPmvqe/jbyon568Gu676jJpvXHvLdENwkI0y279rLYTkC7LrpeMz89/fOVFsu/jbyoHwtrr6ct+Vl/c/CCrt3kMf3h6l8syhNvptq84m/c1qfOXdBjx03Uiz7/UifeTNXvzH1fvz55mk68mapHjBqrP/5koUWdXXsP6NCwljbbyqye+Ssn46hHz2d0cEio3rpjj8PHcGZ9mZfHeHxSit3X1cRb+o8z5/Xo1ybohUu+1PFJKbpt+456y45fdHxSin7+xZf1DyvX6vikFP1PfJKOT0rRf8XE6ipVq9lsa9bs9/TESVN1fFKKHj5yjP5w/sIM95vTY+rs39H6yW7ddY0aNW3q5LRtbtzK2qtGjZoW7+MSb5r+3ePpXvqHn9dYlP8dbYgn/votfTDqdx0QFJyl/RS0cZzbeTm/4nF2LFkdN917PqODgkP1lu279dDhI/Wnny3RN26l6cnTZuhZ78y1WPda0h1dt159HX05Xv918bKu36Chvn4z1eHjJuHGLd0yvJW+HJdot/y/dg4Hzmf0WUyueIl/NaXUMKXUfuMVpP1KqeZWqzytlDpgvII00qxedaXUamOdKKXUK46OTWt9CIjDkGDZUwK4AdwxW/Yc8AWwAOhnp85E4E3rq2GO4ObmhouLYUq4du0a9erXp2q1aqTvyt3dHVdXV4s6v+7fR0BgIO7u7tSoWZOrV66Qlpbm6ND4df8+/AODMtzPH8d/57HmzVFK0bptO3bu2O7wGFxdXSlbtqzFsl27dtCmbXsA2nfoxI7t27IVd07df//9eHl5Aen9cncqP3b0KN7e3lSoUMEmltz2laurKz6l77dYVrnaw9xINFzlSkq8hpdPKQDS0tJYt3wxrZ/qa7H+icO/4V3qPkrdX97uPi6cPUnNBo+glKKxXyi/H/jF7nrWcZWx6pvdu3bQpm07ANp16GgzJpYv+4onn+phs63M6uXGvr17KVO2LBUq2E4JeTGGC8Ixbq+vzp45TYNGjQFo8khTdmzbCoCHhwcASTdu8HCt2jbb2rN7J63aGPqqbfuO7MpFm2V0TL05fQojRo2xW8fZ81909EVahQXR+5ke/PPPP6b2SP8AV7VqNZt4/AOcPx/n9zg2Z29ezq94CkIs+/ftpUyZMlSoaOib2nXqkmC8ypUQH0/p++6zWP/UyZNUrVqNEiVKUKpUKcqWLcfff/3l8Lj2/rKHosWK8ezT3WkTHsove/ZYlP8/ncMl8RL/dku11k211g2BQcAiq/IywCPAY8AgpVQLpZQr8DUwXGvd1Fg2QCnV1JGBKaUCMVyROmS2uKYxSTwGHATGaK1vGtd3BXoDnwFLgQ5KKS+rza4ErgM9HRlrukORkQT5t2DYkEEEhYSalu/etZOLFy/QvIWvxfpxsbF4e/uY3hf39CQhwfJWM0eIjY3Fxyfj/ZhPhD7ePsTGxjo8BnviYmPxNsbl4+NDXJzlfjOLO7eSk5OZOvkNXn5lsGnZsq+/pFt324TCWX1V55HmbPhmKcO6hhC5eytNg1sDsPXnFTQLaYu7RyGL9b9f8C6PP5fx9xxa3+3LYiW8SUyIz1Fc5n+vt1XfpKWlsfrnn+jY+Yls1cutmW9Oy/BDfF6N4YJ4jD9cqzabN25Aa83GDessbv9sGx6Mb7NGtDYmWBaxxTm+r8yPqVMnT3Lj+g3q1a9vd11nt82R46dZv3Erbdt3YOzoEQC8PetNGtZ9mLjYWMqVt/zyIi7Ocr7xdNJ8XBDGcVYVpHjyIpaZb05n+Mi7fRMQEMTCT+fTtHF9NkZsoEPHzhbrx8XF4u3jbXrv7eNDrAPnvHQXL17kyOEolnzxNZ8sXMwrAwdYlP8/ncMl8RL/do2Mv4k6AszDkNgUMStfqA2uAN8DYUBNoA6wzPibrd2AJ2D7laolncXlO5RSp4DNwHittflNw39orRtqrWsDVYFxSqnGxrK2wDmt9XFjvBuxn2CNBqYopTzuFazxauD59Nf169cz+fOgQcOGbN2xm2++/4lhgw2/9zj++++MGzuapV8tx/pCm7ePDwlmH4yvJyaavjV2JB8fH4t70633Yx5XfEI8JUuWdHgM9nj7+Ji+TYyPj8fHx3K/mcWdGykpKfTp9TSDhw6nbr16gOGb8J9++J7Hn+hqP1Yn9NUXc6fx9Ktjmf3tZjr1HshX783g9q2b7Fj7PSGdnrJY98D2jVSt3QBP73v1z92+TEpMwNPLO0dxmf+9CVZ9s3P7Nuo3bIinp2e26uXG2jWradzkEUqVKmW3PK/GcEE8xqfOmMWihZ/yeIfWlCjhRdly5UxlazZs4cCh35nzzkybDzze3o7tK+tjatqUSYx5bXyG6zu7bUqXLg1Al67dOBR5EIARI8cQeeQ4VapW5YvPF1vG42053yQ6oa8KyjjOqoIUj7NjWbdmNY2bNLHom/HjxjBpynT2/xbFkGEjmDh+rEUdb28fEuLvHlcJ8fGUdNCcZ65kyZI0b+6Lp6cnlSpVomixYly7ds1U/v90DpfES/xrGROP74ERWuu6QICxqFDGtdAYPtnFGhOg9NdDWuslmezyMmB9tikN/GO1zF9rXQ3DrYKLlVJl7Aai9XlgL5D+tXM/oIbxoSDnAH/s3G6otd4NRAED7xWs1nq21rpi+qt48eL3/ONu3bpl+rdXCS+KFi3K33/9xfP9+rBoyRemDwHmmj7ajJ07dpCSksLpU6coVbq06VYmRzLsZ3uG+3m4Vm3279uH1pr1a9fg6+fv8Bjs8fMLYN26NQCsWb0S/4DAbMWdU1prXnrhecLCw+nYqbNp+Z7du3i4Vm28vb1t6jirrzTalEiVKFmaxIQ4/rnwNzcSrzHj1Wf5Yu5UDu7cxNaV33Duj6Mc/XUPU1/qSdQv21n89hvEXb5ksb2KVWpw8vBBtNb8tnMztRo3y1Fcvn4BrF+3FoC1q1fh5x9gKlu+7Cu6dbd/0fhe9XIj6lAk27dtpWO71mzaFMGoEUOJjo42lefFGC6ox3iFihX5cvl3/LByHTdv3qRDp8dJTU01PTyiSNGiFC5cmMKFC1vUa+HrT8R6Y1+tWYVvLvrK3jF19uwZhgx+hY7t23DhwnnTVad0zmybGzdukJqaCsDOHdupWrWaqf+UUnh5eVG4SBGLOk0fbcaunc7tq4IwjrOjIMXj7FiioiLZvn0bndq3YfOmCEaPHMalmGhKGY/r++673+ZKUrXq1Tl9+hSJiYnExcURHX2RSpUrOzQuMIzNkydPkJKSQkJCAomJ1yhRooSp/P/pHK6MP9AXosAzJiOdtdaRxvclMNzKV0lrfUkpNQ6YCvhoreON62/RWvdVSpXEcGtfD2AfcBiYqbVeZNxWNQzJWKxSSqdvw2r/7sAfwCta6zVKKRdgPnBTaz3IuI5FXaXU98DfWuvBSqkgYK7xtkiMtxH+BgzFkICdMv4t6XVdgPNAG631IfNtK6VqY7iiVgyop7U+l1n7VahYUZ86+3eG5Vu3bGbalEm4urqitebNWe8w5+1Z/PrrPipVMkzEw0eOJrxVa0YOH8LYcRMpWbIkCxd8whefL8HFxYU5735A/QYNMgvF5lv1rFj46Scs/XwxLi4uzH3vQ2JioomNjaV7j56cPnWKgS/0586dO7Tv2InhI0Zle/tZ0b1bFw5FHqRY0WIEh4Yxaco0BvTvS0x0NJUrP8C8Txfi4eHBiGFDeG28sX2s4s5K+2Q2L29Yv44e3brwSNNHAajfoAGz3pnLq68MJCgohCe6PmlaN7d9teZYjMX7WcP7c/b4EQoXKUq9Zv6EPd6T+dNG4+LiSlpqCi9MmEWlqjVM6x/Zv5td63/ihfFvWWzngwlDCH+yFzXqN+Hgri1cT4jDv+0TRP91lo8njSA15Q5Ng1rRue/LFvVaPWz3ewye7t6VqMhIihYrRnBIKBMnTWXggOeIiY6hcuXKfDh/AR4eHty6dYtHGtThQNQx029mLsXE8P57c5g6/S2SkpLs1rPHzTVnJ+Dnn+tD/wEvkpAQ79AxnNm4yctj/HZKxr+D6NXjSaIORVKsWDECg0No0LAxX3y+CBcXF7p1f5pnnu1D7NWrPNOjK0op7ty+Tf8XXqJb955cionhw/fnMHmaoa9efqEfMTHRVKr8AB98/GmGfeXhdu++yuiYStewbi0ij/wO5P6YysrHroO/HeDlgQMoXrw4bm7uvP/hPBZ8Oo+Dvx0gLS2NBx58iA8//gQPDw+LeD5b8AlfLDXEM/vdD6hfP/N4XFxy9pNhZ43j7LKel1uGt8q3eJwZS1pa1j+vD+jfl/7Pv0BxT08GvzIQV1dXUlJSeP+j+dSqVZu3Z71Ju/YdqVWrNmtWrWTWzBkATHh9MiGhYVnaR3bHzZdLP2fhgk+4c+cOr42fiKur63/2HF7EXV3QWtv9fb8kXuJfw5hIFcHyYRSfYLgqdAVYBszEMvFageGKkhcwX2s9y7itqsBc4AHA1Vi/p9b6glWCMxm4qLWeZ6zXAJiN4cqXC4aEabjW+pqx3Drxqg4cAGpheGLhWgzJGxiuzK3QWr+ulBoFNNNad7H6m2cDblrrV+1seyGGh3E85IjEKy854dkg/ykFaV62TrzyW0aJV37IaeLlLAVp3Nwr8coPmSVeeakAdROQ88RL5K3sJF55QcZNxiTxEkJI4vUvUpDmZUm8MiaJV8Yk8cpYAeomQD5A/1tI4vXvca/Eq+DMREIIIYQQQgjxHyWJlxBCCCGEEEI4mSReQgghhBBCCOFkkngJIYQQQgghhJNJ4iWEEEIIIYQQTiaJlxBCCCGEEEI4mSReQgghhBBCCOFkkngJIYQQQgghhJNJ4iWEEEIIIYQQTiaJlxBCCCGEEEI4mSReQgghhBBCCOFkkngJIYQQQgghhJNJ4iWEEEIIIYQQTuaW3wEIIfKIhpRUnd9RAODupvI7hAJNqYLTPm1rl83vECzsOnU1v0Mw8a1WKr9DsFCQxo2ba8H6XlcXjKkPgNS0AhQM4OJScMaNLkgdRcE6psR/Q8GaGYUQQgghhBDiP0gSLyGEEEIIIYRwMkm8hBBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSLyGEEEIIIYRwMkm8hBBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSLyGEEEIIIYRwMkm8hBBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSL/GvopQ6p5Rq6Kz1zepppZS3neVblFLPmL0fr5S6qZQqbLbsuFIq1PhvpZQ6q5TaZHxfXikVaXydUkolm72fo5QKsloWqZT6wVjXvCxKKbVXKfVYdv82a0lJSYQG+lKpbEm+XbHMomzalDdo0qA2ALdv36ZteIjpVapEYeLi4izWT05Opu+zPWkVGsgL/ftw+/btXMUV6NecsqW9WbHcENfSJYupVaMK4aFBhIcGkZycbFNv0cIFBPm3ICTQjyOHD+d4/9mJy9zZM2doFRZMcIAvc2a/7fD9ZxTDubNnCQsOIDw0iA5tWxEfH29Tb+2a1QT6NSfQrzlbt2x2SCzHjh4lNMifliGBtAkP5eyZM3z80QeEBQcQEuhH/769SUlJsam36LMFBAf4Ehrkn+N+upmcxKs92tC5WVW2rPkBgPU/fE2v8EcY3rsTw3t34tbNZO7cvm16P7x3J9rUL09iQjwA+3duZmTfJxjRpzM/frnAZh9/HIlk8NNtebVHGzav+i5HcZ48cYISRT3Yt/eXPGubzOT3OP51/z5atwymdctg/B57BN9mTTh39izhoYG0bhlMp3at7Y7hdWtWExLQgpCAFg4bw+ZOnjiBVzFDX5nH0/Ee8QQHtCDYAfFkdS4GuHL5Mn2e6U771mE8+UQHm205ci429+e5cwT5t6BlSCDBAb4cjoqyKM+L+c/enJNuyqTXaVi3lt16zjiu7B1Hq1b+TMN6tSjtXTzDes48T5mP4aWfL6ZOzaqmY83eOXPxZwsICfQlLNifI0ccF4u9tjl54gThoUG0Cgtm1IhhaK1t6jn7HA6GMRQS6EdYcACtW4ZYjCFw8jjWWstLXv+aF3AOaOis9c3qacDbzvKJwAKz95uAX4Ag4/tywE2gsPF9GHAQuAw8ZLWtICAys2UZlQGvAMey+jeVL19BX0tOtXnFXb+tT569oMeMm6g/W/Klafmpcxd1lyef0tVr1LSps/OXAzokrKXN8rfnvK9fnzxNX0tO1SNGjdUff7LQ7j6T7+hMX9dvpuizf0frcRNe10u++Fon39H6kwWL9ORpMzKsc+HSVd2oUWN9Lem2PnTkuA4MCs7SvrLzsheX+evxLl31lu27ddLtNO3nH6B/P3EmT2IYNmKUXrjoc518R+sp09/Ub89+16ZOvXr19aWrCfp8zBXdoEFDnXQ7LdN9Jd1Ou+fr3PkYHX05TifdTtM/rlyjn3m2j46/ftNU3vPpXvrHlWss6pyPuaIbNmqsE27c0pGHf9eBQcGZ7if9FXHssum17nCMXr7tiO710kj92tuf6Ihjl/WIae/pfkPHW6xn/vr4u826iW+Qjjh2WX+767huHtxarz10McP1azdsqr/ceFCvPvi3rlKzjv55/1lTWVZj7tHzGR0cEqq37tjt1LYpSOP4+q20LL/emjVbvzFlmh46fKT+9LMl+vqtND152gw98525FuslJN3RdevV1xcvx+s/L17W9Rs01Ik3U7O0jxtZfHXv+YwOCg7VW7bvNsVzwxjPrHfmWqx7zRhP9OV4/Zcxnus3UzPdh705Mbtzcfeez+hfI49muK2szsVZnY/TX4nJd/SNW4Y6azds0l27PeXQcZOVcW5vzkm6nabP/h2tn+zWXdeoUdOmTk6Pq5wcR+djrui4xGRdo2ZNh56ncjKG5336mZ40dXqG6/4dbWiX+Ou39MGo33VAUHCW95OTtmnfsZPeuWe/Tr6j9YsvvaJXrd3gkLbJ7uvPC5d0zJV4nXxH659WrdW9nu3j0HEMnM/os5hc8RL/ekqpYUqp/cYrQfuVUs2tVnlaKXXAeIVppFm96kqp1cY6UUqpV7Kwuy0YEiCUUh7AQ8Cn6cuM//1Fa33T+L6fsfwr4Lkc/okZ2QQ8kNuNuLq6UqZsWZvlb82YyvCRY+zWWbHsK558qofN8t27dtC6TTsA2rbvyM4d23MVV1k7cS1dsoiQQD9mvzPLpuzX/fvwDwzC3d2dGjVrcvXKFdLS0nIcQ3biSvfH8d95rHlzlFK0btsuV22QnRjq1Klr+kY+IT6e0vfdZ1F+6uRJqlSrRokSJShVqhRly5Xjr7/+ynUs999/P15eXgC4u7vj6uqCh4cHcPeLvapVq1nU+XX/PgICA3PdT66urpS8r4zN8vU/fM2QZ9qxYuEHNmWbV31HSLsuAOzdFkHxEiUY/1JPXnuhO3+fPWWx7u1bN7lz5zb3l6+IR6HC1Gn0KCeOHcpWjPv27aVM2TJUqFARIM/aJjMFYRynW7H8a57s1oPaWRnDVc3GcNly/O2AMZxu/769lClThgoVDX1Vu05dEjKJp6oD48nqXJyamsrx348x++23aNMymCWLbK/UOnIuNufm5oaLi+Gj47Vr16hfv4FFeV6MG3tzDsCb06cwYpT9c5azjit7x1GpUqUoXLhwBjWce56yHsMAXyxZTFiwP3MyOmcGOGe+sdc2Z06folHjxgA0bfoo27ZusY3HyedwsDeGXC3KnTmOJfES/wVLtdZNtdYNgUHAIqvyMsAjwGPAIKVUC6WUK/A1MFxr3dRYNkAp1TSTfe0FyiulKhnr7AO2AsHG8mBgM4BSqiTQGkPStRDoo5TKyjFX0+pWQ9vZ0qArYHuPkAOcOnWSGzeuU7defZuytLQ0Vq38iY6dnrApi4uLxdvbBwBvHx/i4mIdGleHTp05GHWMdRGb2bl9G1s2b7Ioj42NxcfHx/S+uKcnCQkJDo0hM+YnCR9vH2JjHdsGGfEPDGLBp/N4pGE9Nm5YT8dOnS3KY2Nj8fG+2zbe3j7EOTC25ORkpk5+g5dfGQzA2zPfpEGdh4mNi6Vc+fIW68bF3h0n4Nh+8g1ty4KVu5j12Q9E/bqb3/bcPWGmpaWxa9Ma/Fq2B+DqPzFE//0nUz/6ir6Dx/Le5JEW27qWEE9xT6+7cZbwMt2imFUzZ0y3+QIjv9omO/JqHJ88cQIPDw8eePBB/AOCWPjpfB5tXJ+NERvo0LGzxbpxcbH4+Hib3jt6jpn5pmVfBRjjaXqPeLyt4ol18Jxnby6+/M8/HI46xKtDhvPjqnUsXbKYM2dO28bmpLn4UGQkgX7NGTr4FYKCQy3K8nL+M59zTp08yY3rN6hX3/acBQXnuALnnqesx3CHjp05cOgoa9ZvYueO7TbnTMMxdTcWTye3S63addgYsQGtNevXr7U5B+X1OTw5OZkpk17n5UGDLZY7cxxL4iX+CxoppbYppY4A8zAkLkXMyhdqgyvA9xhu/6sJ1AGWKaUigd2AJ1Cbe9Ba3wZ2YbiyFQRs1VqfBioaf+cVhOGqGMDTwFqtdbzWOgq4BLTKwt/zh9a6odnL/NNgelIWAwwGpme0EeOVwPPpr+vXr2dh1wYzpk5i1Njxdst27thGgwYN8fT0tCnz8fYhwfjBNCE+Hh+fklneZ1Z4e3vj6uqKh4cHnTo/wcGDv1nu38fH4ncY1xMTTd9q5RWllOnf8QnxlCzp2DbIyPjXRjN56gx+jTzMkOEjmTBurEW5j48P8WZJQ0JCPD4Oii0lJYU+vZ5m8NDh1K1XD4ARo8Zw6OhxqlatytLPF1us7+1zd5yAY/upeAkvXF1dcffwwC+sHaeO3f0NStT+3VSrVY+ixQy/vfD08qHRYwG4ubtTvXYDrl6+ZLEtzxJeXE+8e9K/npiAp5d3lmNZu2Y1jZs0oVSpUhbL86ttsiOvxvHyZV+arp5PGDeGSVOms++3KAYPG8Hr4y3HsLe3D/Hxd/vDkXPMOjt9Nd4Yz/7fohgybAQT7cSTYBVPSQfPefbmYm8fHypWrETtOnUpVKgQvn7+HD921GIdZ87FDRo2ZNvOPXz7/c8MHWx5o0hejRvrOWfalEmMec3+OQsKznEFzjtP2RvD5ufMjp0fJ9LqnGk4pu7Gkujkdnlz5jss+HQ+7duE41XCy+aLp7w8h6ekpNC7V0+GDBthOm+lc+Y4lsRL/KsZb/f7Hhihta4LBBiLCt2jmgYUEGuV4DyktV6Shd1uwXBlKxjD1S4w/M7rSaAChqtiYLjNMMT4gI9zGG5L7JflP86+P4xX9ioBPwBfKvMZwozWerbWumL6q3jxjH/oa+3c2bMMH/IKj3dsw8UL5xk35m7ut2LZV3Tr3tNuvRZ+AWxYtxaAtWtW4ecfYHe9nDL/5mvH9m1Uq1bdorzpo83YuWM7KSkpnD51ilKlS5tui8krD9eqzf59+wzf6K1dg6+ff57sV2tNqVKlAcNtFLFXr1qUV6tenTOnTpGYmEhcXBzRFy9SuXJlh+z3pReeJyw83HSV7datW4Dh5FWihBdFihSxqGPopx1O6acbiddM/476dTcVHqhier9p1beEtu9qet/gUV9OGm8djLnwF54lvC22VahwEdzdPbhyKZrbt2/xe+SvVK9teWvVvUQdimTH9m10bN+GTZsiGDViGH/9+SeQP22THXk1jr//9hue6NoNMI7h0oYxfN9999t8y1ytenXOnDYbw9EXqeSAMQwQFRXJ9u3b6NS+DZs3RTB65DAuxURnGs9pJ8WTzt5cXLhwYSpVfoCLFy6gtSYy8jeqWN2y6qy5OP3YBvDy8qJo0aIW5XkxbuzNOWfPnmHI4Ffo2L4NFy6cZ+zoERZ1CspxdTcWx5+n7I3h9PkGYOeO7XbPmbt25l27VKxYkRXf/sCqtRu4efMmnTpb3jmTV+dwrTUDB/SnZctWNneHgHPHsZvDtiRE/igMeADpN9YPsrNOH2Cb8da/x4EewB/ANaVUX631IgClVDUMyVhm15S3AC8CKVrr48Zl24AJwC6t9W2lVBPgPqC81jrNuH1v4G+l1H1a68s5+muNtNZ3lFKDgRNAZwxJWI49070rUYciKVqsGL/u38embbtMZU0a1Gbam4a7HW/dusX2rVuY/e6HpvJLMTF88N4cpkx/i2ee7cNLA56jdVgQlSpXZtSYcbkJi+7dunAo8iDFihZj/769eHp6ErFhPS4uLjR5pCkdOnYCYMSwIbw2fiIlS5ak73P9CQsOwMXFhbnvfZjJHhwTV8vwVsTGxtK9R0+mTJ3BwBf6c+fOHdp37MRDVapkvkEHxDBm7HgGvfwirq6upKSk8OHHnwAwa+abtG/fkVq1azNx0hTatwkHYPpbs8ggZ8+WiA3r+e7bFfz55zm+XbGc+g0a4Obmxm8HDpCWlsaDDz5k+iZ65PAhjB1n6Kc+z/WjZUggLi4uzHnX9rdYWTVpcB9O/X6EwkWKcjzqAEWKFefAzi0oFxdq1m1Ii9A2ANy+fYvIvTt5dcJMU91KD1WjTuNmDOvVgdTUVAaOmQoYfiN2f7mKNHrMn4FjpjJlWD90mqZL74Gmq2VZMXrsOEaPNRwDA/r1pf+AF/j4o/fzrG0yk9/jeP++vTz0UBVKG5ObUWPHMfiVgbi6upKaksJ7H80H4J1Zb9K2fUdq1arNhNcn06md4caBaTNmOmQMA4waM840Xw3o35f+z79AcU9PUzwpKSm8b4zn7Vlv0s4Yz8TXJ9PRgfFkdS6eMfMd+vV5hjt37tCyVWserlXbqXNxuj27dzF18hu4urqiteatWbPZsH5dno4be3PO1h27TeUN69ZixluGJ9HlxXFlfRw92a07b0wcx/m//6ZtqzAGDx1Oq9ZtnH6esjeGlyxeyMaIDYZzZpNHaG88Z1q0S99+hIca2mW2g+cb67Zp1KgxSxZ/houLCz16PkOdunWBvD+Hm4+hb1Yso36DhoS3ap0n41gZn44mxL+C8cpREeCO2eJPMFxJuoLhN08zAR+tdbxx/RVAKOAFzNdazzJuqyowF8MDKlyN9XtqrS8opbTZNiYDF7XW84z13IA4YLXWurtxWU3gODBWa/2mUuojIFlrPdwq/u+BnVrr2UqpIGCu8QpWenkQsBZDYpguUWvtn8H6vYFhGJ7ceM+DuUKFivr4acf9ED033N3kYvu/RUE7R+w6dTXzlfKIb7VSma+UhxyVhDhCalrBGjcFp2UKXtsUpPm4oM03BemYSitg48bFpeC0TUFTxF1d0FpXtFcmiZcQ/yck8RI5UdDOEZJ4ZawgfUgsaMlFwWmZgtc2BWk+LmjzTUE6piTx+ve4V+JVcI42IYQQQgghhPiPksRLCCGEEEIIIZxMEi8hhBBCCCGEcDJJvIQQQgghhBDCySTxEkIIIYQQQggnk8RLCCGEEEIIIZxMEi8hhBBCCCGEcDJJvIQQQgghhBDCySTxEkIIIYQQQggnk8RLCCGEEEIIIZxMEi8hhBBCCCGEcDJJvIQQQgghhBDCydzyOwAhRB5R4O4m37WI7FFK5XcIFvyql87vEEzib9zO7xAseBfzyO8QTFxdCta4KUhcpG0ypHV+R2CpIE1/BW3cpKUVnM4qaG1zL/IpTAghhBBCCCGcTBIvIYQQQgghhHAySbyEEEIIIYQQwskk8RJCCCGEEEIIJ5PESwghhBBCCCGcTBIvIYQQQgghhHAySbyEEEIIIYQQwskk8RJCCCGEEEIIJ5PESwghhBBCCCGcTBIvIYQQQgghhHAySbyEEEIIIYQQwskk8RJCCCGEEEIIJ5PESwghhBBCCCGcTBIvIQQASUlJBPo1p2xpb1YsXwbAxx9+QGiQP8EBvvTr8ywpKSk29RYtXECQfwtCAv04cvjwfzYeaydPnMCziDt7f/nFYvnZM2doFRZMcIAvc2a/7bT9m7vX35yX8fx57hxB/i1oGRJIcIAvh6Oi8i0WgGNHjxIS6EdYcACtW4Zw9syZPIvn9KkTVCpdjAP795qWzZo+Gb+m9QBISUmh+xPt6Ng6mPYtA9i8cb3NNpKTkxnYrxed2oTw6ov9uH37tkNjhIIzjvN7DNubb5KTk3n2mR6EBvnTv29vu+3v7PmmoB1TkP99BVDauxitWwbTumUwP//0A8nJyfTu1ZOWIQE836+P3b5a/NkCQgJ9CQv258iR/2Zf2RvHJ0+cIDw0iFZhwYwaMQyttU09Z47jkydO4FXMg317f2HGtMmmfqv2UEU++uA9m/Wd3U8A+/ftIzw0iPDQIFo82oTmTRtblDu1r7TW8pLXPV/AOaChs9Y3q6cB7wzKKgDLgDPASWAb8Jix7EUg0viKBS6YvQ8GFgNDrLb3BjDX+O8gINmsTiTwg52yKGBv+n7v8Xekb+MYkGr2fjnwoNmyQ8ZXO7O6fYAEq1g+zKwsK6/yFSro5Ds6w9f1myn67N/RetyE1/WSL77WyXe0Trhxy1Te8+le+qdVay3qXLh0VTdq1FhfS7qtDx05rgODgu+5j+y8Clo81q8ePZ/RwSGheuuOPRbLH+/SVW/Zvlsn3U7Tfv4B+vcTZ5wWQ1b+5ryMJzH5jr5xK1Un39F67YZNumu3p/K1bf68cEnHXInXyXe0/mnVWt3r2T4OjSc6/laGry7demr/wGC9KmK7jo6/paNO/KU7d+mmq1avoaPjb+kLscl6z8FjOjr+lj565qKu8XAtm21MnzVXj504RUfH39KvDh+t53746T33+W8dxwVhDNubb+a8+4GePHW6Tr6j9agxr+lPFizKVtyOeBW0Y8rZfXXjVlqWXjVq1LR4P3vu+/qNKdP0jVtpeuTosXrep59ZlP8dfUU3bNRYx1+/pQ9G/a4DgoKztJ9/W1/ZG8ftO3bSO/fs18l3tH7xpVf0qrUbHDKOs9pX3Xs+o4OCQ/WW7bstljdo2EifPPN3nveT9Wvm23NMx7mj+go4n9FnMbniJQo8pVQxYCtwUGtdRWtdHZgMrFRK1dVaz9NaN9RaNwR+Bmalv9dab8nibv4wq9NQa/24nbL6wFLgs3ttyCyWtkCi2TafMq6SvqwBMA74WinlaraJLVaxvJzFslxxdXWlbNmyFss8PDzS/ya01lStWs2i/Nf9+/APDMLd3Z0aNWty9coV0tLS/pPxmNu3dy9lypalQoWKNmV/HP+dx5o3RylF67bt2Llju8P3by6zvzkv43Fzc8PFxXBauXbtGvXrN7Aoz+u2uf/++/Hy8gLA3d0dV1dXi3JnxfPbr/u4v0wZypW/Oz7mzJrOoKGjTO9dXFx48KGqABQuVBillM129u7ZRctWbQFo3bYDe3btcEh86QrKOC4IY9jefLNr1w7atG0PQPsOndixfVu24naEgnZMFYS+AoiOvkirsCB6P9ODf/75h927dlr0lfV+f92/D/+AwP98X9kbx2dOn6JRY8MVnaZNH2XbVsuPRc4cx/v37aVMmTJUqGg5xxw7dhQvb2/KV6hgG4uT+8na8mVf0e2pHhbLnNlXkniJHFFKDVNK7VdKRRr/29xqlaeVUgeUUqeUUiPN6lVXSq021olSSr2Shd31AOK01m+lL9BabwIWAaMyrOUcm4AHHLw9T6CkA7fpULNmvkn9OjWJi4ulXPnyFmWxsbH4+PiY3hf39CQhIeE/H8/MN6cxYtQYu2XmJwkfbx9iY2Mdvn9zmf3NeR3PochIAv2aM3TwKwQFh1qU5XUs6ZKTk5ky6XVeHjQ4T+J59+03eWWoadrjzOmT3Lh+g9p169ldf9KE0fR/0XYqjIuLxcvbGwAvb2/i4xzbXgVlHBe0MZwuLjYWb2NcPj4+xFm1f17NNwXpmCoofXXk+GnWb9xK2/YdGDt6hCEub0Nc3t4+xFntNy7OMm7P/4O+Slerdh02RmxAa8369Wtt2saZ43jmm9MZPtJ2jln+9Zc8ZZXsQN71U7qTJ07g4eHBAw8+aLHcmX0liZfIqaVa66bGKzuDMCRB5soAjwCPAYOUUi2MV3W+BoZrrZsaywYopZpmsq/GwB47y/cATbIY70hjkhiplIrEcHuiuZrm5UqpWRlspyuGWx4dpSuwWWt92WxZsFUsQ7NYZsGYHJ9Pf12/fj1HAY4cNYaoo39QpWo1li5ZbFHm4+NDfHy86f31xETTFQZnye941q5ZTeMmj1CqVCm75eZXLuIT4ilZ0rk5dWZ/c17H06BhQ7bt3MO33//M0MGWyURexwKG31L17tWTIcNGULeeZeLjjHg2rl9Dg0ZNKFny7vh4+82pDB011u76H777NkWKFOWZ3v1syry9fbhm/NBxLSEBbx/HtVdBGscFbQyn8/bxIcEYV3x8PD5W7Z9X819BOqYKSl+VLl0agC5du3Eo8qAhrgRDXAkJ8fhY7dfb2zLuxP+Dvkr35sx3WPDpfNq3CcerhJfNF5bOGsfr1qymcZMmNnOM1pqffviezk90tamTV/2UbtnXX/JU9542y53ZV5J4iZxqpJTappQ6AszDkLgUMStfqA2uAN8DYUBNoA6wzJj87MZwtad2HsRrfvthQ2PM5qxvNRxpVpaelMUAg4HpuYzF07i9v4D5GG43NGd9O+GcLJZZ0FrP1lpXTH8VL14824HeunULMExCXl5eFClSxKK86aPN2LljOykpKZw+dYpSpUubbrVwhoIQT9ShSLZv20rHdq3ZtCmCUSOGEh0dbSp/uFZt9u/bZ/h2ce0afP38Hbp/a5n9zXkZT3r/AHh5eVG0aFGL8rxuG601Awf0p2XLVnTs1Nmm3BnxHDkcxe6d2+nRpT3bt27i9ddG8uvePYwdMZgeXdoTffECk8aPBuDrpYs5ejiK16e+ZXdbj7XwY1PEWgA2rF1Nc1/HtVdBGscFaQyb8/MLYN26NQCsWb0S/4DAbMXtCAXtmCoIfXXjxg1SU1MB2LljO1WrVsPXz5/1a+/2lZ9/gE3cu3bu+L/qq3QVK1Zkxbc/sGrtBm7evEmnzk9YlDtrHEdFRbJ9+zY6tW/D5k0RjB45jOjoaPbs3sXDtWrjbbyabx2Ls/vJ3HffrqDLk91sljuzr5TxR/tCZEgpdQ7orLWONL73wPAQi2Ct9X6lVAkMD33w0VrHG9fvrbXeZlx/LnAVQwK2QWtdwWYnhvV0+jaslvcHBmitH7VaPhMop7XuZbZsMRCptZ6bybI3MDzIY4hSKgjDgzYa2onJVKaUcgc+AuoBzXUmB49S6kHjfr3tLVOGr1QmAM8BD2utbyql+mBo6852tpdhWVZUqFhRnz53/p7rdO/WhUORBylWtBjBoWG4urry24FfSUtL48EHH+Kj+Z/i4eHBiGFDeG38REqWLMnCTz9h6eeLcXFxYe57H1K/QYN77iM7Clo81p5/rg/9B7xIQkI8sbGxdO/Rk9OnTjHwhf7cuXOH9h07MXyE8++Gtf6bY2Ki8yWerVs2M3XyG7i6uqK15q1Zs7l8+Z98a5sN69fR/ckneKSpYeqo36Ah4a1aOyye+Bv3fsrg4IH9efa552nStJlpmV/Teuzcf5gb169T84H7adSkKe7uht8ufr86gn8uxTD/w3eZMHkGSUlJDH35eS7FxFCxUmVmfzDf9DtHe7yLZVx2LwVhHBeEMWw930yaMo0B/fsSEx1N5coPMO/ThXk+3xS0Ywqc21dpaZl/Jj342wFeHjiA4sWL4+bmzvsfzqNc+fK8+PxzxMREU6nyA3w8fwEeHh6MHD6EseMMffXZgk/4YukSXFxcmP3uBza/wbLHxcX2t5cZKSh9ZT2OGzVqzJLFn+Hi4kKPns/wbJ++ALkex1npq3QD+vel//Mv8Gizxxj8ykACg0N4osuTpvK87Kd0+/buZca0yfzw82rAcL5wVF8VcVcXtNa2P55FEi+RBXYSrxLAFaCS1vqSUmocMBXLxGuL1rqvUqokcBDD77T2AYeBmVrrRcZtVQNitdax90i8imF4ouAn6b/zUkqFACuAEK11lNm6i3FS4mV8XxQ4AQzSWv+QSbs9yD0SL+N7BewHvtRaz8nvxEsIkXWZJV55LaeJlxAFRXY+zOeFnHyg/39RkPqqoPXTvRIvt7wORvxrrVdK3TF7PxXYp5S6gv3fPF1WSh0AvIAPtNa7AZRS7YG5xt8muWJI4GxusFVKTQYuasMTC28YE6B3lFJngRQgGuhonnTlUk3j7Y/pErXWNteWtdZJxkTzDaXUj5ld9cqM1lorpYYDy5VS842Lg61i+cPsiYj3KhNCCCGEEAWUXPES4v+EXPESwrHkipcQjlWQrqJAwbuSUpAUpL4qaP10ryte8nANIYQQQgghhHAyudVQiBxSSs3D8Eh8a8211sl5HY8QQgghhCi4JPESIoe01tb/LzAhhBBCCCHsklsNhRBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSLyGEEEIIIYRwMkm8hBBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSLyGEEEIIIYRwMkm8hBBCCCGEEMLJ3PI7ACGEEOLfyLuYR36HYOF2Slp+h2Di4Sbf64rsc3FR+R2CyCLpq5yRmVEIIYQQQgghnEwSLyGEEEIIIYRwMkm8hBBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSLyGEEEIIIYRwMkm8hBBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSLyGEEEIIIYRwMkm8hBBCCCGEEMLJJPESQgghhBBCCCeTxEsIIYQQQgghnEwSLyGEjaSkJAL9mlO2tDcrli+zKT975gytwoIJDvBlzuy38ySmkydO4FnEnb2//JLvsSxauIAg/xaEBPpx5PDhfI3n2NGjhAT6ERYcQOuWIZw9cyZf4ylZoijhoUGEhwbx048/5GssUHD6Kr+OqaSkJMICfalctiTfrri739mz3qJj23DahYewZ9dObt++TbvwENOrdInCxMXFWWwrOTmZ557tSevQQF7s34fbt287NM6CNOcUlHFT0I5v6ad/Rzz79+0zzcMtHm1C86aN8y2WdAWlbSCfx7HWWl7/gRdwDmjorPXN6mnA287yB41lC82WFTcMMYv1FHAW2GR8Xx6INL5OAclm7+cAQUCkcd1jQHur7XkAl4HGQB8gwax+JPBhJn/PVuAq4GW27Fugj9n7FsA24CRwBvgaKHePbWblb0pfFgXsBR4zq/+G8W8y/zvGZVaW2at8hQo6+Y7O0uv6zRR99u9oPW7C63rJF1/blD/epavesn23Trqdpv38A/TvJ85keds5ffXo+YwODgnVW3fsyddYLly6qhs1aqyvJd3Wh44c14FBwfkaz58XLumYK/E6+Y7WP61aq3s92ydf46lRs2aGZf/PfZUXx1RCcqrNK/b6bX3i7AU9ZtxEvXDJlzohOVV/++MqPWrseLvrJySn6h2/HNAhYS1tlr895309cfI0nZCcqoePGqs/+mRhhtsoiO3zbxw3Be34ln7698ST/pr59hw9eep0aRuzl7PHMXA+o89icsVLOFIS0EYpVfse64QC8UB9pdRDWuuLWuuGWuuGQH/gj/T3WuuhVnUXAn2tlnXEMMB/M77fYla/odb65SzEfQ0YY69AKVUf+BmYrLWurrWugiHZ2aqUKmqvThb/pvRl9YGlwGdWm/nS6u+YlsUyh3B1daVs2bIZlv9x/Hcea94cpRSt27Zj547tjg7Bwr69eylTtiwVKlTM91h+3b8P/8Ag3N3dqVGzJlevXCEtLS3f4rn//vvx8vICwN3dHVdXV4vyvI4n+uJFWoYE0uvp7vzzzz/5GktB6qv8OqZcXV0pY7XfH777hqQbN+jQpiUDn+9LYmKiRfmKZV/x5FM9bLa1e9cOWrdpB0C79h3Z5cD2KkhzTkEaNwXt+JZ++vfEk275sq/oZnU8/7+3TX6OY0m8/sOUUsOUUvuVUpHG/za3WuVppdQBpdQppdRIs3rVlVKrjXWilFKvZHGXd4AZxldG+gGfAl8Bz2Xn78GQoLRSSpU2W/YchoQsN94C+imlytspGwV8prXelL5Aa/0Whitr3XO533SbgAcctK08YT5h+nj7EBsb69T9zXxzGiNG2c2N8zyW2NhYfHx8TO+Le3qSkJCQb/GkS05OZsqk13l50GCL5Xkdz7ETZ4jYvI127TsyZuTwfI2loPaVPXkZS3T0Rdzc3Vm5NoJ69RvywbuzLeJYvfInOnR6wqZeXFws3t6G9vT28SEuLu/aKy/bpyCOm4JyfGfm/7mfClo8YLhF38PDgwcefNBiubTNvTkzHkm8/tuWaq2bGq+8DAIWWZWXAR4BHgMGKaVaKKVcMdxKN1xr3dRYNkAp1TSL+5wH1FVK+VoXKKVKAq0xJF0LgT5KqSyPQa31P8B64Bnj9ioAAcCXZqsFGxPN9Jf1VTN7YoD5wCQ7ZY2BPXaW7wGaZDX2THQFrG8yftrq73gqi2UmxsT7fPrr+vXrDgoXlFKmf8cnxFOyZEmHbdva2jWradzkEUqVKpXvsQD4+PgQHx9ven89MdH0jXR+xAOQkpJC7149GTJsBHXr1bMoy+t4Spc2fC/S9cluHDp0MF9jKYh9lZG8jMXHpyRh4a0ACAtvxZHDUaaynTu2Ub9BQzw9PW3qeXv7kJAQb4gxPh4fn7xrr7xtn4I1bgrS8Z2Z/+d+KmjxACz7+kue6t7TZrm0zb05Mx5JvP7bGimltimljmBIiGoqpYqYlS/UBleA74EwoCZQB1imlIoEdgOewL1uHzTRWt8BJmC4imTtaWCt1jpeax0FXAJaZfNvMr/dsDfws9ba/Bfg1rcazsnidmcB7ZVSD2cznpyqaUyaYoDBwHSrcuvbCZdnscxEaz1ba10x/VW8eHGHBf9wrdrs37cPrTXr167B18/fYdu2FnUoku3bttKxXWs2bYpg1IihREdH50ssAE0fbcbOHdtJSUnh9KlTlCpdGheXu1NpXsejtWbggP60bNmKjp0625TnZTw3btwgNTUVgJ07tlOlarV8iwUKXl/dS17G4hcQyMEDBwA4+NuvFv20YtlXdLPzQQ3A1y+ADevWArBuzSp8/QOcFqO1vGyfgjRuCtLxnRX/r/1UEOMB+O7bFXR5spvNcmmbe3NmPG4O25IoUJRSHhiSqWCt9X6lVAkMt8cVwvBgB3s0hodfxBqvkuXU18BIoJPV8n5AWaXUOeN7T+OytdnY9nrgE6XUIxgepjEwF3GaaK2vKaXewnCbZKpZ0W9Ac+AHqyrNMVwly6k/tNYNlVLuwEfAl0qp5tr4BI2CoHu3LhyKPEixosXYv28vLcNbERsbS/cePZkydQYDX+jPnTt3aN+xEw9VqeK0OEaPHcfoseMAeP65PvQf8CKHow6xbeuWPI8FoGTJkvR9rj9hwQG4uLgw970P2bB+Xb60DUDEhvV89+0K/vzzHN+sWEb9Bg0Jb9U6X+L54/hxXn7xeYoVL467uzsffDQ/X9umoPVVfh1Tz3TvStShSIoVK8aB/ft4Y+oMBg18nvatQilUuBDzFywB4NatW2zfuoXZ735oqnspJoYP3pvDlOlv8fSzfXhpwHO0CQuiUuXKjBwzzmExQsGZcwrSuClIx3c66ad/Rzz79u7loYeqmO5CkLaxlF/jWBWgz3kiF4zJTGetdaTxfQngClBJa31JKTUOmAr4aK3jjetv0Vr3Nd4CeBDoAewDDgMztdaLjNuqhiEZi1VK6fRtWO3/QQxPH/Q2vm+F4Srbg1prpZRqguEhFZW01mnGdbyBv4EqWuvLSqkgYK550pfBsqkYrpSVAqqmJytKqT7GNuicjXbbatz+j0qpQsBxY9EkrfVipVRDDL/B6pb+Oy+l1CjgeaCB1jopk+1n+jcZH9JxAhiktf5BKfUGhidHDrGzvQzLMlOhYkV9+tz57FYTQvxL3E5Jy3ylPOLhJjfUCCH+PxVxVxe01rZPA0NuNfyvWZ/+ex4Mj16fCuxTSh0A7P0PVy4by/YBH2itd2utU4D2wBPGB2scxXB7XxHrykqpyUqpF+0ForVej+HR6+n6AcvSky7jOvFABNArm3/nZxh+X7XIzhUi69942b0NL4OYbwETMTwaP31ZJIYrd28opU4qpc4a9x2UWdKVjf0mAeOM+0i/sdj6d1zmt0zeq0wIIYQQQhRAcsVLiP8TcsVLiP82ueIlhBD5T654CSGEEEIIIUQ+kodriP88pdREwPZ/SgNdtNanc7ntn4HKVovjtNbBudmuEEIIIYT4b5FbDYX4PyG3Ggrx3ya3GgohRP6TWw2FEEIIIYQQIh/d81ZDpdSr9yrXWr/n2HCEEEIIIYQQ4r8ns994NbpHmdyjKIQQQgghhBBZcM/ES2vdN68CEUIIIYQQQoj/qiz9xksp5aWU+kAptdL4vrZSqodzQxNCCCGEEEKI/4asPlxjPhADPGR8fxYY7ZSIhBBCCCGEEOI/JquJVw2t9VTgDoDWOhlQTotKCCGEEEIIIf5Dspp43TZ/o5QqgiReQgghhBBCCJElmT3VMN0WpdQ4oLBSKgwYCnzvvLCEEI6mNSTfTs3vMAAo4uGa3yFYSEktOP/j2YIm8WZKfodgoWgBGjsF7X8S7OZScL4PLdf3y/wOwcLZT7rndwgFVmH3gnNMpaYVrAdma11w4ilobeNagOYbN9eCNRffS1YjnQCkAdeA6cAuYIqzghJCCCGEEEKI/5IsXfHSWqcAM4wvIYQQQgghhBDZkNXHyfsopeYppU4ppU4qpT5SSvk4OzghhBBCCCGE+C/I6q2Gi4FUoAvQ1fjvxc4JSQghhBBCCCH+W7L6cI0aWutOZu8HKaV+d0ZAQgghhBBCCPFfk9UrXheVUvelvzH++4JzQhJCCCGEEEKI/5Z7XvFSSs02/jMOOKyUWm183xbY4czAhBBCCCGEEOK/IrNbDROM/z1sfKWb55xwhBBCCCGEEOK/556Jl9Z6Ul4FIoQQQgghhBD/VVl9uAZKqUeBhkDh9GVa6/ecEJMQQgghhBBC/KdkKfFSSr2G4THylYFtQEtgEyCJlxBCCCGEEEJkIqtPNewJtADOa627AE2BNKdFJYQQQgghhBD/IVlNvG5qrW8CLkoppbX+A6jqxLiEEEIIIYQQ4j8jq4lXslLKHYgE3lZKDQVcnRaVECJP/H7sKG3CAmgXHkSnNmGcO3vGVDZj6hs0a1QHgJSUFLp0bEObsADCg33ZuGGdzbaSk5Pp3/tp2rYM5KXn+3L79m2Hxrpo4QKC/FsQEujHkcOHLcrOnjlDq7BgggN8mTP7bYftMykpiZBAXyqWKcm3K5YBsHrVzzRpUIeypUqY1ktJSaFz+9a0DA4gJNCXiAzap2+vnoSHBDKgX59ctY/WmlcGDqBVaBCd27fm/N9/M//jDwkPCSQsyJ8Bz/UmJSXFpt7izxYQGuRHy+AAjh45bGfL2XP61Akqly7Ggf17AXh/ziy6dWpNl3Yt2btnFwDLv/yc1kHNaRfqx/tzZtlsIy0tjbEjXqVzmxD69OjCtYQEm3Uyk5SURMsgXyqXK8V33ywH4Ny5s7RpGUS7ViE80bEN8fHxAKxZtZKwwBa0aRnEimVf2Y1nxJBBtAkLpMeTj5OQg3jSHTt6lNAgf1qGBNImPJSzZ85w7uxZWoYE0iosmI7tWpviMrd2zWqC/FsQ5N+CrVs253j/9pT2LkbrlsG0bhnMzz/9wAfvzSXAtxmhQX4MHzLIbp3Fny0gJNCXsGB/juRi3KReiyb+y96kXD4FwM0jP3N94wwSN0wl5Z8/AEj6ZQEJ375M0t7PLOrejPqBxPWTub5xBmk3rtpsO+XqGRLXTyJx3RvcPrs7S/EkJSURHuTLA2bj5tTJE7RvFUKH1qGMGz0crTUAXy1dQrBvM8ICmjPn7bdstmU+bnrmcNwUtHjM4wr0a07Z0t6sWG6YBz/+8ANCg/wJDvClX59n7c4395qzc+Pgbwfo2LYVbcJDmPT6eM6dPUt4aCCtWwbTKYNjat2a1YQEtCAkwDHHlL1zQ0Zz/Gefzic4oAXhIYFs3bzJZlu5PTfYm/9OnTxBu1YhtG8dymvGcZOSksITHdvQOjSAlkEZn8f79X6aNmGBvJjL87i989S5s2dpFRpEm5YhdG6fQV+tXU1IoC8hgb5sc+D8Z28cp5sy6XUa1H3Ybj1Hj+OsJl4DAQ9gOFAC8AV65XrvQmRCKXVOKdXQWeub1dNKKW87yx9USqUqpSKVUoeUUgeUUsHGsj5KqQRjWfrrQztlR5VSa5VSlY1li5VSF4xlx5VS841fbKTH/4fVNuvZKftDKTUmu3+ntdKl72P5dytZvWErg4aOYNab0wD459IlTp88aVrPxcWFt+d+wNqN21n27c9MeG2Uzba+/HwRderWY03ENspXqMC3y7/ObXgmsbGxfDr/YyI2b2PeJwsZMWywRfm410Yzacp0Nm/byZpVKzl39qxD9luoUCG+Xv4dL71yd3+PNfdl194DlK9Q0bTMxcWF2e9+SMSW7Xzz/c+8NnqkzbaWLllEnXr12bB5GxUqVLT7oT+rVq38iUKFCrF+01ZenzyN18ePpW+/59mweRsbtxr+F4tbNm+0qBMbG8vCT+ezLmILH87/lFHDh+Z4/+nmzpzBY77+AGyOWEdyUhIrflrHd6sjaNbcF4B3357B96s3sjJiO9+v+MomsdocsY7UlBR+XLuZlq3b8slH2f/pcKFChfhi2XcMfPlV07JFC+bTu29/Vq/fTEBgMMu+WkpaWhqTJr7Gj6s3sHLtRj77dJ7NB9KI9WtJSUlh7cZttG7Tjo/en5vteNKVvu8+vv9pFRGbtzF0+EhmTJ/Kgk/m0fe5/qzfuIXAoGC++uJzizqpqam8MWEcP69ex3c/rmTMqBGmD9uOUKlSZdZFbGFdxBY6dnqcNm3bs23nL2zaupMrV66wY/s2i/VjY2P59JN5rN+4lY/mLWDk8CE53vfNwz/iVsbw4ebOhUPo1NsUDxuLZ/h43O6vCUDh+k9Q1O9li3qp8edJuXwCz1YTKVSnPcmHvrXZdvL+pRTze5niLV/j5rFV6Ds3M42nUKFCLLUaN6+PG8OU6TNZuW4Td+6ksNV4HL391nRWbdjMhq27WLHsq3uOm1Zt2vFxDsZNQYvHPK7l3/7AK68OMS3r9/wANm3dwZbthi9YNm+ynW/uNWfn1O3bt5k0cTxfrfiOtRs28/qkqSz81HBMrYvYQmBwBsfUxHH8uGod3/ywktdG5/6YsndusDfHX/7nHz5fsoiIzdv5/ufVTHp9PKmpqRbbyu25wd78N3HcGKZOn8kqs3Hj4uLCO3M/YN2m7Sz/7mfGj7U9j3+xxHAeX7txGxXKV+CbXJzH7Z2nFi6YT5/n+rE2YjMBQSF8/eVSizqpqalMmjieH1euNZxLx4x02PxnbxwDXLp0iZMnT9it44xxnKXES2t9RGt9Q2t9WWv9vNa6q9Y6Mtd7F+LfIVFr3VBr3QCYBqxQSilj2RZjWfrL/BNDelkd4AQwx6xslta6IYYnhTYEXjQre8pqm4ety4AQYKzxaaM5dt/991PCywsAd3d3XF0NF7LffmsaQ0eMNq3n4uLCQ1UMdxcXKlwYhbLZ1p7dO2nVph0Abdp3ZNfO7bkJzcKv+/fhHxiEu7s7NWrW5OqVK6Sl3f2Z6R/Hf+ex5s1RStG6bTt27nDMvl1dXSlTtqzFslKlSlG4cGGLZS4uLlSpamifwoULc3d43LV71w7atDW0T7sOHXMV46mTJ2nUuAkADRs1ZveunXh4eACGbxm11lSpWs2izoFf9+EXEGhowxo1uXrVsg2z67df93FfmTKUL29IQH/+LVpG2gAAoN5JREFU4TuSk27QrWMrhgzsz/XERACq1XiYGzeuc+vWLdzdPfAoVMhiO3v37CKsVVsAWrXtwC+7dmQ7Fnv9VKt2XRIS4gFISIindOn7uHrlCqXvu4/ixYvj5uZGteo1TVfr0hnGsSGetrkcx/fffz9eFseXC7XrmMUVb4jL3KmTJ6lStRolSpSgVKlSlC1Xjr//+ivHMViLjr5Iq7Agej/Tg3/++Yeq1aqZxqub2RyQ7tf9+/BPHzd2jr2sSrlyCpfCXqiiJQG48+cvkHKL6xunc2P3fPSdZABcjOUWdf/5A/cKjQwxlq1LaqzlFys69TakpeBSrDTK1QO3+6rbrGOPvXFz5sxpGjRqDEDjR5qyY9tWAGrUfJgb1w3j2MPdg0JW49gR46agxWMeV1mruKznm6pW801mc3ZO7f1lD0WLFaPPMz1o1yqMvb/soXaduqYrJwnx8ZS+L5Njqmzujyl7fWVvjv/zz3PUfLgWbm5uFC9enGLFinPmzOlM6+U2lrNm46aJcdzYnMftnKfMz+Nt23dkl4PPU7Vr1zF9SWCY/0pb1jl1kipVq5r1VVmHzX/2xjHAjGlTGDlqrN06zhjH90y8lFKz7/XK1Z6FyCGl1DCl1H7jlZ/9SqnmVqs8bbwydUopNdKsXnWl1GpjnSil1Cs52P06oDRQKpv11gM1rRcafzu5zV7ZvWitLwDHgQeyGYddycnJvDltEi++NIjTp05y4/p16tSrb3fdia+N4oWXbW9JiouNxcvHBwBvbx/i42IdERpg+NbJx7htgOKenhbf8JpPhD7ePsTGOm7f2TVuzEgGZtA+3t7G9vHxIS4X7VOnbl02RWxAa83GiPVcvvwPAO/MeotG9WoRGxdLuXLlbfbv423WhsU9c3X70btvv8krQ+9e2bsUcxE3d3dW/LyeOvXqM++DuQB07tKNlv6PEtC0Ph06d7FJWuPjYvEyxuXlwHHjFxDIogWf0KJpQzZFRNCuQydK33cfVy5fJiY6msTERPbs3klcXJxFvbjYOLx9zPspzt7msyU5OZmpk9/g5VcGExAYxIJP5tO0UX0iIjbQoVNny/3HxeLt42167+jxfOT4adZv3Erb9h0YO3qEafnuXTu5ePECzVv42sRjfux5euZs3Nw8/BOF6nYwvU9LjgcXV4qHvYarzwPcPLYmw7r69nWUR1EAw4dFbfnBR9+6YSoHUB7FSLt1PdsxAtSqVZvNG43H1oZ1pv5/4smnCHisCY82rEOnJ+yMYyeMm4IYj7lZM9+kfp2axMXFUq685XyT2ZydU9HRFzl6OIpFS79i/oJFDHrpBfwDglj46XwebVyfjREb6NCxs0Udwxj2Nr3P7fybEXtzfJWq1TgUeZDExERioqOJOnSQOKvj2ZHnhnQPZzBu0k0YO4oXX7Jznopz7nkqva+aNWnApo0baG/dV2ZtAYbPEs7oq3SnTho+79Srb//zjjPGcWZXvBIyeQmRH5ZqrZsar/wMAhZZlZcBHgEeAwYppVoopVyBr4HhWuumxrIBSqmm2dx3D+AvrfUV4/tgq9sCbe7fMu77SeCAnTIfoLVV2XKrbRaxU+9hDMnf1owCNSao59NfN67b/yCSkpLCgL7P8Mrg4dSuW4+3pk1mxJhxdtd9b/YsihQpQu++/W3KvH18SEj/1jEhHm8f22+uc8rHx8fiXvDriYmmKwmAxTd38QnxlCzpuH1nx5x3ZlGkaFH69nvepszbx8fiSodPLtonvFUbqlWvQdvwUCLWr6OuMUkePnI0Bw//TtWq1fhy6RKb/ccb9w9w/bplG2bHxvVraNCoCSVL3v3+wdunJMGh4QAEhYXz+9HDXE9MZPbMaezYf5hfDh1n/97dHD4UabEtL28frhnjuubAcfPG+LFMnDSN3fsjeXXocCZNHIdSitnvfcjzz/Wif++nqVW7DmXLlbOo5+3jfXccx8dbnHRzIiUlhT69nmbw0OHUrVeP8a+NYdLU6ew/GMXQYSOYON7ym1Zvbx8S4u+eXh09ntO/Ye7StRuHIg8CcPz33xn/2miWfrnc5ltwb2/LYy8xMfvj5s75g7iVqoJLIU/TMuVRDLdyhnHrXr4+afF/Z1hfeRRD30kCDFdYUC625beTTO/17SRcChXPVozppsyYxeKFn/JEh9aUKOFFuXLlSExMZNaMqew7dIzIYyfZu2c3Uca2S+fl4HFTUOMxN3LUGKKO/kGVqtVYumSxRVlmc3ZOlfQpyWMtfPH09KRipUoUK1aMkcOHMGnKdPb9FsXgYSN43c4xFW92TOV2/s2IvTm+ZMmSjB03gScf78iIYa9Sr35Dmy/FHHluSDd1xiwWLfyUx43jxnyee3f2LIoULULv5+ycx72de56aOG4Mb0yZxt4Dhxg8dDhvTHjNcv9mbQGG+c8ZfZVu6uQ3GDtuQoblzhjH90y8tNaT7vXK1Z6FyLlGSqltSqkjwDygplVyslAbXAG+B8IwXFGqAyxTSkUCuwFPoHYW9ueZngQBTwAdzcqsbzU0v50w2FjnAKAx/EYy3Uhj2SbgW2CxWZn1rYbJZmXLlVK/A8eA97XWlzMKWms9W2tdMf1VrLjtBxGtNYNfGkBIWDjtOnQC4Ny5M4wcOoiundpy8cJ5Jow1XNX4YskiDkcdYsoM2wckALTw9Wfj+rUArFuzCl+/gIxCy7amjzZj547tpKSkcPrUKUqVLo2Ly93p6+Fatdm/bx9aa9avXYOvn7/D9p1Vny/+jMOHIpn+pv328fULYP06Q/usXb0KP//ctc+4iW+wNmIzbdt1wC8gkFu3bgGGJLRECS+bb8AfadqM3Tt3GNrw9ClKlbJsw+w4ejiKPTu307NLe7Zv3cQbr42kWvWaHIo0fH8QdfA3HqxSFRcXFzw8PCharBiurq54efkQH2/57eVjLfzYHGH4kfeGtatNvxnLLa01pUobEsP77ruP2FjDAxl8/QJYuXYjCz//iqSkGzR99DGLei18/YlYb4hnbS7Hsdaal154nrDwcDoar2xprU3Jz33330/sVcv2qFa9OqdPnyIxMZG4uDiiL16kUuXKOY7B3I0bN0y/L9m5YztVq1bj77/+YkD/Pny2+Aub237AcOztSh83do69rEiN+4uUS79zfdNbpEQfIfnAF7h6lTfdDph69QwunmUyrO92/8PcuXAIgJRLx3At+ZBFuXLzABc30pJi0al3SL18EteSD2YrxnQVKlbki+Xf8f3Kddy6eZP2nR7HxcUFdw8PihnHsb0rAebjxpHzX0GLJ535fOPl5UWRIpbfD2Y2Z+fUI48249TJE6SkpJCQkMC1a9coVKgQpdKPqfvut7lCXK16dc6YH1PRjjumzGU0x3d6vAvrNm5h9twPKFyksM2+HX1uAMO4+XL5d/ywch03b96kQ6fHAcPvyQ5HHWLqPc7jEcbz+No1q/B18HlKa02pUmZ9ddXyQTnVqlXnzOnTpr6KiY52Sl+lO3v2DENefZmO7Vpz4fx5xowaYVHujHGsHPmjXSEcTSl1Duic/ptCpZQHEAsEa633K6VKYLj66qO1jjeu31trvc24/lzgKoYEbIPWukIG+9Hp27Ba/iAQqbX2tlOnjzG2ztksW2zc5tzM/t6MypRSYcBK4FGr34BlqHyFivroyT8tlm3csI7ePZ+k8SOGC3916zVkxqy7dxE3a1SHvQePcv36dR4qX4rGjzQ13du/ct1mLsXE8NH7c5g07S2SkpJ45cV+XIqJplKlB3jv409N61or4pH9h6Iu/PQTln6+GBcXF+a+9yExMdHExsbSvUdPTp86xcAX+nPnzh3ad+zE8BG2Pxq+l5TUjO/Zfrp7V6IiIylarBjBIaF0efIpJr8+gX179/Bos+YMGjKUFr7+VCxTkiZNH8XD3fA3r40wtM/7781h6nRD+/yPvfsOj6L6Gjj+vWl0kgAiKiJSpRdFBdIrHVSkitLEBtKb2ChWVFDR1wICoj8BFTsQEJGuFAlNlC69phBIIAk57x+7ibubDQmwm6x6Ps8zD9m5c2fO3rkzs2fv7PDYgL4cP3acKlWq8M770/Nsn/ycPn2aXt274OPjQ+Wbb+a1KW/xwsTn2bxpE1lZWdxStSrT/u8D/Pz8GD1iKKOfeoZy5crx0fQP+PSTj/EyXrzx5ts0aNgo322lXMj9tDJbQx7rT6++D1O/YWNGDHqUY0ePUKx4Md567yPKV7iOGe+/w4L5n+Ft/U3Va2/9H15eXjz5SF/eev8jsrKyeGrEk/y5cydl/f15672P8A8IyHN7JfPoO72638/WLfGUKlWK0PAIHuzdj2FPPo6XtzeXMjOZOu09bqtTl3FjRrAlfjO+vr4889zEnL7/SP/evD99Vs7T4Hbu3IG/fwDvTZ9FQB7x+Plc/gK8JG4x3bvcxx3NLD/FbNioEX36PsyTAx/D29ubzMxMpr37PnXq1uW1V1+mbbsO1Klblx++/47Jr7wEwLPPTyAiMuqy28mW3+V882+beOKxAdbfuPny9jvvMeH5Z9i4YX3Oh5thI0YTE9uKkcOHMHbcszn95pM5s60PkZlGwwL0m5v6OX9AwPm171OsZiTe5W4h9ZfpSGoCePtSssWjeBUvy4WtX5FxeBNZF5LxLnsjpSJHY4wXaVu+JPP4Doy3DyWbD8CrVAUu7l2JV6ny+FaqR+bpvaRt+gREKFYrCr9qQXbb3f9BN6fxPGjtNyVLlSIsPIKGjZvy6ccz8fLyoku3nvR8sDcAH/zfNOZ/9inePj7UqnUbb777Pl5eXjzavzfv2fSbP2z6zeX6cV6KIp7ivvmfj7t1uY8t8ZspVbIU4ZFReHt789umjWRlZVG16q28+77lfD9i2BCeetrSbxzP2Q0b5d9vLmXl/5n0f598zMwZH5KRkcGYp56hStWqDLYeU5cyM3nr3fepU6cur09+mTbtOlCnTl0Wfv8dr71qOaaeeW4C4QU+pvKOx/Ha8Oz4SU7P8f0eeoDjx49TslRJXp78BtWr17iqa8Pl2sbx/NeocVM+sek3DzzYm3PnznHLDeW5/Y5m+FrX/0Oc5Tr1zttTmGC9jj/xSD+OHz/GzVVuYdplruPeXrl/I2bL2XXq4F8HGDzw8Zzz39vvWs7Lr09+hbbt2nNbnbos/OE7Xnv1ZQCeeXZ8gfaVj3fBkiHHfjz59b+/K29U/za2bP8D4Jr7cQlfc0REKjsr08RLeTQniVdZ4DRws4icMMaMAyZhn3gtF5E+xphywGYstweuB7YBr4rITOu6agAJIpLwT0u8rK/fAKqLSEfHZZ1xlngVlatJvNzpconXf11+iVdhyyvxKgr5JV6FzZMu53klXkUlr8RLFSzxKiwFSbwKkyd9Rva0tskv8SpMBU28CsvlEi+fwg5GqasQZ4zJsHk9CVhvjDkNzHWy/CljzCbAH5gmImsBjDHtgKnm7/+H7jTQw7GyMWYCcFRE3itAbNm3E2b7U0S6FuRNXcY8Y4zt7YVDRWS5k+UmAnuMMbeLSK7fjymllFJKKc9R4BEvY8ztQF0RmWN9IEBxETnm1uiUUi6jI1550xGvvOmIV950xCtvOuL1z6EjXnnTEa+86YhX3i434lWgSI0xjwMfAc9bZ5UDPOusqpRSSimllFIeqqAp4gAsj98+CyAie4HrLltDKaWUUkoppRRQ8MTrosMjrQE86/4TpZRSSimllPJQBU28ThljamH5v4iyn9h20F1BKaWUUkoppdS/SUGfajgE+Ay4zRhzCMsth+3cFZRSSimllFJK/ZsUKPESkT3GmLuA2oDB8sjsS26NTCmllFJKKaX+JQqUeBljqlj/PG/99yZjDCKitxsqpZRSSimlVD4KeqvhJiy/7zJAcaAkcAao6Ka4lFJKKaWUUupfo6C3Gto9Ot4Ycy/QyC0RKaWUUkoppdS/zFX9V88isgBo6+JYlFJKKaWUUupfqaC/8Spr89IbuAsom8fiSimllFJKKaVsFPQ3Xkn8/RuvS8Bu4Ek3xaSUUkoppZRS/yoF/Y3XVd2SqJTyHMY6qdyM8ayW8fKgcMoUL+j3c4XD25Max8N4eVDbHPywe1GHYOfN1fuKOoQcw0OrF3UIHsvTjm+Roo7Ac3navvqnyDehMsZ4G2N+L4xglFJKKaWUUurfKN/Ey/ofJZ8yxpQshHiUUkoppZRS6l+noPeQ7AHWGGM+B85lzxSRt9wSlVJKKaWUUkr9ixQ08fIC4oGaNvP0zlellFJKKaWUKoCCJl4jReS07QxjTAU3xKOUUkoppZRS/zoFfVrhkgLOU0oppZRSSinl4LIjXsYYP6A44G2MKcPfT6P2B0q5OTallFJKKaWU+lfIb8RrLJb/PLk+kGz9OwnYBnzixriUUkoppZRS6l/jsomXiIy3/ufJH4iIl80UICITCylGpZRSSimllPpHK9BvvETkMXcHopRSSimllFL/VgV9uIZSSimllFJKqaukiZdSSimllFJKuZkmXkoppZRSSinlZpp4qf8cY8wBY0xjdy1vU0+MMQEO8+4wxsRbp4PGmGSb1yONMb0d5sUbY95xWMd4Y8wlY8wtVxqTo52/76BVVAhtYsLo0DqKA/v3sfCH77iraX0qV/S3W/Z/c2YTHnQXUaHNmfLaK7nWlZWVxYihg2gdHUqPLveQnJx8reHZmTljOmHBLYgIDWL7tm12Zfv37SM2KpzwkJZMeeM1l24327DBA4kIaUFoy7tYGreYlSt+pkbVm2gVHU6r6HAO7N+fq87ihT8QEdKCiJAW/Lz8J5fF8vuOHUSGBRMdEUrrmEj279vHtLemEtziLiJCgxg2ZJDTejM/mk54SEsiw4JzteGVSk1NJSK0JZWvL8cX8+cCkJaWRp9ePYiJCGVAv96kp6cD8NumjUSFBRMR2pL5c/+Xa1151bsaztom28Txz9G4fh2n9VzZNpeL5f/enUZUeAgRoUH07/MQmZmZhRKLM+XKliQmMoyYyDC++foruzJ3HVOpqalEhrbk5kp/95v3/+8dYiNDiQ4PZkC/v9vk0zmzCG15J+HBzXljsvNzzrAhA4mNDKXb/Z0KdM45cWA3Hw7pxvRh3floZC8Sjh3MKVs2+03e7Bub83rG8J58MLgLM4b3ZNnsNwE4+PvmnHkfjXiA5FPHcm3jyJ/b+HBwVz548n62/PTtlTWQlbO+8+KkCcRGhRMbFU71qpV5d9pbueq5u+/8deAAYcEtiI4IJTykJdu2brUrL4xzsa2ivi78deAA4SEtiYkMIyI0iG1btzLn41nUrV09Z1+lpaXljtvN5+J33n6TsKC7iQoLZsTQJ3OW/eTjWYS0sBxTr+d1TA0eSExEKF07F+yYyouztins61ReNqxfn3Pua3Hn7TRv1tSu3K19R0R00uk/NQEHgMbuWt6mngABlynvDXyd3zyHci/gL2AZ8PyVxHPjjTdJ4vlMu2nX/qNy4OgZSTyfKZ9/9b30eOAh2XvwhBw7c05q1qptt+yt1arL4ZPJciYlXW6rUy+nXvY098tv5KG+D0vi+UyZOu09Gf3UM7m2lz2lZcgVTUdOnJEmTZrK2dR02bL9DwkNC7crv+e+zrJ85VpJTc+SoOAQ2blr3xWt/9zFrMtOG+N3SGhYhJy7mCV7/zoqjZs0lYVLfpK+/QfkWSc5NUPqN2goR08lyV9HT0nDRo0l5cKlfLd17mKWpKZffjpw+LgcO5UoqelZ8vV3C+WBB3vLtt93yfmLlyQ1PUs6399V4n5cblfn8PHT0rhJU0k+f1Hit+2U0LDwfLeTmp4lKRcuOZ2SzqfLngNHZOy4Z2Xmx59KyoVL8vrUt+W5CS9IyoVLMmLUWPm/D2ZIyoVLcufdzeX3XfvlVNJ5adCwkRw7nWy3rrzqOZuupm1S07Nk/6Fjcn+XblKrVu1cda62ba4mlqRzF3LKe/TsJV9/t9BlsVzpcVWrdu08y671mDqbdsnplHguXXbvPyJjxj0rH83+VM6mXZLTyWk55d16PCBffvODnE27JLdWqy7HTp+VpPMZUqduPTl0PMFuXfMXfCt9+j0sZ9MuyVvvvCdjxj2b53YnLt0tE5fultHzf5FxX/8mE5fulgdfnCFNYu61zl8nDcLaSoWbq+UsW7XhnTJq3tqc1xOX7pbnFu7I+bvT8BcluOsAu/KJS3fLzXWbyPBPV8izP2yXStVuk6e/jbcrv9q+Y1veqHET2b3/kEv6zpXs15S0DDl/8ZKkZYgsWrJMOnfp6tJ+40nXhbQMybftzqamy7kLmZKaniUL436Uzvd3lfenfyQTJr2YZ53COBfH7/hTzqZlSsqFS3Lf/V1k0ZKfJOXCJalWrbocP3NWklMtx9ThEwl26/r8K8sxlXLBckyNHffsVZ+LnbWNu65T19KPXn1tikyY9KJL+w5wOK/PYjripRRgjBlmjNlgHWHaYIxp7rBIT2PMJmPMHmPMSJt6NY0xP1jrbDXGDHRzqNHACWAE0McYc03H8HUVK+LvbxnZ8vX1xdvbm3Lly1O8ePFcy9aqfRvnz53j4sWL+Pn5UaxYMbvydWtWE9u6DQBt2nZgzeqV1xKanY0b1hMcGoavry+1atfmzOnTZGVl5ZT/+cdO7m7eHGMMrdq0ZfUq120boNINN1C8eHEyMzNJSkqifPkKACxdspjo8GCeHjuKS5cu2dXZs3s31arXoGzZspQvX55KlW7g0MGDzlZ/xSrm2m9eVK9RA2OMzTxvuzobN6wnJDQ0zza8Ut7e3lxfqZLdvLVrVtG6TVsA2rbvwOpVK7lw4QIZ6encXKUKxYsX5667mxP/26Z8610tZ20D8PKLExkxaozTOq5um8vF4ufnB/z9pWf16jUKJRZnjh09SnREKL16duPkyZN2Ze46ppz1G8c2qWZtk9q35X/OadXa2m/adWRNAWIsHVie4qXKAODl7YOXl+U4+fmTdwjp/qjdssYY5k18klmjH+Lwn5aRHR9fv5zyi6nnqFTtNrs6GekXuZSRQUDFG/H1K0aVek05umt7vnE5yqsfg2U0LCAggJtuusmuTmH0HR8fH7y8LLGcPXuWhg0b2ZW7+1xsq6ivC5C7PRo0bAjAnNmziAwLZsrrk53G7e5zcfXqNtcDH1+8rNeDWvkcU2vXrKaV9Vzcrn3Ha2ozZ21T2Nepgpg393906drdbp47+44mXkpZzBGRZiLSGBgEzHQovx64A7gbGGSMaWGM8QY+A4aLSDNr2QBjTLNrjCXc4VbDoTZl/YCPRGQzcAaIusZtAZZbvV56YTyPPO586B/g3s5dCWl+O3c2qUfHe+7LlZwlJSYSEBAIQEBgIIkJia4IDYCEhAQCAwNzXpcuU8buFgjbE3NgQCAJCQku2zaAv78/t1StSuN6tWkdE86wkaNpevsdxG//k7hlKzh79iyffDzLrk5iYgKBgQE5rwMCA0lMdG1caWlpTJrwPE8MHJwzb+2a1Rw9eoTmLVrax5OQkLN/IHcbuoLtNrLfb2JCAv7+ATnLBAQEkuDQDs7qXSvbttmzezfnz53P+VB0ubjB9W3juJ9ee/VlGtW7jYTEBG648cZCjcXW77v2sfSnFbRt14ExI4fblbn7mHL0xuRXaNqwDomJCdxwg6VN7uvclZZ3N+WORnXpdG/nXOecxMSr7zcZFy/w08dvcfe9D3Hm8AHS087nSqK6PvMW/ad8RtuBz7Hg1VHZdx2we8NK3nviXtZ/9xk31bbvU2lnkyheumzO6+Kl/UlLufr95+wYn/vZp3Tp1j3XsoXVd7bExxMa1JyhgwcSFh5pV1aY/aaorwvZtsTHExbcgmFDBhEWEUn7Dp34besOFi1ZxqpVK1n+0zK75QvzGLdcD47mXA8639+VFnc15faGeRxTLj4XO7aNfVxFc52ytXvXLvz8/LilalW7+e7sO5p4KWXRxBizwhizHXgPqG2MKWFTPkMsTgMLsCQ8tYF6wFxjTDywFigD1L3GWJaLSGObaQqAMaY8EIMl2QP4CEsi5pR1FO9w9nTu3Dmny2VmZvJwnwcYNHg49eo3cLpMSkoKk1+exPr434nfsZtff1nL1vjNdsv4BwSQnJwEQHJSEoHlAp2s6eoEBgaSlJSU8/pcSkrOt8FAzjdoAEnJSZQrV85l2wb46celnDhxgq07d7Mxfgejhg+hePHiFCtWDC8vL+7t3IX4zb/Z1QkICCQp6e8LRnJSEoGBrosrMzOT3r16MnjocOo3sOy3P3buZNzY0cz53zy7NgHLRTR7/0DuNnQF221kv1/H7SYnJ1HOoR2c1bsWjm3zwsTxjHnq6QLFDa5tG2f7acSoMWzZ8QfVq1dnjkPCXhj7KVuFCpaR2873d2HLFvvj2d3HlKNhI0fz29adVKtWg0/nzCYlJYVXXprEpi072bpzD7+sW8MWh3NOQEAgSVfRby5dyuTzl4bR8v5+VLq1Nj/NeYuwB57ItVwpf8v6rru5GiX9A0lNtnz4qtkshEffWUB03+Es/eh1uzolyvhz4dzZnNcXzp2lRJmr23/O+o6I8M1XC7jn3s65li+svtOocWNWrF7HFwu+Zehg+5s8CrPfFPV1IVujxo35edVaPl/wDcMGDyIgIABvb2/8/Pzo2Ome3NeGQtpPf/yxk2fGjWH2p3MxxpCSksLLL07it6072fZHHseUTWxJLjgXO7YNFP11ytbczz6la7ceuea7s+9o4qX+84wxfliSqREiUh8IsRYVy7sWAhggwSFJulVEZrsp1F6AD7DFGHMAGA20tyZkuQMUeUNEKmdPpUuXdrYMTz4+gIioGNq275jnhr28vPD19aNUqVJ4e3sTEJD7m7AWQcEsjVsMwOKF39MyKMTZqq5KszvvYvWqlWRmZrJ3zx7KV6iQcwsDwG116rJh/XpEhLhFC2kZFOyybYOlnQIDA/Hy8qJMmTKkX7zI+fPnc8pXrfyZGjVq2tWpUbMm+/buISUlhcTERI4dO8rNVaq4LJ7HH3mYqJgYOnTsBMChgwd5uF9vZs7+JOcDtS1LG67Ksw1doWVQCHGLFwGw6IfvCQoOoUSJEvj6+XH0yBEuXrzI+l9/oVGTpvnWu1rO2mb//n0MGTyQDu1ac+TIYcaOHmFXx11t4yyWixcvApYLe9my/pQoUcKuTmHsJ4Dz58/n3B67etXKnNv7srn7mLJl1yb+/pQoURwvL8ttmfmdc5bEWfvNwu9oWYB+IyJ88/pT1Lg9iLotowFIPHaI794ez+yxfTl76jiL338ZgAvnUwA4n3SGcwmnKVE2kMz0iznrKlG6LL7F7EcMfIsVx9vXl7Onj5OZfpFDOzdzY816V9wmzvoOwLq1a7itTl0CAgJy1SmMvpO9r8ByJ0DJkiXtyguz3xT1dQEc2qOspT1sR2hWr1xJdYdrQ2Hsp0MHD/Jo/z7MmDkn53rgeEwFBgSS6DCS0zIomCU55+Lvrulc7KxtPOE6ZevLL+Zz3/1dcs13Z9/xcdmalPrnKg74Adk/wHF2v11vYIUxphxwD9Ad+BM4a4zpIyIzAYwxNbAkY+64p6Ef0FlEFmfPMMbMAx4A3ryaFS5bGsfXCz7n4MEDLPhiHg0aNOa+Ll2Z9PwzHDl8iE5tY3jiyaFEx7amd9/+xEYE4e3jQ61atxEcGg7Ao/178970WUTHtCZu0ULaxITh7x/Aex/OcsFbtihXrhx9+vYnKjwELy8vpr71DkviFpOQkEC37j2YOOklHnukPxkZGbTr0JFbq1Vz2bYBwiOj+Hz+XKIjQrh44QKPPjGIL+bPZfbMGRQrVozKN1dh5AdPAfD65Jdp064DderU5ZnnJtCxreUpaS+89Gqub/eu1tIlcXz5xXz++usAX8yfR8NGjThx/ARnzpzmkYf7AjB85GhiYlsxcvgQxo57lnLlytG7bz+iI0Lx8vJiypvTrjmOnt06szU+npKlSrFxw3qeHT+Jxwb0JTYyjCpVqjBq7DgAXpn8Bg/27EaWZDHwySGUKVOGE8eP8/ZbU5j04is88GBvp/Vc1TY/r1qbU964fh1eesXylCp3tk1esfj4+PDbpk1kZWVRteqtOSNx7o7F0Z9//METjz5MqdKl8fX1Zdq77xfaMfVAt85s3fJ3v/H29mbzb5Y2uaVqVUaNGYefnx+9+z5MVFgQPj4+1KpdmxDrOWdAv4f4YMZsYmJbE7foB1pFheEf4M/70/P/zmvPxlVsX7mIxBNH2PbzD9xQvQ4D3vo8p/zNvrG0emQMWVlZzBzZCx+/4mRdyqDN40/j5eXFtlWL2fjDPIyXF17ePnQcOgmA3+K+JKDijVRr0pw2j41j3sTBiGTR4r6+FCuZ+0uv/DjrO5Nfn2r9ht7+NsPC7Dvr1q5h0oTn8fb2RkR4ZfIbhXoutlXU1wWwtMcLE8fntMfLk1/nzSmv8+PSJXh5eXH7HXfQvoPlS83CPBcfP36MM6dP89gAy00xw0aOIjqmFX36WY4pb2/rMRVmPab6PsQHH1mOqcULfyA20nJMfTDj6r9HdtY248aOLvTrVF7W//ort95aLScBLKy+Y7LvWVbqv8I6WlQCyLCZ/QGWxOY0MBd4FQgUkSTr8vOBSMAfeF9EJlvXVR2YCtwCeFvr9xCRI8YYsVnHBOCoiLxnE0dvoJOIdHKY9yZg+2zyP4HXge+Am0Qk02b5DsAkEXH+4xUbN91UWXbs/iu/xQpFcT/v/BcqRJeyPOs86OWa/MwlPK1tvD2pcTyMqxJ7V8jIdO8P4q/Um6v35b9QIRkeWr2oQ7DjSf3G03jSZ2Q9F+fN0/pwCV9zREQqOyvTxEup/whNvPLmaRc0D7qeeVzbeNLF3tN40ocPTbzyponXP4cnfUbWc3HePK0PXy7x0t94KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZj5FHYBSqpAY8PE2RR2FR/K0VsmSoo7gb54UC0BGRlZRh5DD18OOJ28P+io1Szyr4wwLqV7UIeR4etGfRR2CnRfa3FbUIeS45GEnHG8vzznGxcOOKWO0ba6GB52mlVJKKaWUUurfSRMvpZRSSimllHIzTbyUUkoppZRSys008VJKKaWUUkopN9PESymllFJKKaXcTBMvpZRSSimllHIzTbyUUkoppZRSys008VJKKaWUUkopN9PESymllFJKKaXcTBMvpZRSSimllHIzTbyUUkoppZRSys008VJKKaWUUkopN9PESymllFJKKaXcTBMvpRQAIsLAxwYQGxlGp3atOHzoEAf27yc2MozW0RF0ateKpKSkXPUWL/qBiNCWRIS2ZMXyn1wWT2pqKqFBzalUIYD58+YCMGf2LOrUqkZMZBgxkWGkpaXlqjdzxnTCglsQERrE9m3bXBYPwO5du/Av5cf6X3/JmTdpwnM0aVDH6fKzPppORGhLosKD2b7ddbFs3LCeVtHhtIoOJ+juO2h51+2kpaXRu1cPoiNCGNCvN+np6U7jiQxtSbQL4klNTSUqtCVVKpXji/lzc+a/MfkVOrSJoW1MBOvWrM6Zn5GRQZP6tXlj8iu51pWWlkbfB3vQKjKUR/s7j/1ydv6+g9ZRIbSNCaNj6ygO7N+XU/bSpOe5q0m9nNezZnxAdFgL2kSHsmL5Mqex9H+oJ22iQ3n84T5XHIstZ8fUD99/y+2N6lGpfNk86836aDqRYUFEh4eww4X95q8DBwgPaUlMZBgRoUFs27qV3bt2ERsVTqvoCEaPHIaI5Ko386PphIe0JDIs+JqPqdTUVKLDWlLlhvJ8+fk8AA4c2E/r6DDaxkZwb4fWOeeZB7p1pm1sBG1jI7ixQlm2b9tqt66srCxGDBlE66hQut9/D8nJydcUG9gf4y+9MCHnOKtxa2XenfZWruWv9Rg/fXA3c8f0ZN7YB/j86d4kHT8EwPovPuSLZ/owf9yDHPl9EwBbF8/jfyO7Mm/sAxzcsi5nHevmvsPcMT354pk+pJw+nmsbx3dvZ+7oHnw2qhs7V3x/xTH+vmMHEaFBRIWH0Co6gv379vH9d9/SuEEdKgSUzrOeu87Fzs5/P3z3LU0b1uX6cmXyrOfK8182Z9epbBPHP0ej+rc5refKtklNTSUytCU325yL3/+/d4iNDCU6PJgB/R4iMzMTgE/nzCK05Z2EBzd3ei7Oyspi2JCBxEaG0u3+Ttd0TDlrmxcnTci5fle75SbeeTv3MeWufvP7jh1EhgUTHRFK65hI9u/bx5yPZ1G3dnVio8KJjQp3/pnChec/AOPsJKvUv4Ux5gDQSUTi3bG8TT0BAkUkyWF+VWAvsA0w1tlPicgP1vLe1u11sr6uCLwChALJgABfiMiL1mXfBPbbbGKNiDxRkBhvqlxZ/tx7MM/y7779mp9/WsbrU99m82+bmPbmFG6sXJm6devRvWcv3njtVUqUKMFjTwzKqXPp0iWC7r6DuGUryMjIoEObGFb/shFjTJ7bAfDxzv87n0uXLnHq1Cmmf/AetWrfRpeu3ZgzexbHTxxn5KgxTuskJCTQrlU0K9b8wv59+3hy4GMsXpp/MpiVVbDzYL8+D3L82DGeGz+RO++6mxMnTjBqxFC2xm9m87aduWJp3yaGn1etY/++fQx+8nEWxeX+oO/MlZyV33lrKmkX0ihTpiwpKWcZMWoszz87jho1avLAg73t4unQJobl1niGPPk4CwsQz6U82ubSpUucPnWKj6a/T81atencpRtL4xax/tdfGPfs+FzLf/B/77Dsxzjuurslw0aOtiv78L13OZtyluEjxzDhuaepXqMGPXv1zrWOvOI5dfIkxYoVo6y/Pz8uWcxXX37OO+/P4OSJEzw1ahjbtsbz6+YdnDp5ku6dO7D4p9VcuHCBTm2jiftpNd7e3jnrmv7+u6ScPcvQkWOY9PzTVKtekx69HnIai6/35fu5s2Pq1TfepFSpUrS4sym/bf09V52EhAQ6to3lp5Vr2b9/H0MHPcEPcT9edjvZvL0uH09mZiZeXl54eXnx8/Kf+Gj6h1y4cIHRT43j9tvvYNiQQbRt14HIqGi7eNq1jmHFams/HvQ4i5bk32/SM7OczrftN7Vq38Z993fluafHUKdufbr1eICpr79K8RIlePTxv88zp0+don3rKNZt3GK3rrhFP7Doh++ZOu3/mP3RdI4ePcLYp59zul3fApxzIPcxnq3FXbfzxYJvufGmm3LmXe0x/sziP3P+Tk06g7evH8VKlWH/b6vYtWoRtYJacfSPeFr2fNJuua8mPUb3V/5HZvpFvnimL91e+R8JR/axYsYr3Dd+On/Fr2Hniu9pNfglu+19Nqo7bUe+Tkn/8nw2qhtdX/oEvxKlcspfaOM8Och20np8+fv7syRuMV/Mn8dLr75GqVKluOuOxmzZ/keuOld7Ls7rfJOX7PNfn34DKFWqFM2bNcl1Ls6O52rOf/kdU86uUwAnTpxg5PAhbInfnKt9rrZtMvI5pmZMf59a1nNxeno6fn5+AAzo9xD3d+1OdEwrGtWrxdr1mylRogTNmzVmyU+r8Pf3z1nX4kU/sOiH73hz2nvM+uhDjh49ylN5HVM+lz+m8mqbbM2bNeWLr7/jJodj6mrapiC5TK5+/Pl8gkNCOHH8OCMu95niKs5/Jf28johIZWdlOuKllPuliEhjEWkEjAM+M8Z4Oy5kjCkBrAD+AmqKSBMgCDhvs9hy67qypwIlXQWxZ/dumjS9HYDGTZqyds1q6tatl/ONV3JSEhUqVLCvs2c31apXp2zZspQvX55KlSpx6GDeyd2V8Pb2plKlSrnmz5k9k4jQIN54fXKuso0b1hMcGoavry+1atfmzOnTZGU5v1hdqQ3rf+X666/npsp/n0tfeXFinifsjRvWExwS6pZYbM2f9xn3d+nO2jWradWmHQDt2ndk9aqVdsttcnE83t7eXO+wf7768nNSz5+nfetoHnu4DykpKQCcO3eOpUsW0aHTvU7XtXbNKlq1bgtA23YdWOMQe36uq1iRstYPD76+vjmJ1GuvvMDQEX8neQcPHqD2bXXx8fGhdOnSlC5Vmv379tqta93a1cRaY2ndrgNrVl9ZLLacHVPly5enePHiedbZtHE9Qdn7qVZtzpxxXb/x8fHBy8ty2T979iwNGjZk3949NGnSFIA77riTFT8vt6uzccN6QkLd22/q1K1PcnISAMnJSVSocJ1d+Vdffk7He+7LtS7LvmoDQJtr3Ffg/BgH+P33HfgHBNglXeCaY7xkQHmKlbKM0nh7+2C8vNi1ejGZF9P4/Jk+LH5zLOmp50k+eYTyN1fHy9sHvxKl8C1RkuTjBzmyYxPVmoUBUKVRC07s3WG3/sz0i2RlZlD2uhvx8SvGjbc1zrVMfipWrJjz4Tz7+MqvH7vzXGwr+/yX73HlpvNxXtepl16YyMhRY53WcXXbODumspMuEUFEqFa9BgC1b7uN8+fOcfHiRfz8/ChWrJhdvXVrVtucizte8bnYMS5nbQOW0Sf/gAC7pAvc229y92PLuXDO7FlEhgUzJY/PFK48/4EmXuo/yBgzzBizwRgTb/23ucMiPY0xm4wxe4wxI23q1TTG/GCts9UYM/AqNr8MKAOUc1LWA0uS9ryIXAIQkVQRefMqtnPF6tWvz7KlSxARflwax6lTJwkOCWPGh+9z1+2NWPbjEtp16GRXJzEhgYCAwJzXAQGBJCYmuC3G9h07sXnr7yxe+hOrV65g+U/23zwlJCQQGPh3PKXLlHHJ7UcAr778IsNH/p1k7dm9m3Pnz9OgQUOnyycm2sdSxoWxZNu9axd+fn7cUrUqiQkJBFr3RUBAIIkJ9vshMTGBADfHc+zYUXx8fflu0VIaNGzMtDffAOCtKa/x2MDBedZLTPy7HwUEXn0fSktL4+UXxvPo44PYu2c358+do57N/qlWrQZb4jeTkpLC8WPH2Lo1Pte2EhMS8A/8ux2TrqE/Ozum8mO7HwFKl3btftoSH09YcAuGDRlEWEQkderW40drjEviFjttD9tj3JXHVLagkFBmTv+AFs0as2zpUtq272hX/vm8/9GlW49c9RITEnP6tKXfJF5THI7HeLZ5n31K167dc2/fhcd4xsULrP1sGk3aP8i5hJN4eftw/8SZVLz1NjZ+M5OAG6pwcu/vpKee51zCSU7u20nauWQunEumWGnLbavGGOSS/YfCCynJOYkdQLFS/lxIuboY09LSmDj+OZ4YlPexnM2d5+Jstue//BTG+S/bnt2Wc0+Dhs6vDYXRNmC57btpwzokJiZwww03AnBf5660vLspdzSqS6d7O+dKVl11Ls7P3M8+pauTY7ow2iYtLY1JE57niYGDad+hE79t3cGiJctYtWplrs8U7jj/aeKl/ovmiEgzEWkMDAJmOpRfD9wB3A0MMsa0sI5QfQYMF5Fm1rIBxphmV7jtzsBPInLKSdntwDon822FWxPG7GloXgtaE8zD2dO5lHOXXXFMbGtq1KxFm5hIlsYtpn6Dhjw7bgzPT3yBXzdtYfDQ4Tz/zFN2dQICA3O+qQZISk4iMNBZTukaAQEBeHt74+fnR8dO97J582925YGBgXa/QzuXkmJ3G8XVWrzwB5refjvly5fPmffCpPGMGfv0ZWK1jyXFRbHYmjf3U+63fiAMCAwkyWbUILCc/X4ICAgk2c3xBAaWIyomFoComFi2b9vKyRMn2LplMxGR0XnWCwj4ux8lJV1dH8rMzGRAnwcYOHg4des34JUXJjBizDj7+MqVY9RTz9C9cwdGjxhMgwaNcj6Q5MQS+Hc7JScnEXAN/dnZMZUf2/0IcO6ca/dTo8aN+XnVWj5f8A3DBg/ipVdfY8aHH9C+TSxl/cs6bw/beNzQb55/eizPjn+BtRvieXLocMY/+/d+O7B/H5cuXcr5xt4+toC/91VSkt0Htivl7BgHy4jBN18toNO9nXNv30XHeNalTBa+PoI7OvXhuqq1KF7Gn6pNgwGo2jSY0wf+pESZAO7u9gRfTXqU5R+8QMVbb6N0uYoUL12Wi+dTcmI1DrdUFrMpB7h4/izFy1x5jJmZmTzUqwdDho2gfoMG+S7vrnOxLdvzX34K4/yXbdKE5xk77pk8ywujbQCGjRzNb1t3Uq1aDT6dM5uUlBReeWkSm7bsZOvOPfyybg1b4jfb1QkIsLmOXOW5OD8iwtdffck99+U+ptzdNpmZmfTu1ZPBQ4dTv0EDh88U9xDv8JnCHec/TbzUf1ETY8wKY8x24D2gtvU2v2wzxOI0sACIAmoD9YC5xph4YC2Wkau6BdheGWuSdBB4H8vthlfL8VbDKXktKCJviEjl7Kl0mbx/BJ1t3LPPs2jpT7Rp256gkFBEhPLlLbcXXnddRRLOnLFbvkaNmuzbu5eUlBQSExM5fuwYN1epcg1v7/Jsv2latXIFNWrUtCtvduddrF61kszMTPbu2UP5ChVybq26Flu3xrNy5Qo6tmvNT8uWMnrkMH5dt5ahgwfSsV1rjhw5zNjRI3LFsmb1KpfHYmvBF59zb+cuALQMCmbJooUALPzhO4KCQ+yWvaMQ4gkKCWXzJsuDADb/tpFq1WuwY8c2Tp86zb0dWjPtzSl8OmcWPy6Ns6vXMiiEJYsXAbB44fe0dIg9PyLC4McHEBEVkzNacuDAPkYOHUTnjm04euQwz4y1DF536HQv38ctZ/Ibb1O8RAkq32zfX1u0DObHOJtYgq4sFkeOx1R+7mh2F2uz99PePZQv77r9dPHixZy//cv6U7JkSSpXrsy8Lxbw3cI4Lly4SEeH20Etx5R7+42IUL6CJeG57rrrSEj4+zzz+bzP6JzHh+sWLYNZGrcYgEXXuK+cHePHjh1j3do13FanLgEBAbnquOIYFxGWTHuGqk2CqHF3FAA317+TE3u2A3B8z3YCbrD00VotYuj64hwiHn0GH79ilL3uRm6qdwcHNlluBzu07Veur17Pbv2+xYrj5eNLypkTZGakc+zPeK6vZr9MQWJ8bEB/oqNj6dCxU4HquOtcbMv2/Jefwjj/Zdu/fx9DnnyCDm1bceTwYcaMyn1tcHfbZB/rxhjK+vtTokRxvLy88PPzo1SpUnh7ezu9Q6VFUDBLrOe/RQu/u+JzcUGsXXP5Y8pdbSMiPP7Iw0TFxOT0Y9vPFKtXrqS6088Uru03PtdUW6l/GGOMH5ZkKlxENhhjymJ5iEUxIPfjbCwEy4MxEqyjZFcqRUQaG8sTJ57BkrzdJiIXHJbbBAy4ivW7xOnTp+nVvQs+Pj5UvvlmXpvyFgf/OsDggY/j7e1NZmYmb7/7HgCvT36Ftu3ac1udujz93Hg6tmsFwKQXX8n3wRpXoluX+9gSv5lSJUuxYf2vlClThqVL4vDy8uL2O5rRvoPlQ/aIYUN46ulnKVeuHH369icqPAQvLy+mvvWOS+IYNWYco6yjJwP696H/w4/Y/fC+SYM6vPTKawCMHD6EseMssfTu04+YyFC8vLx4481pLokl24b1v3LrrdVyfnfX66E+PPpwX2IiQ6lS5RZGW0fjRg0fwhhrPA/16UesC+N5oFtntm6Jp1SpUmzasJ7nJ73EoMcepl1sJMWKF+P96bOpcN11hEdYPlB+OmcWJ46fICo6lhPHjzPtrSlMfPEVej7Ym8cH9KV1VBg3V6nCyDFX9t3EsqVxfL3gcw4ePMCCL+ZRv0Fjlixfk1N+V5N6THzJcv/+gD69OHH8GCVLleKlyZbvLU4cP867b09h/Auv0KNXbwY+2o+2MWHcfPMtjBh99d+TODumNqz/lQnPPcORw4do3zqGQUOGEhPbmtEjhjL6qWcoV64cD/buS2xUGF7GizfefPuqt+9o3do1vDBxPN7e3ogIL09+nf99MoePZ8/Ey8uLbj16Uq9+fcChH/ftR3SEpd9McUG/6dX9/px+s3HDr4wY/RTDnnwcL29vLmVmMnXaeznLfvXl53z13WK7+o/0783702cRHduauEULaR0dhr9/AO9Nn3XVMTk7xm+44QZefmECXbrZJ36uPMYPbF7NrtWLOXvyCH+uXsh1t95G8EMjWDrtaeaPewgfv2K0GvIyAAtfH8n5xFP4Fi9B2MOWuw8qVKnJ9TUbMHdMT7x9/Yh98gUAdiz7ijLX3UCVhncT1n8sP7w6FJEsmnbsjV/JUnnG48zSJXF8+cV8/vrrAJ/Pn0vDRo3p0rU7zz87jsOHDtEmNorBQ4cT26q128/F2RzPfxvW/8r4Z5/myOFDtGsVzZNDhhHTqrVbz3/ZHK9TK1b/feNKo/q38fKrlmuDO9sm+1xcslQpNm5Yj7e3N5t/20RWVha3VK3KqDHj8PPzo3ffh4kKC8LHx4datWsTEhoOWB7A8cGM2cTEtiZu0Q+0igrDP8Cf96fPvqa4HNtm8utTLLfuOtxmWBj9xrYffzF/Hg0bNaJMmbL8uHSJ9TPFHTmfKdx5/tOnGqp/NcenFFoTrdPAzSJywhgzDpiE9YmE1uWXi0gfY0w5YDPQHViP5cmEr4rITOu6amBJxhLyeaphvIgEWF8bYAPwqYhMsX2qoTGmpHV7nwAvisgl60jcwyLyluMTEK9Ufk81LEwFeaphYSroUw0LiydFc6VPGXM3T4onv6caFrb8nsBWmPJ6qmFRKehTDQuD7VMNPUF+TzUsTJ50fINnHVN5PdWwqOT3VMPC5Gm5jD7VUP3XxWX/zgn4HUuitd4Yswlw9p/0nLKWrQemichaEckE2gH3Wh+ssQOYAZRwrGyMmWCMedRZIGI5OwwHRlsTLduyVCyPka8O7DHGbAN+BWyXc/yN17wragmllFJKKVUkdMRLqf8IHfHKm4545c3TvoH2pHh0xCtvOuKVNx3xypsnHd/gWceUjnjlzdNyGR3xUkoppZRSSqkipImXUkoppZRSSrmZJl5KKaWUUkop5WaaeCmllFJKKaWUm2nipZRSSimllFJupomXUkoppZRSSrmZJl5KKaWUUkop5WaaeCmllFJKKaWUm2nipZRSSimllFJupomXUkoppZRSSrmZJl5KKaWUUkop5WaaeCmllFJKKaWUmxkRKeoYlFKF4KbKlWXvgcNFHYZSyk086XpujCnqEFQBbdqfWNQh5Lj91sCiDsFjZWV5zvEN4OWlx3heSviaIyJS2VmZjngppZRSSimllJtp4qWUUkoppZRSbqaJl1JKKaWUUkq5mSZeSimllFJKKeVmmngppZRSSimllJtp4qWUUkoppZRSbqaJl1JKKaWUUkq5mSZeSimllFJKKeVmmngppZRSSimllJtp4qWUUkoppZRSbqaJl1JKKaWUUkq5mSZeSimllFJKKeVmmngppZRSSimllJtp4qWUAiA1NZXQoOZUqhDA/HlzATiwfz9R4SHERIbRvk0sSUlJueotWvgDoUHNCQ1qzs/Lf3JbfDNnTCcsuAURoUFs37bNrmz/vn3ERoUTHtKSKW+85pbtO2sfgMmvvkyb2ChiIsNYs3r1FcXtCr/v2EFEaBBR4SG0io5g/759duVF1TYvTppATGQYMZFhVLvlJt55+61c9dzdNnnts2yF0TbZPGE//XXgAOEhLYmJDCMiNIhtW7eSlpbGQw/0ICo8hIf79iY9PT1XvZkfTSc8pCWRYcEu3U/O9s/uXbuIiQwjNiqcUSOGISK543FzvwH4bdMm2rWOITYqnOeffdqurDD2lbP+8v1339K4QR0qBJTOs961ts2FtFQe6RJDq9ur8uP3X9qVzXjzJXrE3pXz+pVxg+nYsg6Tnx2WM++3X1bxSJcYBvZsx4j+XTiblJhrG39s28xj3VrxSJcYlnz3xRXH6Gj3rl2UKeHLr7/8Yje/MI/vbEV9nQKoEFCKVtHhtIoO59tvvmLaW1MJaXkXkWFBDB8yyGmdWR9NJyK0JVHhwWzf/u88pjwmFhHRqQgm4ADQ2F3L29QTIMDJ/KrAJSAe2Ab8AXwIVLZZZhZwxLpM9tTHprwrsBH4E9gEfAc0cIzXZj2bgd3AaqCXzXrCgHgn8SXZvPYH3gf2WWPdALSxKe8NfO2wDrv1As8C24Et1nVMzqftegPJDu//jgLGEwakWetsBX4F7rYpfx445bDucdaym4Fvrftlm7UsAnjUZtkEh30Tnl9fuPGmmyQtQ/Kczl3IlP2Hjsm4Z56T2Z98JmkZIsNGjJIZMz+WtAyRiS++LK+98WauOg0aNJQTZ5Ll8PHT0qhRY0lNz7rsdq5mOnLijDRp0lTOpqbLlu1/SGhYuF35Pfd1luUr10pqepYEBYfIzl37XB6Ds/b5+ruFMnbcM1cdtyumv46ckOOnkyQtQ+Sb7xdJrwd7e0Tb2E6NGzeRPQcOF3rb5BdXYbRNYe6n1PSsy05nU9Pl3IVMSU3PkoVxP0rn+7vKG2++LeMnviCp6VkycvRYeX/6R3Z1Dh8/LY2bNJXk8xclfttOCQ0Lz3c7BT0HONs/7Tp0lNXrNkhahsijjw+U7xctKfR+k3z+okTHxMqpxBSn5YXRb5z1l8PHT0tiSprUql3baZ2rbZvVuxJyphU7T8k3a3ZKn4Gj5Pk3PsyZ/+3aPySy7b1S5daaOfO+Wrld3przrXTs1jtn3pcrtsqybUdl9a4EGTH+dek7aLTd+lfvSpD6TZrJFz9blqtxW31ZsvlgTtnVtFX3Hg9IeESk/LxqXZEd3wVp/2uN5/zFrAJNtWrVtnu9dccuOXfhkpy/mCWd7+8qi5cutys/dMxyjCeduyibt+6UkLDwAm3nn3ZMFWYswOG8PovpiNd/W4qINBaRBkBD4Biw1hjjb7PMZOsy2dNMAGNMH2Ai8KCI1BaR27EkEzfmsa3JItJERGoCA4GnjTHD8ljWjjHGAAuBDKCWiNwGPAx8aIyJLuA6OgOtgWYi0gioD3xSgKrLHd7/xiuI509rnYbAHOAjh3V/6rDuF6zz/8+63QbWfRMF7BGR97KXxZKY2e6b5QVph8vx9vamUqVKdvPq1aufM8qVnJREheuusyvfs3s31WrUoGzZspQvX55KN9zAwYMHrzWUXDZuWE9waBi+vr7Uql2bM6dPk5WVlVP+5x87ubt5c4wxtGrTltWrVro8Bmft8+Xn8zl//jytYyJ5uG9vUlJSrihuV6hYsSL+/pZD1tfXF29vb7vyomqbbL/v2IF/QAA33XST3fzCaJvLxQWF0zbZPGE/+fj44OVlueyfPXuWBg0bsnb1alq3aQdAuw4dWbXSfrsbN6wnJDTULfvJ2f7Zt3cPTZo2BaBZsztZ8bP9qa0w+s2vv6yjZKlSPNizG61jIvll3Tq78sLYV876S/ny5SlevHiedVzRNt7e3pS/7vpc82e98xq9HhlqN++6Srkv99ffUJlixSwx+vj44OXQzy9evEBGRgaVbrQsV7/pnfy5Y8sVxWhr/a+/cn2lStx0U+VcZYV5fINnXKcAjh07SmxUGA890J2TJ09SvUYNLB9bwMfJuWfjhvUEh7jnGM/mCceUp8SiiZcHMcYMM8ZsMMbEW/9t7rBIT2PMJmPMHmPMSJt6NY0xP1jrbDXGDLzSbYtIuog8i2UU5YECVBkPDBGR323WsUlE4gqwrXhgMDDaZJ8NLi8SuAUYJiKZNut4AXimAPUBKmMZJbpgrZ8pIld7tr+aeJZZ6xQ01iPZL0TktIi4PpspgODQMKZ/+B53NG7Aj0vi6NCxk115QkICgQGBOa8DAgJJTEhweRwJCQkEBv69ndJlypCcnJzz2vYiERgQSIIbYnDm2LGj+Pr6smjJMho2asybU163K88vbldKS0tj4vjneGLQYLv5RdU22eZ+9ildu/XINb8w2yYvRdE2Rb2ftsTHExbcgmFDBhEWEUliYgIB1v0Q6OT4TUxIICCg8PZTnbr1+HHpEkSEuLhFueIpjH5z9OhRtm/byuxPPuODGbMY+NgAu/LC7Dd59Rdn3NU2hw7sJS31PDVuq1fgOokJp1nwv49o19n+40RKUiKly/z93W6ZsgFOb0csqFdffoERo8Y4LSvs49tTrlPb/9hL3I8/06Zde8aOHpEzf+2a1Rw9eoTmLVraLZ+YaB93mX/5MVXUsWji5VnmiEgz64jGIGCmQ/n1wB3A3cAgY0wLY4w38BkwXESaWcsGGGOaXWUM6wHbs+tIayKYPQUbYypiuR1unfNVFMivQEXguvwWBJoCm0TE8ccH64DbC7i9ucCtwD5jzMfGmL7GmBIFqBdu896zk8qriaezNQZbPR3atqt1/ivADGPMGmPM68aYkALEmYs1kT+cPZ07d+6K1/H0U6OZMOklNsZvY8jwkTwzbqxdeWBgIEnJSTmvk5OTCCxX7mrCvazAwEC735edS0nJ+TYYwDZ/T0pOopwbYnAaV7lyxMS2AiAmthXbtm21L88nblfJzMzkoV49GDJsBPUbNLArK6q2Acut7F9/9SX33Nc5V1lhtc3lFHbbeMJ+atS4MT+vWsvnC75h2OBBBAQEkmzdD0lOjt+AwECSbY5xd++nl199nekfvk+71jH4l/XnhhvtR1UKo9+UK1eO5s1bUqZMGW6++WZKlirF2bNnc8oLa19drr844662+ejtV+j9xIj8F7RKPX+OZwf3Zfjzk6lQ0X5Es4x/AOdS/v5Qf+5sMmVtEvsrsWjhDzS9/Q7Kly/vtLywj29PuU5VqFABgPs6d2FL/GYA/ti5k6efGs2cT+fZxQGWL0xt4075Fx9TnhCLJl6epYkxZoUxZjvwHlDbITmYIRangQVYbkGrjSVRmmuMiQfWAmWAulcZg+MIlOOthquucr2X207uX09ffv6VLGv5oZvIcaAB0BPL76Yex3JbpV8+67W91TD2CuIBy/6LN8YcxzLC96JDueOthvOssX4GVAGyh0++sR3hLCgReUNEKmdPpUvn/YPsy6yD8uUtJ/GKFSuScOaMXXmNmjXZt2cPKSkpJCYmcuzoUapUqXLF28lPszvvYvWqlWRmZrJ3zx7KV6iQc8sUwG116rJh/XrLt+SLFtIyKNjlMTgTEhLGpk0bAfht00aqV69xRXG7gojw2ID+REfH5hqRhKJrG4C1a9ZwW526BAQE5CorjLbJT2G2jSfsp4sXL+b87V/Wn5IlS9IyOJi4xQsBWPj9dwSH2H/PY9lPqwptP1WuXJn5X3zF94uWcOHCBTp2utdJPO7tN83uvIvdu3eRmZlJcnIyKSlnKVu2bE55Yeyr/PpLXnG7o22OHjrA6+NHMqxfZ06dOMq0l/O+0SQjPZ1nnuxDt75PUK/RHbnKixUvga+vL6eOHyU9/SI74jdQu27Dq4pr65Z4Vq74mQ5tW7Fs2VJGjRjKsWPHcsoL+9znCdep8+fPc+nSJQBWr1pJ9eo1OHTwIAP69+ajWZ/kJGWOca9Z7d5j3BOOKU+Jxcela1NXzZoALMDykIQNxpiyWB7sUAzLQxqcESwJTIJ1lMwVmmH5PVKeROSkMeYw0BzLb52udjsnreuqADh+ZVUBOGn9+zfgSWOMr4hk2CzT3FoGlgdVXG4diMglLInpWmPMW8AJLL/1+o0rU5B4wPobL2OML/Au8KkxprlYn6BxOSKSiKU/LDDGbACeAiZfYZxXrFuX+9gSv5lSJUuxYf2vjBn7NIOeeBRvb28yMzN55/8+ACxP8mvXrgN16tbl2fETadc6BoAXX5mc69s0VyhXrhx9+vYnKjwELy8vpr71DkviFpOQkEC37j2YOOklHnukPxkZGbTr0JFbq1VzeQyQu30mvfgyjw3oT2xUOMWLF2f6zI8BGDFsCE89/azTuF1t6ZI4vvxiPn/9dYDP58+lYaPGxMS2KvK2mfz6FOY5uc2wMNvGWVzRMbGF3jbgGftp3do1vDBxPN7e3ogIL09+ndq1b+OR/n2JjgilSpVbGPOU5QlfI4cPYew4y37q3bcf0RGheHl5MeXNaS6NyXH/NGnSlNmzPsLLy4vuPR6gXv36QOH2m4CAAB4e8CgxkWFkZGTw4suTC/1846y/dOnaneefHcfhQ4doExvF4KHDiW3V2uVtM27gg+z6fRslSpbk962beH/+kpyyHrF3MXDMRABmTnuVVcsWkXj6JIMfuocpM7/khy8/5fetm7g44wKfzZjGXcGR9HpkCAsX/I/rb6jM7c1DePKpF3l2SF+ysrLo2udxSpYuc1Vxjh47jtFjxwHwcN/e9B/wKNu2bmHFz8sL/fgGz7hO7frzD554bAClS5fGx8eXt995j6efGs2Z06d5dEBfAIaNGE1MbCv7Y7xPP2IiLcf4Gy4+xsEzjilPicUU4DOgcgNjzAGgk/W3QVgTrdPAzSJywhgzDpgEBIpIknX55SLSxxhTDssTArtjuTVwG/CqzYMvamBJxhKMMZK9DoftV8XyxL8A62s/YCzQH6gvIsnGmFnWZaY6ib8fMNL6Hv6wzmsCXCciS2zfn+N6jDENgXnAhyLyhjUx+RMYKCILjTFeWJ4YeEFEBllfr8Hy5MQhIpJpjGkM/AD0FZE4Y0x5YCcQY91mMeBr4EcRed0YcweQKCJ7rTE0wpKEVRWRU3nso97W99DJYX5B4gkDpmYnxMaYksAuYJCIfGWMeR7L0yaHONluO+AnEUm1/gbuZSwP8bjHZpk8901ebqpcWfYeOFzQxZVS/zCedD13xxcwyj027b/631i52u23Xt1th/8FWVmec3wDeHnpMZ6XEr7miIjkfuILOuJV1OKMMbYjJpOA9caY0+T+PRDAKWPMJiyPMp8mImsh54P6VGPMUMAbSwKX69fsxpgJwFERec86q4z19kQfwBdYBbQQEdtfVY60JiDZPhWRySIywxiThmUUpzSQCezFkrw5k72eklhGoV4SkY8BRCTDGHMP8IYx5kUst8D+CoyzlmcZY1pjGfHZbYxJB1KAR7Mf5iEiZ4wxXYB3rUmOF7AYyP7Pg8oD04wxAVhGEC8BPfJKui6nIPE4qZNqTaafN8Z8bZ3d05qgZVsuIkOBUGCyMSYTy4jmn1ieBKmUUkoppf6hdMRLqf8IHfFS6t/Nk67nOuL1z6EjXv8MOuL1z3G5ES99uIZSSimllFJKuZneaqj+06y/zZrlpGi2iEwp3GiUUkoppdS/lSZe6j/N+nCTxkUchlJKKaWU+pfTWw2VUkoppZRSys008VJKKaWUUkopN9PESymllFJKKaXcTBMvpZRSSimllHIzTbyUUkoppZRSys008VJKKaWUUkopN9PESymllFJKKaXcTBMvpZRSSimllHIz/Q+UlfoPEZGiDgGALM8II4e3lynqENQ/UFr6paIOwU4JP++iDiFH5qWsog7Bjo+353zP7Cnn4Wy33xpY1CHkGDBvS1GHYOeDro2KOoQcXnqd+lfwnDORUkoppZRSSv1LaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllALgrwMHCA9pSUxkGBGhQWzbupVpb00luMVdRIQGMWzIIKf1Zn40nfCQlkSGBbN92zaXxbNxw3paRYfTKjqcoLvvoOVdt7N71y5aRYfTOiaCMSOHISK56s36aDqRoS2JDg9m+3bXxWOrXNmSxESGERMZxjdff2VXtn/fPmKjwgkPacmUN15zy/YdzZwxnbDgFkSEBuXaB4UZz+87dhARGkRUeAitoiPYv29foceSmppKaFBzKlUIYP68uQAc2L+fqPAQYiLDaN8mlqSkpFz1Fi38gdCg5oQGNefn5T9dUww7f99B66gQ2saE0bF1FAf27+N/c2bTpF5N2reKoH2rCNLS0gAY/MQj1KlWmWFPPu50XWlpafR/qCdtokN5/OE+pKenX3Vcztrm++++pXGDOlQIKJ1nvcv1r6uJISK0JZWvL8cX8y0xvPP2m4QF3U1UWDAjhj6Zs2zr6Agiw4JoHR3BCxOez7WutLQ0+vTqQUxEKAP69b6mtnGM0bGdbBVGP/59xw4iw4KJjgildUyk3bE0cfxzNK5fx2k9d52PbeMqrGP83KkjLB7/IHGT+rF4/EMkHtxFZvoFVk0bQ9yEPqx572kuZWYAsG76eL54IopfPpqUU//U7i0sHv8gSyb1Y8kL/Tl/5kSubZzZt4PF4x9i0fMPsn/twmuKF4r+2nC5vjtx/HM0qn+b03quPMYvF8v/vTONyLBgwkNa0q/3g2RmZhZKLAWJzZY795Vx9sFFKfXvc1PlyrJn/6E8yzMzM/Hy8sLLy4ufl//ER9M/5LnxE6lWvTrGGB7s2Z2HH3mU4JDQnDoJCQm0ax3DitXr2L9vH4MHPc6iJcvyjSXrCk8777w1lbQLaWxcv55RY8fR9PY7GD5kEG3bdSAiKtoung5tYli+yhLPkCcfZ2Fc/vF4e5kriqdR/dvYsv0Pp2U9ut3Pk4OHcdfddxMTGcaHM2ZR9dZbr2j9VyIhIYF2raJZseYX9u/bx5MDH2Px0r8Th8KM5+TJkxQrVgx/f3+WxC3mi/nz+GDGzEKN5dKlS5w6dYrpH7xHrdq30aVrN8aNHU29evXp8UAvXpv8CiWKl+CJQU/a1WnerCk//ryKjIwM2sZGsW7Dbxhz+X6Rln7J6fxT1nYo6+/Pj0sW89WXn9MyKISTJ44zZMRou2WPHj3Cvj27WfDFfN54691c65r+/ruknD3L0JFjmPT801SrXpMevR5yut0Sft5X3DZnzpyhVKlS3HVHY6d9Or/+lZfMS1l5xnD61ClmfPg+tWrXpnOXbuzdu4dq1Sznmd69utP/4UcJCgmldXQEs+b8j+srVXK6rg/ee5ezZ88yYtQYxj/7NNVr1OCBB3s7XdbHu+DfMztrJ1vX2o8L8rkr17H0+Xw+mP4RJ06cYNTwoWyJ30z89p12da72fJxfP79sXC4+xgfM25Lzd9alTIzxwnh5cWzHenYv/5LrazchPe08DTr0Y/P8tylbqQrVQzqSmnCCs8cPcuCXOO7u+zQAlzIz8PbxBWDPiq85e+wvmnYbbLe9xeMfJPiJVyhethyLnu9F7LOz8C1eMqf8g66NChw7FP21Ia++e+LECUYOH8KW+M254rvaY/xqYklPT8fPzw+Afr0fpGv3HsTEtnJ7LAWJzda17qsSvuaIiFR2VqYjXuqaGGMOGGMau2t5m3pijAlwMr+qMeaSMSbeGLPFGLPJGBNuLettjPnaZjkxxsywqVvaGCM2r382xuy3rit7is0jnjtsljlojEm2eT3Suu3seduNMcuNMbVs6s8yxhxx2FafApQ1MMb8ZH2v240xG4wx9a+0PZ3x8fHBy8tySjh79iwNGjakeo0aORdlX19fvL3tP9ht3LCekNBQfH19qVW7NmdOnyYry/kHrmsxf95n3N+lO3v37qFxk6YA3NHsTlauWG633KYN6wkOcX88x44eJToilF49u3Hy5Em7sj//2MndzZtjjKFVm7asXrXS5du3tXHDeoJDw/J8z4UZT8WKFfH39wec95fCiMXb25tKDh/U69WrnzPKlZyURIXrrrMr37N7N9Vq1KBs2bKUL1+eSjfcwMGDB686husqVqSsk3b43yezaR0VwltT/v4G9cYbb7rsutatXU1s67YAtG7XgTWrr77NnLVN+fLlKV68eJ518utfVxODYyJVvbrNecbHFy9rexlj6NWjKx3axLBp44Zc61q7ZhWt21japm37Di7rT87ayVZh9OPcx5Ll3PzyixMZMWqM0zqFcT4uzGPcy9sHY70mZaSdI7BKLU78uZnKTUIAuPn2ME7s3ARAyXLX56qfnXTZ1rd1Kf0ilzIzKVXhBrz9inFdzUYk7P/9quOFor825NV3X3phIiNHjXVax9XH+OViyU66RAQRoXr1GoUSS0Fis+XOfaWJl/o3SBGRxiLSCHgBmG+cf4WXCrQ2xtS9zLqGWteVPcU5W0hENmYvAzwLLLepM9m6WPa8+sAmYKrDaiY7bGtmAco+A94WkUbW9d4LnMRFtsTHExbcgmFDBhEWEZkzf+2a1Rw9eoTmLVraLZ+YkEBAQGDO69JlypCcnOyqcADYvWsXfn5+3FK1KnXq1mPZ0iWICEviFpOQkGAfT2ICAYF/x1PGDfEA/L5rH0t/WkHbdh0YM3K4XZntRSIwIDBXjK6WkJBAYGDe+6Cw4wHLLWATxz/HE4Psv10uilgAgkPDmP7he9zRuAE/LomjQ8dOduUJCQkE2vTjgIBAEl0QW1paGi+/MJ5HHx9E2/YdWbdpG98s/JG1q1eyYnn+IxFgOcb8rfs3ICCQpMTCabNs+fUvV7KcZ47mnGc+/t88lvy0gtemvs0j/fvkGimyPf8EBAaSWEhtU5j9OC0tjUkTnueJgYPZs3s358+dp0HDhk6XLYzzsW1chXGMJ/z1B4uef5ANs1/mhnp3kn4uGb+SZQHwK1WWi+fPXrb+kS1rWPhMD3b9+Dnlq9WzK7t4Phm/kmVyXvuVKsvFc5dfX3486dqQzdJvzuXZbwrzGAeY/OrLNKxXm8TEBG648cYijSUv7txXmngplzPGDLOOxMRb/23usEhP68jUHmPMSJt6NY0xP1jrbDXGDLyKzS8GKgDlnZRlAC9Zp8K2DLjFBeupDBzJfiEih0TEaeJl3Q+Hs6dz587lu/JGjRvz86q1fL7gG4YNtvym64+dOxk3djRz/jcv1y0pAYGBJCcn5bw+l5KS822oq8yb+yn3d+0OwEuvvMaM6R/QoU0sZcuWzXXSDggIJNnm9zspbogHoEKFCgB0vr8LW7ZstiuzbaOk5CTKlSvn8u3bCgwMtPvNkuM+KOx4MjMzeahXD4YMG0H9Bg3sygo7lmxPPzWaCZNeYmP8NoYMH8kz4+y/+Q0MDCTJph8nJycReI2xZWZmMqDPAwwcPJy69RvgHxCAt7c3fn5+tOtwD1viN+e/EqzHWPZoXXISAYGF02bZ8utfrvLHHzt5ZtwYZn86N6efZB9ntWrVpnz5Cpw+fdquju35JzkpicBCapvC6seZmZn07tWTwUOHU79BA16YOJ4xTz2d5/KFcT7OjquwjvFyt9xG6+c/JmzYm6yf/TJ+pcqSnpoCQPr5FIqVKnvZ+jc1akmbif+jSdcniZ//tl2Z7boA0lNTKFb68uvLjyddG7JNmvA8Y8c9k2d5YR3j2UaOGsPWHX9SrXoN5syeVaSx5MWd+0oTL+UOc0SkmXU0aBAw06H8euAO4G5gkDGmhTHGG8toznARaWYtG2CMaXaF2+4OHBSR03mUvwfUN8a0zKN8isMtftWvcPu5GGO8gHsAx19wjnTYVnAByiYCy40xy4wxLxhjmuS1XRF5Q0QqZ0+lS+f943mAixcv5vztX9afkiVLcujgQR7u15uZsz/JuaDYanbnXaxetYrMzEz27tlD+QoVcm5XdJUFX3zOvZ27AHBT5crM/XwB3y6M4+LFi3TodK/dsnfceRdrVrs3nvPnz3PpkuW3PatXraSaw60St9Wpy4b16xER4hYtpGVQsLPVuIxlH6zM8z0XZjwiwmMD+hMdHZtrVKmwY3GMq3x5S/+tWLEiCWfO2JXXqFmTfXv2kJKSQmJiIseOHqVKlSrXtL3Bjw8gIiqGtu07AnDW5lvbtatXUr1GzQKtq0XLYH6MWwTA4oXf0zIo5Krjuhr59S9XOHTwII/278OMmXPszjNnz1pGH06dOsWJE8cpX97++7SWQSHELba0zaIfvicouHDapjD6sYjw+CMPExUTk3Ms7d+/jyGDB9KhXWuOHDnM2NEj7OoUxvm4MI/xSxl/PyzFr2RpfPyKc/1tTTm6ZRUAhzev5Po6txeovm/JMnj7FbMr9/ErjrePD6kJJ7iUkc7p3VspV9X5Q0sKwtOuDdn279/HkCefoEPbVhw5fJgxo5z1G/ce49myP2cYY/D396dEiRJFFsvluHNf+bhsTUr9rYkxZhyWUadMoLYxpoSIpFnLZ4jlnpHTxpgFQBSQBNQD5tp801AGqAvkvrnfXhljTLz17yNAh7wWFJEMY8wzwCtAKyeLDBWRr/PZXkGFW+OqAiQAdzmUTxaRqXnUdVomIq8bYz4BIoAQYJUxpp+IzLvWYNetXcMLE8fj7e2NiPDy5NcZN3Y0Z86c5pGH+wIwfORoYmJbMXL4EMaOe5Zy5crRu28/oiNC8fLyYsqb0641DDsb1v/KrbdWy/kw9tmnc/h49ky8jBfdevSkXj3Lz9tGDR/CGGs8D/XpR2ykJZ43XBwPwJ9//METjz5MqdKl8fX1Zdq77+fc9titew8mTnqJxx7pT0ZGBu06dOTWatVcHoOtcuXK0advf6LCQ/Dy8mLqW+8UWTxLl8Tx5Rfz+euvA3w+fy4NGzUmJrZVocfSrct9bInfTKmSpdiw/lfGjH2aQU88ire3N5mZmbzzfx8Allte2rXrQJ26dXl2/ETatY4B4MVXJl/RAwccLVsax9cLPufgwQMs+GIe9Rs0pkzZMvz04xK8vLxoensz2rSznKZefWkii77/jpMnT3BP2xi+/G4xp06e5N23pzD+hVfo0as3Ax/tR9uYMG6++RZGjB7n0ra5v0s3nn92HIcPHaJNbBSDhw4ntlVrRgwbwlNPP+u0f12rnt06szU+npKlSrFxw3qOHz/GmdOneWxAPwCGjRxFZFQMbWMjKV68BJmZGbz6+hS8vLw4cfw4b781hUkvvsIDD/bmsQF9iY0Mo0qVKowae21tY8uxnaJjYgu1H9seS1/Mn0fDRo34edXanPLG9evw0iuW3woW1vnYMS53H+Mnd8WzdcF7lt95iXB7zxH431iVtR88R9zEvpSqcAMNOj0MwNav3ufQpp+5kHyGpS89QtTo/+Ov9UvZvXwBxhi8vH24u59l1Gfvym8oWf4Gbqh3J3c8MJKVb49CRKjTuhe+JUpddbyecm1w7LsrVq/LKWtU/zZeftXSb9x5jOcVi7e3N79t2khWVhZVq96aM4JbGLHkF1thHeP6VEN1TYwxB4BOIhJvfe2HJckIF5ENxpiyQDIQKCJJ1uUfEpEV1uWnAmeABcASEXH6S3PrQzACRSTJYX5VIF5EApzU6W2NrZPtctbff/0GvAZ8IiLGuvzPwNQrTbxst5PHtksCX2D5LVpXa/ksazxTnawvzzIny44BWohInslmtvyealiYrvSphu52pU81VAryfqphUcnvqYaFKa+nGhaVK3mqobt52ueua/mSwdVsn2roCa70qYZKgT7VUBWu4oAfkP1IMGf/+VNvAGNMOSy34C0D/gTOZj+9z1pew7qMS1lH28YAk/Jb1kXbSwX6A20ud2tgQRhj7jHG+Fr/9gEaAnuvPUqllFJKKeVOmngpV4jLfoAD8DuWhGa9MWYT4Ox/tDxlLVsPTBORtSKSCbQD7rU+WGMHMAMo4VjZGDPBGPPotQRsfVrhPidFjr/x6nkt27HZ3lEsI2wTbGY7/o5rZAHK7gW2G2O2AluAi8BzrohRKaWUUkq5j95qqNR/hN5qmDe91VBdDb3VMG96q2HePO1zl95qmDe91VBdDb3VUCmllFJKKaWKkD7VUKl8GGM2kvtY2SEiLrkNUSmllFJK/ftp4qVUPkTkjqKOQSmllFJK/bPprYZKKaWUUkop5WaaeCmllFJKKaWUm2nipZRSSimllFJupomXUkoppZRSSrmZJl5KKaWUUkop5WaaeCmllFJKKaWUm2nipZRSSimllFJupomXUkoppZRSSrmZEZGijkEpVQhuqlxZ9h44XNRhKKWUUv8Il7I85zOyt5cp6hBUAZXwNUdEpLKzMh3xUkoppZRSSik308RLKaWUUkoppdxMEy+llFJKKaWUcjNNvJRSSimllFLKzTTxUkoppZRSSik308RLKaWUUkoppdxMEy+llFJKKaWUcjNNvJRSSimllFLKzTTxUkoppZRSSik308RLKaWUUkoppdxMEy+llFJKKaWUcjNNvJRSSimllFLKzTTxUkoppZRSSik308RLKZVLamoqoUHNqVQhgPnz5uYq379vH7FR4YSHtGTKG68VSkwzZ0wnLLgFEaFBbN+2rcji+X3HDiJCg4gKD6FVdAT79+0rsliyeUrbeFosnhaPJ8XiSfH8deAAYcEtiI4IJTykJdu2bi2yWLJ5Stt4WiyeFo8nxDJs8EAiQloQ2vIulsYtZsP6X7nr9kaUL1uCE8ePO62zeOEPRIS0ICKkBT8v/8ktcf22aRPtWscQGxXO888+bVdW2PvJ066bRfoZR0R0uswEHAAau2t5m3oCBORR9iywHdgC/AFMvlw92xiAWcARIN5adw5Q8grq/wzst9bfASwErreWVQWS8nlfK4A9gHHyfn90mHcaqOoQ92ZgN7Aa6FWAdnweOGWNdwuwAWhxBe83FFhnrf87sMbm/c4ChjjZ3lTr32FA/GViM9a2XOYwv6o1rhk280pbDs+c17b7YQ+wFGh7JX3sxptukrQMKdB07kKm7D90TMY985zM/uSzXOX33NdZlq9cK6npWRIUHCI7d+0r8LqvZjpy4ow0adJUzqamy5btf0hoWHiRxfPXkRNy/HSSpGWIfPP9Iun1YG9tGw+MxdPi8aRYPC2elLQMOX/xkqRliCxaskw6d+mqbeOBsXhaPIURy7mLWZedNsbvkNCwCDl3MUv2/nVUGjdpKkdPJcmx08kSFBIqe/86mqtOcmqG1G/QUI6eSpK/jp6Sho0aS8qFS/lu60riTj5/UaJjYuVUYorT8sLuN5523XT3ZxzgcF6fxXTEy8MZYzoDrYFmItIIqA98coWrmSwijYFGQDVg4BXWHyoijUWkHvAXMKIglYwxNYGawEUsCY2j6saY2MusYrKINBGRmtaYnzbGDCvApj+1xtsIeB14s4Dx+gBfAU9Y69cF+gLnC1K/ACKBJKChMeZWh7JUoLUxpu5l6mfvhxrAC8AMY8y9LorNjre3N5UqVcqz/M8/dnJ38+YYY2jVpi2rV610Rxg5Nm5YT3BoGL6+vtSqXZszp0+TlZVVJPFUrFgRf39/AHx9ffH29rYr/y+3jSfF4mnxeFIsnhaPj48PXl6WjyNnz56lYcNGduX/5bbxpFg8LR5PiKXSDTdQvHhxMjMzSUpKonz5CpQtW5YyZcrkWWfP7t1Uq16DsmXLUr58eSpVuoFDBw+6NK5ff1lHyVKleLBnN1rHRPLLunV25YXdbzztulmUn3E08boKxphhxpgNxph467/NHRbpaYzZZIzZY4wZaVOvpjHmB2udrcaYgiRAlYEE4AKAiGSKyJariVtELmIZObrlaupbE5PSQGIBq/TFkiROB/o5KX8WeNkYY/JbkYjEA4OB0QVZ3oY/BY+3DFAWyLk3QET+FJFzV7C9y+kHfAj8D0vb2MoAXrJO+RKRn7GMto11UWxXxPbiFhgQSEJCglu3l5CQQGBgYM7r0mXKkJycXGTxAKSlpTFx/HM8MWiw3fz/ctt4UiyeFo8nxeKJ8WyJjyc0qDlDBw8kLDzSruy/3DaeFIunxeMJsfj7+3NL1ao0rleb1jHhDBs5Ot86iYkJBAYG5LwOCAwkMdG1sR09epTt27Yy+5PP+GDGLAY+NsCuvCiumeA51838uDMeTbyuzhwRaWYdRRoEzHQovx64A7gbGGSMaWGM8QY+A4aLSDNr2QBjTLN8tjUXuBXYZ4z52BjT1xhTwmGZVdYkMN4YEw/c6GxFxhh/LLfDfVnQN2o1xbreY1hGzd7Jr4L1/T4EfITl9sb21u3b+g44B/QoYBy/AhWB6/JZrqe1LfYDLwJPFWTlIpIITAP+NMYsNMY8Y4yp5bDYSIe2frQg6zbGlANaYUm6ZgC9jTGOx997QH1jTMuCrBNLe9S7zDaHGWMOZ0/nzrkqfwTb3DcpOYly5cq5bN3OBAYGkpSUlPP6XEpKzrdnRRFPZmYmD/XqwZBhI6jfoIFd2X+5bTwpFk+Lx5Ni8cR4GjVuzIrV6/hiwbcMHWz/neR/uW08KRZPi8cTYvnpx6WcOHGCrTt3szF+B6OGDyEzM/OydQICAklK+jtBTE5KIjDQtbGVK1eO5s1bUqZMGW6++WZKlirF2bNnc8oLu9+AZ1038+POeDTxujpNjDErjDHbsXxYru2QDM0Qi9PAAiAKqI3lQ/Jc6wf2tVhGWC53axkichxoAPQEtgGPA2uNMX42iwVbb0FrbE0GjzqsZqQxZitwAjgMLC/AexSbv4da11sRy614HxWgfhvggIj8YW2HH3GeYI0GJjq8n7wUdKQr+1bDW4EuwAInyaojyw/ARIZguZ1zPlAL2GyMCbJZbrJDW79XwJh6AotEJElEsveF3W2WIpIBPAO8UsB1XrY9ROQNEamcPZUuXbqAq83fbXXqsmH9ekSEuEULaRkU7LJ1O9PszrtYvWolmZmZ7N2zh/IVKuTcmlTY8YgIjw3oT3R0LB06dspV/l9uG0+KxdPi8aRYPC2eixcv5vzt7+9PyZIl7cr/y23jSbF4WjyeEIuIEBgYiJeXF2XKlCH94sV8E68aNWuyb+8eUlJSSExM5Nixo9xcpYpL42p2513s3r2LzMxMkpOTSUk5S9myZXPKC7vfeNp1Mz/ujMfHZWv6j7AmCAuAcBHZYIwpCyQDxYC0PKoJlg/JCdYP61dERC5hSdTWGmPewvKhvT7wWwFXMVlEphpjqgCrsIzS/J+17BRQHstvj7JVAE46iUOMMfMo2G+8+gG1jDEHrK9LYHmIxP/ZLiQia61J4WMFWGcz4KSI5IotLyKyzBhTHEt7baAA71dE/sLyII1ZxpjzWJK31QXdZh76AZVs2qOMdd4ih+U+A0YCHQuwzmZYHrriFt263MeW+M2UKlmKDet/JTomloSEBLp178HESS/x2CP9ycjIoF2HjtxarZq7wgAs39716dufqPAQvLy8mPrWOyyJW1wk8SxdEseXX8znr78O8Pn8uTRs1JiY2FbaNh4Wi6fF40mxeFo869auYdKE5/H29kZEeGXyG9o2HhiLp8XjCbGER0bx+fy5REeEcPHCBR59YhAnjh/niUcfZvvWLfTq2ZUHH+rDAw/25vXJL9OmXQfq1KnLM89NoGNby3evL7z0qt0IiysEBATw8IBHiYkMIyMjgxdfnlyk/cbTrptQdJ9xjPWJaSoP1g/Knay/McKaaJ0GbhaRE8aYccAkIFBEkqzLLxeRPtbbyzYD3YH1WEasXhWRmdZ11cCSjCUYYyR7HQ7bvwNIFJG91teNsCRhVUXklLN6tjEbY2ZhedLeVGtZB+B9oJqIpBlj5gDHRGSUtfxBYISINLS+/hnLU/u+tr4eBPQRkabGmKrWdQc4xHw9lifv3Zwdl/W2usNAaxHZYhu39YESPwGlgAYicsBJ3A2BecCHIvLGZfbX81ieWjjEpr3WAbdY2yvP92uMKQ0EA4utSWYJYDGwQETedIzJcXvGmDBrWzV2iOl24Ftre2RZ5wUAh7A87KSUbTsaywNH3sOyj00e+yEYy6jcQBEp0K2jN1WuLHsPHC7IokoppdR/3qUsz/mM7O3l2uRMuU8JX3NERCo7K9MRr4KJM8Zk2LyeBKw3xpzG8hssR6eMMZuwPNhhmoisBTDGtAOmGmOGAt5YErhct98ZYyYAR0XkPSyjM9OsH9TTgEtADxE5dTVvRES+tW7/cSxP/BtijWkrkIXlwRL3O1SbYk0wvLA8qOIhm7KyxhjbT/OHsNyOuMQ2GRSRLGPMXCyjPE86xPS7MeYHcj9wYqQxpjdQEsuI1Esi8nEB3mZPaxJksIw29rJpr8u9X4NlNPBNY0wa4Isl8cr3N2026jq0xzoso2xzs5MuAGvCuRTohWUEFZuyOGPMPiwjhLay90MpLE+XfFhEvr+C2JRSSimlVBHRES+l/iN0xEsppZQqOB3xUlfjciNe+nANpZRSSimllHIzvdVQ/eMYY9pgeUy8o5dEZF5hx6OUUkoppVR+NPFS/zgishBYWNRxKKWUUkopVVB6q6FSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6m/4GyUkp5GBEp6hByGGOKOgSP5Un7Sf1z6DH1z+FJeyolLaOoQ7BTpoRvUYfwj6QjXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaUASE1NJTSoOZUqBDB/3lwA5syeRZ1a1YiJDCMmMoy0tLRc9WbOmE5YcAsiQoPYvm2bW2Ib8uRAQoOaE9T8TpbELbYrO3PmDPd0aEtkWDCjRgxzy/bBefu8OGlCTttUu+Um3nn7rVz13NE+v+/YQWRYMNERobSOiWT/vn1Me2sqwS3uIiI0iGFDBjmtN/Oj6YSHtCQyLNilsUSEBhEVHkKr6Aj279tHWloaDz7QnciwYPr3eYj09PTcsbip3zjbT//3zjQiw4IJD2lJv94PkpmZWSjxONtPu3ftIjYqnFbREYweOQwRyR2LG/YTwF8HDhAe0pKYyDAiQoPYtnUrB/bvJzoilNiocDq0bUVSUlKueosW/kBYcAvCglvw8/Kf3BbLnI9nUbd2dWKjwomNCnd+vnFT2zjbV0XVNuC55+MN69fnbL/FnbfTvFlTu/L9+/YRGxVOeEhLprzxmsu3D87b5u03pxLU/E7CQ1oydHAe5z83tU2FgFK0ig6nVXQ4337zFT989y1NG9alYrkyedaZ9dF0IkJbEhUezPbt1xbLwb8O0CYqhI6tI2kbHcqO7VsBeOuNV7mvQys6tYnil3VrSE9Pp1ObqJzppvKlSEpMtFtXWloaj/R5gPax4Qx8pK/Tc/fV8oTreLYi7cciopNOVzQBB4DG7lrepp4AAXmUXQ98BOwDtgBbgfeA8tby54FTQDywE/gWuN5hHX2s2wh2mN8A+Mm63u3ABqC+texm67q2Wad4IMJa1hv4+jLvpwxwDpjhMD/MGsczNvPqAwcc2vBPa0x7gG+AFlfSnjfedJOkZUie07kLmbL/0DEZ98xzMvuTzyQtQ+SD6TNlwgsv5VnnyIkz0qRJUzmbmi5btv8hoWHhl93G1Uybt/4uYeERkpYhsv/QMWnSpKld+ZBhI2TWnP9JWoZI1249JO7H5S6PIa/2sZ0aN24iew4cdkn7pKZnXXY6cPi4HDuVKKnpWfL1dwvlgQd7y7bfd8n5i5ckNT1LOt/fVeJ+XG5X5/Dx09K4SVNJPn9R4rftlNCw8Hy3k5qelW+sfx05IcdPJ0lahsg33y+SXg/2lilvTpMJk16UtAyRUWOekg+mzyy0fuNsPyWfv5hT3qNnL/nm+0VFtp/ate8oq9atl9T0LHn08Sfku4VxLtlPBZnOpqbLuQuZkpqeJQvjfpTO93eVYcNHyvSPZktqepZMfOElee2NqXZ1UtIypEGDhnL8dJIcOnZKGjZqnNPPXB3L+9M/kgmTXsyzjjvbxtm+clfbXG0/9oTzse306mtTco7z7Ome+zrL8pVrJTU9S4KCQ2Tnrn2Fci7evnN3Ttt27tJVliz72SVtc/5iVr5TrVq17V4fPHpKziSn5pqfPR06ZunHSecuyuatOyUkLLxA2zl5Nt3pdDQhVY4nXZCTZ9Ply+/ipNO998tnX3wrw0Y9lWedZavXS1hEdK75L732pox7bqKcPJsuQ0aMlrf+b3qe67iSfeYp1/HC6sfA4bw+i+mIl/rHMcaUBFZiSUZqikgj4A4sSclNNot+KiKNgXrABeA5h1X1A5ZZ/7X1GfC2iDQSkfrAvcBJa9n/ActFpIGINACisCRCBdEV2ATca4wp7VB2HBhkjKlwufrWmGoAs4GFxpi7CrjtfHl7e1OpUqVc8+fMnklEaBBvvD45V9nGDesJDg3D19eXWrVrc+b0abKyslwVEgCVbriB4sWLk5mZSXJSEuUr2DfRmtWraNO2HQDtOnRk1coVLt1+trzaByzflvsHBHDTTTfZzXdX+1SsWBF/f38AfH198fb2onqNGhhjbOZ554olJDS0EGLxZs2aVbRuY90n7XPvE3f2G2f7yc/PD/j7i8bq1WsUSjzO9tO+vXto0sTy7eodd9zJip+X54rFHfsJwMfHBy8vy2X/7NmzNGjYkLr16pOcnARAclISFSpcZ1dnz+7dVKteg7Jly1K+fHkq3XADhw4edEssYBnViQwLZkoe5xt3tY2zfVVUbQOeez62NW/u/+jStbvdvD//2MndzZtjjKFVm7asXrXS5dt11jZ25z8fX7y8cp//3NU2x44dJTYqjIce6M7JkycpX748xYsXz3P5jRvWExziun5seyylpJylXoOGfPPVF6SmpnJf+1gGPdqPcykpdnW+nD+Xe+/vmmtdv65dTXSrNgC0atOBtatds/885TruTGH3Y028lEsYY4YZYzYYY+Kt/zZ3WKSnMWaTMWaPMWakTb2axpgfrHW2GmMGFmBzPYBEEZkgIpcARCRdRP5PRLY6LiwiWcBy4Bab7dYGbgUeBDoZY8raVKkMHLGpf0hETuZRdlpECnql7Qe8giVpdDzjnQDmAM8UZEUisgDLCN+IAm77qrTv2InNW39n8dKfWL1yBct/WmZXnpCQQGBgYM7r0mXKkJyc7NIY/P39uaXqrTSoW4vYqDBGjBpjV56ScpYyZSy3dAQGBpKQkODS7RfE3M8+pWu3Hrnmu7t90tLSmDTheZ4YODhn3to1qzl69AjNW7S0WzYxIYGAAPfGMnH8czwxaLBlW9b3HRgYSGKi/T4pjH7jaPKrL9OwXm0SExO44cYbCzUe2/1Up249fly6BBFhSdziXG3j7v20JT6esOAWDBsyiLCISEJCw5j+wfs0a9KQpUuX0L5jJ/t4EhMICAzIeR0Y4LpjzDGW9h068dvWHSxasoxVq1bmOt+4u23Afl8VZds44wnn42y7d+3Cz8+PW6pWtZtvm0C4uz2cWbPacv5r0dL+/OfOttn+x17ifvyZNu3aM3Z0/pfkxET7WMq4IJZtW+NpHRnM2BFDCA6N4PixY/j6+vDld3HUb9CId9+ekrNsVlYWi77/lnYd7nESW2LOMRYQEEBSomv2n6dex4uiH2vipVxljog0s44wDQJmOpRfj2VU6m4sIzstjDHeWEaXhotIM2vZAGNMs3y21RT4taCBGWOKAe2AeTaz+1ljPorltsJuNmUTgeXGmGXGmBeMMU1syl4BZhhj1hhjXjfGhBQwhrpYblOMA2aQe5QN4AWguzHm1gK+tV+xjObltc1hxpjD2dO5c+cKuNq/BQQE4O3tjZ+fHx073cvmzb/ZlQcGBtr97uFcSkrOt8ausuzHpZw4cZwdf+zht62/M2LoYLvf6JQuXYbs95aUlES5cuVcuv38iAhff/Ul99zXOVeZO9snMzOT3r16MnjocOo3aADAHzt3Mm7saOb8b17Ot7/ZAgIDc769d0csD/XqwZBhI6jfoIFlW9b3nZSURGCg/T4pjH7jaOSoMWzd8SfVqtdgzuxZhRaP43566dXXmPHhB7RvE0tZ/7LccIN9EujO/QTQqHFjfl61ls8XfMOwwYN4+qkxjJ/0Ihs2b2XosBE8+/RY+3gCAklO+vtDYVKy644xx1jszzf3EO9wvnF32zjuq6JsG2c84XycLa8vm2zPO+5uD0eW898oPvlsfq7znzvbpoJ19Oa+zl3YEr853+UDAuxjSXFBLA0aNmbRslXMmbuAsSMGExgYSERULAAR0TH8vuPv35GtXb2SBo0aUbpM7t+gBQQG/D3Km5xMQKBr9p+nXseLoh9r4qVcpYkxZoUxZjuWkZjaxpgSNuUzxOI0sADLLXq1sSQOc40x8cBaLL+DqnslGzbGdLWOtO03xjxsU9TTut7TQCAw37q8D5aRruzk8CNsEiEReR2oBkwHygGrjDFdrWWfAVWA162Lf2M7gncZ/YCPrSN0C4FbjTF1bBcQkQRgKjCpoG/9coUi8oaIVM6eSpd2vLsxf7bfwq1auYIaNWralTe78y5Wr1pJZmYme/fsoXyFCjm3PLiKiFAusBxeXl6UKVOGi+kX7U7YQcEhLF60EICF339HcEioS7efn7Vr1nBbnboEBATkKnNX+4gIjz/yMFExMXSwfgt/6OBBHu7Xm5mzP8n5IJA7llVuieWxAf2Jjo7NiSUoKITFi6375Ifc+6Qw+o2tixcvApaLqb+/PyVKlLArL8z9VLlyZeZ9sYDvFsZx4cJFOna610ksrt9P8Hc7APiX9adkyZKISE5/ua5iRRLO2H+zW6NmTfbu3UNKSgqJiYkcO3qUm6tUcUsstueb1StXUt3p+cY9beNsXxVV2+TFE87H2b78Yj733d8l1/zb6tRlw/r1iAhxixbSMijYLdt3dPDgQfr3fYhZH396mfOf69vm/PnzXLp0CYDVq1bmuo3ZmWZ33sWa1a7rx7bHUpmyZSlRsiQtgkOJ37wJgPjfNnFrteo5y3w5/zPu69I913oA7m4RzI9LLA++iFv0PS2CCvTdcr489TpeFP3Yx2VrUv9Zxhg/LMlUuIhssN62lwwUA3I/dslCsCQOCdZRsiuxGeibsyKRecA8Y8wsoJTNcp+KyBBjTDlgKTAeGI1l9CsAiLN+q2GAG40x9UVku3WdJ7CMxn1mjPkL6Il1xExEEq3vd4ExZgPwFJD7hnsrY4wv0AvIMMZkf7VSEksy5nhfwlRgF7CY/DXD8vAPl+nW5T62xG+mVMlSbFj/K2XKlGHpkji8vLy4/Y5mtO/QEYARw4bw1NPPUq5cOfr07U9UeAheXl5MfesdV4YDQERkFPPnfkZkWDAXLlzg8See5M8//uDn5T8xeOgwho0YxcN9H+L/3nmbJk1vd+sJ27F9Jr8+hXlOvjFzd/ssXRLHl1/M56+/DvDF/Hk0bNSIE8dPcObMaR552HJoDB85mpjYVowcPoSx4yyx9O7bj+iIULy8vJjy5jSXx/L5/Lk0bNSYCZNeZED/PkSFh1Clyi2MeeppoPD6jeN+8vb25rdNG8nKyqJq1VsLLR5n+6lJk9v5ePZMvLy86NajJ/Xq1wdw+34CWLd2DS9MHI+3tzciwsuTX6eYXzGeHPgY3t7eZGZmMu3d9wF47dWXaduuA3Xq1uXZ5yfQvo3l2/MXX34112iCq2J5c8rr/Lh0ifV8c0fO+aYw2sbZvho9dlyRtE02TzwfA6z/9VduvbVaToKzJG4xCQkJdOveg4mTXuKxR/qTkZFBuw4dubVaNbfE4Ng2x48f48yZ0wzo3weAEaPGEBPbyu1ts+vPP3jisQGULl0aHx9f3n7nPTas/5Xnn32aw4cP0bZVNE8OGUZsq9b2/bhPP2IiLf34jWvsx+t/WcvklybmHEsTXpxM7Tp1GTrwEe5pG02xYsWZ9sFHgCVJW7XyZ1554+2c+idOHOe9aVN5buLLdH/gIQY/3p8OrSKofHMVho166ppiy+ZJ1/FsRdWPjfWJaUoVmDHmANBJROKtr8tiGVW6WUROGGPGYRm1CRSRJOvyy0WkjzUJ2gx0B9ZjeTLgqyIy07quGliSsQRjjGSvw2H7pbA8TXAW8HL277yMMfOBtSIy1RjzPJYnIg6xljUBVgE1gQ+AH0TkPZt1vgL4ichQY8w9wPcikmEdHfsYOGEtawf8JCKpxnKFfRmoJSL3GGN6W9ulk0O89wEjReRum3l1gJ+x/GasJTA1OwE1xjwCjMFyfFbNo807YnnARqyIFOi2y5sqV5a9Bw4XZFFVxDzpvOzKD5L/Np60n9Q/hx5T/xxZWZ5zjJ+/mPu/wShKZUr4FnUIHquErzkiIpWdlemthupqxWX/dgj4HUuitd4Yswlw9h8/nLKWrQemichaEcnEMvp0r/XBGjuw/P6phGNlY8wEY8yjACJyHgjBkkTtMcZsNsasxZL8LXAWrIhsBj4HJgCR1r9tfQo8YB29uxfYbozZiuVJiRf5+4mIocAmY0z24+RrALYPBIm1/V2VMeYNLCNbnzrEsxPLQzraOwl3Bs7bcJ4xZosxZo91nW0KmnQppZRSSqmipSNeSv1H6IjXP4cnnZf12/m8edJ+Uv8cekz9c+iIV950xCtvOuKllFJKKaWUUkVIEy+llFJKKaWUcjNNvJRSSimllFLKzTTxUkoppZRSSik308RLKaWUUkoppdxMEy+llFJKKaWUcjNNvJRSSimllFLKzTTxUkoppZRSSik308RLKaWUUkoppdxMEy+llFJKKaWUcjNNvJRSSimllFLKzTTxUkoppZRSSik38ynqAJRS/z0iUtQh2DHGFHUIdjwtHvXPoP1GKdfy8vKcY6p0cc/6yH7q7MWiDiHHdWWLFXUIBaYjXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaWUUkoppZSbaeKllFJKKaWUUm6miZdSSimllFJKuZkmXkoppZRSSinlZpp4KaUASE1NJTSoOZUqBDB/3tyc+ZNffZk2sVHERIaxZvXqXPVmzphOWHALIkKD2L5tm8vi+X3HDiLDgomOCKV1TCT79+1jzsezqFu7OrFR4cRGhZOWlpY7no+mEx7SksiwYJfG46x93n5zKkHN7yQ8pCVDBw9yWs9d7VPQbezft4/YqHDCQ1oy5Y3X3LJ9T43lrwMHCAtuQXREKOEhLdm2dWuhxvPXgQOEh7QkJjKMiNAgu+1PHP8cjevXcVrPXX0413Y8ZF+JCI8/8jBR4SG0bxPLoUOHCj0WZ8f39999S+MGdagQUDrPeu4+vou6DzvK6zpRmPF40r76fccOIkKDiAoPoVV0BPv37SvSfuPsujntrakEt7iLiNAghg3J4zrlwnNOrcqBdOkQTZcO0Sz+/hsA3pk6me73tKZLh2jW/7KG9PT0nGW6dIimeqUyJCUl2q3nQloaAx/uxX1tIxj6eD/S09OvKa5sRX6+ERG3TsABoLG7lrepJ0BAHmXPAtuBLcAfwGSHetuAeJupvLWsNDAV2GOtuxl4DfC1ltcBfgD2Wqfvgdts1v28df3BNvMGArOsf1cFLlm3uc0a24dAZYf4ywDngBkO88OANGv9rcCvwN1AJeAoUN9m2WrAMeDWfNr+T+t73QN8A7SwKe8NJDu01Ts25XcAi4D9wCZrez1tU/6ztSzeup0pgJdDDLOBs0ApV8VmU7YZ2Gldx3NAiXz6lG37Zk8drGV+wCvWWHZa999DNnVt9+0W69S2gPEGAJ9g6bNbrf/2ADrYLHscOGXzumd+x8iNN90kaRmS53TuQqbsP3RMxj3znMz+5DNJyxD5+ruFMnbcM3nWOXLijDRp0lTOpqbLlu1/SGhY+GW3kT2lpmflOx04fFyOnUqU1PQs+fq7hfLAg73l/ekfyYRJL+ZZ5/Dx09K4SVNJPn9R4rftlNCw8AJtqyAxO2uf7Tt359Tv3KWrLFn2s0va50qm/LZxz32dZfnKtZKaniVBwSGyc9c+l8fgibGkZYikpGXI+YuXJC1DZNGSZdK5S1eXxpNfvzqbmi7nLmRKanqWLIz7UTrf31VS07Nk/6Fjcn+XblKrVm2X9eGC9mNP3FfzvvhKHnnsCUnLEFnzy0bp2q1Hocfi7Pg+fPy0JKakSa3ata+qDf8JfdgV7fRf3ld/HTkhx08nSVqGyDffL5JeD/Z2WyxXe93c9vsuOX/xkqSmZ0nn+7tK3I/LXXLOOXjmgtOpeo1adq9nz/tGBo8Ym+fyi37+VULCo3LNn/jKVBn19AQ5eOaCDBw6Sl5/+4M813El+6wwzjfA4bw+i/3rR7yMMZ2B1kAzEWkE1MfyodZWsIg0tpnOGGMMlkSqFNDAWvdOLB+0ixljbgRWAJ+KSHURqQ58CvxsjKlks+4DWD6g5yXFus0GQEMsydFaY4y/zTJdsSQy9xpjHL9C+dNavyEwB/hIRI4DQ4DZxhgf63uZCTwrIvvzabKuItJIRGpgSYIWGmPusilf7tBWTwAYYxoAi7EkD7eKyO1AJFDWYf1DRaQx0AzoCHTOLjDGlAXaY0lS7ndVbDZlTUSkDhAN3A7My6ct4O/2zZ6+tc6fBdQAGlnX2R4YY4zpZ1M3e982AsYBnxljvAsQ7yQsSVUD635tDmwQkW+zlwXew9L3sut+WoD3clne3t5UqlTJbt6Xn8/n/PnztI6J5OG+vUlJSbEr37hhPcGhYfj6+lKrdm3OnD5NVlbWtYYCQMWKFfH3txwGvr6+eHtbTldzZs8iMiyYKa9PzlVn44b1hISGuiUeZ+1TvUYNLIcX+Pr44uXlbVfuzvYp6Db+/GMndzdvjjGGVm3asnrVSpdu31NjAfDx8cHLy9Jvzp49S8OGjezK3R2P4/YbNGwIwMsvTmTEqDFO67izDztux1P21e7du7j99jsAaNK0KWvWrLIrL4xYnB3f5cuXp3jx4nnWKYzju6j7sCNn7VTY8XjSvsp9nfIu0n7j7Lppd52yxugYjyvPOSeOH+P+9lE80b8Xp0+d5PuvvyA1NZVunVox7In+nHP4HPH1F3PpeF/XXOtZ/8saomLbABDTuj2/rF2Va5mrUdTnmyJJvIwxw4wxG4wx8dZ/mzss0tMYs8kYs8cYM9KmXk1jzA/WOluNMQMLsLnKQAJwAUBEMkVkSwHqRWD5YP2EiKRZ62aIyHsicg54HPhZRP6XXUFEPgNWWsuyfQv4GmPuyW+DIpIuIs8CR4AHbIr6YUneVmJJwvKyDLjFuq75wC7gKeBJ4LyIfJhfDA7xLMDyAX9EARYfDUwXke9t6ieIyKg81n0W2JAdr1V34EfgDSzv2VWxOdY9CTwERBlj6l1pfWNMTaATMEBEzlvXeQAYjmUkzZllWEYuyxVgE5WBY2Id/hKRFBHZfaVxusKxY0fx9fVl0ZJlNGzUmDenvG5XnpCQQGBgYM7r0mXKkJyc7NIY0tLSmDTheZ4YOJj2HTrx29YdLFqyjFWrVrL8p2V2yyYmJBAQ4N54nFmzejVHjx6hRcuWdvMLo33y24btBTQwIJCEhASXbt9TY8m2JT6e0KDmDB08kLDwSLuywohnS3w8YcEtGDZkEGERkezZvZvz587nJGGOCqsPe9K+ql+/AUuXxiEiLF0Sx6mTJ+3Ki6LfFERhHN9Q9H34SnhaPNncva/S0tKYOP45nhg0uMhjyY4n+7qZbe0ay3WqeQv765Srzzmrf9vJ59/9SHSrtkx8ZjQnjh/Dx8eXuV8vpm6DRnzw7tScZbOysohb+C2t23XKtZ6kxAT8/QMA8A8IJCkxMdcyV6OozzdFNeI1R0SaWb+5H4RlNMbW9VhuW7sbGGSMaWEdKfgMGC4izaxlA4wxzfLZ1lzgVmCfMeZjY0xfY0wJh2VWWZPAeGPMcuu824FNIpLXTaVNgXVO5q+z1s0mwBjgRYfRjstZD9QDMMbUBW4G4oAZXD4h6Yzl/WZ7AuiLJTm5bCJzGb9mx2IVbtNW8caYodb5Ta3LFogx5gagEZZRxWz9gI+s82oaY2q7KLZcRCQR2O1Q35naDuv0BpoAu0XkjMOy64CbjTHXOVlPZ+AnETlVgHjfBEZbv3yYZoxpl0+MTlm/4DicPZ07d+6K1xFYrhwxsa0AiIltxbZt9r8vCAwMJCkpKef1uZSUnG/bXCEzM5PevXoyeOhw6jdoQEBAAN7e3vj5+dGx0z3Eb/7NbvmAwECSk90XjzN/7NzJuLGj+OSz+TnfKmZzd/sUZBu2MSUlJ1GuXEFy/39+LNkaNW7MitXr+GLBtwwdbP9dXWHE06hxY35etZbPF3zDsMGDeGHieMY89XSeyxdWH/akfRXbqjU1a9YiNiqcuMWLqN/APiktin5TEIVxfEPR9+Er4WnxZHPnvsrMzOShXj0YMmwE9Rs0KNJYsuOxvW5C9nVqNHP+Ny/XdcrV55xy5SsA0K5TZ3Zs20JAYCBhkdEAhEXE8MeO7TnL/rJmJfUaNKZ0mTK51uMfEMjZs5YE8GxyEgE2yeq1KOrzTVElXk2MMSuMMduxjFrUdkiGZojFaWABEAXUxvIhea4xJh5Yi2UEoe7lNmS97a4B0BPL73Aex3Irn5/NYra3Goa75i3axbAMOIQlCSoI26OiH/CxiFwCFgK3GmNsf5GdnRgcBwYDL9psNwHL7Ydfi8ixqwzfOLx2vD1uitNKxky2xnXEYVRpinW/HwQWichO6/INgBuAJSKSgeV20Pza66piu0x9ZxxvNbxUgDrZyljb4CDwPpbbDfONV0SWA1WAZ4Ak4H1jzDtXsF2s63lDRCpnT6VL5/1D37yEhISxadNGAH7btJHq1WvYlTe78y5Wr1pJZmYme/fsoXyFCjm3xVwryf4BbEwMHTp2ArD7Fm71ypVUr1HTSTyr3BKPMwcPHqR/34eY9fGnVKhQIVe5O9unoNu4rU5dNqxfj4gQt2ghLYOCXbp9T40F4OLFizl/+/v7U7JkSbtyd8djt/2ylu3v37+PIYMH0qFda44cOczY0faD9oXVhz1tXz3z3HiWLPuZdu07EBIaZldW2LEUVGEc30Xdh6+Up8WTzV37SkR4bEB/oqNjc65TRRVLdjyO181DBw/ycL/ezJz9yWWuU64556SeP8+lS5aPSb+uXUXVW6tzd8sQtsZbviTdGr+JW6pVz1n+6y/mck/nbk7XdVfzIH5auhiAH+N+4O4WrutLRXm+8XHp2grAmvAsAMJFZIP1dz3JQDEsDzJwRrB8SE6wjpJdEeuH5bVYEq63gBNYfuv122WqbcIy2uaXx6jXb1h+e+P44b55Husdg+WBEG8XIORmwBxjjC/QC8gwxvSwlpXEkoxlX63/FJHG1mXfBT41xjTPvk0NywMeriRZcBbL9nyXsjy44k7gKwARGQlgjDkA+NosN1REvjbGNMQy0rhERBZZ31MZLCOTWOt4GWPGiUjmNcaWizEmEMutpFdTfzOWEbnyDqNezYFDInLKGFMK62+8/r+9O4+OqkzzOP59EiKbIAkuKNGDe9ujBhR7XICwh0YbcHRkaRdAxKWbBkRQpHVQcEUBbXq0x20c7VFobbF7xAb0iKLYgGiQRsUFcUQBDSE0CAgMz/xxb9KVorKwVPJKfp9z7jmpeu/yq1uVSj31vvdNfI3dLURfGvzI3bdVdYB4COMsouvY/geYQ9SDmVb9LrmIpYXv0bhRYxYvWsjEO+/m2qFDKOjaiQYNGvDoE/8FwA3Xj+DmX99KTk4OgwYPoWunDmRkZDD1wT2uDys0d85snn9uBl98sYrnZkzn9Lw8mjRpyitz55CRkcGZbdvys169ARg9agRjx0V5Bg6+km6d88nIyGDKA9P2Wx7Y/fysXbuG9euLGDpkEAA3jLmJ7gU9auT8lEp1jDmz/0JxcTH9+g9gwsS7uPbqIezYsYMLevXm2OOO2+8ZQswC8PaCt5h4+3gyMzNxd+6ZNLlG87y94C3umHBb2fHvnnQ/bdqcUdbe+tRTuOueaNasmnoNlwrpuSoqKmJA34upV68eRx99DJMf+E2tZEn+/f7XS/ox/tZxrP7yS3oWdGX4yFEU9Phpjf5+1/ZrOJXk89Ste0Gdfa4S/079YcaznJ7Xmkv69q+1102qv5vr1q5j/foirr4q+i571Ogb6V7QIy3vOZ9+soKbRl5Ho8aNqVcvi7sn/5YjW+YyZvg19O3dnfr1GzDl3x8Doi8V3po/j4mTHizb/pt1a3nkoQcZN/5OLhlwOaOGDeXiC7rQMvcYho0au0/nplRtv9/YPz6fp0f8wbuPuxfGt5sCRcDR7r7OzMYRTSaQ7e4l8fqvufsgM8sh+pDbn2j43TLgXnd/It7XCUTFWLGZeek+ko7fFtjg7p/Ft/OIirBW8QfkirYzoskzPgBGuPs2M6tH1Avz38AhRLPJDS+9zsvM+hMNE8tz9zVmNp5opsURcfszREMkX3f3gWbWCih092Zx+0HAWGAIUWHYFRjt7mcn5DqFaHbAXOA8YGppMWpmjYiu6xrm7i/E95XLUJkUz1VvokksCtx9oZkNjNv7pNg2j+g6psvdfVbC41kJXODuhWY2L847M27/FTAoPidfAe3c/aOEfS4E7nT3F/cxW7m2eCjgfwCZ7t6rkvPRkYTzm9Q2neiLi8vcfUv8XL4MTHb3R1I8t0Z0Tdvv3X1KFXm7E02msSG+/QtgiLu3SVhnPNV8Xku1zM31z1atru7qaZXu9509lTz0QqQ69DoWkZoS2vtN0ab9M737/nBY0/q1HaGchln2lbvnpmqrqR6v2Wa2I+H2RGCRmRVR/pqkUt+a2RKi4maauy8AiK91mRpfC5NJVMANSN7YzG4Hvnb3h4HmwDQza0bUo/Z/wICka23mm1lir1Bfd19hZucDdwDLzWwr0dDMl4Bt7r45/mB+n5lNJOqVWwHkVzKsbxzRlPGJmsRDJ+sR9fLMJ5omfaNFM+SVm63O3T80s6+IZtErTmrbEhey481spu/db+l0M9tGNJvjB0BPd0+8dqtTnLfUCnfv6+5LzawnMCEeFvctsAN4iKgYTOUhoun1+wBfJBZdsd8T9YS9uC/ZEtreAxoC3xP1zFU222RVLid6HS8zs+1Er6tJ7v54qpXd3c1sVPwYfldF3tOA++NibRfRTJeXIiIiIiI/WGnv8RKRMKjHq2LqKZC9odexiNSU0N5v1ONVscp6vA74/+MlIiIiIiJS22p8cg2pXWb2MNE1VcnO8fj/ldUlZnY40cQVyeaWThAiIiIiIrKvVHjVMe5+TW1nCIlH/0y5dW3nEBEREZEDm4YaioiIiIiIpJkKLxERERERkTRT4SUiIiIiIpJmKrxERERERETSTIWXiIiIiIhImqnwEhERERERSTMVXiIiIiIiImmmwktERERERCTN9A+URaTGmVltRxDZZ3odi0hNCe395rCm9Ws7Qhl3r+0I1aYeLxERERERkTRT4SUiIiIiIpJmKrxERERERETSTIWXiIiIiIhImqnwEhERERERSTMVXiIiIiIiImmmwktERERERCTNVHiJiIiIiIikmQovERERERGRNFPhJSIiIiIikmYqvERERERERNJMhZeIiIiIiEiaqfASERERERFJMxVeIpLSE489Ssf259I5vx1/W7asXNvnK1dS0LUTnTqcx5TJ99W5PCFlCS1PSFlCyxNSltDyhJQltDxbtmwhv905tDi0GTOmP7tbe03mCSkLhPU8hZYnpCylPvn4Y5o0zGLhX/9a43k+WL6cLh3b061zPj/t3oXPV64E4L577+b8Ht0o6NqJBW+9udt2Tzz+KJ06nEeXju13O497xd21aNFSB5ajWrb0rTu8WstX69Z7mzZn+N+3bPelf/vI8zt2Ktd+4UUX+2tvLPAt23d5u/Yd/MOPV1Z733uzhJQnpCyh5QkpS2h5QsoSWp6QsoSYZ/O2nf75l2t83C3/5k8+/cxu7TWZJ6QsoT1PIeUJKUvi0n/Apd6pcxefN//t/Zpny/ZdVS6rVq/1Nd9u8C3bd/nMP8/ySy8f6C/86SW/6eZfV7jN6rVF3rrNGb7xu++9cNmHnt+xU7WOBayu6LOYerzqADNbZWat07V+wnZuZs1S3N8qbnsx6f7b4vv7xLfHm9nU+OeOcdstCeufamarknKuMLPChOW0SvJ1NLOtCesuN7OrUqz3upl9amaW4vEtM7OlZvaBmQ2qZN+FZvZC3JZlZg/Gxyvd9vqEbVua2bNmttLMPomPf3ZC+0Azm5lwLksqeoz7yzuLF9E+vyNZWVmcdPLJrC8qYteuXWXtKz76kLPPOQczo0fP83lz/ht1Jk9IWULLE1KW0PKElCW0PCFlCTFPZmYmLVq0qLC9JvOElCW05ymkPCFlKbVo4UKOaNGCli1zd2uriTyHH344hxxyCABZWVlkZmbw/HN/YMuW7+hZ0JWhVw5i06ZN5bZ5Z/EiOuTnV3ge94YKL6kpG4GTzOwIADPLAPoDlfXbrgWGmdmhlazT191bJyxV9QOvKF0XKACmmVmT0kYzOxE4EfgeyE+xfXt3z4uz/87Mjky173i5ML5/OHAUkBdvewYwOz5eY2Ae8J67H+fuJwK3A382s1OreCxpU1xcTHZ2dtntg5s0YePGjWW3E994sptlU1xcXGfyhJQltDwhZQktT0hZQssTUpYQ81QlpDx63YSRJ6Qspe69+w5uGHNTyraazLN161Ym3j6eX/xyOGvXfE1WvSxmzX6F0/PyeGDK/eXW3VBcTLNmFZ/HvaHCq44ys+vNbHHcM7PYzM5JWuXnZrYk7vkZnbDdiWb2UrzN+2b2yz047NPA5fHPXYH3gMp+u9YBTwG3VLLOvmgKfAfsSLhvMFHOR4ErK9rQ3ZcCG4Ddv7rZXS7wjbvvjLfd5u7L47b+wAZ3vydh368CTwBjqv9Qdhc/x6tLl82bN1d72+zsbEpKSspub960qeybonjfZT+XbCwhJydnX6L+oPKElCW0PCFlCS1PSFlCyxNSlhDzVCWkPHrdhJEnpCwAL896iTPObEvz5s1TttdUnp07dzLwsp8zfOQoTj3tNLKzc+hW0AOAbt177HYNV7PsbDZuLCm7nXwe94YKr7rrKXc/K+75GUb0QT/REUBb4GyiXqdzzSwTeAYY5e5nxW1Dzeysah7zSeCK+OfBwOPV2OYOoL+ZHVtB+/Sk4X0Nq9jfyfF6HxAVfje5+zaA+PFdEed6CviZmaX8DTOzfKAIWJpi36XLpPj+R+J9fWhmj5hZv/hYEPV+vZ3iEG8DZ1bxWCrl7pPdPbd0Ofjgg6u97Vk/+WfenP8GO3fu5LNPP6X5oYeSkfGPt4sfnfJjFi9ahLsz++VZnNeu/b5E/UHlCSlLaHlCyhJanpCyhJYnpCwh5qlKSHn0ugkjT0hZAN5fWsgbr8+j1/k9ePXVuYy5YSRr1qyp0TzuznVXX0XX7t3p1bsPAO3z83l3yTsAvLvkHY4//vhy20TncX6F53Fv1NunreWHrI2ZjQOaAzuJioaG7r41bn/M3R0oMrM/EvVQlQD/BDyb8O1EE+DHwOKqDujupb0vFxAVFQOAsVVsU2zRdV8TgbtSrNLX3QurOnaCFXGxiZnlAm+Z2Tvu/i7QE1jl7h/F7a/EGR9K2H5+XNwdC1zs7ttT7TvpMSw3s+OBdsC5wG3AZcD5e5C7RuXk5DBo8BC6dupARkYGUx/8LXNm/4Xi4mL69R/AhIl3ce3VQ9ixYwcX9OrNsccdV2fyhJQltDwhZQktT0hZQssTUpYQ8wD0u+Qilha+R+NGjVm8aCHduhfUWp5QsoT2PIWUJ6QsADeOHceNY8cBcNXggQwZeg3L3l/K6/Neq7E8c+fM5vnnZvDFF6t4bsZ0Ts/LY+Kd93Dd1VfRo1tn6jdowKOPPwnA6FEjGDvuVnJychg4+Eq6dc4nIyODKQ9M2+ccFn22lgOZRRNS9CktUMzsIKIhfp3cfbGZNSW6Bivb3Uvi9a9w99fj9acC64E/AnPcvWUFx/HSfSTd3woodPdmZtYXmAY87O63mNk8YKq7zzSz8UAzdx9hZh3j+1ubWSPgY6IibYK7t0r1uKpxHsr2mXDfDGCxu0+KJ7BoB5SOyWsIfOnubZMfn5kNBB4ATnL3dan2XUmOFsAaoqL3X4Ch7v6TpHXuBY5098viY/Vx9z6J57I6jzlRy9xc/2zV6j3dTERERCRYodUyjQ7K+MrdU16KoqGGdVMD4CDgf+Pbw1KsMxDAzHKAC4FXgRXA3638bH4nxOtU10zgPuDh6m7g7luACUSTTuw38TDCM4EV8aQfXYAT3L1VXNwdCRxlZnkpMv0n0Tm5uRrH6ZA0CceZRIVvCdHQzeZmdmPC+p2JhmJOQkREREQOCBpqWHfMNrPESSQmAovMrAjY/b8gwrdmtgQ4BJjm7gsA4mGCU81sJJBJdJ3TgOSNzex24Gt3L1dgufv3wD3J61fDY8D1QP2k+6eb2daE2yPd/bVK9nOymRXGP9cHnnb3P5nZGKLevJKErLvM7FmiSTZ+lWJfNwJL4t6p5H0DbHL39sAxROesAbCdqEett7vvAr6Le8vuN7PPiYZ9rgF6ufv7FTyGpmaW2HX1pbsnT44iIiIiIgHRUEOROkJDDUVERORAE1oto6GGIiIiIiIitUhDDeWAYmaHA3NSNM1199Ep7hcRERERSTsVXnJAcfdvgNa1nUNEREREJJGGGoqIiIiIiKSZCi8REREREZE0U+ElIiIiIiKSZiq8RERERERE0kyFl4iIiIiISJqp8BIREREREUkzFV4iIiIiIiJppsJLREREREQkzczdazuDiNQAM/se+HYfd3MwsHk/xNlfQsoTUhYIK09IWUB5KhNSFggrT0hZIKw8IWWBsPKElAXCyhNSFth/eQ5z9/qpGlR4iUi1mdlqd8+t7RylQsoTUhYIK09IWUB5KhNSFggrT0hZIKw8IWWBsPKElAXCyhNSFqiZPBpqKCIiIiIikmYqvERERERERNJMhZeI7InJtR0gSUh5QsoCYeUJKQsoT2VCygJh5QkpC4SVJ6QsEFaekLJAWHlCygI1kEfXeImIiIiIiKSZerxERERERETSTIWXiIiIiIhImqnwEhERERERSTMVXiIiIiIiImmmwktERERERCTNVHiJiIiIiIik2f8DVh3hA39wtkkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 960x800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure(figsize=(12, 10), dpi=80)\n",
    "\n",
    "plot_confusion_matrix(conf_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hundred-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions:  [0.81719324 0.89508258 0.66570605 0.78279757 0.54946365 0.55395431\n",
      " 0.22597137 0.20797011 0.56151035 0.42535114 0.67537032 0.86045094\n",
      " 0.70380752 0.10887097 0.1551797  0.2528992  0.12871287]\n",
      "Mean precision:  0.504134817440931\n",
      "\n",
      "Recalls:  [0.33900268 0.784375   0.49107143 0.60714286 0.76961603 0.71636364\n",
      " 0.71290323 0.86979167 0.68970676 0.74333333 0.6758794  0.87593052\n",
      " 0.83787542 0.84375    0.53034682 0.76209677 0.8125    ]\n",
      "Mean recall:  0.7095109146762099\n",
      "\n",
      "F-Score:  [0.47921065 0.83607994 0.56520675 0.68387097 0.64116829 0.62477701\n",
      " 0.3431677  0.33567839 0.61904122 0.54108305 0.67562476 0.86812173\n",
      " 0.76501206 0.19285714 0.24010468 0.37977227 0.22222222]\n",
      "Mean f-score:  0.5301764030080907\n"
     ]
    }
   ],
   "source": [
    "recall, precision, fscore = recall_precision_fscore_from_confusion_matrix(conf_matrix)\n",
    "\n",
    "print(\"Precisions: \", precision)\n",
    "print(\"Mean precision: \", np.mean(precision))\n",
    "print(\"\\nRecalls: \", recall)\n",
    "print(\"Mean recall: \", np.mean(recall))\n",
    "print(\"\\nF-Score: \", fscore)\n",
    "print(\"Mean f-score: \", np.mean(fscore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
