{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "varied-facial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/tb/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, activations, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Activation, SpatialDropout2D, GlobalAveragePooling2D,\n",
    "    Dense, Dropout, Flatten,\n",
    "    Conv2D, MaxPooling2D, SeparableConv2D\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "# Import project utils scripts\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join('../src/')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from statisticsUtils import recall_precision_fscore_from_confusion_matrix\n",
    "from labelsUtils import Label\n",
    "from regionUtils import vietnam_labels_coordinates\n",
    "from rasterUtils import make_dataset_from_raster_files\n",
    "from convNetUtils import cross_validation, evaluate_model\n",
    "from visualizationUtils import label_first_detections, plot_confusion_matrix\n",
    "from bandUtils import Band\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_TESTS = 4\n",
    "NB_PIXEL_AROUND = 4\n",
    "EPOCHS = 2000\n",
    "LABELS_COORDINATES = vietnam_labels_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acquired-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without :\n",
    "# Label.INTERCROP,\n",
    "# Label.STICK_FOR_PEPPER,   \n",
    "# Label.PEPPER_AND_COFFEE,     \n",
    "# Label.PEPPER_AND_OTHER\n",
    "# Label.SPARE_TREE,     \n",
    "\n",
    "\n",
    "bands = [\n",
    "    Band.COASTAL_AEROSOL.value, \n",
    "    Band.BLUE.value, \n",
    "    Band.GREEN.value, \n",
    "    Band.RED.value, \n",
    "    Band.NIR.value, \n",
    "    Band.SWIR1.value, \n",
    "    Band.SWIR2.value, \n",
    "]\n",
    "\n",
    "labels = [\n",
    "    Label.COFFEE,\n",
    "    Label.DENSE_FOREST,\n",
    "    Label.RUBBER,\n",
    "    Label.SEASONAL_AGRICULTURE,\n",
    "    Label.URBAN,\n",
    "    Label.WATER,\n",
    "    Label.OTHER_TREE,\n",
    "    Label.NATIVE_NO_TREE,\n",
    "    Label.PEPPER,\n",
    "    Label.TEA,\n",
    "    Label.RICE,     \n",
    "    Label.DECIDUOUS_FOREST,\n",
    "    Label.PINE_TREES,     \n",
    "    Label.SHRUBLAND_BUSHLAND,     \n",
    "    Label.GRASSLAND,     \n",
    "    Label.SECONDARY_DEGRADED_FOREST,     \n",
    "    Label.MINE_BARESOIL,\n",
    "]\n",
    "\n",
    "dataset_args = dict(\n",
    "    labels = labels,\n",
    "    raster_paths = [os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_january_to_april_collection2/merged.tif')],\n",
    "    labels_coordinates_list = [LABELS_COORDINATES],\n",
    "    nb_pixel_around = NB_PIXEL_AROUND\n",
    ")\n",
    "\n",
    "dataset = make_dataset_from_raster_files(**dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 9, 9, 7)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 9, 9, 7)           28        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 9, 9, 32)          2048      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d (SpatialDr (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 77,261\n",
      "Trainable params: 77,247\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n",
      "\n",
      "Validation 1, fold 1 :\n",
      "---------------------------\n",
      "\n",
      "WARNING:tensorflow:From /home/simon/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 2.9004 - accuracy: 0.1020 - val_loss: 2.7922 - val_accuracy: 0.2522\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.7192 - accuracy: 0.1700 - val_loss: 2.3769 - val_accuracy: 0.1780\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.5588 - accuracy: 0.1754 - val_loss: 2.3714 - val_accuracy: 0.1794\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3789 - accuracy: 0.2112 - val_loss: 2.2333 - val_accuracy: 0.2437\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.2969 - accuracy: 0.2267 - val_loss: 2.1391 - val_accuracy: 0.2842\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1643 - accuracy: 0.2573 - val_loss: 2.1413 - val_accuracy: 0.2544\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.1850 - accuracy: 0.2631 - val_loss: 2.0653 - val_accuracy: 0.2856\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.0533 - accuracy: 0.2710 - val_loss: 1.9389 - val_accuracy: 0.3542\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8877 - accuracy: 0.3144 - val_loss: 1.9555 - val_accuracy: 0.3282\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.8149 - accuracy: 0.3340 - val_loss: 1.8497 - val_accuracy: 0.4011\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7075 - accuracy: 0.3376 - val_loss: 1.9031 - val_accuracy: 0.3410\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7335 - accuracy: 0.3505 - val_loss: 1.7186 - val_accuracy: 0.4131\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.7159 - accuracy: 0.3427 - val_loss: 1.8316 - val_accuracy: 0.3485\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5857 - accuracy: 0.3638 - val_loss: 1.6534 - val_accuracy: 0.4071\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5353 - accuracy: 0.3814 - val_loss: 1.7294 - val_accuracy: 0.4075\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4599 - accuracy: 0.4034 - val_loss: 1.5860 - val_accuracy: 0.4337\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5250 - accuracy: 0.3738 - val_loss: 1.6677 - val_accuracy: 0.4316\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4399 - accuracy: 0.4125 - val_loss: 1.8701 - val_accuracy: 0.3528\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4297 - accuracy: 0.4129 - val_loss: 1.7321 - val_accuracy: 0.4028\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3793 - accuracy: 0.4222 - val_loss: 1.5158 - val_accuracy: 0.4757\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4320 - accuracy: 0.4123 - val_loss: 1.6683 - val_accuracy: 0.4494\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3282 - accuracy: 0.4361 - val_loss: 1.5804 - val_accuracy: 0.4671\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4079 - accuracy: 0.4369 - val_loss: 1.6053 - val_accuracy: 0.4558\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3207 - accuracy: 0.4371 - val_loss: 1.5065 - val_accuracy: 0.4796\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3046 - accuracy: 0.4425 - val_loss: 1.4289 - val_accuracy: 0.5218\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4334 - accuracy: 0.4357 - val_loss: 1.6132 - val_accuracy: 0.4561\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3614 - accuracy: 0.4550 - val_loss: 1.4509 - val_accuracy: 0.5218\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3886 - accuracy: 0.4362 - val_loss: 1.4309 - val_accuracy: 0.4970\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2149 - accuracy: 0.4754 - val_loss: 1.5523 - val_accuracy: 0.4877\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2246 - accuracy: 0.4755 - val_loss: 1.3939 - val_accuracy: 0.5325\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2778 - accuracy: 0.4768 - val_loss: 1.3552 - val_accuracy: 0.5439\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2705 - accuracy: 0.4684 - val_loss: 1.4311 - val_accuracy: 0.5094\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1869 - accuracy: 0.4856 - val_loss: 1.4087 - val_accuracy: 0.5187\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1632 - accuracy: 0.4964 - val_loss: 1.3948 - val_accuracy: 0.5130\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1726 - accuracy: 0.4917 - val_loss: 1.4101 - val_accuracy: 0.5325\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2540 - accuracy: 0.4825 - val_loss: 1.7552 - val_accuracy: 0.4419\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2040 - accuracy: 0.4802 - val_loss: 1.4659 - val_accuracy: 0.5158\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1384 - accuracy: 0.4971 - val_loss: 1.3857 - val_accuracy: 0.5375\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1476 - accuracy: 0.5025 - val_loss: 1.3833 - val_accuracy: 0.5563\n",
      "Epoch 40/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1152 - accuracy: 0.5029 - val_loss: 1.4864 - val_accuracy: 0.4959\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2542 - accuracy: 0.4742 - val_loss: 1.3668 - val_accuracy: 0.5339\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2146 - accuracy: 0.4766 - val_loss: 1.5816 - val_accuracy: 0.4519\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1539 - accuracy: 0.4958 - val_loss: 1.3101 - val_accuracy: 0.5385\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0868 - accuracy: 0.5078 - val_loss: 1.3214 - val_accuracy: 0.5492\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3625 - accuracy: 0.4809 - val_loss: 1.4926 - val_accuracy: 0.4675\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1459 - accuracy: 0.4936 - val_loss: 1.4206 - val_accuracy: 0.5385\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1005 - accuracy: 0.5171 - val_loss: 1.4809 - val_accuracy: 0.5133\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0621 - accuracy: 0.5201 - val_loss: 1.2768 - val_accuracy: 0.5741\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0870 - accuracy: 0.5256 - val_loss: 1.4816 - val_accuracy: 0.5528\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0052 - accuracy: 0.5329 - val_loss: 1.2257 - val_accuracy: 0.5929\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9336 - accuracy: 0.5485 - val_loss: 1.1971 - val_accuracy: 0.5954\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0316 - accuracy: 0.5366 - val_loss: 1.3263 - val_accuracy: 0.5357\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1312 - accuracy: 0.5132 - val_loss: 1.3478 - val_accuracy: 0.5496\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0467 - accuracy: 0.5266 - val_loss: 1.3016 - val_accuracy: 0.5648\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1053 - accuracy: 0.5282 - val_loss: 1.2039 - val_accuracy: 0.5851\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2280 - accuracy: 0.5129 - val_loss: 1.4507 - val_accuracy: 0.5275\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5080 - accuracy: 0.5077 - val_loss: 1.3900 - val_accuracy: 0.5524\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1277 - accuracy: 0.5195 - val_loss: 1.3721 - val_accuracy: 0.5414\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 2s 4ms/step - loss: 1.1256 - accuracy: 0.5350 - val_loss: 1.3231 - val_accuracy: 0.5520\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0078 - accuracy: 0.5391 - val_loss: 1.5221 - val_accuracy: 0.5030\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0355 - accuracy: 0.5414 - val_loss: 1.3784 - val_accuracy: 0.5542\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0713 - accuracy: 0.5255 - val_loss: 1.3047 - val_accuracy: 0.5687\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1105 - accuracy: 0.5303 - val_loss: 1.2116 - val_accuracy: 0.5940\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.9841 - accuracy: 0.4816 - val_loss: 1.4459 - val_accuracy: 0.5243\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.4637 - accuracy: 0.4708 - val_loss: 1.4637 - val_accuracy: 0.5176\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1825 - accuracy: 0.5098 - val_loss: 1.4613 - val_accuracy: 0.5147\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1433 - accuracy: 0.5115 - val_loss: 1.2827 - val_accuracy: 0.5620\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0184 - accuracy: 0.5491 - val_loss: 1.2127 - val_accuracy: 0.5901\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0095 - accuracy: 0.5401 - val_loss: 1.2908 - val_accuracy: 0.5595\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0281 - accuracy: 0.5420 - val_loss: 1.2090 - val_accuracy: 0.6057\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0266 - accuracy: 0.5453 - val_loss: 1.2436 - val_accuracy: 0.5737\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0165 - accuracy: 0.5270 - val_loss: 1.6413 - val_accuracy: 0.4686\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9434 - accuracy: 0.5502 - val_loss: 1.2362 - val_accuracy: 0.5822\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9461 - accuracy: 0.5609 - val_loss: 1.2126 - val_accuracy: 0.5972\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9526 - accuracy: 0.5575 - val_loss: 1.2414 - val_accuracy: 0.5805\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8996 - accuracy: 0.5742 - val_loss: 1.2629 - val_accuracy: 0.5780\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1253 - accuracy: 0.5306 - val_loss: 1.4891 - val_accuracy: 0.5052\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3845 - accuracy: 0.4960 - val_loss: 1.5938 - val_accuracy: 0.4522\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3970 - accuracy: 0.4961 - val_loss: 1.4625 - val_accuracy: 0.5133\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 2.3102 - accuracy: 0.4674 - val_loss: 1.4401 - val_accuracy: 0.5062\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2458 - accuracy: 0.5021 - val_loss: 1.4264 - val_accuracy: 0.5176\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0625 - accuracy: 0.5432 - val_loss: 1.2315 - val_accuracy: 0.5908\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0034 - accuracy: 0.5509 - val_loss: 1.2854 - val_accuracy: 0.5581\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9008 - accuracy: 0.5701 - val_loss: 1.2228 - val_accuracy: 0.5947\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8984 - accuracy: 0.5700 - val_loss: 1.1028 - val_accuracy: 0.6231\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9496 - accuracy: 0.5614 - val_loss: 1.2380 - val_accuracy: 0.5787\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9190 - accuracy: 0.5606 - val_loss: 1.1405 - val_accuracy: 0.6039\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9422 - accuracy: 0.5734 - val_loss: 1.4129 - val_accuracy: 0.5403\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0277 - accuracy: 0.5536 - val_loss: 1.1543 - val_accuracy: 0.6011\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9587 - accuracy: 0.5677 - val_loss: 1.1149 - val_accuracy: 0.6284\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1883 - accuracy: 0.5330 - val_loss: 1.3169 - val_accuracy: 0.5528\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.5061 - accuracy: 0.4710 - val_loss: 1.3216 - val_accuracy: 0.5464\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2520 - accuracy: 0.4852 - val_loss: 1.2988 - val_accuracy: 0.5591\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0426 - accuracy: 0.5258 - val_loss: 1.2425 - val_accuracy: 0.5801\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9141 - accuracy: 0.5647 - val_loss: 1.2713 - val_accuracy: 0.5712\n",
      "Epoch 96/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 1s 4ms/step - loss: 0.9575 - accuracy: 0.5552 - val_loss: 1.1508 - val_accuracy: 0.6146\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9232 - accuracy: 0.5623 - val_loss: 1.2222 - val_accuracy: 0.5922\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1993 - accuracy: 0.5353 - val_loss: 1.2361 - val_accuracy: 0.5861\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0263 - accuracy: 0.5407 - val_loss: 1.1945 - val_accuracy: 0.5872\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1593 - accuracy: 0.5272 - val_loss: 1.1491 - val_accuracy: 0.6014\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2430 - accuracy: 0.5449 - val_loss: 1.2996 - val_accuracy: 0.5641\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0707 - accuracy: 0.5685 - val_loss: 1.1206 - val_accuracy: 0.6167\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0529 - accuracy: 0.5487 - val_loss: 1.1257 - val_accuracy: 0.6149\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8560 - accuracy: 0.5750 - val_loss: 1.2748 - val_accuracy: 0.5805\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9147 - accuracy: 0.5693 - val_loss: 1.2124 - val_accuracy: 0.5812\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9440 - accuracy: 0.5618 - val_loss: 1.1147 - val_accuracy: 0.6291\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8837 - accuracy: 0.5802 - val_loss: 1.2061 - val_accuracy: 0.5886\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8968 - accuracy: 0.5788 - val_loss: 1.1455 - val_accuracy: 0.6174\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0616 - accuracy: 0.5552 - val_loss: 1.2207 - val_accuracy: 0.5918\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8610 - accuracy: 0.5880 - val_loss: 1.1811 - val_accuracy: 0.6036\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8412 - accuracy: 0.5889 - val_loss: 1.0965 - val_accuracy: 0.6274\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9839 - accuracy: 0.5503 - val_loss: 1.1027 - val_accuracy: 0.6323\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1209 - accuracy: 0.5269 - val_loss: 1.2955 - val_accuracy: 0.5705\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.3485 - accuracy: 0.5168 - val_loss: 1.3355 - val_accuracy: 0.5432\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.1640 - accuracy: 0.5234 - val_loss: 1.1712 - val_accuracy: 0.5972\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.2554 - accuracy: 0.5432 - val_loss: 1.2387 - val_accuracy: 0.5925\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 1.0648 - accuracy: 0.5282 - val_loss: 1.2020 - val_accuracy: 0.5893\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9389 - accuracy: 0.5591 - val_loss: 1.1680 - val_accuracy: 0.6043\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.9137 - accuracy: 0.5778 - val_loss: 1.1556 - val_accuracy: 0.6117\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8368 - accuracy: 0.5893 - val_loss: 1.0859 - val_accuracy: 0.6341\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8426 - accuracy: 0.5806 - val_loss: 1.0672 - val_accuracy: 0.6416\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8408 - accuracy: 0.5959 - val_loss: 1.1268 - val_accuracy: 0.6163\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8579 - accuracy: 0.5813 - val_loss: 1.1612 - val_accuracy: 0.5982\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 1s 3ms/step - loss: 0.8115 - accuracy: 0.5893 - val_loss: 1.0775 - val_accuracy: 0.6288\n"
     ]
    }
   ],
   "source": [
    "model_name = \"january_to_april_2018_every_usable_labels\"\n",
    "\n",
    "# images have all the same shapes, take the shape of the first image\n",
    "image_width = len(dataset[0][1][0][0])\n",
    "image_height = len(dataset[0][1][0])\n",
    "image_depth = len(bands)\n",
    "nb_outputs = len(labels)\n",
    "\n",
    "# Create model\n",
    "model = Sequential([\n",
    "    Rescaling(0.0000275, offset=0.2, input_shape=(image_width, image_height, image_depth)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    SpatialDropout2D(0.25),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(nb_outputs, activation='softmax'),\n",
    "])\n",
    "\n",
    "mean_loss, mean_accuracy, histories, conf_matrix = cross_validation(model, dataset, bands, labels, EPOCHS, NB_TESTS, early_stopping=True, with_model_checkpoint=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-minority",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, history in enumerate(histories):\n",
    "    pl.plot(history.history['loss'], label='Training', color=\"blue\")\n",
    "    pl.plot(history.history['val_loss'], label='Testing', color=\"orange\")\n",
    "    \n",
    "    if i == 0:\n",
    "        pl.legend()\n",
    "        \n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, history in enumerate(histories):\n",
    "    pl.plot(history.history['f1_score_train'], label='Training', color=\"blue\")\n",
    "    pl.plot(history.history['f1_score_val'], label='Testing', color=\"orange\")\n",
    "    \n",
    "    if i == 0:\n",
    "        pl.legend()\n",
    "        \n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(12, 10), dpi=80)\n",
    "\n",
    "plot_confusion_matrix(conf_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, fscore = recall_precision_fscore_from_confusion_matrix(conf_matrix)\n",
    "\n",
    "print(\"Precisions: \", precision)\n",
    "print(\"Mean precision: \", np.mean(precision))\n",
    "print(\"\\nRecalls: \", recall)\n",
    "print(\"Mean recall: \", np.mean(recall))\n",
    "print(\"\\nF-Score: \", fscore)\n",
    "print(\"Mean f-score: \", np.mean(fscore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
