{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mediterranean-calculation",
   "metadata": {},
   "source": [
    "## Before running this notebook\n",
    "If you have an old version of jupyter notebook, it's required to activate ipywidgets \n",
    "\n",
    "`jupyter nbextension enable --py widgetsnbextension`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "above-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/tb/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from tensorflow.keras import Sequential, activations, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Activation, SpatialDropout2D, GlobalAveragePooling2D,\n",
    "    Dense, Dropout, Flatten,\n",
    "    Conv2D, MaxPooling2D, SeparableConv2D\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "# Import project utils scripts\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join('../src/')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from lossesUtils import categorical_focal_loss\n",
    "from bandUtils import Band\n",
    "from convNetUtils import predict_on_raster, predict_label_category_on_raster\n",
    "from labelsUtils import Label, LabelCategory, category_from_label\n",
    "from visualizationUtils import label_first_detections\n",
    "from regionUtils import vietnam_labels_coordinates\n",
    "from rasterUtils import create_image_metadata\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "willing-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 9\n",
    "bands = [\n",
    "    Band.COASTAL_AEROSOL.value, \n",
    "    Band.BLUE.value, \n",
    "    Band.GREEN.value, \n",
    "    Band.RED.value, \n",
    "    Band.NIR.value, \n",
    "    Band.SWIR1.value, \n",
    "    Band.SWIR2.value, \n",
    "]\n",
    "\n",
    "# Only labels that contains georeferenced points.\n",
    "labels = [\n",
    "    Label.COFFEE,\n",
    "    Label.DENSE_FOREST,\n",
    "    Label.RUBBER,\n",
    "    Label.SEASONAL_AGRICULTURE,\n",
    "    Label.URBAN,\n",
    "    Label.WATER,\n",
    "    Label.OTHER_TREE,\n",
    "    Label.NATIVE_NO_TREE,\n",
    "    Label.PEPPER,\n",
    "    Label.TEA,\n",
    "    Label.RICE,     \n",
    "    Label.DECIDUOUS_FOREST,\n",
    "    Label.PINE_TREES,     \n",
    "    Label.SHRUBLAND_BUSHLAND,     \n",
    "    Label.GRASSLAND,     \n",
    "    Label.SECONDARY_DEGRADED_FOREST,     \n",
    "    Label.MINE_BARESOIL,\n",
    "]\n",
    "categories = pd.unique([category_from_label(label) for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "personal-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 9, 9, 7)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_4 (Rescaling)         (None, 9, 9, 7)      0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 9, 9, 7)      28          rescaling_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 9, 9, 16)     464         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 9, 9, 16)     64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 9, 9, 16)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 9, 9, 16)     1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 16)     64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 9, 9, 16)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 9, 9, 16)     1040        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 16)     64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 9, 9, 16)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 9, 9, 16)     1040        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 9, 16)     64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 9, 9, 16)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "last_pretrained_layer (Flatten) (None, 1296)         0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          166016      last_pretrained_layer[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "label (Dense)                   (None, 17)           2193        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "category (Dense)                (None, 6)            774         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 189,363\n",
      "Trainable params: 189,221\n",
      "Non-trainable params: 142\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"final_reptile_model\"\n",
    "\n",
    "model = load_model(\n",
    "    os.path.join(MODEL_ROOT_PATH, 'final_reptile_model.hdf5'),\n",
    "    custom_objects={\n",
    "        'categorical_focal_loss_fixed': categorical_focal_loss\n",
    "    }\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss={\n",
    "    'label': categorical_focal_loss([[.25] * len(labels)]),\n",
    "    'category': categorical_focal_loss([[.25] * len(categories)])\n",
    "}, metrics={\n",
    "    'label': 'accuracy',\n",
    "    'category': 'accuracy'\n",
    "})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "molecular-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n",
      "2015 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18896ad1a44c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mraster_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Vietnam_20{}_whole_year_collection2/merged.tif\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlabel_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_label_category_on_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraster_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0myear_label_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/HEIG/TB/scripts/notebooks/../src/convNetUtils.py\u001b[0m in \u001b[0;36mpredict_label_category_on_raster\u001b[0;34m(trained_model, raster_path, bands, square_size)\u001b[0m\n\u001b[1;32m    865\u001b[0m         ])\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m         \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mcategory_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tb/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "year_label_predictions = []\n",
    "year_category_predictions = []\n",
    "year_img_indices = []\n",
    "\n",
    "for year in range(14, 21):\n",
    "    print(f\"20{year} ...\")\n",
    "\n",
    "    raster_path = os.path.join(DATA_ROOT_PATH, \"Vietnam_20{}_whole_year_collection2/merged.tif\".format(year))\n",
    "    label_predictions, category_predictions, img_indices = predict_label_category_on_raster(model, raster_path, bands, IMAGE_SIZE)\n",
    "    \n",
    "    year_label_predictions.append(label_predictions)\n",
    "    year_category_predictions.append(category_predictions)\n",
    "    year_img_indices.append(img_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices = [\n",
    "    [indices[0] for indices in year_img_indices[year]]\n",
    "    for year in range(len(year_label_predictions))\n",
    "]\n",
    "\n",
    "col_indices = [\n",
    "    [indices[1] for indices in year_img_indices[year]]\n",
    "    for year in range(len(year_label_predictions))\n",
    "] \n",
    "\n",
    "df_list = [\n",
    "    pd.DataFrame(data=dict({\n",
    "        'image row': row_indices[year - 14],\n",
    "        'image col': col_indices[year - 14],\n",
    "        'label_predicted': year_label_predictions[year - 14],\n",
    "        'category_predicted': year_category_predictions[year - 14]\n",
    "    })).assign(year=int(\"20\" + str(year)))\n",
    "    for year in range(14, 21)\n",
    "]\n",
    "\n",
    "# Concatenate all those dataframe into one\n",
    "concat_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(os.path.join(DATA_ROOT_PATH, 'final_predictions_whole_year_2014_2020.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.read_csv(os.path.join(DATA_ROOT_PATH, 'final_predictions_whole_year_2014_2020.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_year_df = concat_df.groupby('year').agg(count=pd.NamedAgg(column='label_predicted', aggfunc='value_counts')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-telling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    total_per_year_df[total_per_year_df['label_predicted'] == labels.index(label)][['count', 'year']].plot(x=\"year\", title=label.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_COORDINATES = vietnam_labels_coordinates()\n",
    "raster_example = rasterio.open(os.path.join(DATA_ROOT_PATH, \"Vietnam_2018_whole_year_collection2/merged.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.read_csv(os.path.join(DATA_ROOT_PATH, 'final_predictions_whole_year_2014_2020.csv'))\n",
    "map_width = int(concat_df.agg(['max'], column='image col')['image col']) + 1\n",
    "map_height = int(concat_df.agg(['max'], column='image row')['image row']) + 1\n",
    "    \n",
    "def draw_image(img, cmap):\n",
    "    img = np.ma.masked_where(img == 0, img)\n",
    "\n",
    "    dpi = 96\n",
    "    plt.close()\n",
    "    plt.figure(figsize=((map_width / dpi), (map_height / dpi)))\n",
    "    plt.imshow(img, aspect=\"auto\", vmin=1, cmap=cmap, interpolation='nearest')\n",
    "    \n",
    "def save_visualization_to_disk(arr, raster_example, filename, upscale_factor=9):\n",
    "    filepath = os.path.join(DATA_ROOT_PATH, filename)\n",
    "\n",
    "    metadata = raster_example.meta.copy()\n",
    "    metadata.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": arr.shape[0] * upscale_factor,\n",
    "        \"width\": arr.shape[1] * upscale_factor,\n",
    "        \"transform\": raster_example.transform,\n",
    "        \"crs\": raster_example.crs\n",
    "    })\n",
    "\n",
    "    # Write merged raster to disk\n",
    "    with rasterio.open(filepath, \"w\", **metadata) as dest:        \n",
    "        dest.write(arr, indexes=1)\n",
    "    \n",
    "def first_prediction_year():\n",
    "    img = np.zeros((map_height, map_width))\n",
    "    \n",
    "    points_x = concat_df[concat_df.year == 2018]['image col'].tolist()\n",
    "    points_y = concat_df[concat_df.year == 2018]['image row'].tolist()\n",
    "\n",
    "    coffee_first_detections = label_first_detections(\n",
    "        os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_whole_year_collection2/merged.tif'),\n",
    "        concat_df,\n",
    "        labels.index(Label.COFFEE),\n",
    "        LABELS_COORDINATES[Label.COFFEE.value]\n",
    "    )\n",
    "    \n",
    "    colors = ['black', 'silver', 'yellow', 'olive', 'lime', 'green', 'fuchsia', 'purple', 'red', 'maroon']\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    coffe_first_detections = pd.DataFrame(coffee_first_detections, columns=['row', 'col', 'year'])\n",
    "    \n",
    "    nan_list = coffe_first_detections[(coffe_first_detections.year == 'nan')][['row', 'col']]\n",
    "    nan_detection_x = nan_list.col.to_list()\n",
    "    nan_detection_y = nan_list.row.to_list()\n",
    "    \n",
    "    for i in range(len(points_x)):\n",
    "        x = points_x[i]\n",
    "        y = points_y[i]\n",
    "        \n",
    "        img[y][x] = 1\n",
    "        \n",
    "    for i in range(len(nan_detection_x)):\n",
    "        x = nan_detection_x[i]\n",
    "        y = nan_detection_y[i]\n",
    "        \n",
    "        img[y][x] = 2\n",
    "\n",
    "    for year in range(14, 21):\n",
    "        detection_list = coffe_first_detections[(coffe_first_detections.year == 2000 + year)][['row', 'col']]\n",
    "        detection_list_x = detection_list.col.to_list()\n",
    "        detection_list_y = detection_list.row.to_list()\n",
    "        \n",
    "        print(f\"{2000 + year}: {colors[year-12]}\")\n",
    "                \n",
    "        for i in range(len(detection_list_x)):\n",
    "            x = detection_list_x[i]\n",
    "            y = detection_list_y[i]\n",
    "\n",
    "            img[y][x] = year - 11\n",
    "            \n",
    "    draw_image(img, cmap)\n",
    "    save_visualization_to_disk(img, raster_example, 'first_prediction_year.tiff')\n",
    "    \n",
    "def year_coffee_prediction(year):\n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    year_df = concat_df[concat_df['year'] == year]\n",
    "    \n",
    "    other_points = year_df[year_df['label_predicted'] != labels.index(Label.COFFEE)]\n",
    "    other_points_x = other_points['image col'].to_list()\n",
    "    other_points_y = other_points['image row'].to_list()\n",
    "    \n",
    "    coffee_points = year_df[year_df['label_predicted'] == labels.index(Label.COFFEE)]\n",
    "    coffee_points_x = coffee_points['image col'].to_list()\n",
    "    coffee_points_y = coffee_points['image row'].to_list()\n",
    "    \n",
    "    # Known coffee points\n",
    "    row_col_coffee_labels = []\n",
    "\n",
    "    with rasterio.open(os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_whole_year_collection2/merged.tif')) as raster:\n",
    "        row_col_coffee_labels = [raster.index(coord[0], coord[1], precision=23) for coord in LABELS_COORDINATES[Label.COFFEE.value]]\n",
    "    \n",
    "    for other_point_index in range(len(other_points)):\n",
    "        x = other_points_x[other_point_index]\n",
    "        y = other_points_y[other_point_index]\n",
    "\n",
    "        img[y][x] = 1\n",
    "\n",
    "    for coffee_point_index in range(len(coffee_points)):\n",
    "        x = coffee_points_x[coffee_point_index]\n",
    "        y = coffee_points_y[coffee_point_index]\n",
    "\n",
    "        img[y][x] = 2\n",
    "        \n",
    "    for row_col in row_col_coffee_labels:\n",
    "        x = round(row_col[1] / 9)\n",
    "        y = round(row_col[0] / 9)\n",
    "\n",
    "        img[y][x] = 3\n",
    "    \n",
    "    cmap = ListedColormap([\"black\", \"green\", \"red\"])\n",
    "    draw_image(img, cmap)\n",
    "\n",
    "def year_category_predictions(year):\n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    year_df = concat_df[concat_df['year'] == year]\n",
    "    \n",
    "    colors = ['green', 'maroon', 'fuchsia', 'black', 'blue', 'red']\n",
    "    cmap = ListedColormap(colors)\n",
    "\n",
    "    for label in LabelCategory:\n",
    "        points = year_df[year_df['category_predicted'] == categories.index(label)]\n",
    "        points_x = points['image col'].to_list()\n",
    "        points_y = points['image row'].to_list()\n",
    "        \n",
    "        print(f\"{label.name}: {label.value}, {colors[label.value]}\")\n",
    "        \n",
    "        for i in range(len(points)):    \n",
    "            img[points_y[i]][points_x[i]] = label.value + 1\n",
    "            \n",
    "    # Known coffee points\n",
    "    row_col_coffee_labels = []\n",
    "\n",
    "    with rasterio.open(os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_whole_year_collection2/merged.tif')) as raster:\n",
    "        row_col_coffee_labels = [raster.index(coord[0], coord[1], precision=23) for coord in LABELS_COORDINATES[Label.COFFEE.value]]\n",
    "    \n",
    "    for row_col in row_col_coffee_labels:\n",
    "        x = round(row_col[1] / 9)\n",
    "        y = round(row_col[0] / 9)\n",
    "\n",
    "        img[y][x] = 6\n",
    "    \n",
    "    draw_image(img, cmap)\n",
    "\n",
    "def forest_replaced_by_coffee(reference_year=2018):\n",
    "    df = concat_df[concat_df['year'] == reference_year]\n",
    "\n",
    "    # Select all non coffee tiles from 2018 and see how many times coffee appears after that\n",
    "    df = df.loc[   \n",
    "        (df['label_predicted'] == labels.index(Label.DENSE_FOREST)) |\n",
    "        (df['label_predicted'] == labels.index(Label.OTHER_TREE)) |\n",
    "        (df['label_predicted'] == labels.index(Label.DECIDUOUS_FOREST)) |\n",
    "        (df['label_predicted'] == labels.index(Label.PINE_TREES))     \n",
    "    ]\n",
    "    \n",
    "    col_list = df[\"image col\"].tolist()\n",
    "    row_list = df[\"image row\"].tolist()\n",
    "\n",
    "    # filter years after reference_year and take only images with row-col where forest where in 2018   \n",
    "    df = concat_df[concat_df['year'] > reference_year]\n",
    "    df = df[\n",
    "        df\n",
    "            .set_index(['image row','image col'])\n",
    "            .index.isin(list(zip(row_list, col_list)))\n",
    "    ]\n",
    "\n",
    "    # counts number of occurences of coffee at each row and col where forest was present in 2018\n",
    "    df = df[df['label_predicted'] == labels.index(Label.COFFEE)]\n",
    "    df = df.groupby(['image row','image col']).size().reset_index(name='counts')\n",
    "\n",
    "    # create image with a different color based on the number of occurences of coffee that replaced forest  \n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    for _, position in df.iterrows():\n",
    "        img[position['image row']][position['image col']] = position['counts']\n",
    "\n",
    "    draw_image(img, 'Reds')\n",
    "\n",
    "def forest_replaced_by_culture(reference_year=2018):\n",
    "    df = concat_df[concat_df['year'] == reference_year]\n",
    "\n",
    "    # Select all forest tiles from a year of reference and see how many times culture appears after that\n",
    "    df = df[df['category_predicted'] == categories.index(LabelCategory.FOREST)]\n",
    "    col_list = df[\"image col\"].tolist()\n",
    "    row_list = df[\"image row\"].tolist()\n",
    "\n",
    "    # Select every years after reference year\n",
    "    df = concat_df[concat_df['year'] > reference_year]\n",
    "    \n",
    "    # Select only images with row-col where forest where in 2018   \n",
    "    df = df[\n",
    "        df\n",
    "            .set_index(['image row','image col'])\n",
    "            .index.isin(list(zip(row_list, col_list)))\n",
    "    ]\n",
    "\n",
    "    df = df[df['category_predicted'] == categories.index(LabelCategory.CULTURE)]\n",
    "    df = df.groupby(['image row','image col']).size().reset_index(name='counts')\n",
    "\n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    for _, position in df.iterrows():\n",
    "        img[position['image row']][position['image col']] = position['counts']\n",
    "\n",
    "    draw_image(img, 'Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-panic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Coffee prediction\")\n",
    "widgets.interact_manual(year_coffee_prediction, year=widgets.IntSlider(min=2014, max=2020, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category prediction\")\n",
    "widgets.interact_manual(year_category_predictions, year=widgets.IntSlider(min=2014, max=2020, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prediction_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_replaced_by_coffee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_replaced_by_culture()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
