{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mediterranean-calculation",
   "metadata": {},
   "source": [
    "## Before running this notebook\n",
    "If you have an old version of jupyter notebook, it's required to activate ipywidgets \n",
    "\n",
    "`jupyter nbextension enable --py widgetsnbextension`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "above-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/tb/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from tensorflow.keras import Sequential, activations, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Activation, SpatialDropout2D, GlobalAveragePooling2D,\n",
    "    Dense, Dropout, Flatten,\n",
    "    Conv2D, MaxPooling2D, SeparableConv2D\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "# Import project utils scripts\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join('../src/')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from lossesUtils import categorical_focal_loss\n",
    "from bandUtils import Band\n",
    "from convNetUtils import predict_on_raster, predict_label_category_on_raster\n",
    "from labelsUtils import Label, LabelCategory, category_from_label, CATEGORIES_LABELS\n",
    "from visualizationUtils import label_first_detections\n",
    "from regionUtils import vietnam_labels_coordinates\n",
    "from rasterUtils import create_image_metadata\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "willing-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 9\n",
    "labels = [\n",
    "    Label.COFFEE,\n",
    "    Label.DENSE_FOREST,\n",
    "    Label.RUBBER,\n",
    "    Label.SEASONAL_AGRICULTURE,\n",
    "    Label.URBAN,\n",
    "    Label.WATER,\n",
    "    Label.OTHER_TREE,\n",
    "    Label.NATIVE_NO_TREE,\n",
    "    Label.PEPPER,\n",
    "    Label.TEA,\n",
    "    Label.RICE,     \n",
    "    Label.DECIDUOUS_FOREST,\n",
    "    Label.PINE_TREES,     \n",
    "    Label.SHRUBLAND_BUSHLAND,     \n",
    "    Label.GRASSLAND,     \n",
    "    Label.SECONDARY_DEGRADED_FOREST,     \n",
    "    Label.MINE_BARESOIL,\n",
    "]\n",
    "\n",
    "labels_names = [label.name for label in labels]\n",
    "categories = pd.unique([category_from_label(label) for label in labels])\n",
    "\n",
    "bands = [\n",
    "    Band.COASTAL_AEROSOL.value, \n",
    "    Band.BLUE.value, \n",
    "    Band.GREEN.value, \n",
    "    Band.RED.value, \n",
    "    Band.NIR.value, \n",
    "    Band.SWIR1.value, \n",
    "    Band.SWIR2.value, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "personal-pilot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 9, 9, 7)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 9, 9, 7)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 9, 9, 7)      28          rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 9, 9, 32)     2048        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 32)     9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 3, 3, 32)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 3, 3, 64)     18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 64)     36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 1, 1, 64)     0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           spatial_dropout2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "label (Dense)                   (None, 17)           2193        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "category (Dense)                (None, 6)            774         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 78,035\n",
      "Trainable params: 78,021\n",
      "Non-trainable params: 14\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"january_to_april_2018_multi_output_focal_loss_collection2_new_categories\"\n",
    "\n",
    "model = load_model(\n",
    "    os.path.join(MODEL_ROOT_PATH, 'january_to_april_2018_multi_output_focal_loss_collection2_new_categories.hdf5'),\n",
    "    custom_objects={\n",
    "        'categorical_focal_loss_fixed': categorical_focal_loss\n",
    "    }\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss={\n",
    "    'label': categorical_focal_loss([[.25] * len(labels)]),\n",
    "    'category': categorical_focal_loss([[.25] * len(categories)])\n",
    "}, metrics={\n",
    "    'label': 'accuracy',\n",
    "    'category': 'accuracy'\n",
    "})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n",
      "2015 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n",
      "2016 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n",
      "2017 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n",
      "2018 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n",
      "2019 ...\n",
      "Image width: 16708\n",
      "Image height: 7422\n",
      "Nb row of images: 1856\n",
      "Nb col of images: 824\n",
      "Width is not dividable by 9, some px will be ignored...\n",
      "Height is not dividable by 9, some px will be ignored...\n"
     ]
    }
   ],
   "source": [
    "year_label_predictions = []\n",
    "year_category_predictions = []\n",
    "year_img_indices = []\n",
    "\n",
    "for year in range(14, 22):\n",
    "    print(f\"20{year} ...\")\n",
    "    raster_path = os.path.join(DATA_ROOT_PATH, \"Vietnam_20{}_january_to_april_collection2/merged.tif\".format(year))\n",
    "    label_predictions, category_predictions, img_indices = predict_label_category_on_raster(model, raster_path, bands, IMAGE_SIZE)\n",
    "    \n",
    "    year_label_predictions.append(label_predictions)\n",
    "    year_category_predictions.append(category_predictions)\n",
    "    year_img_indices.append(img_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices = [\n",
    "    [indices[0] for indices in year_img_indices[year]]\n",
    "    for year in range(len(year_label_predictions))\n",
    "]\n",
    "\n",
    "col_indices = [\n",
    "    [indices[1] for indices in year_img_indices[year]]\n",
    "    for year in range(len(year_label_predictions))\n",
    "] \n",
    "\n",
    "df_list = [\n",
    "    pd.DataFrame(data=dict({\n",
    "        'image row': row_indices[year - 14],\n",
    "        'image col': col_indices[year - 14],\n",
    "        'label_predicted': year_label_predictions[year - 14],\n",
    "        'category_predicted': year_category_predictions[year - 14]\n",
    "    })).assign(year=int(\"20\" + str(year)))\n",
    "    for year in range(14, 22)\n",
    "]\n",
    "\n",
    "# Concatenate all those dataframe into one\n",
    "concat_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(os.path.join(DATA_ROOT_PATH, 'final_predictions_january_to_april_2014_2021.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.read_csv(os.path.join(DATA_ROOT_PATH, 'final_predictions_january_to_april_2014_2021.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.groupby('year').agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_year_df = concat_df.groupby('year').agg(count=pd.NamedAgg(column='label_predicted', aggfunc='value_counts')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-telling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    total_per_year_df[total_per_year_df['label_predicted'] == labels.index(label)][['count', 'year']].plot(x=\"year\", title=label.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_COORDINATES = vietnam_labels_coordinates()\n",
    "raster_example = rasterio.open(os.path.join(DATA_ROOT_PATH, \"Vietnam_2018_january_to_april_collection2/merged.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.read_csv(os.path.join(DATA_ROOT_PATH, 'final_predictions_january_to_april_2014_2021.csv'))\n",
    "map_width = int(concat_df.agg(['max'], column='image col')['image col']) + 1\n",
    "map_height = int(concat_df.agg(['max'], column='image row')['image row']) + 1\n",
    "    \n",
    "def draw_image(img, cmap):\n",
    "    img = np.ma.masked_where(img == 0, img)\n",
    "\n",
    "    dpi = 96\n",
    "    plt.close()\n",
    "    plt.figure(figsize=((map_width / dpi), (map_height / dpi)))\n",
    "    plt.imshow(img, aspect=\"auto\", vmin=1, cmap=cmap, interpolation='nearest')\n",
    "    \n",
    "def save_visualization_to_disk(arr, raster_example, filename, upscale_factor=9):\n",
    "    filepath = os.path.join(DATA_ROOT_PATH, filename)\n",
    "\n",
    "    metadata = raster_example.meta.copy()\n",
    "    metadata.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": arr.shape[0] * upscale_factor,\n",
    "        \"width\": arr.shape[1] * upscale_factor,\n",
    "        \"transform\": raster_example.transform,\n",
    "        \"crs\": raster_example.crs\n",
    "    })\n",
    "\n",
    "    # Write merged raster to disk\n",
    "    with rasterio.open(filepath, \"w\", **metadata) as dest:        \n",
    "        dest.write(arr, indexes=1)\n",
    "    \n",
    "def first_prediction_year():\n",
    "    img = np.zeros((map_height, map_width))\n",
    "    \n",
    "    points_x = concat_df[concat_df.year == 2018]['image col'].tolist()\n",
    "    points_y = concat_df[concat_df.year == 2018]['image row'].tolist()\n",
    "\n",
    "    coffee_first_detections = label_first_detections(\n",
    "        os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_january_to_april_collection2/merged.tif'),\n",
    "        concat_df,\n",
    "        labels.index(Label.COFFEE),\n",
    "        LABELS_COORDINATES[Label.COFFEE.value]\n",
    "    )\n",
    "    \n",
    "    colors = ['black', 'silver', 'yellow', 'olive', 'lime', 'green', 'fuchsia', 'purple', 'red', 'maroon']\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    coffe_first_detections = pd.DataFrame(coffee_first_detections, columns=['row', 'col', 'year'])\n",
    "    \n",
    "    nan_list = coffe_first_detections[(coffe_first_detections.year == 'nan')][['row', 'col']]\n",
    "    nan_detection_x = nan_list.col.to_list()\n",
    "    nan_detection_y = nan_list.row.to_list()\n",
    "    \n",
    "    for i in range(len(points_x)):\n",
    "        x = points_x[i]\n",
    "        y = points_y[i]\n",
    "        \n",
    "        img[y][x] = 1\n",
    "        \n",
    "    for i in range(len(nan_detection_x)):\n",
    "        x = nan_detection_x[i]\n",
    "        y = nan_detection_y[i]\n",
    "        \n",
    "        img[y][x] = 2\n",
    "\n",
    "    for year in range(14, 22):\n",
    "        detection_list = coffe_first_detections[(coffe_first_detections.year == 2000 + year)][['row', 'col']]\n",
    "        detection_list_x = detection_list.col.to_list()\n",
    "        detection_list_y = detection_list.row.to_list()\n",
    "        \n",
    "        print(f\"{2000 + year}: {colors[year-12]}\")\n",
    "                \n",
    "        for i in range(len(detection_list_x)):\n",
    "            x = detection_list_x[i]\n",
    "            y = detection_list_y[i]\n",
    "\n",
    "            img[y][x] = year - 11\n",
    "            \n",
    "    draw_image(img, cmap)\n",
    "    save_visualization_to_disk(img, raster_example, 'first_prediction_year.tiff')\n",
    "    \n",
    "def year_coffee_prediction(year):\n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    year_df = concat_df[concat_df['year'] == year]\n",
    "    \n",
    "    other_points = year_df[year_df['label_predicted'] != labels.index(Label.COFFEE)]\n",
    "    other_points_x = other_points['image col'].to_list()\n",
    "    other_points_y = other_points['image row'].to_list()\n",
    "    \n",
    "    coffee_points = year_df[year_df['label_predicted'] == labels.index(Label.COFFEE)]\n",
    "    coffee_points_x = coffee_points['image col'].to_list()\n",
    "    coffee_points_y = coffee_points['image row'].to_list()\n",
    "    \n",
    "    # Known coffee points\n",
    "    row_col_coffee_labels = []\n",
    "\n",
    "    with rasterio.open(os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_january_to_april_collection2/merged.tif')) as raster:\n",
    "        row_col_coffee_labels = [raster.index(coord[0], coord[1], precision=23) for coord in LABELS_COORDINATES[Label.COFFEE.value]]\n",
    "    \n",
    "    for other_point_index in range(len(other_points)):\n",
    "        x = other_points_x[other_point_index]\n",
    "        y = other_points_y[other_point_index]\n",
    "\n",
    "        img[y][x] = 1\n",
    "\n",
    "    for coffee_point_index in range(len(coffee_points)):\n",
    "        x = coffee_points_x[coffee_point_index]\n",
    "        y = coffee_points_y[coffee_point_index]\n",
    "\n",
    "        img[y][x] = 2\n",
    "        \n",
    "    for row_col in row_col_coffee_labels:\n",
    "        x = round(row_col[1] / 9)\n",
    "        y = round(row_col[0] / 9)\n",
    "\n",
    "        img[y][x] = 3\n",
    "    \n",
    "    cmap = ListedColormap([\"black\", \"green\", \"red\"])\n",
    "    draw_image(img, cmap)\n",
    "\n",
    "def year_category_predictions(year):\n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    year_df = concat_df[concat_df['year'] == year]\n",
    "    \n",
    "    colors = ['green', 'maroon', 'black', 'blue', 'fuchsia', 'red']\n",
    "    cmap = ListedColormap(colors)\n",
    "\n",
    "    for label in LabelCategory:\n",
    "        points = year_df[year_df['category_predicted'] == categories.tolist().index(label)]\n",
    "        points_x = points['image col'].to_list()\n",
    "        points_y = points['image row'].to_list()\n",
    "        \n",
    "        print(f\"{label.name}: {label.value}, {colors[label.value]}\")\n",
    "        \n",
    "        for i in range(len(points)):    \n",
    "            img[points_y[i]][points_x[i]] = label.value + 1\n",
    "            \n",
    "    # Known coffee points\n",
    "    row_col_coffee_labels = []\n",
    "\n",
    "    with rasterio.open(os.path.join(DATA_ROOT_PATH, 'Vietnam_2018_january_to_april_collection2/merged.tif')) as raster:\n",
    "        row_col_coffee_labels = [raster.index(coord[0], coord[1], precision=23) for coord in LABELS_COORDINATES[Label.COFFEE.value]]\n",
    "    \n",
    "    for row_col in row_col_coffee_labels:\n",
    "        x = round(row_col[1] / 9)\n",
    "        y = round(row_col[0] / 9)\n",
    "\n",
    "        img[y][x] = 6\n",
    "    \n",
    "    draw_image(img, cmap)\n",
    "\n",
    "def forest_replaced_by_coffee(reference_year=2018):\n",
    "    df = concat_df[concat_df['year'] == reference_year]\n",
    "\n",
    "    # Select all forest tiles from 2018 and see how many times coffee appears after that    \n",
    "    df = df.loc[df['label_predicted'].isin(\n",
    "        [labels.index(forest_label) for forest_label in CATEGORIES_LABELS[LabelCategory.FOREST]]\n",
    "    )]\n",
    "    \n",
    "    col_list = df[\"image col\"].tolist()\n",
    "    row_list = df[\"image row\"].tolist()\n",
    "\n",
    "    # filter years after reference_year and take only images with row-col where forest where in 2018   \n",
    "    df = concat_df[concat_df['year'] > reference_year]\n",
    "    df = df[\n",
    "        df\n",
    "            .set_index(['image row','image col'])\n",
    "            .index.isin(list(zip(row_list, col_list)))\n",
    "    ]\n",
    "\n",
    "    # counts number of occurences of coffee at each row and col where forest was present in 2018\n",
    "    df = df[df['label_predicted'] == labels.index(Label.COFFEE)]\n",
    "    df = df.groupby(['image row','image col']).size().reset_index(name='counts')\n",
    "\n",
    "    # create image with a different color based on the number of occurences of coffee that replaced forest  \n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    for _, position in df.iterrows():\n",
    "        img[position['image row']][position['image col']] = position['counts']\n",
    "\n",
    "    draw_image(img, 'Reds')\n",
    "\n",
    "def forest_replaced_by_culture(reference_year=2018):\n",
    "    df = concat_df[concat_df['year'] == reference_year]\n",
    "\n",
    "    # Select all forest tiles from a year of reference and see how many times culture appears after that\n",
    "    df = df[df['category_predicted'] == categories.index(LabelCategory.FOREST)]\n",
    "    col_list = df[\"image col\"].tolist()\n",
    "    row_list = df[\"image row\"].tolist()\n",
    "\n",
    "    # Select every years after reference year\n",
    "    df = concat_df[concat_df['year'] > reference_year]\n",
    "    \n",
    "    # Select only images with row-col where forest where in 2018   \n",
    "    df = df[\n",
    "        df\n",
    "            .set_index(['image row','image col'])\n",
    "            .index.isin(list(zip(row_list, col_list)))\n",
    "    ]\n",
    "\n",
    "    df = df[df['category_predicted'] == categories.index(LabelCategory.CULTURE)]\n",
    "    df = df.groupby(['image row','image col']).size().reset_index(name='counts')\n",
    "\n",
    "    img = np.zeros((map_height, map_width))\n",
    "\n",
    "    for _, position in df.iterrows():\n",
    "        img[position['image row']][position['image col']] = position['counts']\n",
    "\n",
    "    draw_image(img, 'Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-panic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Coffee prediction\")\n",
    "widgets.interact_manual(year_coffee_prediction, year=widgets.IntSlider(min=2014, max=2021, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category prediction\")\n",
    "widgets.interact_manual(year_category_predictions, year=widgets.IntSlider(min=2014, max=2021, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prediction_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_replaced_by_coffee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_replaced_by_culture()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
